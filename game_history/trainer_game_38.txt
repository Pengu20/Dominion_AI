 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.023075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0   -8    0    0
    0    0] 
sum of rewards: -513 

action type: buy - action 0.0
Learning step: -15.53364086151123
desired expected reward: -10.745641708374023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.220743]
 [19.745014]
 [18.142862]
 [13.473271]
 [17.909378]
 [21.23087 ]
 [20.303883]
 [21.30887 ]
 [16.4876  ]
 [18.701729]
 [19.011873]
 [19.203362]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5313882827758789
desired expected reward: 18.87042999267578



buy possibilites: [-1] 
expected returns: [[21.591076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.39744025468826294
desired expected reward: 21.706308364868164






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.860346]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5656326413154602
desired expected reward: 21.02544403076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.491741]
 [23.060894]
 [21.430252]
 [16.60762 ]
 [24.56819 ]
 [23.629677]
 [21.999033]
 [22.50957 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5785366892814636
desired expected reward: 21.526187896728516



buy possibilites: [-1] 
expected returns: [[21.194702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  3.  0.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.42568302154541
desired expected reward: 7.181937217712402






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.941196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5522201061248779
desired expected reward: 20.64248275756836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.486881]
 [22.990982]
 [21.401634]
 [16.701069]
 [21.170055]
 [24.460167]
 [23.545412]
 [24.536224]
 [19.7596  ]
 [21.956064]
 [22.263699]
 [22.453678]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5827545523643494
desired expected reward: 21.666860580444336



buy possibilites: [-1] 
expected returns: [[20.408375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5177611708641052
desired expected reward: 20.883874893188477






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  3.  0.] 
adversary cards in discard: [3. 0. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[18.66447 ]
 [20.844738]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0.] 
cards in discard: [3. 0. 0. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5516327023506165
desired expected reward: 19.85674285888672



action possibilites: [-1.] 
expected returns: [[24.243462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.07666047662496567
desired expected reward: 21.006521224975586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.288858]
 [24.874655]
 [23.231758]
 [18.435213]
 [26.43489 ]
 [25.453289]
 [23.804869]
 [24.319225]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 6. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.02350570634007454
desired expected reward: 24.219955444335938



buy possibilites: [-1] 
expected returns: [[22.741337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [3. 0. 0. 0. 6. 0. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: -0.014814605005085468
desired expected reward: 25.438474655151367






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3  8] -> size -> 14 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[23.098766]
 [24.190496]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  6  3  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5802053809165955
desired expected reward: 22.161130905151367



action possibilites: [-1] 
expected returns: [[17.825886]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.07885242253541946
desired expected reward: 18.689496994018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.040716]
 [12.505091]
 [17.895   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 3. 8. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08283720165491104
desired expected reward: 17.908723831176758






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 3 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  9. 10. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  3.  8.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.055971]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4206124544143677
desired expected reward: 17.105209350585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.574844]
 [25.105564]
 [23.492205]
 [18.742504]
 [26.582956]
 [25.665594]
 [24.052237]
 [24.529789]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6229276657104492
desired expected reward: 23.678234100341797



buy possibilites: [-1] 
expected returns: [[23.416132]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [8. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5813758969306946
desired expected reward: 21.993467330932617






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[20.276604]
 [22.299086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16 15] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6246145963668823
desired expected reward: 22.79151725769043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.849327]
 [21.24436 ]
 [19.702143]
 [15.387717]
 [19.486858]
 [22.681517]
 [21.78914 ]
 [22.755339]
 [18.159739]
 [20.235882]
 [20.527105]
 [20.691027]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16 15] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5478233098983765
desired expected reward: 19.941062927246094



buy possibilites: [-1] 
expected returns: [[18.29276]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16 15] -> size -> 16 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.419557571411133
desired expected reward: 5.968158721923828






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 8.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  3  3 16 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 6.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 6.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 6.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 6. 3. 8.] 
adversary cards in discard: [ 6.  0.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.521975]
 [22.60068 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 6.  0.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15  0] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4648300111293793
desired expected reward: 17.827930450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.73454 ]
 [16.095095]
 [21.591051]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 6.  0.  0. 29.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15  0] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5928834676742554
desired expected reward: 21.040536880493164



buy possibilites: [-1] 
expected returns: [[20.899118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 8.] 
cards in discard: [ 6.  0.  0. 29.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 16.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15  0] -> size -> 15 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5225955247879028
desired expected reward: 19.211946487426758






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 16.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0  8  3  3 16 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  9. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  0.  8.  3.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.177958]
 [17.230795]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 29  6  3  8  0  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5985559821128845
desired expected reward: 20.300561904907227



action possibilites: [-1] 
expected returns: [[12.928253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.08477623015642166
desired expected reward: 16.783790588378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[11.512566 ]
 [13.689021 ]
 [12.295372 ]
 [ 8.446676 ]
 [14.9705305]
 [14.174803 ]
 [12.775406 ]
 [13.189715 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1996973305940628
desired expected reward: 13.127950668334961



buy possibilites: [-1] 
expected returns: [[20.813768]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [15.  0.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.7978739738464355
desired expected reward: 14.486894607543945






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [15.  0.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  8  3  3 16 15  0 16  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  6.  0.  0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 29.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[16.285675]
 [18.311636]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  0.  0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5895922183990479
desired expected reward: 20.22417640686035



action possibilites: [-1.] 
expected returns: [[20.771887]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.12168119102716446
desired expected reward: 18.534183502197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.105988]
 [21.596571]
 [20.002779]
 [17.061922]
 [15.629381]
 [19.780064]
 [23.042154]
 [22.144926]
 [25.310965]
 [23.119732]
 [18.397776]
 [18.51729 ]
 [20.55113 ]
 [16.22551 ]
 [20.851425]
 [20.997625]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 27. 30.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.049222469329833984
desired expected reward: 20.821109771728516



buy possibilites: [-1] 
expected returns: [[20.123991]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0. 4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 65 

action type: buy - action 4.0
Learning step: 1.6494442224502563
desired expected reward: 18.711366653442383






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  4.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 8. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [29.  4.  0.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  4.  0.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[13.23632 ]
 [15.096523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  4.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16. 16.  0.] 
adversary cards in discard: [0. 8. 3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6008481979370117
desired expected reward: 19.523143768310547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.612475]
 [ 8.597517]
 [13.24156 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  4.  0.  6.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 16. 16.  0.] 
adversary cards in discard: [0. 8. 3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4317975640296936
desired expected reward: 13.01050853729248



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 16.  0.] 
cards in discard: [0. 8. 3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8  3  3 16  0 16  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.] 
cards in discard: [0. 8. 3. 3. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [0. 8. 3. 3. 0. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.] 
cards in discard: [0. 8. 3. 3. 0. 0. 0. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 26. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 6. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [1. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.87159]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.36894160509109497
desired expected reward: 12.87261962890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.436821]
 [17.840788]
 [16.302376]
 [13.328874]
 [11.81503 ]
 [16.087425]
 [19.240238]
 [18.370056]
 [21.473722]
 [19.316584]
 [14.71957 ]
 [14.841019]
 [16.831644]
 [12.448549]
 [17.121487]
 [17.262646]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 26. 29.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47656938433647156
desired expected reward: 16.504880905151367



buy possibilites: [-1] 
expected returns: [[17.700203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 4.0
Learning step: 1.1359858512878418
desired expected reward: 14.464860916137695






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [0. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.473415]
 [18.548899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.48957765102386475
desired expected reward: 17.21062469482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[15.885753]
 [18.191736]
 [16.71042 ]
 [12.482167]
 [16.505653]
 [19.5566  ]
 [18.705706]
 [19.631308]
 [15.200768]
 [17.214382]
 [17.493174]
 [17.630222]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.492708295583725
desired expected reward: 17.093278884887695



buy possibilites: [-1] 
expected returns: [[21.301886]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 0.] 
cards in discard: [29.  4.  0.  6.  3.  4.  1.  6.  0.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.33708229660987854
desired expected reward: 17.85465431213379






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 4. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 25. 28.  8.  8.  8. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 4. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  0.  3. 16.  0.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [6. 0. 4. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 4. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.409285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 4. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 17 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5943222045898438
desired expected reward: 20.707563400268555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.242836]
 [19.597805]
 [18.091055]
 [13.764954]
 [20.9644  ]
 [20.11618 ]
 [18.609428]
 [19.03154 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 25. 28.  8.  8.  7. 10.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 17 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5075693130493164
desired expected reward: 18.038555145263672



buy possibilites: [-1] 
expected returns: [[16.790976]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 4. 0. 0.] 
cards in discard: [11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 16.] 
adversary cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 17 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.06262664496898651
desired expected reward: 20.901771545410156






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 16.] 
cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.] 
cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.] 
cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.] 
cards in discard: [ 3.  0.  3. 16.  0.  3. 16.  0.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.973824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [11.  6.  0.  4.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44342055916786194
desired expected reward: 16.34755516052246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.203497]
 [20.625376]
 [19.070374]
 [16.086884]
 [14.576346]
 [18.855131]
 [22.044947]
 [21.163853]
 [24.312166]
 [22.121113]
 [17.483528]
 [17.605389]
 [19.600143]
 [15.206075]
 [19.893625]
 [20.037128]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [11.  6.  0.  4.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 25. 28.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5387115478515625
desired expected reward: 19.49068832397461



buy possibilites: [-1] 
expected returns: [[22.275642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [11.  6.  0.  4.  0.  0.  4.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 4.0
Learning step: 1.1048064231872559
desired expected reward: 17.191688537597656






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  4. 29.  0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 25. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  4. 29.  0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
adversary victory points: 8
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 24. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  6.  4. 29.  0.] 
adversary cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
adversary victory points: 8
player victory points: 6 





Player: 0 
cards in hand: [ 0.  6.  4. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.203285]
 [19.185291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  4. 29.  0.] 
cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3. 16.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3] -> size -> 17 
adversary victory points: 6
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6242696642875671
desired expected reward: 21.6513729095459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.67795 ]
 [16.450264]
 [12.426672]
 [18.378407]
 [17.291157]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  4. 29.  0.] 
cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 24. 27.  8.  8.  7.  9.  8. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3. 16.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3] -> size -> 17 
adversary victory points: 6
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4949258863925934
desired expected reward: 16.781661987304688



buy possibilites: [-1] 
expected returns: [[19.563541]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  4. 29.  0.] 
cards in discard: [11.  6.  0.  4.  0.  0.  4.  3.  0.  0.  1.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [16.  3. 16.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3] -> size -> 17 
adversary victory points: 6
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.25593501329421997
desired expected reward: 18.12247085571289






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [16.  3. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 16.  3.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  4. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8] -> size -> 20 
adversary victory points: 8
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  4. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8] -> size -> 20 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  4. 29.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8] -> size -> 20 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [11.  4. 29.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8.] 
expected returns: [[18.604935]
 [20.385569]
 [20.45769 ]
 [19.626503]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4. 29.  8.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5265520811080933
desired expected reward: 19.036989212036133



action possibilites: [-1] 
expected returns: [[18.304398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  8.  1.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.2539297342300415
desired expected reward: 22.196144104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.861818]
 [17.661633]
 [13.541287]
 [19.641825]
 [18.520668]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29.  8.  1.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 8.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.08697761595249176
desired expected reward: 18.391374588012695






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 8.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 4. 0. 3. 1.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
adversary victory points: 8
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 4. 0. 3. 1.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
adversary victory points: 8
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 3.  0. 16.  0.  0.  3.  1. 16. 16.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [8. 4. 0. 3. 1.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
adversary victory points: 8
player victory points: 5 





Player: 0 
cards in hand: [8. 4. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.27526 ]
 [18.370333]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 0. 3. 1.] 
cards in discard: [10. 11.  4. 29.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 29  6  3  8  0  6  0  1  4  4  1 11  4  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5163790583610535
desired expected reward: 18.004289627075195



action possibilites: [-1] 
expected returns: [[14.392893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [10. 11.  4. 29.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0.12457915395498276
desired expected reward: 16.00945281982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.201574]
 [13.93902 ]
 [10.059288]
 [15.797485]
 [14.725336]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [10. 11.  4. 29.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.16516204178333282
desired expected reward: 14.55805492401123



buy possibilites: [-1] 
expected returns: [[21.30249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16. 16.  0.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.2776288688182831
desired expected reward: 13.479204177856445






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [16. 16.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.  1.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  7. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 4. 6.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 4. 6.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  7.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 4. 6.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.] 
cards in discard: [25.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 0. 4. 6.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
adversary victory points: 5
player victory points: 5 





Player: 0 
cards in hand: [6. 0. 0. 4. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.451275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 4. 6.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0.] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25  8] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5945683717727661
desired expected reward: 20.707921981811523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.00718 ]
 [17.804571]
 [13.720164]
 [19.787853]
 [18.668066]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 4. 6.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  6.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0.] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25  8] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.518038272857666
desired expected reward: 18.006372451782227



buy possibilites: [-1] 
expected returns: [[14.850456]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 4. 6.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0.] 
adversary owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25  8] -> size -> 16 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.34770581126213074
desired expected reward: 19.440147399902344






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  3.  3.] 
cards in discard: [25.  8. 16. 16.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3  3 16  0 16  0  0  3  0  3 16  0  3 25  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  7.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 27.  8.  8.  6.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 24. 27.  8.  8.  6.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 24. 27.  8.  8.  6.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
adversary victory points: 5
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.221666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 27.  8.  8.  6.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.40353310108184814
desired expected reward: 14.44692325592041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.697823]
 [18.935678]
 [17.470842]
 [14.851079]
 [13.590172]
 [17.28251 ]
 [20.281124]
 [19.451494]
 [22.458464]
 [20.358362]
 [16.01948 ]
 [16.114971]
 [17.957777]
 [14.078321]
 [18.218433]
 [18.258032]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 27. 30. 24. 27.  8.  8.  6.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4892653524875641
desired expected reward: 17.327102661132812



buy possibilites: [-1] 
expected returns: [[21.40071]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10. 11.  4. 29.  8.  1.  0.  8.  3.  1.  8.  6.  0.  0.  4.  6. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 8. 0.] 
adversary cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
adversary owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16  0] -> size -> 17 
adversary victory points: 4
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 16.0
Learning step: -0.20376788079738617
desired expected reward: 17.07874298095703






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 0.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 16  0 16  0  0  3  0  3 16  0  3 25  8 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
adversary victory points: 5
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  8. 16. 16.  0.  0. 16.  0. 16.  0.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [1. 8. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [1. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.49959 ]
 [22.724695]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5573519468307495
desired expected reward: 20.84335708618164



action possibilites: [-1] 
expected returns: [[20.288431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.06796783208847046
desired expected reward: 19.903324127197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[19.198618]
 [21.42294 ]
 [19.963497]
 [17.295732]
 [15.9984  ]
 [19.778324]
 [22.70265 ]
 [21.916124]
 [24.809748]
 [22.77625 ]
 [18.506922]
 [18.606987]
 [20.447777]
 [16.504766]
 [20.711641]
 [20.75205 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 27. 30. 24. 27.  8.  8.  5.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06217855215072632
desired expected reward: 20.350608825683594



buy possibilites: [-1] 
expected returns: [[20.909428]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0.] 
cards in discard: [16.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 16.0
Learning step: 0.31619933247566223
desired expected reward: 20.09452247619629






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  5.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.026297]
 [20.70712 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [16.  8.  1.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 25.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5557809472084045
desired expected reward: 20.353647232055664



action possibilites: [-1. 16.] 
expected returns: [[24.356333]
 [23.309065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [16.  8.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 25.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.07417184859514236
desired expected reward: 20.979875564575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.759575]
 [25.152136]
 [23.593508]
 [19.278212]
 [26.52051 ]
 [25.675632]
 [24.117006]
 [24.439848]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [16.  8.  1.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 24. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 25.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.023883648216724396
desired expected reward: 24.332448959350586



buy possibilites: [-1] 
expected returns: [[24.79703]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [16.  8.  1.  1.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 25.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.06256353110074997
desired expected reward: 23.656070709228516






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 25.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  4.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8.  0. 25.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  4.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8.  0. 25.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  4.  4.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3] -> size -> 23 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11.  4.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.773111]
 [20.57974 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  4.  4.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [16.  0. 16.  0. 16.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.684658944606781
desired expected reward: 24.11237144470215



action possibilites: [-1] 
expected returns: [[22.032442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 4.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  0. 16.  0. 16.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 10
Learning step: 0.6044761538505554
desired expected reward: 19.166624069213867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.662647]
 [21.4355  ]
 [17.455456]
 [23.470278]
 [22.248814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 4.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [16.  0. 16.  0. 16.] 
adversary cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25.] 
adversary owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.015172461979091167
desired expected reward: 22.04761505126953






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [16.  0. 16.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  0. 16.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9. 10.  8.] 
adversary cards in hand: [0. 8. 3. 8. 6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 8. 3. 8. 6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [ 8. 16.  0.  8.  0.  0.  0.  3.  3.  8.  0. 25. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 8. 3. 8. 6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
adversary owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [0. 8. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[23.317114]
 [24.576569]
 [24.576569]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 6.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 29  6  3  8  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  0. 22.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5629368424415588
desired expected reward: 21.685874938964844



action possibilites: [-1] 
expected returns: [[23.339188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  0. 22.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.10811255872249603
desired expected reward: 26.664356231689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.121405]
 [19.026491]
 [23.514767]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [16.  8.  1.  1.  0.  3. 10.  0.  6.  0.  0. 16. 15. 11.  0.  0.  4.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  0. 22.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.019739169627428055
desired expected reward: 23.319448471069336






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 22.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 22.  0. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  1.  3.  4. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 22.  0. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  1.  3.  4. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
adversary victory points: 6
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [16.  1.  3.  4. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[21.823507]
 [20.937605]
 [23.849016]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  4. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  8.  8.  3.  3.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6183176636695862
desired expected reward: 22.896448135375977



action possibilites: [-1. 16. 16.] 
expected returns: [[22.475666]
 [21.650764]
 [21.650764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  4. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  8.  8.  3.  3.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: -0.03560806065797806
desired expected reward: 23.863828659057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.071007]
 [23.082973]
 [21.757235]
 [18.06605 ]
 [24.244854]
 [23.534693]
 [22.193737]
 [22.417454]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  4. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 23. 27.  8.  8.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  8.  8.  3.  3.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.011830615811049938
desired expected reward: 22.487497329711914



buy possibilites: [-1] 
expected returns: [[18.62041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  4. 16.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [16.  8.  8.  3.  3.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.] 
adversary owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.896466255187988
desired expected reward: 9.169583320617676






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [16.  8.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8.  3.  3.] 
cards in discard: [ 8.  0. 22.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [15.  4.  3. 11.  0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3.] 
cards in discard: [ 8.  0. 22.  0. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [15.  4.  3. 11.  0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3.] 
cards in discard: [ 8.  0. 22.  0. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [15.  4.  3. 11.  0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [15.  4.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[18.281353]
 [18.285067]
 [20.045155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  4.  3. 11.  0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.  0. 16.  8.  3.  3.] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5073591470718384
desired expected reward: 18.113052368164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.059574]
 [14.166106]
 [18.366592]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  4.  3. 11.  0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0. 22.  0. 16.  0. 16.  8.  3.  3.] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5225463509559631
desired expected reward: 17.809938430786133



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8.  0. 22.  0. 16.  0. 16.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8.  0. 22.  0. 16.  0. 16.  8.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  9.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 8.  0. 22.  0. 16.  0. 16.  8.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
adversary owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [6. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.982464]
 [22.152304]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  6  3  0  6  0  1  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.472965806722641
desired expected reward: 17.89362907409668



action possibilites: [-1] 
expected returns: [[15.098174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.08080226927995682
desired expected reward: 17.671754837036133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.014663]
 [14.715285]
 [11.042503]
 [16.503855]
 [15.389234]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  4.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1521110087633133
desired expected reward: 15.250285148620605



buy possibilites: [-1] 
expected returns: [[17.669628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.38041549921035767
desired expected reward: 16.884267807006836






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0. 16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 23. 27.  8.  7.  4.  8.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
adversary victory points: 6
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 23. 27.  8.  7.  4.  8.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
adversary victory points: 6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [2.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 29. 23. 27.  8.  7.  4.  8.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
adversary victory points: 6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 2. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 23. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  8. 10.  0.  6.] 
adversary cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
adversary victory points: 6
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[18.799587]
 [19.953758]
 [18.562212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 23. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 19 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.477536141872406
desired expected reward: 17.192092895507812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.548487]
 [18.27636 ]
 [14.536114]
 [20.132244]
 [18.976927]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 29. 23. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 19 
adversary victory points: 2
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5218750238418579
desired expected reward: 18.293542861938477



buy possibilites: [-1] 
expected returns: [[18.746265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  0.  6.] 
cards in discard: [ 6. 29. 16.  1.  3.  4. 16. 15.  4.  3. 11.  0.  8.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 19 
adversary victory points: 2
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.25152844190597534
desired expected reward: 17.693946838378906






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [6. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
adversary victory points: 7
player victory points: 1 





Player: 0 
cards in hand: [6. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[15.875154]
 [17.055319]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  0  6  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 25. 22.  0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5377135872840881
desired expected reward: 18.20855140686035



action possibilites: [-1] 
expected returns: [[17.552986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 25. 22.  0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 3
Learning step: 0.1806035339832306
desired expected reward: 15.304031372070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[16.632744]
 [17.279337]
 [13.762786]
 [18.974195]
 [17.874   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  3.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 25. 22.  0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10525497049093246
desired expected reward: 17.658241271972656



buy possibilites: [-1] 
expected returns: [[18.973078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 25. 22.  0.] 
adversary cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.31999149918556213
desired expected reward: 19.294185638427734






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 25. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 22.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25. 22.  0.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  7.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  4. 15.  3.  8.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8] -> size -> 22 
adversary victory points: 8
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 22.  0.  0. 16.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  4. 15.  3.  8.] 
adversary cards in discard: [8. 8. 0. 0. 6.] 
adversary owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 23 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 22.  0.  0. 16.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  4. 15.  3.  8.] 
adversary cards in discard: [8. 8. 0. 0. 6.] 
adversary owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 23 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 22.  0.  0. 16.] 
cards in discard: [ 2. 11. 16.  0.  0.  0.  0.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  4. 15.  3.  8.] 
adversary cards in discard: [8. 8. 0. 0. 6.] 
adversary owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 23 
adversary victory points: 8
player victory points: 1 





Player: 0 
cards in hand: [ 8.  4. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
expected returns: [[13.326311]
 [14.462116]
 [13.361023]
 [14.462116]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  4. 15.  3.  8.] 
cards in discard: [8. 8. 0. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  4  1 11  4  8 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3.  2. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.571662902832031
desired expected reward: 9.40141487121582



action possibilites: [-1] 
expected returns: [[16.44261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [8. 8. 0. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3.  2. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.131705179810524
desired expected reward: 16.496444702148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.213278]
 [12.275086]
 [16.481258]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [8. 8. 0. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3.  2. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.11444726586341858
desired expected reward: 16.557056427001953






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 3.  2. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  2. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  9. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 16.  4. 11.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 2. 0. 8.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 16.  4. 11.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 8.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8. 10. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 16.  4. 11.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 8.] 
cards in discard: [29. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 16.  4. 11.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 3. 16.  4. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[17.513756]
 [16.696056]
 [19.437214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  4. 11.  3.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16.  0.  8. 22.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.45259889960289
desired expected reward: 16.02865982055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.276878]
 [13.327986]
 [17.640293]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  4. 11.  3.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16.  0.  8. 22.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14] -> size -> 20 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5081870555877686
desired expected reward: 17.07575225830078



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  8. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8. 22.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 29.  6. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8. 22.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 29.  6. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  8. 22.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0. 29.  6. 10.] 
adversary cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0.  0. 29.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[19.189222]
 [20.987011]
 [19.012047]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  6. 10.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11. 16.  0. 25.  0.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4691115617752075
desired expected reward: 17.171180725097656



action possibilites: [-1. 10.] 
expected returns: [[20.624674]
 [20.441767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11. 16.  0. 25.  0.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.035273779183626175
desired expected reward: 21.052509307861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[19.503078]
 [21.434519]
 [20.150034]
 [16.678888]
 [19.99285 ]
 [22.542309]
 [21.863548]
 [22.606747]
 [18.88192 ]
 [20.574823]
 [20.791563]
 [20.757227]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  8.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11. 16.  0. 25.  0.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.050778236240148544
desired expected reward: 20.67544937133789



buy possibilites: [-1] 
expected returns: [[23.847935]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [ 8.  8.  0.  0.  6.  8. 15.  3.  3. 16.  4. 11.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11. 16.  0. 25.  0.] 
adversary cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0.986732006072998
desired expected reward: 23.593477249145508






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [11. 16.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 25.  0.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 22. 27.  8.  6.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 16.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29] -> size -> 22 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.  0.  0.  0.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 29. 22. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 16.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6] -> size -> 23 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  0.  0.  0.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 29. 22. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 16.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6] -> size -> 23 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  0.  0.  0.  0.] 
cards in discard: [29. 14. 11.  3.  2.  0.  8.  0.  0. 16.  0.  8. 22.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 27. 29. 22. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6.  3.  0. 16.  1.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6] -> size -> 23 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 6.  3.  0. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[13.425279]
 [12.734841]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 16.  1.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 22. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.726495742797852
desired expected reward: 14.121438980102539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[12.291102]
 [14.194811]
 [12.918289]
 [ 9.625478]
 [15.281753]
 [14.622968]
 [13.334281]
 [13.479628]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 16.  1.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 29. 22. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4122583568096161
desired expected reward: 13.100600242614746



buy possibilites: [-1] 
expected returns: [[15.266198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 16.  1.] 
cards in discard: [6. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 29. 21. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.31725355982780457
desired expected reward: 12.601035118103027






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  5.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  2.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [6. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 3. 29. 29.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
adversary owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3. 29. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[20.232895]
 [22.087711]
 [22.087711]
 [21.354137]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  8.  0.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  3  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 25.  2. 11. 29.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38137274980545044
desired expected reward: 14.884825706481934



action possibilites: [-1] 
expected returns: [[21.029821]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 25.  2. 11. 29.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.19021831452846527
desired expected reward: 16.210044860839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.980087]
 [17.020329]
 [21.267761]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 25.  2. 11. 29.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.02691856399178505
desired expected reward: 21.056739807128906






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8. 25.  2. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 29.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  2. 11. 29.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  4.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  4.  3.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.] 
adversary owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  2. 11. 29.  0.  0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  3.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  4.  3.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
adversary owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  2. 11. 29.  0.  0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 27. 29. 21. 27.  8.  3.  4.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  4.  3.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
adversary owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  2. 11. 29.  0.  0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  4.  3.  8.  0.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
adversary owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 23 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  4.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[16.757408]
 [18.451199]
 [17.828865]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  3.  8.  0.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  0  1 11  4 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 14. 16. 22.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1.0
Learning step: -9.60077953338623
desired expected reward: 11.666977882385254



action possibilites: [-1] 
expected returns: [[11.136416]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 14. 16. 22.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.1494167149066925
desired expected reward: 14.066604614257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.270244]
 [ 7.888491]
 [11.273162]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 14. 16. 22.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2219904512166977
desired expected reward: 11.358407020568848



buy possibilites: [-1] 
expected returns: [[16.582981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 14. 16. 22.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
adversary owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.31601396203041077
desired expected reward: 10.586257934570312






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 16. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 16. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 16. 22.  0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  0  3 25  8 16  0  0  8  0 22  0 11  2 11  0  0 29 14  0  0  6  8
 16] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  6. 15. 16.  8.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  6. 15. 16.  8.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  6. 15. 16.  8.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  6. 15. 16.  8.] 
adversary cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 15. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.  8.] 
expected returns: [[18.221317]
 [18.285267]
 [17.517677]
 [19.391722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15. 16.  8.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.45259323716163635
desired expected reward: 16.130388259887695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.09996 ]
 [14.361637]
 [18.284975]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15. 16.  8.] 
cards in discard: [ 6.  3.  6.  3.  0. 16.  1.  8. 29. 29.  6.  0.  8. 11.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16.  3.  0.  0.] 
adversary cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5189506411552429
desired expected reward: 17.70236587524414



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  1.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 11. 16.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.  8.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 11. 16.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6.  8. 11.  0.  0.  0.  0. 16. 25.  8.  2. 11. 29.  0.  0.  0.  8.  0.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 6. 11. 16.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 6. 11. 16.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 10.] 
expected returns: [[ 9.822007]
 [11.206245]
 [ 9.27685 ]
 [ 9.711069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 16.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  8. 11.  2.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5899896025657654
desired expected reward: 17.694984436035156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.972981 ]
 [6.8806686]
 [9.893613 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11. 16.  0. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  8. 11.  2.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.35466083884239197
desired expected reward: 9.562997817993164



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [11.  8. 11.  2.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 11.  2.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 16.  8.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  2.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 16.  8.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 11.  2.  3.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0.  3.  6. 16.  8.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  6. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[11.829303 ]
 [11.320515 ]
 [12.7476845]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 16.  8.] 
cards in discard: [ 6. 11. 16.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16  3 15  6  8  3  8  6 29  6  3  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3022511601448059
desired expected reward: 9.027223587036133



action possibilites: [-1] 
expected returns: [[11.011062]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.] 
cards in discard: [ 6. 11. 16.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.14315634965896606
desired expected reward: 14.225150108337402





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.231807 ]
 [ 7.9644446]
 [11.127641 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [ 6. 11. 16.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22514307498931885
desired expected reward: 11.236205101013184



buy possibilites: [-1] 
expected returns: [[10.602654]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [25.  0.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.2543736696243286
desired expected reward: 10.486181259155273






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 0. 8. 8. 3.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 21 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  7.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 0. 8. 8. 3.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 21 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 0. 8. 8. 3.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
adversary owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 21 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [1. 0. 8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[10.446986]
 [11.377351]
 [11.377351]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 8. 3.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  1 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3513070046901703
desired expected reward: 10.251347541809082



action possibilites: [-1] 
expected returns: [[10.149632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.29764336347579956
desired expected reward: 8.928569793701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.436597]
 [ 6.994881]
 [10.465564]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8. 29.  0.  0.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24280044436454773
desired expected reward: 10.392433166503906






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.  0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29. 15.  3.  0.  6.] 
adversary cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
adversary victory points: -1
player victory points: 0 





Player: 0 
cards in hand: [29. 15.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
expected returns: [[10.293357]
 [11.849557]
 [10.376073]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3.  0.  6.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.34790462255477905
desired expected reward: 10.117661476135254



action possibilites: [-1. 15. 29.] 
expected returns: [[12.985507]
 [13.069975]
 [14.563914]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 0
Learning step: 0.3126640021800995
desired expected reward: 9.70114803314209



action possibilites: [-1. 15.] 
expected returns: [[16.81595 ]
 [16.911564]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 0
Learning step: 0.8658409714698792
desired expected reward: 12.910136222839355



action possibilites: [-1] 
expected returns: [[19.342123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 15.0
Learning step: 1.345745325088501
desired expected reward: 18.25731086730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[18.098948 ]
 [18.82057  ]
 [14.8850565]
 [19.413921 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 29. 21. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.2600642442703247
desired expected reward: 20.602188110351562



buy possibilites: [-1] 
expected returns: [[18.488302]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [ 6. 11. 16.  0. 10.  0.  8.  0. 16.  8.  8.  3.  6.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 20. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 8.  8. 16. 16.  0.] 
adversary cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
adversary owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  8  0] 
sum of rewards: 63 

action type: buy - action 3.0
Learning step: 1.4830207824707031
desired expected reward: 21.519901275634766






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 16. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 16. 16.  0.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1
 29  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 20. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [10.  3.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 16.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [10.  3.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 16.] 
cards in discard: [ 1. 11.  8. 11.  2.  3. 29. 25.  0.  0.  0.  0.  8.  1. 29.  0.  0.  0.
  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [10.  3.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
adversary victory points: 0
player victory points: 1 





Player: 0 
cards in hand: [10.  3.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[8.594393]
 [8.545396]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.613493800163269
desired expected reward: 17.87480926513672



action possibilites: [-1.] 
expected returns: [[12.46472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.3213110566139221
desired expected reward: 8.973593711853027





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.528135]
 [ 9.264345]
 [12.450054]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3] -> size -> 20 
action values: 2 
buys: 1 
player value: 0 
card supply: [10. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.19528260827064514
desired expected reward: 12.660002708435059



buy possibilites: [-1] 
expected returns: [[8.632214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 3. 3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [1. 8. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.1947942078113556
desired expected reward: 11.722929000854492






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [1. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  8 16  0  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29
  1  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 16.  8.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 16.  8.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 29. 19. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 16.  8.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 16.  8.  6.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 0
player victory points: 2 





Player: 0 
cards in hand: [29.  0. 16.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
expected returns: [[10.633278 ]
 [12.248193 ]
 [10.104826 ]
 [11.6623125]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 16.  8.  6.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8  6 29  6  3  6  0  0  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 16.  2.  8.] 
adversary cards in discard: [3. 8. 1. 0. 6.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3] -> size -> 26 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2893238663673401
desired expected reward: 8.342889785766602



action possibilites: [-1] 
expected returns: [[10.741119]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 16.  2.  8.] 
adversary cards in discard: [3. 8. 1. 0. 6.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.2805284857749939
desired expected reward: 9.688970565795898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.0645895]
 [ 7.697036 ]
 [10.999714 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  8.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 11. 16.  2.  8.] 
adversary cards in discard: [3. 8. 1. 0. 6.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3] -> size -> 26 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2313975840806961
desired expected reward: 10.972517013549805






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 16.  2.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 16.  2.  8.] 
cards in discard: [3. 8. 1. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  6.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 15.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  2.  8.] 
cards in discard: [ 3.  8.  1.  0.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  5.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 15.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  2.  8.] 
cards in discard: [ 3.  8.  1.  0.  6. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  5.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 15.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  2.  8.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  8.] 
adversary cards in hand: [11.  0.  0.  8. 15.] 
adversary cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8.] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [11.  0.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
expected returns: [[11.360342]
 [13.101543]
 [12.487226]
 [11.474922]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8. 15.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  8.] 
adversary cards in hand: [29.  0. 29.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3507876992225647
desired expected reward: 10.64892578125



action possibilites: [-1] 
expected returns: [[12.155151]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0. 29.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.6265680193901062
desired expected reward: 14.995270729064941





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.253931]
 [11.802601]
 [ 8.786013]
 [12.231844]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 29. 18. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0. 29.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2035885602235794
desired expected reward: 12.358739852905273



buy possibilites: [-1] 
expected returns: [[12.646807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.] 
cards in discard: [ 0. 10.  3.  6.  6.  3.  3.  0. 16. 29.  0.  8. 15.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [29.  0. 29.  8.  3.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.4687134325504303
desired expected reward: 12.27131462097168






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [29.  0. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  8.  3.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 29.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 16.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 29.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 29.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 29.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [10.  0. 29.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  0. 29.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8. 16.] 
expected returns: [[10.371797]
 [10.325599]
 [11.599072]
 [11.149536]
 [ 9.969708]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  8. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4143424928188324
desired expected reward: 12.232463836669922



action possibilites: [-1] 
expected returns: [[9.122774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.21922379732131958
desired expected reward: 11.104734420776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.536616 ]
 [6.551146 ]
 [9.3379135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [ 0. 11.  3.  0.  0.] 
adversary cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0] -> size -> 29 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2643182873725891
desired expected reward: 9.387092590332031






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [11.  6.  3.  3.  8.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [11.  6.  3.  3.  8.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  9.  9.  7.] 
adversary cards in hand: [11.  6.  3.  3.  8.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3.  8.  1.  0.  6. 29. 29. 11.  0. 16.  2.  8.  8.  0.  0. 29. 29.  3.
 16.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [11.  6.  3.  3.  8.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11.  6.  3.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[8.69312 ]
 [9.99374 ]
 [9.557501]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  3.  8.] 
cards in discard: [ 0. 16. 10.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0 10] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3300663232803345
desired expected reward: 9.007845878601074



action possibilites: [-1] 
expected returns: [[7.480012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 8.] 
cards in discard: [ 0. 16. 10.  0.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0 10] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 1
Learning step: 0.5204570293426514
desired expected reward: 9.78989315032959





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[6.8600373]
 [5.069902 ]
 [7.5542617]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 8.] 
cards in discard: [ 0. 16. 10.  0.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0.  1.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0 10] -> size -> 31 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.29601937532424927
desired expected reward: 7.776031494140625






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  8. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 25  8 16  0  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1
  3  3 29 29  0  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [15. 15.  0.  6.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [15. 15.  0.  6.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [15. 15.  0.  6.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
adversary owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [15. 15.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[9.547975]
 [9.654116]
 [9.654116]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  6.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [11.  1.  2.  8. 29.] 
adversary cards in discard: [ 8.  1. 25.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2755568027496338
desired expected reward: 7.278704643249512



action possibilites: [-1] 
expected returns: [[15.356895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [11.  1.  2.  8. 29.] 
adversary cards in discard: [ 8.  1. 25.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.32162386178970337
desired expected reward: 9.975740432739258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[14.568556]
 [16.17925 ]
 [15.082113]
 [12.158285]
 [14.959752]
 [17.081264]
 [17.12166 ]
 [14.009677]
 [15.427711]
 [15.592616]
 [15.460934]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  8.  9.  7.] 
adversary cards in hand: [11.  1.  2.  8. 29.] 
adversary cards in discard: [ 8.  1. 25.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1532660275697708
desired expected reward: 15.510161399841309



buy possibilites: [-1] 
expected returns: [[11.39045]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [11.  1.  2.  8. 29.] 
adversary cards in discard: [ 8.  1. 25.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.24176844954490662
desired expected reward: 15.669478416442871






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [11.  1.  2.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  2.  8. 29.] 
cards in discard: [ 8.  1. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  2.  0.] 
cards in discard: [ 8.  1. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  2.  0.] 
cards in discard: [ 8.  1. 25.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 5. 24. 29. 17. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  2.  0.] 
cards in discard: [ 8.  1. 25.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 5. 24. 29. 16. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 3.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[6.2661653]
 [7.55444  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 16. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  8.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10  3] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4178026020526886
desired expected reward: 10.972646713256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[5.5844193]
 [5.990072 ]
 [3.8347   ]
 [6.2852316]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 29. 16. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  8.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10  3] -> size -> 30 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.27922770380973816
desired expected reward: 5.9869384765625



buy possibilites: [-1] 
expected returns: [[7.735332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [ 0. 16. 10.  0.  8.  1. 11.  6.  3.  3.  8. 10. 15. 15.  6.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 15. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0. 11.  8.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0.] 
adversary owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10  3] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.008481187745928764
desired expected reward: 5.98159122467041






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0. 16.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 16  8  0  0 11  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3
 29 29  0  0 10  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 15. 27.  8.  3.  3.  7.  0.  9.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[12.193327]
 [13.166018]
 [11.72592 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  0  8 16 16 15  8  3  8 29  6  3  6  0  0  3  0  0 15  3  0  1 10
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8. 29.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
adversary owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.25016748905181885
desired expected reward: 7.485164642333984



action possibilites: [-1] 
expected returns: [[9.238148]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8. 29.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
adversary owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.2727535665035248
desired expected reward: 9.414320945739746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[8.578173 ]
 [6.4906063]
 [9.351943 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  8. 29.  0. 16.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
adversary owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26087263226509094
desired expected reward: 9.49902057647705






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [29.  8. 29.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  0. 16.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [25  8 16  8  0  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29
 29  0  0 10  3 25  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [15.  6.  3.  0.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[10.437464]
 [10.560104]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  0.  0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0  0 15  3  0  1 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.31924334168434143
desired expected reward: 9.032698631286621



action possibilites: [-1] 
expected returns: [[7.3478155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.20763781666755676
desired expected reward: 10.858112335205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[6.73433  ]
 [7.9240513]
 [7.113488 ]
 [4.976486 ]
 [7.020604 ]
 [8.593728 ]
 [8.618978 ]
 [6.3139515]
 [7.368331 ]
 [7.4876947]
 [7.3720856]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  7.  9.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.30839261412620544
desired expected reward: 7.656208038330078



buy possibilites: [-1] 
expected returns: [[5.6836767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.42362865805625916
desired expected reward: 7.791959762573242






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  7.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [ 8.  1. 25.  8.  3. 29. 11.  1.  2.  0. 25.  0. 16.  0.  8.  0.  8. 29.
 29.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [11.  0. 29. 10.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [11.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
expected returns: [[10.718474]
 [12.216085]
 [12.246803]
 [10.713865]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 10.  3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  7.] 
adversary cards in hand: [29.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.19824832677841187
desired expected reward: 5.485428333282471



action possibilites: [-1] 
expected returns: [[13.4220295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [29.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 9
Learning step: 0.6723601818084717
desired expected reward: 13.9580659866333





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.75382 ]
 [10.333679]
 [13.636814]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [29.  0.  3. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.17880448698997498
desired expected reward: 13.600833892822266






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [29.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [16.  3.  3.  8.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 10.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [16.  3.  3.  8.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 10.  3.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [16.  3.  3.  8.  3.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
adversary owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [16.  3.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[ 9.820444]
 [ 9.417805]
 [10.783149]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  8.  3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8 16 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0.  0. 29.  8. 11.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4523998498916626
desired expected reward: 13.184412956237793



action possibilites: [-1] 
expected returns: [[13.01063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0.  0. 29.  8. 11.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.274822473526001
desired expected reward: 10.667793273925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.433865 ]
 [10.515116 ]
 [13.1298065]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0.  0. 29.  8. 11.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1882743090391159
desired expected reward: 13.198904037475586






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8. 11.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  3.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  6. 10.  1.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  2.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  6. 10.  1.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  8.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 29. 15. 27.  8.  2.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [15.  8.  6. 10.  1.] 
adversary cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [15.  8.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
expected returns: [[12.529753]
 [12.660091]
 [13.454491]
 [12.525486]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  6. 10.  1.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  2.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  6. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.40818309783935547
desired expected reward: 12.721623420715332



action possibilites: [-1] 
expected returns: [[11.239199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  1.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  2.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  6. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.19046974182128906
desired expected reward: 12.775197982788086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[10.658163 ]
 [11.076864 ]
 [ 8.7074375]
 [11.339529 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  1.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 29. 15. 27.  8.  2.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  6. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22437921166419983
desired expected reward: 11.463578224182129



buy possibilites: [-1] 
expected returns: [[11.915449]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  1.] 
cards in discard: [ 8. 10. 15.  6.  3.  0. 15. 11.  0. 29. 10.  3.  8.  3.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  6. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
adversary owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.686110496520996
desired expected reward: 0.02132701873779297






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  6. 11.  0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2 11  0  0 29  0  0  6  8 16  0  8  1 29  1  3  3 29 29  0
  0 10  3 25  0 11  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15  6] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  0. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15  6] -> size -> 22 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[6.679166]
 [6.797202]
 [7.438848]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  6.  8.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8 15  8  3  8 29  6  3  6  3  0 15  3  0  1 10  3 10 15  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.] 
adversary owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.43261781334877014
desired expected reward: 11.482831001281738



action possibilites: [-1] 
expected returns: [[8.13937]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.] 
adversary owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.34338465332984924
desired expected reward: 6.746009349822998





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.4941287]
 [5.534781 ]
 [8.20025  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 1.  0. 29. 25.  0.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.] 
adversary owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2824811041355133
desired expected reward: 8.42185115814209






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25.  0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [10.  6. 10.  6.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.  8.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8  1 29  1  3 29 29  0  0 10
  3 25  0 11  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [10.  6. 10.  6.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [10.  6. 10.  6.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [10.  6. 10.  6.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [10.  6. 10.  6.  3.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  6. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[8.227989]
 [8.24214 ]
 [8.24214 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  6.  3.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 29. 16.  2.  8.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.] 
adversary owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3086581528186798
desired expected reward: 7.891592502593994





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.6099257]
 [5.67699  ]
 [8.313957 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 10.  6.  3.] 
cards in discard: [8. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 29. 16.  2.  8.] 
adversary cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.] 
adversary owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.32131654024124146
desired expected reward: 7.987293243408203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 16.  2.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.  2.  8.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  2  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3
 25  0 11  0  6  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  8.  8. 15. 10.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 16.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  8.  8. 15. 10.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 16.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  8.  8. 15. 10.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 16.] 
cards in discard: [ 0. 29.  0.  3. 10.  3.  6. 11.  0.  0. 29.  8.  8.  6.  0.  0.  0. 29.
  8. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 3.  8.  8. 15. 10.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
adversary owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3.  8.  8. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15. 10.] 
expected returns: [[ 9.699593]
 [10.545307]
 [10.545307]
 [ 9.831372]
 [ 9.712352]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 15. 10.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [29.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2922515571117401
desired expected reward: 8.021706581115723



action possibilites: [-1] 
expected returns: [[8.520291]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [29.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.23577046394348145
desired expected reward: 10.358856201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.979399 ]
 [6.2029667]
 [8.601497 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 10.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [29.  0.  0. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2762491703033447
desired expected reward: 8.796540260314941






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [29.  0.  0. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 15. 29. 11.  1.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  9. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 15. 29. 11.  1.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 25.  1.] 
cards in discard: [14.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  6.  9.  6.] 
adversary cards in hand: [ 0. 15. 29. 11.  1.] 
adversary cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 15. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.] 
expected returns: [[ 9.660721 ]
 [ 9.792177 ]
 [11.005394 ]
 [10.9828205]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29. 11.  1.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 29.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2979072630405426
desired expected reward: 8.303590774536133



action possibilites: [-1. 15.] 
expected returns: [[9.479027]
 [9.629812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  3.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 29.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.24395158886909485
desired expected reward: 10.508058547973633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 9.071809 ]
 [10.321016 ]
 [ 9.463462 ]
 [ 7.2677565]
 [ 9.36334  ]
 [11.02208  ]
 [11.040907 ]
 [ 8.628808 ]
 [ 9.719795 ]
 [ 9.843406 ]
 [ 9.694069 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  3.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  6.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 29.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2693301737308502
desired expected reward: 9.748356819152832



buy possibilites: [-1] 
expected returns: [[10.738481]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  3.] 
cards in discard: [ 8.  3. 10.  6. 10.  6.  3.  8.  8. 15. 10. 11. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 29.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 10.0
Learning step: 0.4061601459980011
desired expected reward: 10.125957489013672






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 29.  0.] 
cards in discard: [14. 29.  0.  0. 25.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  6. 15. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1  3 29 29  0  0 10  3 25
  0 11  0  6  0  0 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  6. 15. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  6. 15. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  6. 15. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  6. 15. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29.  6. 15. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10.] 
expected returns: [[7.9140167]
 [9.195938 ]
 [8.05547  ]
 [7.939222 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 15. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 0.  6.  6. 16.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3821702301502228
desired expected reward: 10.35630989074707



action possibilites: [-1. 15.] 
expected returns: [[7.298217]
 [7.445153]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.] 
cards in discard: [10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  0  1 10  3 10 15  6 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 0.  6.  6. 16.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0.22159823775291443
desired expected reward: 10.420222282409668



action possibilites: [-1] 
expected returns: [[7.4898615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 0.  6.  6. 16.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 15.0
Learning step: 0.9052889943122864
desired expected reward: 8.350441932678223





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[8.042126 ]
 [7.2612457]
 [5.241061 ]
 [7.168837 ]
 [8.67589  ]
 [8.692492 ]
 [6.4928856]
 [7.4994235]
 [7.6091766]
 [7.4755044]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  4.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 0.  6.  6. 16.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.9058516621589661
desired expected reward: 8.395712852478027



buy possibilites: [-1] 
expected returns: [[6.6853514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [10.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 0.  6.  6. 16.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 1.8194215297698975
desired expected reward: 10.51191234588623






         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  6. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 16.  0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  6  8 16  0  8 29  1 29 29  0  0 10  3 25  0
 11  0  6  0  0 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 15. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 3.  8. 10. 11.  6.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 3.  8. 10. 11.  6.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [16.] 
owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [ 3.  8. 10. 11.  6.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3.  8. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[11.239159]
 [12.249029]
 [11.269545]
 [12.729111]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10. 11.  6.] 
cards in discard: [10.  3. 29. 29. 15.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  8.  8.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.22374850511550903
desired expected reward: 6.461602687835693



action possibilites: [-1.  8. 11.] 
expected returns: [[ 9.675673 ]
 [10.5069275]
 [10.908087 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  6.  1.] 
cards in discard: [10.  3. 29. 29. 15.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  6.] 
adversary cards in hand: [29.  8.  8.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.22102239727973938
desired expected reward: 11.518972396850586



action possibilites: [-1.  8.] 
expected returns: [[9.05941 ]
 [9.955635]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 1.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3  1 10  3 10 15  6 10 29 15] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [29.  8.  8.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 1.3187977075576782
desired expected reward: 11.717878341674805



action possibilites: [-1] 
expected returns: [[9.321598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [29.  8.  8.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.4623109102249146
desired expected reward: 10.981172561645508





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[7.327092]
 [9.57877 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [29.  8.  8.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.4614720344543457
desired expected reward: 10.783069610595703






         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [29.  8.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8.  0.  0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [ 8. 15.  3.  3. 10.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8.  0.  0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 24. 29. 14. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [ 8. 15.  3.  3. 10.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  8.  0.  0.] 
cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 13. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [ 8. 15.  3.  3. 10.] 
adversary cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.] 
adversary owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 8. 15.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
expected returns: [[12.239604]
 [13.128927]
 [12.386654]
 [12.266067]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  3.  3. 10.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 13. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [25. 11.  3.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.  3.
 29.  8.  8.  0.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3  3] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30474770069122314
desired expected reward: 9.274022102355957





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[10.5662985]
 [13.183781 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  3.  3. 10.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15] -> size -> 19 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 24. 29. 13. 27.  8.  1.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [25. 11.  3.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.  3.
 29.  8.  8.  0.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3  3] -> size -> 32 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4159068465232849
desired expected reward: 12.695530891418457



Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 2 
Gold: 0 
Estate: 7 
Duchy: 3 
Province: 0 
Curse: 5 

Remodel: 2 
Workshop: 1 
Chapel: 5 
Witch: 0 
Poacher: 3 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8. 15.  3.  3. 10.] 
cards in discard: [10.  3. 29. 29. 15.  6. 15. 10. 11.  8.  3.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  8 29  3  6  3 15  3 10  3 10 15  6 10 29 15  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 24. 29. 13. 27.  8.  0.  3.  6.  0.  8.  3.  8. 10.  5.  9.  5.] 
adversary cards in hand: [25. 11.  3.  0.  0.] 
adversary cards in discard: [14. 29.  0.  0. 25.  1. 29.  0. 29.  8.  8.  0.  3. 16.  0.  6.  0.  3.
 29.  8.  8.  0.  0.] 
adversary owned cards: [25  8  8  0  0  0 29  0  0  8 16  0  8 29  1 29 29  0  0 10  3 25  0 11
  0  6  0  0 14  0  3  3] -> size -> 32 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -805 

action type: buy - action 6.0
Learning step: -24.46698760986328
desired expected reward: -13.900689125061035



