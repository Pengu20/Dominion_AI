 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.57162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -4  -90    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -629 

action type: buy - action 0.0
Learning step: -30.800806045532227
desired expected reward: -43.78467559814453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[267.2881 ]
 [283.77313]
 [276.59448]
 [234.86667]
 [274.32846]
 [291.69702]
 [277.9019 ]
 [279.5452 ]
 [250.97409]
 [273.68393]
 [267.63367]
 [296.27246]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.526362419128418
desired expected reward: 287.33343505859375



buy possibilites: [-1] 
expected returns: [[273.0108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.250591278076172
desired expected reward: 213.61607360839844






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[314.83322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.207507610321045
desired expected reward: 265.80328369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[289.7225 ]
 [307.81058]
 [298.8606 ]
 [258.978  ]
 [314.49136]
 [301.74112]
 [295.1731 ]
 [317.0765 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.522551536560059
desired expected reward: 305.7233581542969



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[293.9328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.93076229095459
desired expected reward: 307.145751953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[276.77008]
 [288.4513 ]
 [281.99142]
 [253.29474]
 [292.80927]
 [284.89407]
 [280.22226]
 [294.7943 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.792183876037598
desired expected reward: 283.343994140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[315.25238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -8.316102027893066
desired expected reward: 286.47821044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[287.25964]
 [303.7573 ]
 [296.32922]
 [255.23907]
 [311.05783]
 [297.7982 ]
 [292.90866]
 [314.4372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.5451078414917
desired expected reward: 304.8377380371094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 0.  0.  3.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[289.9425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.888050079345703
desired expected reward: 304.54913330078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[272.53177]
 [284.26917]
 [277.67065]
 [249.20245]
 [288.72333]
 [280.4318 ]
 [275.74844]
 [290.58572]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 14.  0. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.689167976379395
desired expected reward: 279.48016357421875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 15.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[305.6922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 6. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [16. 15. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -8.271525382995605
desired expected reward: 282.314208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[278.19592]
 [295.7051 ]
 [288.3624 ]
 [243.14758]
 [304.08823]
 [289.0823 ]
 [284.88293]
 [309.9987 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0. 6. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [16. 15. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.324130058288574
desired expected reward: 297.6874694824219



buy possibilites: [-1] 
expected returns: [[294.84692]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [ 0.  6.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [16. 15. 14.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 10.0
Learning step: -7.3600897789001465
desired expected reward: 277.5228271484375






Player: 1 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [16. 15. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [16. 15. 14.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [16. 15. 14.  0.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.6669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.71226978302002
desired expected reward: 286.1346435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[265.75247]
 [281.68558]
 [273.33823]
 [233.73367]
 [287.4609 ]
 [276.594  ]
 [270.34735]
 [289.5545 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.200448036193848
desired expected reward: 287.6918640136719



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 10.  6.] 
adversary cards in discard: [3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[278.58276]
 [256.0491 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10.  6.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -9.045610427856445
desired expected reward: 280.50885009765625



action possibilites: [-1.] 
expected returns: [[294.5459]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 8 

action type: take_action - action 10.0
Learning step: -4.754453182220459
desired expected reward: 230.88026428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[271.97263]
 [286.79623]
 [280.056  ]
 [239.6016 ]
 [292.78598]
 [281.43506]
 [276.8503 ]
 [295.04156]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -7.956185817718506
desired expected reward: 286.5897216796875



buy possibilites: [-1] 
expected returns: [[326.8479]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [3. 3. 0. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [ 1. 15.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 25 

action type: buy - action 1.0
Learning step: -5.7357354164123535
desired expected reward: 281.0605163574219






Player: 1 
cards in hand: [ 3.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 1. 15.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [ 1. 15.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1] -> size -> 13 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[287.70917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.508952140808105
desired expected reward: 316.3389587402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[258.3018 ]
 [265.74063]
 [226.72083]
 [268.8083 ]
 [280.29068]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.011252403259277
desired expected reward: 279.1417541503906



buy possibilites: [-1] 
expected returns: [[290.1818]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 14. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -8.535999298095703
desired expected reward: 249.7657928466797






Player: 1 
cards in hand: [ 0.  8. 14. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14. 11.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 15 14 16  8  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.  0.  0.] 
adversary cards in discard: [0. 3. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[287.01492]
 [267.10654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3. 16.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.33244514465332
desired expected reward: 280.8493347167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[259.27975]
 [275.7828 ]
 [268.47293]
 [238.39568]
 [227.31639]
 [266.3349 ]
 [282.4733 ]
 [269.6311 ]
 [294.91373]
 [270.90216]
 [242.03307]
 [253.26706]
 [264.72653]
 [235.63612]
 [258.47726]
 [285.21756]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [0. 3. 3. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3. 16.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.266806602478027
desired expected reward: 277.36614990234375



buy possibilites: [-1] 
expected returns: [[262.08588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.  0.  0.] 
cards in discard: [0. 3. 3. 3. 0. 0. 1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  0.  3.  3. 16.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -8.817208290100098
desired expected reward: 266.9656066894531






Player: 1 
cards in hand: [15.  0.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  3. 16.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3. 16.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  3. 16.] 
cards in discard: [3. 8. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[264.09238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.275848388671875
desired expected reward: 253.81002807617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[237.44434]
 [254.4159 ]
 [246.39749]
 [215.71259]
 [203.5178 ]
 [244.68643]
 [261.28314]
 [248.49936]
 [274.66534]
 [249.8105 ]
 [219.41727]
 [230.72832]
 [243.01823]
 [212.46338]
 [236.56764]
 [263.8833 ]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.697290420532227
desired expected reward: 257.01141357421875



buy possibilites: [-1] 
expected returns: [[208.89452]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 6. 0.] 
cards in discard: [23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 27 

action type: buy - action 23.0
Learning step: -5.486289978027344
desired expected reward: 225.24203491210938






Player: 1 
cards in hand: [3. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  3.] 
adversary cards in discard: [23.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  1.  3.] 
adversary cards in discard: [23.  0.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23] -> size -> 16 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[296.00763]
 [276.81525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  1.  3.] 
cards in discard: [23.  0.  1.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0. 16.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -5.102260112762451
desired expected reward: 203.79225158691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[266.32703]
 [284.1149 ]
 [274.1194 ]
 [233.47176]
 [290.00845]
 [278.81354]
 [270.9058 ]
 [289.52652]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  3.] 
cards in discard: [23.  0.  1.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  9.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0. 16.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.512048721313477
desired expected reward: 283.9826354980469



buy possibilites: [-1] 
expected returns: [[221.6896]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.  3.] 
cards in discard: [23.  0.  1.  0.  6.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [15.  3.  0. 16.  0.] 
adversary cards in discard: [3. 0. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -23.38557243347168
desired expected reward: 210.086181640625






Player: 1 
cards in hand: [15.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 16.  0.] 
cards in discard: [3. 0. 3. 1. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [23.  0.  1.  0.  6.  0.  6.  0. 10.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 16.  0.] 
cards in discard: [3. 0. 3. 1. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [23.  0.  1.  0.  6.  0.  6.  0. 10.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6] -> size -> 17 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[188.73016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [23.  0.  1.  0.  6.  0.  6.  0. 10.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.527019500732422
desired expected reward: 213.16258239746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[162.32355]
 [173.55902]
 [167.86089]
 [138.47485]
 [167.26317]
 [177.56027]
 [170.10207]
 [170.7573 ]
 [149.29941]
 [165.80783]
 [161.33015]
 [178.31209]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [23.  0.  1.  0.  6.  0.  6.  0. 10.  3.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.856046199798584
desired expected reward: 173.15309143066406



buy possibilites: [-1] 
expected returns: [[175.5042]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [23.  0.  1.  0.  6.  0.  6.  0. 10.  3.  1.  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -29.5 

action type: buy - action 1.0
Learning step: -6.204108715057373
desired expected reward: 167.35494995117188






Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 15 16  8  1  3  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[234.289  ]
 [214.75241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -4.8540425300598145
desired expected reward: 170.650146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[210.39291]
 [227.96178]
 [219.01935]
 [174.80055]
 [233.75528]
 [222.15707]
 [215.25711]
 [234.29466]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 1.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.7968597412109375
desired expected reward: 225.19677734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 1.] 
adversary cards in discard: [ 0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 26. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 1.] 
adversary cards in discard: [ 0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [0. 8. 0. 0. 1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 1. 6. 0. 1.] 
adversary cards in discard: [ 0.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 1. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[265.9126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 1.] 
cards in discard: [ 0.  0. 10.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -6.98257303237915
desired expected reward: 227.3120880126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[243.0338 ]
 [257.9527 ]
 [235.2641 ]
 [251.33205]
 [224.05836]
 [213.46783]
 [249.40324]
 [264.10226]
 [252.40703]
 [275.31613]
 [253.52087]
 [227.37625]
 [237.5493 ]
 [248.01607]
 [221.41194]
 [242.32892]
 [266.6473 ]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 1.] 
cards in discard: [ 0.  0. 10.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 25. 30. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.57747745513916
desired expected reward: 255.07406616210938



buy possibilites: [-1] 
expected returns: [[255.64108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 1.] 
cards in discard: [ 0.  0. 10.  3.  0.  2.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 16. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1748 

action type: buy - action 2.0
Learning step: 81.38871765136719
desired expected reward: 316.65283203125






Player: 1 
cards in hand: [ 8.  0.  0. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 16. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 0.  0. 10.  3.  0.  2.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 16. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 6. 1.] 
adversary cards in discard: [ 0.  0. 10.  3.  0.  2.  0.  1.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[225.55386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 6. 1.] 
cards in discard: [ 0.  0. 10.  3.  0.  2.  0.  1.  6.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 16. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.932397842407227
desired expected reward: 246.70867919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[202.5723 ]
 [218.13773]
 [210.55475]
 [170.548  ]
 [224.35875]
 [212.82138]
 [207.57033]
 [226.6082 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 6. 1.] 
cards in discard: [ 0.  0. 10.  3.  0.  2.  0.  1.  6.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 1. 3.] 
adversary cards in discard: [ 8.  0.  0. 16. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.54634428024292
desired expected reward: 216.88284301757812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 16. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 16. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [27. 25. 29. 29. 30.  8.  8.  9.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 1. 3.] 
cards in discard: [ 8.  0.  0. 16. 15. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  1. 23.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  1. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[248.79803]
 [221.07967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -7.1304192543029785
desired expected reward: 219.47776794433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[230.80386]
 [246.45737]
 [238.25745]
 [212.67831]
 [202.71532]
 [237.32568]
 [251.73909]
 [241.2337 ]
 [265.23315]
 [242.13939]
 [214.8664 ]
 [223.93782]
 [234.92339]
 [209.39249]
 [228.99542]
 [251.96738]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 23.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9. 10. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.041534423828125
desired expected reward: 239.96490478515625



buy possibilites: [-1] 
expected returns: [[175.70917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 23.  0.  0.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 26 

action type: buy - action 25.0
Learning step: -8.008201599121094
desired expected reward: 257.2249450683594






Player: 1 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 29. 29. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 29. 28. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 1.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[206.94661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [25.  0.  1. 23.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 28. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0. 16.  0.] 
adversary cards in discard: [3. 1. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -5.908327579498291
desired expected reward: 169.80084228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[197.02435]
 [207.88226]
 [201.68088]
 [182.40802]
 [173.79057]
 [201.65869]
 [211.78413]
 [204.6791 ]
 [221.8314 ]
 [205.41327]
 [184.29706]
 [191.55833]
 [199.90431]
 [179.63591]
 [195.69017]
 [213.73991]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [25.  0.  1. 23.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 29. 28. 30.  8.  8.  8.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0. 16.  0.] 
adversary cards in discard: [3. 1. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.181334018707275
desired expected reward: 196.2467041015625



buy possibilites: [-1] 
expected returns: [[201.1817]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 1.] 
cards in discard: [25.  0.  1. 23.  0.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 29. 28. 30.  8.  8.  7.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0. 15.  0. 16.  0.] 
adversary cards in discard: [3. 1. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16  3] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -26.0 

action type: buy - action 16.0
Learning step: -6.856346130371094
desired expected reward: 194.80233764648438






Player: 1 
cards in hand: [ 0. 15.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 16.  0.] 
cards in discard: [3. 1. 0. 0. 3. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15 16  8  1  3  0  0  1 16  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 28. 30.  8.  8.  7.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [6. 2. 3. 0. 0.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 1. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 28. 30.  8.  7.  7.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [6. 2. 3. 0. 0.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 1. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 29. 28. 30.  8.  7.  7.  9.  9.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [6. 2. 3. 0. 0.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 1. 0. 0. 3. 3. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [6. 2. 3. 0. 0.] 
adversary cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [6. 2. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[120.84873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 2. 3. 0. 0.] 
cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [16.  1.  3.  8.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  3.  3.  6.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.614638328552246
desired expected reward: 192.5670623779297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[102.41751 ]
 [114.271095]
 [108.26974 ]
 [ 88.072   ]
 [ 80.94714 ]
 [107.36681 ]
 [117.92359 ]
 [110.266235]
 [127.592545]
 [110.91285 ]
 [ 89.949905]
 [ 97.30809 ]
 [105.71965 ]
 [ 85.83924 ]
 [101.185974]
 [118.44915 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 3. 0. 0.] 
cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [16.  1.  3.  8.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  3.  3.  6.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -4.2982354164123535
desired expected reward: 109.08171844482422



buy possibilites: [-1] 
expected returns: [[124.96736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 2. 3. 0. 0.] 
cards in discard: [25.  0.  1. 23.  0.  0. 16.  1.  3.  0.  3.  1.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [16.  1.  3.  8.  0.] 
adversary cards in discard: [ 3.  1.  0.  0.  3.  3.  6.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -19.5 

action type: buy - action 1.0
Learning step: -3.8767898082733154
desired expected reward: 110.39431762695312






Player: 1 
cards in hand: [16.  1.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  3.  8.  0.] 
cards in discard: [ 3.  1.  0.  0.  3.  3.  6.  8. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  3.  8.  0.] 
cards in discard: [ 3.  1.  0.  0.  3.  3.  6.  8. 16.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[173.03087]
 [157.58174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -3.705326557159424
desired expected reward: 121.26203155517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[153.52307]
 [159.217  ]
 [128.21022]
 [162.41504]
 [169.64214]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -6.106721878051758
desired expected reward: 164.5152587890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 2. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 0. 1. 2. 0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 2. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[236.23029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 2. 0.] 
cards in discard: [ 3.  6.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [8. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1.0
Learning step: -4.448041915893555
desired expected reward: 165.194091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[216.34079]
 [230.89536]
 [209.86362]
 [225.35161]
 [198.87202]
 [187.75179]
 [222.50453]
 [237.39365]
 [224.77367]
 [247.4751 ]
 [225.90587]
 [202.6069 ]
 [211.98196]
 [221.50995]
 [196.45078]
 [215.97508]
 [240.86295]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 2. 0.] 
cards in discard: [ 3.  6.  0. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  9. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [8. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.632526397705078
desired expected reward: 224.99258422851562



buy possibilites: [-1] 
expected returns: [[218.14087]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 2. 0.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0. 16.] 
adversary cards in discard: [8. 0. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 25.0
Learning step: -8.0405855178833
desired expected reward: 239.43450927734375






Player: 1 
cards in hand: [ 0.  0. 16.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0. 16.] 
cards in discard: [8. 0. 3. 6. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  8.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [8. 0. 3. 6. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [8. 0. 3. 6. 3. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [1. 1. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [1. 1. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[163.73152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -8.530034065246582
desired expected reward: 209.61083984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[149.90266]
 [164.55518]
 [143.416  ]
 [158.7368 ]
 [133.43446]
 [125.36958]
 [156.08797]
 [170.8319 ]
 [158.58766]
 [181.55249]
 [159.7073 ]
 [136.7494 ]
 [145.86026]
 [155.104  ]
 [131.84865]
 [149.79234]
 [174.76016]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 24. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.433090686798096
desired expected reward: 153.54513549804688



buy possibilites: [-1] 
expected returns: [[200.52563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 0. 3.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 23. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [0. 8. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -19.5 

action type: buy - action 1.0
Learning step: -4.690932750701904
desired expected reward: 159.8642578125






Player: 1 
cards in hand: [0. 8. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 0. 3.] 
cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  1  3  0  0  1 16  3  6  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 29. 28. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  0.  3.  6.  3.  8. 16.  0.  0. 16.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 27. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 23.  6.  0.] 
adversary cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 23.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[159.62538]
 [134.44617]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 23.  6.  0.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 27. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.326932907104492
desired expected reward: 192.19869995117188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[139.18806 ]
 [153.26921 ]
 [147.27473 ]
 [111.500725]
 [158.58148 ]
 [147.82474 ]
 [143.71954 ]
 [160.19348 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 23.  6.  0.] 
cards in discard: [ 3.  6.  0. 10.  0. 25.  3.  0.  1.  2.  0.  1.  1.  1.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 29. 27. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [3. 3. 8. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.202847957611084
desired expected reward: 152.1002960205078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 8. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 27. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 23. 29. 27. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 1.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 26. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 1.  0.  0. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  0. 25. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[132.18083]
 [140.84036]
 [122.30575]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 25. 16.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 26. 30.  8.  7.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8. 16.] 
adversary cards in discard: [3. 3. 3. 8. 3. 1.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -7.16864538192749
desired expected reward: 153.0248565673828



action possibilites: [-1] 
expected returns: [[113.57214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8. 16.] 
adversary cards in discard: [3. 3. 3. 8. 3. 1.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -50    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -335 

action type: gain_card_n - action 2
Learning step: -18.106143951416016
desired expected reward: 62.14280319213867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[112.02065 ]
 [119.00405 ]
 [115.00567 ]
 [ 96.98209 ]
 [120.363625]
 [116.91584 ]
 [113.245514]
 [118.782875]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  9. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8. 16.] 
adversary cards in discard: [3. 3. 3. 8. 3. 1.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -4.801388740539551
desired expected reward: 108.770751953125



buy possibilites: [-1] 
expected returns: [[89.11498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 25.] 
cards in discard: [ 6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6. 16.  0.  8. 16.] 
adversary cards in discard: [3. 3. 3. 8. 3. 1.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -17 

action type: buy - action 10.0
Learning step: -4.5071892738342285
desired expected reward: 108.73834228515625






Player: 1 
cards in hand: [ 6. 16.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  8. 16.] 
cards in discard: [3. 3. 3. 8. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 23.  6.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  8. 16.] 
cards in discard: [3. 3. 3. 8. 3. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 23.  6.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  8. 16.] 
cards in discard: [3. 3. 3. 8. 3. 1. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  3.  0. 23.  6.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[67.49096 ]
 [44.907955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 23.  6.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  8.  3.  1.  0.  6. 16.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -5.8668293952941895
desired expected reward: 83.24815368652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[48.907337]
 [26.454885]
 [67.130295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 23.  6.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [ 3.  3.  3.  8.  3.  1.  0.  6. 16.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 19 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: -4.785937786102295
desired expected reward: 61.114139556884766



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [ 3.  3.  3.  8.  3.  1.  0.  6. 16.  0.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  3.  8.  3.  1.  0.  6. 16.  0.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  3.  8.  3.  1.  0.  6. 16.  0.  8. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.55883]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -2.855977773666382
desired expected reward: 64.27430725097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 82.99873 ]
 [ 94.68388 ]
 [ 78.2225  ]
 [ 90.60815 ]
 [ 69.25237 ]
 [ 62.33672 ]
 [ 87.75996 ]
 [ 99.869606]
 [ 89.17976 ]
 [107.64514 ]
 [ 89.96654 ]
 [ 71.78989 ]
 [ 79.790535]
 [ 86.83529 ]
 [ 67.970245]
 [ 82.419426]
 [102.40703 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 23. 29. 26. 30.  8.  6.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -4.620063304901123
desired expected reward: 95.4037857055664



buy possibilites: [-1] 
expected returns: [[70.238495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 7 
card supply: [26. 23. 29. 26. 30.  8.  5.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -18.836469650268555
desired expected reward: 43.50025177001953






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 29. 26. 30.  8.  5.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 25. 10.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 29. 26. 30.  8.  5.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 25. 10.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 29. 26. 30.  8.  5.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  0.  3. 25. 10.] 
adversary cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[103.7091 ]
 [115.75014]
 [ 87.76298]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 25. 10.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 29. 26. 30.  8.  5.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 3.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -3.378378391265869
desired expected reward: 66.86011505126953



action possibilites: [-1] 
expected returns: [[82.39696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 10.  2.  1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 29. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 3.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   5] 
sum of rewards: -21 

action type: take_action - action 25.0
Learning step: -4.983576774597168
desired expected reward: 110.76658630371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[64.75544 ]
 [71.495346]
 [60.572014]
 [67.4891  ]
 [56.333286]
 [51.871796]
 [67.51158 ]
 [74.30487 ]
 [69.21348 ]
 [80.89683 ]
 [69.59812 ]
 [57.360367]
 [61.43304 ]
 [66.55102 ]
 [54.66916 ]
 [63.91138 ]
 [75.00606 ]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 10.  2.  1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 22. 29. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 3.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -3.797197103500366
desired expected reward: 78.59976196289062



buy possibilites: [-1] 
expected returns: [[89.495895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 10.  2.  1.] 
cards in discard: [ 6. 10. 16.  1.  0. 25.  3.  3.  0. 23.  6.  6.  1.  0.  0.  0.  1.  2.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [1. 8. 6. 3. 3.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0   20    0    0 1700    0    0    0    0
   72    0] 
sum of rewards: 1746 

action type: buy - action 2.0
Learning step: 86.2850570678711
desired expected reward: 146.8570556640625






Player: 1 
cards in hand: [1. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 6. 3. 3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 6. 3. 3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 6. 3. 3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 0. 1. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 0. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[136.21521]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16. 16.  3.  0.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -3.2193825244903564
desired expected reward: 86.2765121459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[122.317184]
 [129.89719 ]
 [117.58706 ]
 [125.63413 ]
 [112.55005 ]
 [106.66614 ]
 [125.45492 ]
 [133.21548 ]
 [127.74285 ]
 [139.78575 ]
 [128.22163 ]
 [114.13496 ]
 [118.63664 ]
 [124.82743 ]
 [110.62886 ]
 [121.88671 ]
 [134.34636 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 1. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 22. 28. 26. 30.  8.  4.  7.  9.  7.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16. 16.  3.  0.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -5.657630920410156
desired expected reward: 130.13845825195312



buy possibilites: [-1] 
expected returns: [[143.92328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 1. 0.] 
cards in discard: [8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 22. 28. 26. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16. 16.  3.  0.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3.] 
adversary owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0] -> size -> 18 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -34.0 

action type: buy - action 8.0
Learning step: -4.8488688468933105
desired expected reward: 122.89398193359375






Player: 1 
cards in hand: [ 8. 16. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 16.  3.  0.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 28. 26. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  3.  2. 25.] 
adversary cards in discard: [8. 6. 0. 1. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 28. 25. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  3.  2. 25.] 
adversary cards in discard: [8. 6. 0. 1. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 22. 28. 25. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  3.  2. 25.] 
adversary cards in discard: [8. 6. 0. 1. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  3.] 
cards in discard: [1. 8. 3. 0. 0. 0. 6. 0. 1. 8. 6. 3. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 28. 25. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 6.  6.  3.  2. 25.] 
adversary cards in discard: [8. 6. 0. 1. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  3.  2. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 95.48035 ]
 [102.109436]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  2. 25.] 
cards in discard: [8. 6. 0. 1. 1. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 28. 25. 30.  8.  4.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0] -> size -> 19 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -7.3495025634765625
desired expected reward: 136.5737762451172



action possibilites: [-1] 
expected returns: [[91.13712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 2. 3. 0.] 
cards in discard: [8. 6. 0. 1. 1. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 28. 25. 30.  8.  3.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -25 

action type: take_action - action 25.0
Learning step: -3.8852124214172363
desired expected reward: 93.20635986328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.82192 ]
 [82.7895  ]
 [77.462265]
 [45.326923]
 [75.15857 ]
 [88.15831 ]
 [77.263374]
 [78.01454 ]
 [58.40816 ]
 [73.86629 ]
 [69.14239 ]
 [90.46503 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 2. 3. 0.] 
cards in discard: [8. 6. 0. 1. 1. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 22. 28. 25. 30.  8.  3.  7.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -4.034465312957764
desired expected reward: 87.1026611328125



buy possibilites: [-1] 
expected returns: [[111.24205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 2. 3. 0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6] -> size -> 20 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  32   0] 
sum of rewards: 6 

action type: buy - action 16.0
Learning step: -0.9549831748008728
desired expected reward: 74.20359802246094






Player: 1 
cards in hand: [3. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  0. 23.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  0. 23.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [6. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  0. 23.  3.  0.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [10.  0. 23.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
expected returns: [[96.15472 ]
 [87.09529 ]
 [81.570816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 23.  3.  0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 16.] 
adversary cards in discard: [6. 0. 3. 3. 6. 0. 8.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1
Learning step: -5.299526214599609
desired expected reward: 105.94252014160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[82.15671 ]
 [86.24711 ]
 [67.500046]
 [86.92734 ]
 [93.438545]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 23.  3.  0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  0. 16.] 
adversary cards in discard: [6. 0. 3. 3. 6. 0. 8.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0] -> size -> 21 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1.0
Learning step: -4.635765075683594
desired expected reward: 91.5189437866211



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  0. 16.] 
cards in discard: [6. 0. 3. 3. 6. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 2.  1.  1. 10.  1.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 16.] 
cards in discard: [6. 0. 3. 3. 6. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  6.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 2.  1.  1. 10.  1.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3.  0. 16.] 
cards in discard: [6. 0. 3. 3. 6. 0. 8. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 2.  1.  1. 10.  1.] 
adversary cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 2.  1.  1. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.075623]
 [20.041498]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  1.  1. 10.  1.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 16.  3.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: buy - action -1.0
Learning step: -5.923854827880859
desired expected reward: 87.51469421386719



action possibilites: [-1.] 
expected returns: [[15.465532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 16.  3.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -15 

action type: take_action - action 10.0
Learning step: -1.4040993452072144
desired expected reward: 18.637378692626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[16.138372 ]
 [21.266367 ]
 [12.609272 ]
 [18.243744 ]
 [ 9.364088 ]
 [13.807627 ]
 [ 6.0471644]
 [18.39556  ]
 [21.944597 ]
 [19.832329 ]
 [28.919685 ]
 [20.02648  ]
 [ 9.926876 ]
 [13.117186 ]
 [17.33386  ]
 [ 8.13109  ]
 [15.104279 ]
 [20.428106 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 10 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  8. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 16.  3.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.0861237049102783
desired expected reward: 14.379408836364746



buy possibilites: [-1] 
expected returns: [[88.667305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 8.  6.  0.  1.  1.  0. 16. 25.  6.  6.  3.  2.  3.  0. 10.  0. 23.  3.
  0. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 16.  3.  0.] 
adversary cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.] 
adversary owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5.    0.   -1.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -3.5 

action type: buy - action 25.0
Learning step: 0.37403011322021484
desired expected reward: 29.293716430664062






Player: 1 
cards in hand: [ 1.  8. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 16.  3.  0.] 
cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  5.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
adversary victory points: -1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3.] 
cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3.] 
cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 28. 25. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3.] 
cards in discard: [ 6.  0.  3.  3.  6.  0.  8.  8.  8.  0.  3.  0. 16.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 24. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1. 25. 16.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 1. 25. 16.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 16.] 
expected returns: [[58.540466]
 [63.643528]
 [46.788166]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 16.  6.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 10  1  0  1 23  6  1  2 25 16  1 25  1  6
 10  6  2  8 16 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 24. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -5.401907920837402
desired expected reward: 83.26539611816406



action possibilites: [-1] 
expected returns: [[-7.04566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 23. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: 0 

action type: gain_card_n - action 1
Learning step: -3.325169801712036
desired expected reward: 60.00768280029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -8.100801 ]
 [ -7.3886003]
 [ -7.249138 ]
 [-14.776327 ]
 [ -6.4420643]
 [ -8.135511 ]
 [ -7.754767 ]
 [ -6.596778 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 28. 23. 30.  8.  3.  6.  9.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -0.016521645709872246
desired expected reward: -7.06218147277832



buy possibilites: [-1] 
expected returns: [[22.397493]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  0.] 
cards in discard: [ 3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 23. 30.  8.  3.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 1.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 11.0
Learning step: 1.526046872138977
desired expected reward: -4.916018009185791






Player: 1 
cards in hand: [8. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 28. 23. 30.  8.  3.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3. 25. 16.  1.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 28. 23. 30.  8.  3.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3. 25. 16.  1.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 1.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 28. 23. 30.  8.  3.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  3. 25. 16.  1.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [10.  3. 25. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 16.] 
expected returns: [[36.229996]
 [25.75195 ]
 [38.596676]
 [26.096521]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 25. 16.  1.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 28. 23. 30.  8.  3.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  3. 16.] 
adversary cards in discard: [1. 8. 3. 0. 6. 1.] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1] -> size -> 24 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -1.5401496887207031
desired expected reward: 20.857343673706055



action possibilites: [-1] 
expected returns: [[30.203058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 16.  1. 25.  0.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  3. 16.] 
adversary cards in discard: [1. 8. 3. 0. 6. 1. 6.] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 25.0
Learning step: -1.2926939725875854
desired expected reward: 37.303993225097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.322191]
 [27.47113 ]
 [22.271759]
 [-5.457777]
 [29.100561]
 [24.793324]
 [20.133427]
 [27.761269]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 16.  1. 25.  0.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  3. 16.] 
adversary cards in discard: [1. 8. 3. 0. 6. 1. 6.] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -1.1680736541748047
desired expected reward: 29.034984588623047



buy possibilites: [-1] 
expected returns: [[119.839745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 16.  1. 25.  0.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8. 16.  0.  3. 16.] 
adversary cards in discard: [1. 8. 3. 0. 6. 1. 6.] 
adversary owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1
  6] -> size -> 25 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 14 

action type: buy - action 1.0
Learning step: 2.0228383541107178
desired expected reward: 29.49396324157715






Player: 1 
cards in hand: [ 8. 16.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  3. 16.] 
cards in discard: [1. 8. 3. 0. 6. 1. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  3  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 6. 1. 0. 6.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.] 
cards in discard: [1. 8. 3. 0. 6. 1. 6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 6. 1. 0. 6.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [1. 8. 3. 0. 6. 1. 6. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 6. 1. 0. 6.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 16.] 
cards in discard: [1. 8. 3. 0. 6. 1. 6. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 6. 1. 0. 6.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [6. 6. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.887402]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 0. 6.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 8. 8. 3. 3.] 
adversary cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.] 
adversary owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -5.812020778656006
desired expected reward: 114.02772521972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[13.721748 ]
 [15.866373 ]
 [14.9699135]
 [ 9.45739  ]
 [16.82435  ]
 [15.04907  ]
 [14.502178 ]
 [17.161272 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 0. 6.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 8. 8. 3. 3.] 
adversary cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.] 
adversary owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0  0] -> size -> 26 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -0.6898303627967834
desired expected reward: 16.19757080078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 3. 3.] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  1 16  3  6  8  8  3  3  0  1  6  0  3  0  6  0  8  8  3  1  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  2.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  2.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  2.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  2.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 23.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[-12.255611]
 [ -8.458002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 23.  2.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8.] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -0.7726796269416809
desired expected reward: 16.38858985900879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -8.101358 ]
 [ -9.558468 ]
 [ -7.475309 ]
 [ -8.917208 ]
 [ -8.767082 ]
 [-11.287401 ]
 [ -8.685335 ]
 [-10.257818 ]
 [ -8.842306 ]
 [-11.10355  ]
 [ -9.083714 ]
 [ -7.0883484]
 [ -7.9032426]
 [ -8.653988 ]
 [ -7.4343376]
 [ -8.236893 ]
 [-11.469131 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 23.  2.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8.] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: 0.7289186120033264
desired expected reward: -11.526694297790527



buy possibilites: [-1] 
expected returns: [[-10.26585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 23.  2.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [6. 1. 0. 3. 3.] 
adversary cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8.] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.  0.  1. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 14.0 

action type: buy - action 15.0
Learning step: 0.8808627128601074
desired expected reward: -7.356024265289307






Player: 1 
cards in hand: [6. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  1.  2. 10.  3.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  8.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  1.  2. 10.  3.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 3. 3.] 
cards in discard: [ 1.  8.  3.  0.  6.  1.  6.  0.  0. 16.  8.  0. 16.  0.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  1.  2. 10.  3.] 
adversary cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8.  1.  2. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-7.635112 ]
 [-5.8670697]
 [-5.7111597]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  2. 10.  3.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: 0.675915002822876
desired expected reward: -9.589935302734375



action possibilites: [-1.  8.] 
expected returns: [[-6.987585 ]
 [-6.6738257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 2. 3. 1.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 28 

action type: take_action - action 10.0
Learning step: 1.533388376235962
desired expected reward: -4.177773475646973





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.6548796]
 [-6.352829 ]
 [-4.855171 ]
 [-5.5155544]
 [-5.5263305]
 [-4.7446003]
 [-6.0103436]
 [-6.54058  ]
 [-6.3293223]
 [-7.635934 ]
 [-6.4924626]
 [-5.388529 ]
 [-5.0464544]
 [-5.7229366]
 [-5.082446 ]
 [-5.468216 ]
 [-7.0196157]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 2. 3. 1.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 20. 28. 23. 30.  8.  2.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1.0
Learning step: 1.5285208225250244
desired expected reward: -5.4590606689453125



buy possibilites: [-1] 
expected returns: [[-13.989948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 2. 3. 1.] 
cards in discard: [ 3. 11. 16.  1. 25.  0.  1. 25. 10.  3. 16.  1. 25.  0.  6.  6.  1.  0.
  6. 15.  0.  0.  0. 23.  2.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 7 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -14.327544212341309
desired expected reward: -19.0721435546875






Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [16  0  1 16  8  8  3  0  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 2.  1. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 2.  1. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 2.  1. 23.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 2.  1. 23.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[45.035923]
 [32.377   ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  1. 23.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [11.  8.  3.  1.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 1.3512119054794312
desired expected reward: -12.638736724853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[41.381935]
 [48.43928 ]
 [37.287067]
 [44.866703]
 [32.410503]
 [28.073751]
 [44.391605]
 [50.969948]
 [45.944523]
 [56.860527]
 [46.317062]
 [33.67474 ]
 [38.21283 ]
 [43.390297]
 [31.122625]
 [40.57582 ]
 [51.85639 ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  1. 23.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 20. 28. 23. 30.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [11.  8.  3.  1.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.3410617113113403
desired expected reward: 42.28886032104492



buy possibilites: [-1] 
expected returns: [[48.597527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  1. 23.  3.  0.] 
cards in discard: [4.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 28. 23. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [11.  8.  3.  1.  3.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 40.5 

action type: buy - action 4.0
Learning step: 1.497920036315918
desired expected reward: 33.908409118652344






Player: 1 
cards in hand: [11.  8.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3.  1.  3.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  3  1  6  0  3  0  6  0  8  8  3  1  6  0  0  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  2. 10. 10.  3.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 23. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  2. 10. 10.  3.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 28. 23. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  2. 10. 10.  3.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [8. 0. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 0.  2. 10. 10.  3.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 0.  2. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[22.277254]
 [13.622793]
 [13.622793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  2. 10. 10.  3.] 
cards in discard: [ 4.  2.  1. 23.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 16.  3.  0.] 
adversary cards in discard: [8. 0. 3. 8. 1.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: -0.10250892490148544
desired expected reward: 48.495018005371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.462206 ]
 [19.970945 ]
 [18.331465 ]
 [ 6.8721747]
 [16.819284 ]
 [22.797302 ]
 [17.367258 ]
 [17.754343 ]
 [ 9.903221 ]
 [16.750425 ]
 [14.6297455]
 [24.955172 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 10. 10.  3.] 
cards in discard: [ 4.  2.  1. 23.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  9.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 16.  3.  0.] 
adversary cards in discard: [8. 0. 3. 8. 1.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: 1.2421623468399048
desired expected reward: 23.51942253112793



buy possibilites: [-1] 
expected returns: [[53.89782]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  2. 10. 10.  3.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 16.  3.  0.] 
adversary cards in discard: [8. 0. 3. 8. 1.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 69 

action type: buy - action 14.0
Learning step: 4.1277570724487305
desired expected reward: 14.826641082763672






Player: 1 
cards in hand: [ 8.  6. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 16.  3.  0.] 
cards in discard: [8. 0. 3. 8. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  3. 25.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 16.  3.  0.] 
cards in discard: [8. 0. 3. 8. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [ 3.  1.  0.  3. 25.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ -8.993602]
 [-12.803771]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 25.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  1.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3] -> size -> 19 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: -1.0216385126113892
desired expected reward: 52.876182556152344



action possibilites: [-1] 
expected returns: [[32.014435]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  3. 16.  1.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 60 

action type: take_action - action 25.0
Learning step: 4.360513210296631
desired expected reward: -8.443258285522461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.527233 ]
 [29.289797 ]
 [27.107134 ]
 [15.265556 ]
 [26.082905 ]
 [30.596754 ]
 [27.25185  ]
 [33.890617 ]
 [27.417023 ]
 [16.35613  ]
 [20.902617 ]
 [25.2408   ]
 [14.2451515]
 [22.711626 ]
 [30.537626 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  3. 16.  1.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  7. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 1.9440803527832031
desired expected reward: 33.95851516723633



buy possibilites: [-1] 
expected returns: [[39.845116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  3. 16.  1.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0 -2  0  0 50  0] 
sum of rewards: 106 

action type: buy - action 25.0
Learning step: 4.501983642578125
desired expected reward: 38.392608642578125






Player: 1 
cards in hand: [0. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  6.  1.  8.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  8.  9.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  6.  1.  8.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [ 8.  0.  3.  8.  1.  8.  6. 16.  3.  0.  6. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [ 0. 15.  6.  1.  8.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[21.513391]
 [17.061457]
 [21.531553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  1.  8.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1
Learning step: 0.8730491995811462
desired expected reward: 40.71816635131836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.017185]
 [16.997557]
 [15.011038]
 [16.139246]
 [17.259363]
 [14.922674]
 [14.703312]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  1.  8.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  4.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: 1.6911468505859375
desired expected reward: 23.204538345336914



buy possibilites: [-1] 
expected returns: [[24.521072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  1.  8.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  3.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [ 6.  6.  0.  1. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 50.  0.  0.  0.  0.  0.  0.  0. -3.  0.  0.  2.  0.] 
sum of rewards: 47.0 

action type: buy - action 8.0
Learning step: 2.038755178451538
desired expected reward: 19.29813575744629






Player: 1 
cards in hand: [ 6.  6.  0.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  3.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [25.  1.  0.  1.  6.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  3.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [25.  1.  0.  1.  6.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0.  1. 16.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [25.  1.  0.  1.  6.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25.  1.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[28.11904]
 [30.41192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0.  1.  6.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [1. 0. 8. 6. 8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: buy - action -1
Learning step: 1.843536376953125
desired expected reward: 26.364608764648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.526823 ]
 [18.647802 ]
 [17.147694 ]
 [ 9.945172 ]
 [16.288618 ]
 [20.383875 ]
 [16.766312 ]
 [23.518053 ]
 [16.991417 ]
 [10.769894 ]
 [13.30912  ]
 [15.8849945]
 [ 9.51391  ]
 [14.272522 ]
 [21.31856  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  1.  6.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  8.] 
adversary cards in hand: [1. 0. 8. 6. 8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: 1.4263371229171753
desired expected reward: 29.545381546020508



buy possibilites: [-1] 
expected returns: [[-1.178194]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0.  1.  6.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  7.] 
adversary cards in hand: [1. 0. 8. 6. 8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16.] 
adversary owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 22 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 50.  0.  0.  0.  0.  0.  0.  0. -4.  0.  0.  8.  0.] 
sum of rewards: 52.0 

action type: buy - action 15.0
Learning step: 1.8598641157150269
desired expected reward: 16.132394790649414






Player: 1 
cards in hand: [1. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 6. 8.] 
cards in discard: [ 8.  6.  6.  0.  1. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  6  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8.] 
cards in discard: [ 8.  6.  6.  0.  1. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 8.  6.  6.  0.  1. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  8. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 8.] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  6.  0.] 
adversary cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-12.636717]
 [-10.634806]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  6.  0.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  7.] 
adversary cards in hand: [ 0.  3.  0. 16.  8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
adversary owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: buy - action -1
Learning step: 1.7068111896514893
desired expected reward: 0.5286171436309814



action possibilites: [-1] 
expected returns: [[-9.165037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
adversary owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0 -5  0  0 16  0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 3.6010539531707764
desired expected reward: -3.5442936420440674





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-9.3213005]
 [-8.613006 ]
 [-9.04777  ]
 [-9.165032 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 28. 22. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
adversary owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 58 

action type: take_action - action -1
Learning step: 3.1590335369110107
desired expected reward: -6.006003379821777



buy possibilites: [-1] 
expected returns: [[-1.6850128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [ 4.  2.  1. 23.  3.  0. 14.  0.  2. 10. 10.  3. 25. 25.  3.  1.  0.  3.
 16.  1.  8.  0. 15.  6.  1.  8. 15. 25.  1.  0.  1.  6. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 0.  3.  0. 16.  8.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
adversary owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 3.92747163772583
desired expected reward: -4.685533046722412






Player: 1 
cards in hand: [ 0.  3.  0. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 16.  8.] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [16  1 16  8  1  0  0  6  0  8  8  3  1  6  0  0  0  3  6 14  8 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [15. 10. 14. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [15. 10. 14. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [15. 10. 14. 25. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [15. 10. 14. 25. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14. 25. 16.] 
expected returns: [[27.110487]
 [20.173136]
 [21.908897]
 [14.667875]
 [35.791595]
 [22.553326]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 14. 25. 16.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 6.  3. 14.  0.  0.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: buy - action -1
Learning step: 3.6847598552703857
desired expected reward: 1.9997470378875732



action possibilites: [-1] 
expected returns: [[3.095923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 25. 16.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 6.  3. 14.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 79 

action type: take_action - action 14.0
Learning step: 3.2862648963928223
desired expected reward: 17.954130172729492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[0.6635823]
 [2.3904958]
 [1.714602 ]
 [4.0848217]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 25. 16.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 6.  3. 14.] 
adversary cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.  0.  0.] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 79 

action type: take_action - action -1
Learning step: 3.8631515502929688
desired expected reward: 6.9590744972229






Player: 1 
cards in hand: [ 6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 14.] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [15.  6.  0.  1.  2.] 
adversary cards in discard: [14. 15. 10. 25. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [6. 1. 2.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [ 8.  6.  6.  0.  1. 16. 10.  8.  1.  0.  8.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [6. 1. 2.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [6. 1. 2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-4.4945517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 2.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  8. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   60    0    0    0  -90    0 3400    0   -6    0 -300
  347    0] 
sum of rewards: 3410 

action type: discard_down_to_3_cards - action 5
Learning step: 170.3542938232422
desired expected reward: 171.24615478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-6.1628513]
 [-5.58097  ]
 [-5.4204626]
 [-7.6167946]
 [-6.002185 ]
 [-5.6297174]
 [-6.216658 ]
 [-4.4597244]
 [-6.287431 ]
 [-5.3415337]
 [-5.038279 ]
 [-5.8158283]
 [-5.1470118]
 [-5.94528  ]
 [-5.93705  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 2.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  6. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  8. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 3.0575637817382812
desired expected reward: -1.4369878768920898



buy possibilites: [-1] 
expected returns: [[-3.705754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 2.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  5. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [ 1.  8. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0  0  0  0  0  0 -7  0  0 50  0] 
sum of rewards: 102 

action type: buy - action 25.0
Learning step: 5.239606857299805
desired expected reward: 0.7798795700073242






Player: 1 
cards in hand: [ 1.  8. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 10.  0.  1.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  5. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 15. 23.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  1. 16.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  5. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 15. 23.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [16  8  1  6  0  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 15. 23.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 15. 23.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 16.  8.] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [25.  1.  1. 15. 23.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [25.  1.  1. 15. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 23.] 
expected returns: [[-22.305012]
 [-25.6913  ]
 [-24.562529]
 [-23.977873]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1. 15. 23.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: buy - action -1
Learning step: 2.6100053787231445
desired expected reward: -1.0957486629486084



action possibilites: [-1. 25. 15.] 
expected returns: [[ 6.9644794]
 [ 9.532862 ]
 [-1.5957491]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1. 15.  0.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10
  6  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 42 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 80 

action type: take_action - action 23.0
Learning step: 5.3549275398254395
desired expected reward: -18.62294578552246



action possibilites: [-1] 
expected returns: [[55.86853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  1.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 99 

action type: take_action - action 15.0
Learning step: 6.286829471588135
desired expected reward: 4.691084384918213





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.723618]
 [50.74267 ]
 [45.42163 ]
 [49.814293]
 [41.819084]
 [45.040047]
 [48.425713]
 [52.866074]
 [48.680794]
 [55.224396]
 [48.905495]
 [43.084053]
 [46.090767]
 [48.4663  ]
 [41.705246]
 [46.901855]
 [54.20942 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25] -> size -> 41 
action values: 0 
buys: 2 
player value: 8 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  6.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 99 

action type: take_action - action -1
Learning step: 3.305210828781128
desired expected reward: 59.17374038696289



buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-7.9267144]
 [-4.228861 ]
 [-4.183671 ]
 [-6.769806 ]
 [-0.572881 ]
 [-7.125535 ]
 [-6.8145895]
 [-8.640997 ]
 [-6.1144886]
 [-7.0243654]
 [ 2.9198604]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 60  0  0 40  0  0  0  0 -7  0  0 16  0] 
sum of rewards: 108 

action type: buy - action 15.0
Learning step: 3.017477512359619
desired expected reward: 49.919349670410156



buy possibilites: [-1] 
expected returns: [[-10.028577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  1.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [23. 15.] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 19. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [14.  6.  0.  8.  0.] 
adversary cards in discard: [25. 10. 16.  8.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  60.   0.   0.  40.   0.   0.   0.   0.  -8.   0.   0.
  4.5  0. ] 
sum of rewards: 95.5 

action type: buy - action 1.0
Learning step: 4.760800838470459
desired expected reward: 0.5319199562072754






Player: 1 
cards in hand: [14.  6.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  8.  0.] 
cards in discard: [25. 10. 16.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  8.  0.] 
cards in discard: [25. 10. 16.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 19. 28. 21. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  8.  0.] 
cards in discard: [25. 10. 16.  8.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 43 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[0.7918546 ]
 [0.5312865 ]
 [0.37083483]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 10  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6
  2  8 16 25  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [8. 6. 6. 1. 0.] 
adversary cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25  3] -> size -> 17 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: 2.966336727142334
desired expected reward: -7.062240123748779



action possibilites: [-1] 
expected returns: [[9.222524]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [8. 6. 6. 1. 0.] 
adversary cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25  3] -> size -> 17 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: trash_cards_n_from_hand - action 8
Learning step: 3.563667058944702
desired expected reward: 4.529468536376953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[6.1134186]
 [8.082619 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [8. 6. 6. 1. 0.] 
adversary cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
adversary owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25  3] -> size -> 17 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 69 

action type: take_action - action -1
Learning step: 3.1581265926361084
desired expected reward: 12.380650520324707






Player: 1 
cards in hand: [8. 6. 6. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6. 1. 0.] 
cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  6  8  8  1  6  0  0  0  3  6 14  8 10 25  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3.  3.  6.  8. 25.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
adversary owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3.  3.  6.  8. 25.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
adversary owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 10. 16.  8.  3. 14.  6.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3.  3.  6.  8. 25.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
adversary owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  6.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-4.0559406]
 [-3.096441 ]
 [-4.481202 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  6.  8. 25.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  1  0  1 23  6  1  2 25 16  1 25  1  6 10  6  2  8 16 25
  3 11  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 29 

action type: buy - action -1.0
Learning step: 0.9661943316459656
desired expected reward: 9.048812866210938



action possibilites: [-1] 
expected returns: [[-4.360762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: trash_cards_n_from_hand - action 6
Learning step: 2.4279873371124268
desired expected reward: 0.905901312828064





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.2340665]
 [-4.886412 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 25.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 3. 25.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: 2.543064832687378
desired expected reward: -1.817697286605835






Player: 1 
cards in hand: [ 3. 25.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0  0  3  6 14  8 10 25  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  2.  1. 16.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  0  6 14  8 10  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  2.  1. 16.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  0  6 14  8 10  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  2.  1. 16.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  0  6 14  8 10  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  2.  1. 16.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 1.  2.  1. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[41.550793]
 [40.044205]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  2.  1. 16.  3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1  2 25 16  1 25  1  6 10  6  2  8 16 25  3 11
  1 15  6  4 14 25  8 15 15  3 25 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4. 10.  7.  9.  7. 10.  5.] 
adversary cards in hand: [10.  0.  0.  8.  8.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [16  8  8  8  0  0  0  6 14  8 10  3  0] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 3.1195685863494873
desired expected reward: -1.7668430805206299



action possibilites: [-1] 
expected returns: [[7.8544865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [10.  0.  0.  8.  8.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [16  8  8  8  0  0  0  6 14  8 10  3  0] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 73 

action type: gain_card_n - action 10
Learning step: 4.1943359375
desired expected reward: -3.157870292663574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 2.5226936]
 [ 7.3758516]
 [ 5.7884293]
 [ 4.533522 ]
 [ 9.641216 ]
 [ 5.204611 ]
 [ 5.409337 ]
 [-0.5615647]
 [ 4.3705597]
 [ 2.5512547]
 [10.453796 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [10.  0.  0.  8.  8.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [16  8  8  8  0  0  0  6 14  8 10  3  0] -> size -> 13 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 2.7253243923187256
desired expected reward: 10.579811096191406






Player: 1 
cards in hand: [10.  0.  0.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  8.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0  0  6 14  8 10  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0.  4. 11.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  6 14  8  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0.  4. 11.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  6 14  8  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0.  4. 11.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 0.  0.  4. 11.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
adversary victory points: 4
player victory points: 0 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  4. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-12.578986]
 [-12.505584]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  4. 11.  3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 28. 20. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  8. 14.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 1.1454647779464722
desired expected reward: 11.599261283874512



action possibilites: [-1] 
expected returns: [[-17.484177]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  8. 14.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0 -3  0  0  4  0] 
sum of rewards: 71 

action type: gain_card_n - action 2
Learning step: 3.7397632598876953
desired expected reward: -7.923381805419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-15.034502]
 [-15.254899]
 [-16.326813]
 [-17.48674 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  2.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  8. 14.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 4.0232415199279785
desired expected reward: -13.460935592651367



buy possibilites: [-1] 
expected returns: [[-9.539673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 4. 3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 8.  8. 14.  6. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0 -4  0  0  8  0] 
sum of rewards: 74 

action type: buy - action 8.0
Learning step: 4.301698207855225
desired expected reward: -12.025117874145508






Player: 1 
cards in hand: [ 8.  8. 14.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 14.  6. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0  6 14  8  3  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  9.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  6.  6. 25.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  0  0  6  8  3  0  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  6.  6. 25.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  0  0  6  8  3  0  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  6.  6. 25.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  0  0  6  8  3  0  0 29  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [ 1.  6.  6. 25.  3.] 
adversary cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8. 11.  0.  0.  4.  3.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  6. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[6.199315]
 [5.675665]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  6. 25.  3.] 
cards in discard: [14. 15. 10. 25. 16. 15.  0. 25.  6.  1.  2. 15.  1. 23. 15. 25.  1.  1.
  8.  8.  3. 25. 29. 16.  1.  1.  3.  3.  8. 11.  0.  0.  4.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  8.  6.] 
adversary owned cards: [16  8  8  8  0  0  6  8  3  0  0 29  0] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 3.1131160259246826
desired expected reward: -6.426556587219238



action possibilites: [-1] 
expected returns: [[10.675526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  6.  3. 25.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  8.  6.] 
adversary owned cards: [16  8  8  8  0  0  6  8  3  0  0 29  0] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action 25.0
Learning step: 3.280060291290283
desired expected reward: 12.482841491699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[4.4181824]
 [5.496728 ]
 [4.6427183]
 [7.940527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  6.  3. 25.  8.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [29.  0. 16.  8.  8.  6.] 
adversary owned cards: [16  8  8  8  0  0  6  8  3  0  0 29  0] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 3.1152331829071045
desired expected reward: 13.790759086608887






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [29.  0. 16.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  0  0  6  8  3  0  0 29  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [15. 11.  4. 25.  0.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [29.  0. 16.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [15. 11.  4. 25.  0.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.  0. 16.  8.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [15. 11.  4. 25.  0.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [29.  0. 16.  8.  8.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [15. 11.  4. 25.  0.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [15. 11.  4. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25.] 
expected returns: [[74.14309 ]
 [63.465836]
 [74.35451 ]
 [80.02    ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  4. 25.  0.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 3.817870855331421
desired expected reward: 11.758401870727539



action possibilites: [-1] 
expected returns: [[26.673811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  4.  0.  2.  1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  5] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0.33920976519584656
desired expected reward: 80.5582275390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.160635 ]
 [33.39604  ]
 [16.031412 ]
 [27.795599 ]
 [10.8740425]
 [26.850397 ]
 [38.441643 ]
 [28.653236 ]
 [43.59268  ]
 [29.323835 ]
 [11.407551 ]
 [17.1547   ]
 [25.225136 ]
 [ 9.259063 ]
 [20.580925 ]
 [38.01651  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  4.  0.  2.  1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  5.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 2.908106565475464
desired expected reward: 29.58191680908203



buy possibilites: [-1] 
expected returns: [[5.465934]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  4.  0.  2.  1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 50.  0.  0. 20.  0.  0.  0.  0. -5.  0.  0.  8.  0.] 
sum of rewards: 73.0 

action type: buy - action 15.0
Learning step: 2.743939161300659
desired expected reward: 23.3248233795166






Player: 1 
cards in hand: [0. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  1.  1.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  1.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  1.  1.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 8.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6. 29.  0.  1.  1.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6. 29.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-16.50232 ]
 [-15.105861]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  1.  1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [29.  8. 16.  6.  8.] 
adversary cards in discard: [8. 0. 8. 3. 0. 8.] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 1.8778818845748901
desired expected reward: 7.343815803527832



action possibilites: [-1.] 
expected returns: [[-2.7814093]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [29.  8. 16.  6.  8.] 
adversary cards in discard: [8. 0. 8. 3. 0. 8.] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: discard_n_cards - action 6
Learning step: 4.087032794952393
desired expected reward: -8.905252456665039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-2.1130927 ]
 [-1.0847867 ]
 [-0.27493358]
 [-1.5459865 ]
 [-0.6937742 ]
 [-1.9079115 ]
 [-3.6379342 ]
 [-1.3305383 ]
 [-1.9984442 ]
 [-3.178026  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 19. 28. 19. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [29.  8. 16.  6.  8.] 
adversary cards in discard: [8. 0. 8. 3. 0. 8.] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 3.613658905029297
desired expected reward: 0.832249641418457



buy possibilites: [-1] 
expected returns: [[45.660828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [29.  8. 16.  6.  8.] 
adversary cards in discard: [8. 0. 8. 3. 0. 8.] 
adversary owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 60.  0.  0. 20.  0.  0.  0.  0. -6.  0.  0.  2.  0.] 
sum of rewards: 77.0 

action type: buy - action 3.0
Learning step: 4.891115665435791
desired expected reward: 4.616178512573242






Player: 1 
cards in hand: [29.  8. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 16.  6.  8.] 
cards in discard: [8. 0. 8. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  6  8  3  0  0 29  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [15. 14. 16.  3. 15.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8. 0. 8. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [15. 14. 16.  3. 15.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 0. 8. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [15. 14. 16.  3. 15.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [15. 14. 16.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 16. 15.] 
expected returns: [[52.446022]
 [43.226097]
 [39.597946]
 [45.057816]
 [43.226097]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14. 16.  3. 15.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 1.3479572534561157
desired expected reward: 47.008785247802734



action possibilites: [-1] 
expected returns: [[9.652719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  3. 15.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action 14.0
Learning step: 1.787287950515747
desired expected reward: 41.385250091552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[6.689433 ]
 [7.8903866]
 [9.796463 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  3. 15.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: 3.266389846801758
desired expected reward: 12.919108390808105






Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 3 0 0 0 0 8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 8.  3. 25.  1. 10.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 0 0 8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 8.  3. 25.  1. 10.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 0 0 8] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 8.  3. 25.  1. 10.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 8 3 0 0 8 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 8.  3. 25.  1. 10.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
adversary owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 25.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 10.] 
expected returns: [[-10.595859]
 [-10.737276]
 [-11.134307]
 [ -9.109516]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 25.  1. 10.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  1  0  1 23  1 25 16  1 25  1  6 10  6  2  8 16 25  3 11  1
 15  6  4 14 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 3 0 0 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1.0
Learning step: 1.8387640714645386
desired expected reward: 11.635228157043457



action possibilites: [-1] 
expected returns: [[44.524437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 3 0 0 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: trash_cards_n_from_hand - action 14
Learning step: 4.3698506355285645
desired expected reward: -2.9911656379699707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[29.287561]
 [44.482384]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 8 3 0 0 8 0] -> size -> 8 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: 1.6773594617843628
desired expected reward: 46.20179748535156






Player: 1 
cards in hand: [0. 8. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 8 3 0 0 8 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  8. 16.  3. 23.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
adversary owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0 8 0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  8. 16.  3. 23.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
adversary owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0 8 0] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  8. 16.  3. 23.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
adversary owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 0 0 8 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  8. 16.  3. 23.] 
adversary cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
adversary owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 16.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 23.] 
expected returns: [[-19.81515 ]
 [-20.437069]
 [-20.283602]
 [-20.596704]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3. 23.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 8 0 0] -> size -> 7 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -0.6759527325630188
desired expected reward: 43.80644989013672



action possibilites: [-1.  8. 16. 15.] 
expected returns: [[-29.105558]
 [-30.08123 ]
 [-30.491018]
 [-29.10536 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3. 15.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  0  1 23  1 16  1 25  1  6  6  2  8 16 25  3 11  1 15  6  4 14
 25  8 15 15  3 25 15  1 29  3  8 15  3] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 8 0 0] -> size -> 7 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action 23.0
Learning step: 3.3674049377441406
desired expected reward: -17.229299545288086



action possibilites: [-1] 
expected returns: [[-5.5492325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 8 0 0] -> size -> 7 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: trash_cards_n_from_hand - action 7
Learning step: 5.275025844573975
desired expected reward: -22.722646713256836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-8.866743 ]
 [-7.842471 ]
 [-6.5352526]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [25.  1.  6.  6.  3. 25.  8. 15. 25. 15. 11.  4.  0.  2.  1.  1.  3.  3.
 29.  6.  0.  1. 14. 15. 16.  3. 15.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
action values: 0 
buys: 2 
player value: 2 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0 0 8 0 0] -> size -> 7 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action -1
Learning step: 4.114889144897461
desired expected reward: -1.4343433380126953






Player: 1 
cards in hand: [0. 8. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0 0 8 0 0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6.  3.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6.  3.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 8 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [ 6.  3.  1. 25.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  1. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-10.795412]
 [-10.247572]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1. 25.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: 2.0975024700164795
desired expected reward: -4.437749862670898



action possibilites: [-1] 
expected returns: [[-6.646859]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 61 

action type: take_action - action 25.0
Learning step: 3.3985512256622314
desired expected reward: -6.563559532165527





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-8.516382 ]
 [-7.635083 ]
 [-6.410737 ]
 [-8.944321 ]
 [-8.180165 ]
 [-6.0099306]
 [-6.2320185]
 [-8.644811 ]
 [-8.185523 ]
 [-7.149805 ]
 [-7.1234226]
 [-8.172955 ]
 [-7.3818417]
 [-4.4674835]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1.  1. 25.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  7.  9.  7. 10.  4.] 
adversary cards in hand: [8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: 3.194777250289917
desired expected reward: -3.4520819187164307



buy possibilites: [-1] 
expected returns: [[-9.596477]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1.  1. 25.  0.] 
cards in discard: [14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 8 0] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 40.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  8.  0.] 
sum of rewards: 67.0 

action type: buy - action 14.0
Learning step: 3.543355703353882
desired expected reward: -4.642168998718262






Player: 1 
cards in hand: [8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 8 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  6. 15.  1. 16.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3 14] -> size -> 36 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  6. 15.  1. 16.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3 14] -> size -> 36 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 0.  6. 15.  1. 16.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.] 
adversary owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3 14] -> size -> 36 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 15.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[-2.4420085]
 [-1.936693 ]
 [-1.676682 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  1. 16.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  1 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8
 15 15  3 25 15  1 29  3  8 15  3 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 2.935136318206787
desired expected reward: -6.661340236663818



action possibilites: [-1] 
expected returns: [[56.263985]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  50   0   0  20 -30   0   0   0  -1   0   0   0   0] 
sum of rewards: 39 

action type: gain_card_n - action 0
Learning step: 2.8823628425598145
desired expected reward: 9.553903579711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[47.3668  ]
 [55.141403]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 1.8777118921279907
desired expected reward: 58.14169692993164






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [29.  1.  0.  3. 11.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [29.  1.  0.  3. 11.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [29.  1.  0.  3. 11.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [29.  1.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[ -9.883954 ]
 [-10.1129675]
 [ -9.523022 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  3. 11.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -0.6239525079727173
desired expected reward: 57.43536376953125



action possibilites: [-1. 11.  8.] 
expected returns: [[24.606249]
 [23.786224]
 [21.322254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: discard_n_cards - action 7
Learning step: 4.425079822540283
desired expected reward: -3.3540005683898926





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[18.693245]
 [20.714113]
 [24.618095]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 2.7816474437713623
desired expected reward: 27.387893676757812






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  8.  4. 15. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  8.  4. 15. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  8.  4. 15. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  4. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 25.] 
expected returns: [[ -8.338184]
 [-16.158556]
 [-14.590034]
 [-10.990251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  4. 15. 25.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 1.0280392169952393
desired expected reward: 25.646116256713867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-16.270935]
 [-11.246135]
 [ -8.342999]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  4. 15. 25.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 2.684727430343628
desired expected reward: -5.688663482666016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  3. 15.  3. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  3. 15.  3. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  3. 15.  3. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  3. 15.  3. 25.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 15.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-7.444992]
 [-8.792314]
 [-9.016084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.  3. 25.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 2.7371826171875
desired expected reward: -5.605818748474121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-9.019253 ]
 [-7.7727575]
 [-7.3992624]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 15.  3. 25.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 2.697258472442627
desired expected reward: -4.7477335929870605



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 2.  3. 15. 14.  6.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 2.  3. 15. 14.  6.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 2.  3. 15. 14.  6.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [ 2.  3. 15. 14.  6.] 
adversary cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 2.  3. 15. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[ 4.9232693]
 [ 1.2900174]
 [-1.5197865]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 15. 14.  6.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 2.9377331733703613
desired expected reward: -4.461527347564697



action possibilites: [-1] 
expected returns: [[38.903313]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2.  3. 15.  6.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action 14.0
Learning step: 4.451314449310303
desired expected reward: 2.931523561477661





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[23.469154]
 [28.247473]
 [27.026505]
 [18.383852]
 [25.494162]
 [30.781338]
 [33.295815]
 [26.194366]
 [19.723536]
 [22.798662]
 [25.494562]
 [18.231688]
 [23.684944]
 [32.622646]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 15.  6.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  6.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 2.2027587890625
desired expected reward: 41.10607147216797



buy possibilites: [-1] 
expected returns: [[45.708675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2.  3. 15.  6.] 
cards in discard: [14. 25.  6.  3.  1.  1. 25.  0.  0. 16.  0.  6. 15.  1.  3. 29.  0. 11.
  8.  1.  8.  4. 15. 25.  1.  3. 15.  3. 25. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 50.  0.  0. 20.  0.  0.  0.  0. -2.  0.  0.  8.  0.] 
sum of rewards: 76.0 

action type: buy - action 14.0
Learning step: 3.8422696590423584
desired expected reward: 23.565778732299805






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 15. 25.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 15. 25.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 15. 25.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 15. 25.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0. 15. 25.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.  8. 23.] 
expected returns: [[-14.448462]
 [-13.714794]
 [-15.092553]
 [-15.212718]
 [-13.129466]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 25.  8. 23.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15
 15  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: -0.09126873314380646
desired expected reward: 45.61740493774414



action possibilites: [-1] 
expected returns: [[-5.972907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 23.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action 15.0
Learning step: 4.035313129425049
desired expected reward: -9.358753204345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-8.437174 ]
 [-7.097908 ]
 [-6.8659143]
 [-5.8514147]
 [-7.645158 ]
 [-5.8146763]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8. 23.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 19. 28. 18. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 3.6532533168792725
desired expected reward: -2.3196537494659424



buy possibilites: [-1] 
expected returns: [[-6.9659343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8. 23.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 60.  0.  0. 20.  0.  0.  0.  0. -2.  0.  0.  2.  0.] 
sum of rewards: 81.0 

action type: buy - action 3.0
Learning step: 4.217427730560303
desired expected reward: -2.648484706878662






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 14.  1.] 
adversary cards in discard: [ 3. 15. 25.  8. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 14.  1.] 
adversary cards in discard: [ 3. 15. 25.  8. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 14.  1.] 
adversary cards in discard: [ 3. 15. 25.  8. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 0. 16.  1. 14.  1.] 
adversary cards in discard: [ 3. 15. 25.  8. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  1. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[-4.5067487]
 [-5.7947717]
 [-5.3715014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1. 14.  1.] 
cards in discard: [ 3. 15. 25.  8. 23.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 3.290926694869995
desired expected reward: -3.6750075817108154





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-6.1840515]
 [-5.389262 ]
 [-4.7000217]
 [-6.064389 ]
 [-5.87961  ]
 [-4.599069 ]
 [-5.0474157]
 [-6.1946297]
 [-5.6441894]
 [-5.449979 ]
 [-5.3506613]
 [-5.40125  ]
 [-5.666003 ]
 [-5.1340895]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1. 14.  1.] 
cards in discard: [ 3. 15. 25.  8. 23.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  7.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 3.150831937789917
desired expected reward: -1.16068434715271



buy possibilites: [-1] 
expected returns: [[5.8211484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1. 14.  1.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5.   0.   6.  60.   0.   0.   0.   0.   0.   0.   0.  -3.   0.   0.
  4.5  0. ] 
sum of rewards: 62.5 

action type: buy - action 11.0
Learning step: 3.485929250717163
desired expected reward: -1.11313796043396






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [2. 1. 8. 6. 3.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [2. 1. 8. 6. 3.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [2. 1. 8. 6. 3.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [2. 1. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[6.20987  ]
 [3.7752204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 8. 6. 3.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 2.824302911758423
desired expected reward: 8.645451545715332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-7.790125 ]
 [-7.9510536]
 [-7.414657 ]
 [-6.4473495]
 [-7.8670306]
 [-7.5369387]
 [-8.170294 ]
 [-8.077349 ]
 [-6.5400567]
 [-7.182544 ]
 [-7.469377 ]
 [-5.8627005]
 [-7.3557353]
 [-6.908538 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 8. 6. 3.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 2.7196197509765625
desired expected reward: 6.314128875732422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [11. 15. 25.  3.  6.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [11. 15. 25.  3.  6.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [11. 15. 25.  3.  6.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [11. 15. 25.  3.  6.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [11. 15. 25.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25.] 
expected returns: [[-3.330677 ]
 [-3.2892516]
 [-2.8593845]
 [-3.0857716]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 25.  3.  6.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 3.322592258453369
desired expected reward: -3.585944652557373



action possibilites: [-1] 
expected returns: [[27.838923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  6.  0.  0.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  2] 
sum of rewards: 83 

action type: take_action - action 25.0
Learning step: 4.931604862213135
desired expected reward: 1.8270213603973389





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.681656]
 [25.142874]
 [28.211351]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  3.  6.  0.  0.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 3.2561142444610596
desired expected reward: 31.09503746032715



buy possibilites: [-1] 
expected returns: [[22.95239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  3.  6.  0.  0.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  60.   0.   0.  20. -30.   0.   0.   0.  -4.   0.   0.
   0.   0.] 
sum of rewards: 47.0 

action type: buy - action 0.0
Learning step: 1.7323464155197144
desired expected reward: 24.41399383544922






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [29.  6.  8.  3. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [29.  6.  8.  3. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [29.  6.  8.  3. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [29.  6.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 15.] 
expected returns: [[ 2.6040597 ]
 [ 0.19175911]
 [ 0.1410582 ]
 [-1.667079  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  8.  3. 15.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 1.931695580482483
desired expected reward: 24.88408660888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.5693815]
 [ 2.698639 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  8.  3. 15.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0] -> size -> 39 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 7. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 2.953193426132202
desired expected reward: 5.557262420654297



buy possibilites: [-1] 
expected returns: [[26.312193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6.  8.  3. 15.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  60   0   0   0 -30   0   0   0  -5   0   0   0   0] 
sum of rewards: 26 

action type: buy - action 0.0
Learning step: 1.9704923629760742
desired expected reward: 0.4011279344558716






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  4. 25. 25. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  4. 25. 25. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  4. 25. 25. 15.] 
adversary cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 1.  4. 25. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 15.] 
expected returns: [[-11.630083]
 [ -9.558918]
 [ -9.558918]
 [ -8.963953]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  4. 25. 25. 15.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 1.5203588008880615
desired expected reward: 27.832551956176758



action possibilites: [-1] 
expected returns: [[18.800253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  4. 25. 15.  3. 14.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action 25.0
Learning step: 4.950951099395752
desired expected reward: -4.607957363128662





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.954414]
 [14.561605]
 [18.800251]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  4. 25. 15.  3. 14.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 3.481419086456299
desired expected reward: 22.28167152404785



buy possibilites: [-1] 
expected returns: [[25.726967]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  4. 25. 15.  3. 14.] 
cards in discard: [ 3. 15. 25.  8. 23. 11.  0. 16.  1. 14.  1.  2.  1.  8.  6.  3.  0. 25.
 11. 15.  3.  6.  0.  0.  0. 29.  6.  8.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5.   0.   6.  60.   0.   0.  20. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: 45.0 

action type: buy - action 0.0
Learning step: 2.271261215209961
desired expected reward: 13.225671768188477






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  6.  3. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  6.  3. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  6.  3. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1.  6.  3. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-16.719482]
 [-40.666107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  3. 14.  1.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1
Learning step: 1.1888887882232666
desired expected reward: 26.915855407714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-23.86779 ]
 [-14.10941 ]
 [-15.386992]
 [-19.72739 ]
 [ -9.636587]
 [-19.461227]
 [-32.634186]
 [-20.075459]
 [-23.793522]
 [ -8.686899]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  3. 14.  1.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: take_action - action -1.0
Learning step: 3.657768964767456
desired expected reward: -14.980463981628418



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1. 25.  1.  8. 15.] 
adversary cards in discard: [ 1.  6.  3. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1. 25.  1.  8. 15.] 
adversary cards in discard: [ 1.  6.  3. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [ 1. 25.  1.  8. 15.] 
adversary cards in discard: [ 1.  6.  3. 14.  1.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
adversary victory points: 6
player victory points: 0 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 1. 25.  1.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 15.] 
expected returns: [[ 0.41209745]
 [ 1.1603575 ]
 [-3.7771153 ]
 [-3.3912592 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  8. 15.] 
cards in discard: [ 1.  6.  3. 14.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 61 

action type: buy - action -1.0
Learning step: 3.4394562244415283
desired expected reward: -5.247437477111816



action possibilites: [-1] 
expected returns: [[6.4289007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25.  1.  8.] 
cards in discard: [ 1.  6.  3. 14.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action 15.0
Learning step: 4.405789852142334
desired expected reward: 0.18299627304077148





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 1.8696404]
 [ 4.537228 ]
 [ 4.2314   ]
 [ 4.2796516]
 [ 4.4063406]
 [ 4.432679 ]
 [-4.53427  ]
 [ 4.126742 ]
 [ 1.5349941]
 [ 3.4151812]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  1.  8.] 
cards in discard: [ 1.  6.  3. 14.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  5.  9.  7. 10.  4.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 81 

action type: take_action - action -1
Learning step: 3.808783769607544
desired expected reward: 10.23768424987793



buy possibilites: [-1] 
expected returns: [[-3.6563852]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 25.  1.  8.] 
cards in discard: [ 1.  6.  3. 14.  1. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[-5  0  6 60  0  0 20  0  0  0  0 -7  0  0 32  0] 
sum of rewards: 106 

action type: buy - action 14.0
Learning step: 5.44444465637207
desired expected reward: 0.9101810455322266






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [29. 15.  3.  3. 23.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 2. 19. 28. 17. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [29. 15.  3.  3. 23.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
adversary victory points: 6
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [29. 15.  3.  3. 23.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [29. 15.  3.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 23.] 
expected returns: [[11.718728 ]
 [ 8.532355 ]
 [ 4.7521977]
 [ 3.8894782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3.  3. 23.] 
cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: 2.9394896030426025
desired expected reward: -0.716895580291748





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 5.0549974]
 [11.287996 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  3.  3. 23.] 
cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14] -> size -> 42 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: 2.1783359050750732
desired expected reward: 13.893187522888184



buy possibilites: [-1] 
expected returns: [[-0.05854964]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  3.  3. 23.] 
cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   6  50   0   0   0 -30   0   0   0  -8   0   0   0   0] 
sum of rewards: 13 

action type: buy - action 0.0
Learning step: 0.39593273401260376
desired expected reward: 5.450931072235107






Player: 1 
cards in hand: [8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [ 3. 14. 16.  0.  2.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.  0. 29. 15.  3.  3. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14  0] -> size -> 43 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [ 3. 14. 16.  0.  2.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.  0. 29. 15.  3.  3. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14  0] -> size -> 43 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [ 3. 14. 16.  0.  2.] 
adversary cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.  0. 29. 15.  3.  3. 23.] 
adversary owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14  0] -> size -> 43 
adversary victory points: 6
player victory points: 1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 7 
Gold: 2 
Estate: 3 
Duchy: 1 
Province: 0 
Curse: 4 

Remodel: 2 
Workshop: 2 
Chapel: 3 
Witch: 5 
Poacher: 0 
Militia: 4 
Market: 1 
Village: 2 
Library: 0 
Moneylender: 4 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 3. 14. 16.  0.  2.] 
cards in discard: [ 1.  6.  3. 14.  1. 14. 15.  1. 25.  1.  8.  0. 29. 15.  3.  3. 23.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 23  1  1 25  1  6  6  2  8 16 25  3 11  1  6  4 14 25  8 15 15
  3 25 15  1 29  3  8 15  3 14  0 14  3 11  0  0  0 14  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 19. 28. 16. 29.  8.  0.  6.  6.  0.  4.  8.  4.  9.  7. 10.  4.] 
adversary cards in hand: [] 
adversary cards in discard: [0.] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5 500   6  60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 561 

action type: buy - action -1
Learning step: 28.052927017211914
desired expected reward: 27.99437713623047



