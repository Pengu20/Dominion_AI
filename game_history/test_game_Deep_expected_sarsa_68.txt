 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[74.207405]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0       20        0
        0        0        0     -120        0        0        0        0] 
sum of rewards: -3000315 

action type: buy - action 0.0
Learning step: -120008.2734375
desired expected reward: -120116.2734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.1982  ]
 [83.771126]
 [68.47163 ]
 [22.950811]
 [74.485374]
 [87.81705 ]
 [76.85491 ]
 [99.16729 ]
 [41.278454]
 [61.975796]
 [66.185616]
 [73.66836 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 77.017333984375



buy possibilites: [-1] 
expected returns: [[77.96754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 99.16730499267578






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[88.56599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.96753692626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 74.251884]
 [ 98.21649 ]
 [ 84.090866]
 [ 40.21718 ]
 [101.87612 ]
 [ 91.99827 ]
 [ 77.872665]
 [ 89.07404 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 88.36150360107422



buy possibilites: [-1] 
expected returns: [[72.11684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.87613677978516






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.965237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.11683654785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[49.53895 ]
 [75.96427 ]
 [60.014294]
 [13.546732]
 [80.32737 ]
 [68.6369  ]
 [53.397858]
 [65.39428 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 65.64215850830078



buy possibilites: [-1] 
expected returns: [[63.144764]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 80.3273696899414






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 75.27239 ]
 [101.421715]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.1447639465332



action possibilites: [-1. 11.] 
expected returns: [[ 87.99758 ]
 [101.950356]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.76665496826172



action possibilites: [-1] 
expected returns: [[105.02068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.5661392211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 91.86203 ]
 [117.76702 ]
 [102.50726 ]
 [ 55.093826]
 [108.714134]
 [121.6934  ]
 [111.04819 ]
 [132.57335 ]
 [ 74.25514 ]
 [ 95.78844 ]
 [100.16014 ]
 [107.98499 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 105.02068328857422



buy possibilites: [-1] 
expected returns: [[73.84745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 3. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 132.57334899902344






Player: 1 
cards in hand: [1. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.72191]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.84745025634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[54.98992 ]
 [79.74035 ]
 [65.15875 ]
 [19.85505 ]
 [83.48727 ]
 [73.318436]
 [58.736843]
 [70.37911 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  8. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.6607437133789



buy possibilites: [-1] 
expected returns: [[61.765705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 83.48726654052734






Player: 1 
cards in hand: [ 0. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0. 11.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[60.824665]
 [84.69548 ]
 [74.329704]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 11.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -365 

action type: buy - action -1
Learning step: 0
desired expected reward: 61.76570510864258



action possibilites: [-1. 11. 11.] 
expected returns: [[ 93.24664]
 [105.57917]
 [105.57917]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11. 11.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 84.17948150634766



action possibilites: [-1] 
expected returns: [[88.94399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 119.30626678466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 78.98466 ]
 [102.571304]
 [ 88.67221 ]
 [ 47.746746]
 [ 94.33485 ]
 [106.14045 ]
 [ 96.45288 ]
 [115.77703 ]
 [ 63.76002 ]
 [ 82.55378 ]
 [ 86.527756]
 [ 93.61275 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  8. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.9439926147461



buy possibilites: [-1] 
expected returns: [[84.81869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [11.  3.  3.  0.  0.  0.  6. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 115.77706146240234






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7. 10.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 3. 25.  0.  3.  0.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[42.472248]
 [64.00965 ]
 [31.606459]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.81868743896484



action possibilites: [-1. 10. 29.] 
expected returns: [[56.76903 ]
 [46.653484]
 [76.85581 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 63.305538177490234



action possibilites: [-1. 10.] 
expected returns: [[70.155975]
 [60.15848 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 76.8558120727539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[57.4268  ]
 [79.61397 ]
 [65.479126]
 [33.14763 ]
 [71.1872  ]
 [83.26701 ]
 [73.37095 ]
 [93.0795  ]
 [45.805405]
 [60.024815]
 [63.51106 ]
 [70.592766]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  6.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 70.1559829711914



buy possibilites: [-1] 
expected returns: [[117.21126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  6.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 93.07949829101562






Player: 1 
cards in hand: [3. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  7.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 11. 11.  0.  0.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [29. 11. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[ 80.88746 ]
 [100.29214 ]
 [ 91.844025]
 [ 91.844025]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  0.  0.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [11.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 117.21125793457031



action possibilites: [-1. 11. 11.] 
expected returns: [[129.28218]
 [139.91562]
 [139.91562]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [11.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.01387023925781



action possibilites: [-1] 
expected returns: [[111.24769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [11.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 2 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 151.98104858398438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[104.87681 ]
 [123.043724]
 [112.07223 ]
 [ 80.2954  ]
 [125.87238 ]
 [118.21378 ]
 [107.50778 ]
 [116.03985 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  6.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [11.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 111.24768829345703



buy possibilites: [-1] 
expected returns: [[148.48055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  0.  0.] 
adversary cards in discard: [11.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 125.87239837646484






Player: 1 
cards in hand: [ 0. 25.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0.  0.] 
cards in discard: [11.  3.  3.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  9. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11] -> size -> 22 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6] -> size -> 23 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[31.89047 ]
 [23.007154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5    0    0  -90    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -395 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.4805450439453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.928524]
 [38.768806]
 [27.331469]
 [-4.531585]
 [41.73902 ]
 [33.685364]
 [22.659853]
 [31.359594]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  5.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 31.583581924438477



buy possibilites: [-1] 
expected returns: [[45.75906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [29. 29. 29.  0. 10.  3.  0.  6. 10. 11. 29. 11. 11.  0.  0.  3.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: -41 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 41.7390251159668






Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[60.998302]
 [72.50178 ]
 [81.73682 ]
 [72.50178 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 45.75905990600586



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[67.70971 ]
 [76.493935]
 [76.493935]
 [60.273243]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 80.7718734741211



action possibilites: [-1] 
expected returns: [[81.74616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 87.9327621459961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[74.75427 ]
 [91.74814 ]
 [81.47814 ]
 [52.230923]
 [94.42786 ]
 [87.18397 ]
 [77.253525]
 [85.21064 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  4.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.74616241455078



buy possibilites: [-1] 
expected returns: [[111.1851]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: -1 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.42787170410156






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  0. 10. 11.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11] -> size -> 26 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[79.7265 ]
 [71.04374]
 [71.04374]
 [89.60719]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 11.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  3.  0.  1. 11.] 
adversary cards in discard: [0. 8. 0. 0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 111.18509674072266



action possibilites: [-1] 
expected returns: [[81.55584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.  1. 11.] 
adversary cards in discard: [0. 8. 0. 0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 97.12462615966797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.11821 ]
 [79.052216]
 [44.21174 ]
 [85.413025]
 [83.17011 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  9.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.  1. 11.] 
adversary cards in discard: [0. 8. 0. 0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 81.55583953857422



buy possibilites: [-1] 
expected returns: [[97.09672]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 10.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [25.  3.  0.  1. 11.] 
adversary cards in discard: [0. 8. 0. 0. 3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 85.41303253173828






Player: 1 
cards in hand: [25.  3.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  1. 11.] 
cards in discard: [0. 8. 0. 0. 3. 0. 3. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  6. 29. 29.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  3.  0.  3.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 29. 29.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  3.  0.  3.  3.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 29. 29.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  1.] 
cards in discard: [ 0.  8.  0.  0.  3.  0.  3.  3.  0. 15.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 29. 29.  3.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[30.018389]
 [50.093372]
 [50.093372]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29. 29.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 97.09671783447266



action possibilites: [-1. 29.] 
expected returns: [[37.431194]
 [58.180782]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3.  3.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 50.09337615966797



action possibilites: [-1. 11.] 
expected returns: [[69.56963]
 [79.5826 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 11.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.180782318115234



action possibilites: [-1] 
expected returns: [[52.907055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -38 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 90.78707885742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.538593]
 [61.174313]
 [49.259884]
 [19.349703]
 [64.333916]
 [55.78298 ]
 [45.023247]
 [53.337307]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  3.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 52.90705490112305



buy possibilites: [-1] 
expected returns: [[69.95797]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -11 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 64.33390045166016






Player: 1 
cards in hand: [0. 3. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 28. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  6. 29.  3.  0.] 
adversary cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[21.331942]
 [35.3476  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  3.  0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.95796966552734



action possibilites: [-1. 11.] 
expected returns: [[32.7748 ]
 [41.34824]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 11.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.347599029541016



action possibilites: [-1] 
expected returns: [[30.432154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.15013122558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.029697]
 [35.534435]
 [26.892504]
 [ 3.404798]
 [37.814854]
 [31.660154]
 [23.188644]
 [30.033567]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  2.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.432153701782227



buy possibilites: [-1] 
expected returns: [[32.03529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0.] 
cards in discard: [10. 11. 29. 11.  0.  0. 11. 10. 10.  8. 11.  0. 10.  0. 10. 10. 11. 29.
 29. 11.  0.  6.  3.  3. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 3. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   54    0] 
sum of rewards: -61 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.81486892700195






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3. 0. 3. 1. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3. 0. 3. 1. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3. 0. 3. 1. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[75.812126]
 [93.49349 ]
 [66.78406 ]
 [85.760925]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 15.  3.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.0352897644043



action possibilites: [-1. 10. 11.  8.] 
expected returns: [[86.59536]
 [77.78034]
 [96.31896]
 [88.69199]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 11.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 15.  3.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 91.09696197509766



action possibilites: [-1] 
expected returns: [[101.26569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 15.  3.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 90.027275]
 [ 97.83507 ]
 [ 64.40273 ]
 [104.08358 ]
 [101.942566]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  8.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 15.  3.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 101.26569366455078



buy possibilites: [-1] 
expected returns: [[107.99119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [10.  8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 15.  3.] 
adversary cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -99 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 104.08361053466797






Player: 1 
cards in hand: [ 0.  3.  3. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15.  3.] 
cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 11. 29. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8] -> size -> 34 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15.  3.] 
cards in discard: [ 3.  0.  3.  1.  3.  0.  0.  0. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [10. 10. 11. 29. 11.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8] -> size -> 34 
adversary victory points: 1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 10. 11. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 29. 11.] 
expected returns: [[37.24329 ]
 [30.25228 ]
 [30.25228 ]
 [45.205925]
 [51.747395]
 [45.205925]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 29. 11.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 107.9911880493164



action possibilites: [-1. 10. 10. 11. 11. 10.] 
expected returns: [[11.72047  ]
 [ 4.3132415]
 [ 4.3132415]
 [20.457483 ]
 [20.457483 ]
 [ 4.3132415]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.74740982055664



action possibilites: [-1] 
expected returns: [[48.658085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
   27    0] 
sum of rewards: -88 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 30.460981369018555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.316704]
 [19.021288]
 [48.373615]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.658084869384766






Player: 1 
cards in hand: [ 3.  0.  0.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  8. 25.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  8. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10] -> size -> 35 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6] -> size -> 36 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6] -> size -> 36 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6] -> size -> 36 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[52.076862]
 [60.914043]
 [44.246944]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  1. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0  -10    0 -300
    0    0] 
sum of rewards: -525 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 48.37362289428711



action possibilites: [-1] 
expected returns: [[44.557972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -20    0    0
   27    0] 
sum of rewards: -188 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 71.39945983886719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[33.460815]
 [51.146587]
 [40.35084 ]
 [12.244719]
 [54.129803]
 [46.123615]
 [44.04898 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  1.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.5579719543457



buy possibilites: [-1] 
expected returns: [[40.148495]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  3.  3. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -30    0    0
   54    0] 
sum of rewards: -171 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 54.12980270385742






Player: 1 
cards in hand: [ 3.  3.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 11.  0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6. 10. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11] -> size -> 38 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11] -> size -> 38 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 11.  0. 11. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11] -> size -> 38 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 11.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[-11.755736 ]
 [ -6.1134887]
 [ -6.1134887]
 [ -6.1134887]
 [-16.884834 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.148494720458984



action possibilites: [-1] 
expected returns: [[1.4308133]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -40    0    0
   27    0] 
sum of rewards: -208 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -7.756985664367676





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -6.270791  ]
 [-22.433187  ]
 [  0.97747755]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  3.] 
adversary cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.4308133125305176






Player: 1 
cards in hand: [ 3.  0.  0. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  0.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  7.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  0.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  3.] 
cards in discard: [ 3. 25.  3.  0.  0.  8.  0.  0. 14. 11.  3.  3.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  6.  0.  3. 10.] 
adversary cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  6.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[-12.579    ]
 [ -3.6033657]
 [-17.271927 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  0.  3. 10.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.9774842262268066



action possibilites: [-1. 10.] 
expected returns: [[-36.34588 ]
 [-40.898533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.907832145690918





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-42.262844]
 [-53.953175]
 [-36.34588 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.] 
cards in discard: [10.  8. 29. 11.  0.  3. 10.  8. 10. 29. 11. 10. 10. 11. 10.  6. 10. 11.
 11.  0.  0.  0. 10.  1. 11. 11.  0. 11. 10.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -36.34587860107422






Player: 1 
cards in hand: [0. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  6.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  5.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6. 11.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[50.096508]
 [58.695515]
 [65.41228 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6. 29.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  5.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -36.34587860107422



action possibilites: [-1. 11.] 
expected returns: [[33.97737]
 [41.73717]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.] 
cards in discard: [ 6. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  7. 10.  0.  5.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 56.19522476196289



action possibilites: [-1] 
expected returns: [[45.831028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 6. 11.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  5.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0  -50    0    0
   27    0] 
sum of rewards: -198 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 39.47359085083008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[35.130054]
 [42.104828]
 [11.601076]
 [47.83016 ]
 [45.88948 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 6. 11.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  5.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.83102798461914



buy possibilites: [-1] 
expected returns: [[64.17933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 6. 11.  1.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25.  3.] 
adversary cards in discard: [8. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0  -60    0    0
   16    0] 
sum of rewards: -219 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 47.83016586303711






Player: 1 
cards in hand: [ 3.  0.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25.  3.] 
cards in discard: [8. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  0. 11. 10.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8] -> size -> 41 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 25.  3.] 
cards in discard: [8. 8. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 6.  8.  0. 11. 10.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8] -> size -> 41 
adversary victory points: 0
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[38.052868]
 [39.87692 ]
 [46.394382]
 [30.54753 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 11. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  0.  8.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.17932891845703



action possibilites: [-1] 
expected returns: [[22.411427]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  0.  8.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0  -70    0    0
   27    0] 
sum of rewards: -238 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 43.98294448852539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.5841675]
 [-8.851479 ]
 [22.83141  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  0.  8.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.411426544189453






Player: 1 
cards in hand: [15.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  8.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 10.  0.  3.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 10.  0.  3.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 10.  0.  3.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11. 10.  0.  3.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [10. 11. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[34.97128 ]
 [27.421675]
 [43.376705]
 [27.421675]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.  3.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.831418991088867



action possibilites: [-1] 
expected returns: [[45.005642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  3.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0  -80    0    0
   27    0] 
sum of rewards: -218 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 40.94973373413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.131756]
 [ 9.063116]
 [44.07726 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  3.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14.  0.  0.  3.] 
adversary cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.00564193725586






Player: 1 
cards in hand: [11. 14.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  0.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  7. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.] 
cards in discard: [ 8.  8.  0.  0.  0.  3.  0.  0. 25.  3.  0.  8. 15.  3.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 11. 10. 11.  0.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[11.198442 ]
 [17.214941 ]
 [ 5.7871404]
 [17.214941 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  0.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 44.07725143432617



action possibilites: [-1] 
expected returns: [[16.425077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0  -90    0    0
   27    0] 
sum of rewards: -198 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 15.472814559936523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[  7.8130965]
 [ 13.439707 ]
 [-11.604443 ]
 [ 17.951487 ]
 [ 16.350891 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  4.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.425077438354492



buy possibilites: [-1] 
expected returns: [[0.843328]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0 -100    0    0
   16    0] 
sum of rewards: -219 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 17.951480865478516






Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  0. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 29.] 
expected returns: [[-33.082523]
 [-36.85413 ]
 [-26.952127]
 [-26.952127]
 [-20.974169]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 11. 29.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.8433279991149902



action possibilites: [-1. 11. 10.] 
expected returns: [[-37.754005]
 [-31.677431]
 [-43.21578 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 24. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -29.175962448120117



action possibilites: [-1] 
expected returns: [[-42.29959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -168 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -33.43446350097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-49.5005  ]
 [-44.759457]
 [-63.1925  ]
 [-40.97478 ]
 [-42.2996  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  3.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: 0
desired expected reward: -42.299591064453125



buy possibilites: [-1] 
expected returns: [[-55.025394]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  2.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  8.  0. 14.  0.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: -189 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -40.974788665771484






Player: 1 
cards in hand: [ 0.  8.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  2.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  3. 10. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.  0.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  2.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  3. 10. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.  0.] 
cards in discard: [0. 8. 0. 3. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10.  8.  3. 10. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10.  8.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 29.] 
expected returns: [[-24.597715]
 [-28.532295]
 [-23.639036]
 [-28.532295]
 [-16.623848]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3. 10. 29.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -55.025394439697266



action possibilites: [-1. 10. 10.] 
expected returns: [[-31.650877]
 [-36.11784 ]
 [-36.11784 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.486709594726562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-37.5573  ]
 [-49.458645]
 [-31.650877]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 1 
buys: 1 
player value: 1 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11.  0.  3. 25.  0.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -31.650880813598633






Player: 1 
cards in hand: [11.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 25.  0.] 
cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 25.  0.] 
cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 25.  0.] 
cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0.  3.  1. 11. 29.] 
adversary cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  1. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[-17.19116 ]
 [-10.83545 ]
 [ -5.787217]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11. 29.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -31.650880813598633



action possibilites: [-1. 10.] 
expected returns: [[-30.883696]
 [-35.774185]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -3.5544333457946777





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[-37.348763]
 [-27.00409 ]
 [-33.094353]
 [-51.936428]
 [-30.617304]
 [-29.683918]
 [-21.20283 ]
 [-44.369225]
 [-34.02456 ]
 [-30.883696]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  6.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -30.88369369506836



buy possibilites: [-1] 
expected returns: [[-33.636513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 10.] 
cards in discard: [ 6. 11.  1.  8. 29. 11.  6.  0.  1. 11.  6.  8.  0. 10.  1. 11. 10. 10.
  0.  3.  1.  8. 11.  0. 10. 11.  0. 11. 10.  1.  8. 29. 11.  0. 10.  8.
 10. 29.  3. 10. 10.  3. 11. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 15.  6.] 
adversary cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0 -130    0    0
  128    0] 
sum of rewards: -107 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -21.20284080505371






Player: 1 
cards in hand: [ 3.  0.  3. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 15.  6.] 
cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29] -> size -> 48 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 15.  6.] 
cards in discard: [ 0.  8.  0.  3.  8.  0.  8.  0. 14.  0.  0. 11.  0.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29] -> size -> 48 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[18.5422  ]
 [12.420927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1.  1.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -33.636512756347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 9.620184  ]
 [24.043564  ]
 [ 2.06282   ]
 [15.55279   ]
 [-1.0467052 ]
 [-8.591797  ]
 [18.988182  ]
 [20.303122  ]
 [45.076794  ]
 [32.11832   ]
 [ 0.91050863]
 [12.940647  ]
 [-0.261549  ]
 [14.255573  ]
 [18.678486  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1.  1.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29] -> size -> 48 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  9.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.542200088500977



buy possibilites: [-1] 
expected returns: [[62.7439]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  1.  1.] 
cards in discard: [25.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.     0.     0.     0.     0.
    0.  -140.     0.     0.    62.5    0. ] 
sum of rewards: -202.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 45.0767936706543






Player: 1 
cards in hand: [8. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  1.  1. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  1.  1. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  1.  1. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [ 1. 10.  1.  1. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1. 10.  1.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[34.77039 ]
 [26.890715]
 [44.509525]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.  1. 11.] 
cards in discard: [25.  0. 10.  0.  1.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.743900299072266



action possibilites: [-1] 
expected returns: [[45.959938]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -150    0    0
   27    0] 
sum of rewards: -198 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 41.63816833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[32.516552]
 [49.304398]
 [23.041536]
 [39.241707]
 [19.14324 ]
 [10.201998]
 [43.31402 ]
 [44.873615]
 [73.803734]
 [59.125187]
 [21.600574]
 [36.23685 ]
 [20.133003]
 [37.710934]
 [42.967953]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  8.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.959938049316406



buy possibilites: [-1] 
expected returns: [[38.45612]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  1.  1.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25.] 
cards in deck: 38 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [0. 8. 8. 3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.     0.     0.   -90.     0.     0.    20.     0.     0.     0.
    0.  -160.     0.     0.    62.5    0. ] 
sum of rewards: -172.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 73.80375671386719






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25] -> size -> 51 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0. 8. 8. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  7.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25] -> size -> 51 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8.  8.  3. 25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [10. 11.  3. 11. 10.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25] -> size -> 51 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10. 11.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 10.] 
expected returns: [[ -5.098499]
 [-12.874532]
 [  4.391275]
 [  4.391275]
 [-12.874532]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3. 11. 10.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14. 25.  8.  3.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.456119537353516



action possibilites: [-1] 
expected returns: [[8.177492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14. 25.  8.  3.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -170    0    0
   27    0] 
sum of rewards: -218 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 1.6758456230163574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -0.48062325]
 [-19.215601  ]
 [  7.9413104 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 11. 10.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [11. 14. 25.  8.  3.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.177492141723633






Player: 1 
cards in hand: [11. 14. 25.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14. 25.  8.  3.] 
cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 14. 25.  8.  3.] 
cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29.  0.  0.  0. 10.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[ 5.074983 ]
 [18.615084 ]
 [-1.9373703]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 10.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.941304683685303



action possibilites: [-1.] 
expected returns: [[11.017328]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.433652877807617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
expected returns: [[  3.172523 ]
 [ 15.652716 ]
 [  8.308943 ]
 [-14.696222 ]
 [ 11.282547 ]
 [ 12.418516 ]
 [ 23.469902 ]
 [ -5.3038507]
 [  7.1896443]
 [ 11.0173435]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  5.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.017328262329102



buy possibilites: [-1] 
expected returns: [[8.529778]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1 29] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -90    0    0   20    0    0    0    0 -180    0    0
  128    0] 
sum of rewards: -127 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 23.469892501831055






Player: 1 
cards in hand: [15.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  6.  0.  0.] 
cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11. 11. 11. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1 29] -> size -> 53 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  6.  0.  0.] 
cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  1.  6.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [29. 11. 11. 11. 11.] 
adversary cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1 29] -> size -> 53 
adversary victory points: 0
player victory points: 3 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 5 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29. 11. 11. 11. 11.] 
cards in discard: [25.  0. 10.  0.  1.  1.  1. 25. 11.  1. 10.  1.  1.  1. 11. 10.  3. 11.
 10. 10. 29. 29. 29.  0.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 11  6 10 29 29 10 11  6 11
 10 11 10  8 10 11 10 11 10  8 10  6 10 11  1  1  8  1  1  1  8  1  8 29
 25  1 25  1 29] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 26. 30.  8.  6. 10.  0.  0.  6.  4.  9. 10.  0. 10.  9.] 
adversary cards in hand: [15.  3.  6.  0.  0.] 
adversary cards in discard: [ 0.  8.  8.  3. 25.  0.  0.  0.  0.  0. 11. 14. 25.  8.  3.  8.] 
adversary owned cards: [ 0  0 25  3  8 11  0  0 15  3  3  0  3 14  8  8  0  6  0  0  8  0  0 25
  8] -> size -> 25 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[      -5 -3000000        0      -90        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000095 

action type: buy - action -1
Learning step: -120004.140625
desired expected reward: -119995.609375



