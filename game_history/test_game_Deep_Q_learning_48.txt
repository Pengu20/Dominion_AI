 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.219913]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -240        0        0        0        0
        0        0        0      -50        0        0        8        0] 
sum of rewards: -3000287 

action type: buy - action 8.0
Learning step: -120010.5859375
desired expected reward: -120032.8125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[15.250071]
 [23.884262]
 [21.753284]
 [ 6.465621]
 [27.845108]
 [21.816662]
 [19.619556]
 [19.922684]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.88582992553711



buy possibilites: [-1] 
expected returns: [[18.614107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.845108032226562






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.016058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.614107131958008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.436258 ]
 [23.671864 ]
 [21.827341 ]
 [ 8.689615 ]
 [21.103529 ]
 [27.287498 ]
 [21.896414 ]
 [27.887682 ]
 [14.1402855]
 [20.051893 ]
 [21.37589  ]
 [19.813995 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.592937469482422



buy possibilites: [-1] 
expected returns: [[19.05155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.88768196105957






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[23.620817]
 [30.93706 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.051549911499023



action possibilites: [-1.] 
expected returns: [[19.049494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 30.25432777404785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.582693]
 [21.791622]
 [12.767124]
 [19.976057]
 [ 8.794254]
 [ 6.988558]
 [19.231556]
 [25.401276]
 [20.007915]
 [31.865705]
 [26.077265]
 [12.403913]
 [18.836477]
 [18.192352]
 [11.627546]
 [19.612839]
 [18.761017]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.04949378967285



buy possibilites: [-1] 
expected returns: [[32.8375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [10.  0. 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 77.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 31.86570167541504






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0. 14.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0. 14.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [10.  0. 14.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 11.] 
adversary cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[50.97644]
 [58.36487]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.837501525878906



action possibilites: [-1] 
expected returns: [[48.646942]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.23444366455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[43.274048]
 [49.809128]
 [34.18248 ]
 [49.959145]
 [48.680717]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 48.646942138671875



buy possibilites: [-1] 
expected returns: [[48.50718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25. 29.  0.  0.  0.  0.  0. 10.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 49.959136962890625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  9.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.162676]
 [21.932705]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 25 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 48.507179260253906



action possibilites: [-1] 
expected returns: [[29.40658]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 21.280214309692383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.938253]
 [19.740438]
 [29.948229]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 10.  0.] 
adversary cards in discard: [8. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.406579971313477






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [8. 3. 0. 0. 0. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10. 29.  0. 25.  0.] 
adversary cards in discard: [8. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[35.359024]
 [33.296852]
 [44.306145]
 [52.125862]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 25.  0.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.948232650756836



action possibilites: [-1] 
expected returns: [[39.159073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0.  0.  0.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.71519470214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.9441  ]
 [42.47603 ]
 [40.513733]
 [27.165922]
 [39.72782 ]
 [47.072998]
 [40.559143]
 [47.981743]
 [32.75946 ]
 [38.68492 ]
 [40.19397 ]
 [39.618324]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0.  0.  0.] 
cards in discard: [8. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.15907287597656



buy possibilites: [-1] 
expected returns: [[33.833466]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  0.  0.  0.  0.] 
cards in discard: [ 8.  3.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  1. 14.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 113 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.98173522949219






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 14.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 30.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 3.] 
cards in discard: [6. 4.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  3. 11.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[29.623064]
 [30.393671]
 [36.392822]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.] 
cards in discard: [0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 26.533891677856445



action possibilites: [-1] 
expected returns: [[27.862413]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -48 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.14605712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.77015 ]
 [18.176018]
 [29.948473]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [ 0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.86241340637207






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  4. 14.  3.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 25.  0.  3. 29.] 
adversary cards in discard: [ 0.  0. 10. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  4. 14.  3.  0.  1.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 25.  0.  3. 29.] 
adversary cards in discard: [ 0.  0. 10. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [10. 25.  0.  3. 29.] 
adversary cards in discard: [ 0.  0. 10. 11.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [10. 25.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.] 
expected returns: [[47.61782 ]
 [44.746994]
 [62.14994 ]
 [55.012054]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0.  3. 29.] 
cards in discard: [ 0.  0. 10. 11.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  9. 10.  9.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.9484806060791



action possibilites: [-1] 
expected returns: [[34.90126]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 29.  0. 29.] 
cards in discard: [ 0.  0. 10. 11.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.058006286621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.605173]
 [34.5737  ]
 [21.838459]
 [34.61978 ]
 [33.669   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 29.] 
cards in discard: [ 0.  0. 10. 11.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  7.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.90126037597656



buy possibilites: [-1] 
expected returns: [[46.883873]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 29.  0. 29.] 
cards in discard: [ 0.  0. 10. 11.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 34.619773864746094






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 6.  4. 14.  3.  0.  1.  3.  8.  0.  0.  0.  0.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.837894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.883872985839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.188082]
 [24.655497]
 [22.7698  ]
 [11.311131]
 [ 9.505436]
 [21.987473]
 [28.400974]
 [22.819258]
 [35.086052]
 [29.092691]
 [14.940208]
 [21.575827]
 [20.933565]
 [14.144428]
 [22.407618]
 [21.499334]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 17.931608200073242



buy possibilites: [-1] 
expected returns: [[17.52069]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 185 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 35.08605194091797






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  8.  3. 10.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 30. 29.  8.  8. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  8.  3. 10.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  0. 10.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  8. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  8.  3. 10.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [29. 25.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8. 10.] 
expected returns: [[41.964188]
 [46.985275]
 [52.401215]
 [41.674637]
 [40.181328]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  8.  3. 10.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  8. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 6.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1] -> size -> 21 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.52069091796875



action possibilites: [-1] 
expected returns: [[59.49286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  3. 10. 10.  8.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 6.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 49.78813171386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.78797]
 [49.41768]
 [61.72573]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  3. 10. 10.  8.] 
cards in discard: [25.  0.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 6.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6] -> size -> 22 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.49285888671875






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 6.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0. 25. 29.  8.  3. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 6.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 30. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0. 25. 29.  8.  3. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 6.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 11.] 
adversary cards in discard: [25.  0.  0.  0.  0.  0. 25. 29.  8.  3. 10. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[30.471811]
 [38.101074]
 [36.94052 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 11.] 
cards in discard: [25.  0.  0.  0.  0.  0. 25. 29.  8.  3. 10. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 61.725730895996094



action possibilites: [-1. 11. 25.] 
expected returns: [[29.419237]
 [36.45105 ]
 [43.827477]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 25.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  7. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3] -> size -> 23 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.820518493652344



action possibilites: [-1] 
expected returns: [[22.109446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.827476501464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.756556]
 [22.404364]
 [20.358706]
 [ 9.149862]
 [19.486786]
 [26.538054]
 [20.3969  ]
 [27.36357 ]
 [13.22113 ]
 [18.352287]
 [20.038164]
 [20.090345]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.109445571899414



buy possibilites: [-1] 
expected returns: [[44.855293]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 10.  0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6] -> size -> 24 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 103 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.363563537597656






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 10.  0.  8.] 
adversary cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  7.  9. 10.  7. 10. 10.] 
adversary cards in hand: [25.  0. 10.  0.  8.] 
adversary cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.  0.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0. 10.  0.  8.] 
adversary cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [25.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
expected returns: [[76.886696]
 [93.89317 ]
 [76.21983 ]
 [78.549706]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10.  0.  8.] 
cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  6. 10.  9.  6.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [4. 3. 8. 6. 0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.85529327392578



action possibilites: [-1] 
expected returns: [[107.60075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  8.  3. 29.] 
cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  6.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [4. 3. 8. 6. 0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15  6] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.65650939941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.30044 ]
 [105.45309 ]
 [ 85.8415  ]
 [105.62592 ]
 [103.572975]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  8.  3. 29.] 
cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  6.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [4. 3. 8. 6. 0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15  6] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 107.60075378417969



buy possibilites: [-1] 
expected returns: [[27.078402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  8.  3. 29.] 
cards in discard: [29. 29. 25.  3.  0.  0. 11. 10.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [4. 3. 8. 6. 0.] 
adversary cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15  6] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 105.62593841552734






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [4. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 8. 6. 0.] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 14 10  1  8  0  6  4  8  6  1  6  3  6
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8] -> size -> 20 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  0.  8.  0.  0. 10.  6.  3.  0.  1.  3.  3.  6.  6. 15. 14.  0.  0.
  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 8. 11.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8] -> size -> 20 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 8. 11.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
expected returns: [[27.68514 ]
 [27.062447]
 [33.3024  ]
 [27.062447]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.078401565551758



action possibilites: [-1] 
expected returns: [[31.995836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 34.199981689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.19442 ]
 [31.133684]
 [17.607449]
 [31.08011 ]
 [31.816229]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.99583625793457






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29.  8.] 
adversary cards in discard: [10. 11.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3. 29. 29.  8.] 
adversary cards in discard: [10. 11.  8.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3. 29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.  8.] 
expected returns: [[63.75699 ]
 [75.62798 ]
 [69.94598 ]
 [69.94598 ]
 [64.134346]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29. 29.  8.] 
cards in discard: [10. 11.  8.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  5. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [3. 0. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6] -> size -> 22 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.81623649597168



action possibilites: [-1] 
expected returns: [[134.04285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  8. 29.  0.] 
cards in discard: [10. 11.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.71944427490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.05388]
 [119.20476]
 [136.15593]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  8. 29.  0.] 
cards in discard: [10. 11.  8.  8.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  6.  0.  0.] 
adversary cards in discard: [3. 0. 0. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 134.0428466796875






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [15.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  6.  0.  0.] 
cards in discard: [3. 0. 0. 6. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0.  0. 25.  3. 29. 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0.  0.] 
cards in discard: [3. 0. 0. 6. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  9.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0.  0. 25.  3. 29. 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  6.  0.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [10. 11.  8.  8.  0.  0. 25.  3. 29. 29.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [10.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[50.84079 ]
 [45.136597]
 [45.136597]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [10. 11.  8.  8.  0.  0. 25.  3. 29. 29.  8. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 14.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 136.1559295654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[39.392212]
 [44.96675 ]
 [32.5431  ]
 [44.79554 ]
 [48.780853]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [10. 11.  8.  8.  0.  0. 25.  3. 29. 29.  8. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 14.  0.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 50.821495056152344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1.  3.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 14.  0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 25.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 28. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 25.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 25.  0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 8. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[24.009306]
 [23.937014]
 [35.253403]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.] 
cards in discard: [0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  4. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  8.  6.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1] -> size -> 25 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 59.512290954589844



action possibilites: [-1] 
expected returns: [[11.200209]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8.] 
cards in discard: [0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  8.  6.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.29441833496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 5.645609 ]
 [-0.1431284]
 [11.331894 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 8.] 
cards in discard: [0. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  8.  6.] 
adversary cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1  6] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.20020866394043






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  3. 10.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  8.  6.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 6. 1.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  6  1  6  3  6 15  6  6 11
  1  6] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1.] 
cards in discard: [ 3.  0.  0.  6.  0.  6. 11. 15.  0.  6.  0.  0.  1. 14.  1.  3.  0.  0.
  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29. 10. 10.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [29. 10. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10. 29.] 
expected returns: [[37.11312 ]
 [44.602417]
 [37.94996 ]
 [37.94996 ]
 [44.602417]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 10.  0. 29.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.331876754760742



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[62.328667]
 [64.29522 ]
 [64.29522 ]
 [73.883644]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 29.  0.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.817161560058594



action possibilites: [-1. 10. 10.] 
expected returns: [[39.132126]
 [37.46025 ]
 [37.46025 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.  3.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 73.8836441040039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[30.75427 ]
 [39.091393]
 [37.00036 ]
 [22.51946 ]
 [36.074745]
 [43.28888 ]
 [37.0428  ]
 [44.179222]
 [28.430613]
 [34.951767]
 [36.76773 ]
 [36.623634]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  3.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  7.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.13213348388672



buy possibilites: [-1] 
expected returns: [[-0.5494585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.  3.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [15.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 44.179229736328125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [15.  0.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 25.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29. 29. 29. 10. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 10.  6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0. 25.  0. 29.] 
adversary cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29. 29. 29. 10. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
expected returns: [[28.272642]
 [29.081362]
 [32.27723 ]
 [29.723764]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 25.  0. 29.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29. 29. 29. 10. 10.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  3. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0] -> size -> 26 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.5494585037231445



action possibilites: [-1] 
expected returns: [[22.49999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3. 10.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29. 29. 29. 10. 10.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.27723693847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.629831]
 [22.243895]
 [11.621243]
 [22.16237 ]
 [24.260849]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 29.  3. 10.] 
cards in discard: [ 0.  0. 25.  8.  0.  8.  8. 29. 29. 29. 10. 10.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0  6] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.499990463256836






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [11.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [15.  0.  0. 10.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6 11  1
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15.  0.  0. 10.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  0.  0. 10.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [25.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[50.373955]
 [65.10793 ]
 [57.42859 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  2. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0] -> size -> 25 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.26087188720703



action possibilites: [-1] 
expected returns: [[35.322998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 62.739173889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[36.38398 ]
 [40.714973]
 [30.733126]
 [40.626144]
 [42.611656]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 29. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [0. 6. 3. 1. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6] -> size -> 26 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.322998046875






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 1. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 29. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0. 25. 11.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 27. 30. 29. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0. 25. 11.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [10.  8.  0. 25. 11.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [10.  8.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25. 11.] 
expected returns: [[74.79202]
 [76.2015 ]
 [77.91253]
 [88.5835 ]
 [82.7328 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 25. 11.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  1. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3] -> size -> 27 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.611656188964844



action possibilites: [-1] 
expected returns: [[4.8997326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0. 11. 10.  0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.22779083251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-1.140449 ]
 [ 2.7120695]
 [ 2.7450619]
 [ 1.5582218]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11. 10.  0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  5.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.89973258972168



buy possibilites: [-1] 
expected returns: [[-0.42745876]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  0. 11. 10.  0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 0. 8.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6] -> size -> 28 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 2.7450618743896484






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  6.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 8.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8.  0.  0.  0.] 
adversary cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [29.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[100.97922]
 [101.65276]
 [ 97.93108]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  0.  0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.4274587631225586



action possibilites: [-1.  8.] 
expected returns: [[28.26047 ]
 [28.869852]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 98.96572875976562



action possibilites: [-1] 
expected returns: [[5.019722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 31.414342880249023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[0.73681355]
 [4.1493506 ]
 [4.0831633 ]
 [5.790352  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  3.  0. 29.  3.  0. 29.  8. 25. 10.  8.  0. 11. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 6.] 
adversary cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 5.019721984863281






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 29.  8.  0. 10.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 6.] 
cards in discard: [15.  0.  0. 10.  6.  6.  0.  8.  3.  6.  3.  0.  6.  3.  1.  6.  6. 29.
  1.  3.  0.  0.  8. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 29. 10.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 0. 29. 10.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 10.] 
expected returns: [[-1.7962987]
 [ 1.4865322]
 [-2.5500815]
 [-1.6607506]
 [-2.5500815]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8. 10.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 5.79035758972168



action possibilites: [-1. 10. 10. 25.] 
expected returns: [[ 8.571054]
 [ 7.458824]
 [ 7.458824]
 [19.544556]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 25.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.281508207321167



action possibilites: [-1] 
expected returns: [[26.95816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  3.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.5445556640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[21.307158]
 [24.964302]
 [24.841991]
 [26.445833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.  3.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 6.  6.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.958160400390625






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [29.  8. 29.  8. 25.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8. 25.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 27. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8. 25.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0.] 
cards in discard: [1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8. 25.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [ 8.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[42.63085 ]
 [45.925514]
 [45.925514]
 [53.780373]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16  1] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 20.820858001708984



action possibilites: [-1] 
expected returns: [[14.210176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  0.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16  1] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.78038024902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 6.638336 ]
 [13.0729885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  0.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  6. 15.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16  1] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.210176467895508






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 15.  6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6
  0  6  3  6 29 16  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  8.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  8.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 26. 30. 28. 29.  8.  0.  9.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  8.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  0. 10.  8.] 
adversary cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
adversary victory points: 2
player victory points: -4 





Player: 0 
cards in hand: [11.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[31.192457]
 [32.369736]
 [28.650553]
 [29.539576]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10.  8.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 1. 8. 1.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1 16] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.072996139526367



action possibilites: [-1] 
expected returns: [[30.488634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [6. 3. 1. 8. 1.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1 16] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 259 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 33.258766174316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.320704]
 [29.263643]
 [29.17375 ]
 [30.858225]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  8.] 
cards in discard: [ 8. 29. 25.  0. 10. 10.  3.  3. 29. 29. 25.  8.  8. 29.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [6. 3. 1. 8. 1.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1 16] -> size -> 31 
adversary victory points: -4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.48863410949707






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [6. 3. 1. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 8. 1.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0 14 10  1  8  0  8  1  6  3  6 15  6  6  1  6  0  6  0
  6  3  6 29 16  1 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 28. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [10. 11. 29. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [10. 11. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29. 10.] 
expected returns: [[-4.1487184 ]
 [-4.9025245 ]
 [-1.2862978 ]
 [-0.86587524]
 [-4.9025245 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 10.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.85822868347168



action possibilites: [-1. 10. 11. 10.] 
expected returns: [[ 9.059005 ]
 [ 7.6160555]
 [10.697647 ]
 [ 7.6160555]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 10.  0.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.633962631225586



action possibilites: [-1] 
expected returns: [[34.62702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 249 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 11.461151123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[30.697657]
 [32.637695]
 [32.49398 ]
 [34.078568]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.] 
cards in discard: [29. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 10.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.62702178955078






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25. 15.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25. 15.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.  6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8. 25. 15.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -3 





Player: 0 
cards in hand: [ 0.  0.  8. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 15.] 
expected returns: [[ 1.4312525]
 [ 2.5167112]
 [12.50285  ]
 [ 2.1938372]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 25. 15.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 16.  0.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 34.07855987548828



action possibilites: [-1] 
expected returns: [[12.032873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15.  8.  8.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 16.  0.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.502839088439941





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[ 8.130671]
 [11.354326]
 [11.268471]
 [12.21265 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 15.  8.  8.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 6.  0. 16.  0.  6.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3  0] -> size -> 30 
adversary victory points: -3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.032873153686523






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 6.  0. 16.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 16.  0.  6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3  6 15  6  6  1  6  0  6  0  6  3  6
 29 16  1 16  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  4.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  3.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  3.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29. 25.  3.  8.  0.] 
adversary cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [29. 25.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[ -9.316245]
 [ -8.344156]
 [ -5.161271]
 [-12.441643]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  8.  0.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29.  3.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 12.212656021118164



action possibilites: [-1] 
expected returns: [[11.719456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  0. 10. 29.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29.  3.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -5.161258697509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 7.595045]
 [11.434569]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.  0. 10. 29.] 
cards in discard: [29. 15. 29. 11. 10. 10.  0. 25.  0.  0.  8. 15.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [29.  3.  3.  1.  0.] 
adversary cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8. 16.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.71945571899414






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [29.  3.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  1.  0.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  1.  0.] 
cards in discard: [ 1. 14.  6.  6.  0.  0. 16. 15.  0.  6.  6.  3.  8.  1.  0.  8.  0.  3.
 10.  6.  8.  8. 16.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [10. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[-17.21534 ]
 [-18.086357]
 [-16.699268]
 [-17.775143]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8.  3.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.43457317352295



action possibilites: [-1] 
expected returns: [[-5.846547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 199 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -16.85104751586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.859271 ]
 [-6.1742225]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3.  0.] 
cards in discard: [15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.8465471267700195






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 29. 25.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  6. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 29. 25.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8.  0.  0. 29. 25.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 8.  0.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[ 7.8515635]
 [ 7.498371 ]
 [11.132802 ]
 [14.3393345]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29. 25.] 
cards in discard: [15. 11. 10.  8.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 1. 3. 8. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -6.1742262840271



action possibilites: [-1] 
expected returns: [[-3.750579]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29.  8.  0.] 
cards in discard: [15. 11. 10.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 1. 3. 8. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.33932876586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-6.2996974 ]
 [-2.4011092 ]
 [-3.3413863 ]
 [-0.08383989]
 [-3.4270804 ]
 [-4.367359  ]
 [-2.8660982 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  8.  0.] 
cards in discard: [15. 11. 10.  8.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  8.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 1. 3. 8. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.7505791187286377



buy possibilites: [-1] 
expected returns: [[-14.34362]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  8.  0.] 
cards in discard: [15. 11. 10.  8.  3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [6. 1. 3. 8. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -0.08384037017822266






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 1. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 3. 8. 6.] 
cards in discard: [10.  0.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  1  3 15  6  6  1  6  0  6  0  6  3  6 29
 16  1 16  3  0  8  8 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 25. 29.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  0.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 25. 29.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  0.  0.  8.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 25. 29.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29. 10. 25. 29.] 
adversary cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29. 10. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 25. 29.] 
expected returns: [[10.492447]
 [13.027826]
 [ 9.366351]
 [15.501406]
 [13.027826]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 25. 29.] 
cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [14. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -14.343620300292969



action possibilites: [-1] 
expected returns: [[12.17267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10. 29.  3. 29.] 
cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [14. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 15.501401901245117





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 6.7216463]
 [11.12745  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10. 29.  3. 29.] 
cards in discard: [15. 11. 10.  8.  3.  0. 11. 25.  8.  0.  0. 29.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [14. 16.  0.  8.  3.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10  0] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.172670364379883






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [14. 16.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  8.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29 16  1 16
  3  0  8  8 10  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 15. 15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 15. 15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 15. 15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 15. 15.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10. 15. 15.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.  8. 10.] 
expected returns: [[6.6516457]
 [4.527858 ]
 [5.293909 ]
 [5.293909 ]
 [5.0817566]
 [4.527858 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15. 15.  8. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.127470016479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[1.6424785]
 [4.9841623]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15. 15.  8. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  6.  0.  0. 16.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.796738624572754



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  8.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  8.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  0. 16.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0. 29.  8.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-4.0698175 ]
 [ 0.42819095]
 [-4.707785  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  8.  0.] 
cards in discard: [10. 15. 15.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  1.  3.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 4.984163284301758



action possibilites: [-1. 15.] 
expected returns: [[-13.4783125]
 [-14.3117485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 15. 15.  8. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  1.  3.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.368222951889038





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-16.300308 ]
 [-11.948445 ]
 [-13.225008 ]
 [-13.797119 ]
 [ -9.266878 ]
 [-13.286634 ]
 [ -8.54903  ]
 [-17.12125  ]
 [-14.443983 ]
 [-13.2809925]
 [-12.02355  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 15. 15.  8. 10.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  5.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  1.  3.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -13.478312492370605



buy possibilites: [-1] 
expected returns: [[-1.5473142]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  1.  3.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
adversary owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -8.549030303955078






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  3.  8.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0
  8  8 10  0  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  2.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29.  8. 10.  0.  0.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
expected returns: [[12.927673]
 [14.855139]
 [11.216992]
 [10.674675]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 10.  0.  0.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [1. 6. 6. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.547314167022705



action possibilites: [-1. 10. 25.] 
expected returns: [[17.09252 ]
 [13.467339]
 [24.163233]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 25.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [1. 6. 6. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.969511985778809



action possibilites: [-1] 
expected returns: [[-9.156446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [1. 6. 6. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 24.163244247436523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-15.02811 ]
 [-11.460333]
 [-12.41807 ]
 [ -9.4424  ]
 [-12.556721]
 [-13.514463]
 [-11.091597]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  7.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [1. 6. 6. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -9.15644645690918



buy possibilites: [-1] 
expected returns: [[30.91696]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [1. 6. 6. 3. 6.] 
adversary cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -9.442403793334961






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [1. 6. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 25. 11. 29.  3.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8. 11. 29. 25. 10.  0.
  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  1.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 25. 11. 29.  3.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8. 11. 29. 25. 10.  0.
  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 3. 6.] 
cards in discard: [10.  0.  0.  8.  0. 10.  0.  8.  3.  0.  8. 14.  3.  1.  0.  6.  0.  0.
 16.  8.  8. 15.  1.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 25. 11. 29.  3.] 
adversary cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8. 11. 29. 25. 10.  0.
  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8. 25. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 29.] 
expected returns: [[30.77899 ]
 [31.391562]
 [37.02082 ]
 [33.947075]
 [34.31382 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 11. 29.  3.] 
cards in discard: [10. 15. 15.  8. 10.  8. 29. 29.  0.  0.  0. 15.  8. 11. 29. 25. 10.  0.
  0. 29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10.  6.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.916959762573242



action possibilites: [-1] 
expected returns: [[6.5082464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 29.  3. 15. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10.  6.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.02082824707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.528142 ]
 [6.4994392]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 29.  3. 15. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10.  6.  3.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.508246421813965






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [10.  6.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 25.  0.  0. 10.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  1. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 25.  0.  0. 10.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  3.  1. 29.] 
cards in discard: [0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 25.  0.  0. 10.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29. 25.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 10.] 
expected returns: [[29.900652]
 [33.021614]
 [35.73059 ]
 [29.092012]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0. 10.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  8.  8.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 6.499432563781738



action possibilites: [-1] 
expected returns: [[-4.934902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10. 11.  3.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  8.  8.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.73058319091797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-8.341572]
 [-5.383127]
 [-4.907835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10. 11.  3.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 14.  6.  8.  8.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.934902191162109






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  6.  8.  8.] 
cards in discard: [ 0. 10.  6.  3.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 15.  8. 29.  8.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0. 10.  6.  3.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0. 10.  6.  3.  1. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  6.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 8. 8.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0. 29.  8.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-8.578862]
 [-6.695713]
 [-8.969125]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 7.07869815826416



action possibilites: [-1. 29.] 
expected returns: [[-3.2693708]
 [-1.6794224]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -8.298954963684082



action possibilites: [-1.] 
expected returns: [[11.594014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -5.677413463592529





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 3.1162424]
 [ 6.507351 ]
 [10.439083 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [3. 8. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
adversary owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.594014167785645






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8
  8 10  0  0  1  8  8  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [10. 10.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[25.296   ]
 [23.155294]
 [23.155294]
 [24.095625]
 [27.77375 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 29.  0.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
adversary owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 10.439111709594727



action possibilites: [-1. 10. 15.] 
expected returns: [[3.287897  ]
 [0.02744007]
 [0.8926506 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 15.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
adversary owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.171220779418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.70275927]
 [ 0.9672575 ]
 [ 3.5700722 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 15.] 
cards in discard: [25.  8. 11. 29.  3. 15. 11. 25. 29.  0.  0. 10. 11.  3. 15.  8.  0.  8.
  0. 29. 29. 10.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 6. 15.  0.  8.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
adversary owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 3.2878971099853516






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  8.  0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8
 10  0  0  1  8  8  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [25.  0. 29. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [25.  0. 29. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 15.] 
expected returns: [[-17.937393]
 [-10.226367]
 [-14.435609]
 [-18.233429]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 15.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 1.  6.  0. 16.  3.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.] 
adversary owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 3.5700745582580566



action possibilites: [-1] 
expected returns: [[-3.1289353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 1.  6.  0. 16.  3.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.] 
adversary owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -10.301399230957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.8072653]
 [-3.2073133]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  3.  3.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 1.  6.  0. 16.  3.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.] 
adversary owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.1289353370666504






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 1.  6.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 16.  3.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  0  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10
  0  0  1  8  8  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 10. 11. 25. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 3.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 10. 11. 25. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 10. 11. 25. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 3.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 10. 11. 25. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29. 10. 11. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11. 25. 15.] 
expected returns: [[24.268791]
 [27.209574]
 [22.783133]
 [26.666142]
 [30.291273]
 [23.734789]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 25. 15.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 10.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -3.2073116302490234



action possibilites: [-1] 
expected returns: [[1.563334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11. 15. 10.  8.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 10.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.2912654876709





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-1.1505113]
 [ 1.6302538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10. 11. 15. 10.  8.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 10.  1.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.5633339881896973






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 11. 11.  8. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  5.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 11. 11.  8. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  1. 29. 11. 14.  0.  6.  8.  8.  8.  3.  8.  0. 15.  6.
  8.  0.  0.  0. 16.  1.  6.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [29. 11. 11.  8. 15.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [29. 11. 11.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.  8. 15.] 
expected returns: [[-5.335463 ]
 [-3.7854614]
 [-4.026142 ]
 [-4.026142 ]
 [-5.2879257]
 [-5.303018 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 11.  8. 15.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.6302604675292969



action possibilites: [-1. 11. 11. 15.] 
expected returns: [[37.65924 ]
 [38.13124 ]
 [38.13124 ]
 [34.798035]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.82188606262207



action possibilites: [-1] 
expected returns: [[-16.997875]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 34.95653533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.829432]
 [-16.842009]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 6. 0. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -16.997875213623047






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8. 6. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 29. 10.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1. 29.
 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 0.  0.  8. 29. 10.] 
adversary cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1. 29.
 11. 11. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
expected returns: [[4.446785 ]
 [4.401198 ]
 [8.484934 ]
 [3.2505693]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 29. 10.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1. 29.
 11. 11. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 16.  8.] 
adversary cards in discard: [8. 6. 0. 1. 0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -16.842004776000977



action possibilites: [-1.  8. 10.] 
expected returns: [[-14.660707]
 [-16.695042]
 [-16.916737]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1. 29.
 11. 11. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 16.  8.] 
adversary cards in discard: [8. 6. 0. 1. 0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.602169036865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-16.76017 ]
 [-15.778681]
 [-13.922157]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.] 
cards in discard: [25.  0. 29. 15.  3.  3.  8. 25. 29. 10. 11. 15. 10.  8.  8. 29.  1. 29.
 11. 11. 15.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 8. 15. 10. 16.  8.] 
adversary cards in discard: [8. 6. 0. 1. 0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -14.660709381103516






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8. 15. 10. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10. 16.  8.] 
cards in discard: [8. 6. 0. 1. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [25. 10.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 10. 16.  8.] 
cards in discard: [8. 6. 0. 1. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [25. 10.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 10.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8. 11.] 
expected returns: [[-18.50547 ]
 [-12.083228]
 [-18.925997]
 [-18.378738]
 [-16.291687]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -13.922159194946289



action possibilites: [-1] 
expected returns: [[-20.403429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -12.083233833312988





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-19.679222]
 [-19.269974]
 [-20.403429]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 27. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -20.40342903137207



buy possibilites: [-1] 
expected returns: [[-17.515919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 11.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [8. 0. 8. 3. 0.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -19.26997184753418






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 1. 25. 15.  0. 15.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8. 3. 0.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 1. 25. 15.  0. 15.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1. 25. 15.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15. 15.] 
expected returns: [[-3.756262]
 [ 4.385314]
 [-3.835851]
 [-3.835851]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 25. 15.  0. 15.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.515918731689453



action possibilites: [-1] 
expected returns: [[-5.3376293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0. 15. 29.  8.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.385311603546143





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-8.111635 ]
 [-4.5146503]
 [-5.391775 ]
 [-2.7242875]
 [-6.321271 ]
 [-5.0459337]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 15. 29.  8.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  4.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.337629318237305



buy possibilites: [-1] 
expected returns: [[20.08897]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0. 15. 29.  8.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -2.7242815494537354






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [11.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  6.] 
adversary cards in hand: [ 3. 11. 15.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 3. 11. 15.  8.  0.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8.] 
expected returns: [[11.111948 ]
 [12.7611065]
 [ 9.793424 ]
 [ 9.647186 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 15.  8.  0.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 0.  3. 29.  3. 14.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.088970184326172



action possibilites: [-1] 
expected returns: [[25.238241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 0.  3. 29.  3. 14.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 10.74346923828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.628819]
 [24.641804]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  0.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 0.  3. 29.  3. 14.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.23824119567871






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 14.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [10. 29. 29. 10.  0.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 23. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [10. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 30. 26. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [10. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [10. 29. 10.] 
adversary cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[ -9.605599 ]
 [-11.215964 ]
 [ -7.1132517]
 [-11.215964 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 8. 10.  6.  6. 11.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -19.099071502685547



action possibilites: [-1. 10.] 
expected returns: [[-0.0892632]
 [-2.7697809]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 8. 10.  6.  6. 11.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.416918754577637





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.949325  ]
 [-0.05169964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 3. 25. 10.  8. 11.  0.  0.  8. 11. 25.  1. 15.  0. 15. 29.  8.  1. 11.
  3. 15.  8.  0. 29.  0. 10. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [ 8. 10.  6.  6. 11.] 
adversary cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -0.08925962448120117






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.  6. 11.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  5.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.  6.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.  6.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  6.  6.] 
cards in discard: [ 8.  6.  0.  1.  0.  8. 15. 10. 16.  8.  8.  0.  8.  3.  0.  0. 15. 11.
  0.  1.  0.  3.  3. 14.  0.  3. 29.  3. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [15.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[-8.145646 ]
 [-9.752323 ]
 [-5.4879847]
 [-4.6540556]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 11.  3. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  3.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -0.05169963836669922



action possibilites: [-1. 15. 29.] 
expected returns: [[4.718685 ]
 [3.2863302]
 [7.7674227]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.] 
cards in discard: [ 0. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  3.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -3.996025562286377



action possibilites: [-1.] 
expected returns: [[-11.149828]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 11. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  3.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.511288642883301





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-13.078598]
 [-11.62441 ]
 [-11.950272]
 [-10.475322]
 [-12.379357]
 [-11.393525]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11. 15.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  3.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  3.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -11.14982795715332



buy possibilites: [-1] 
expected returns: [[-12.8359]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 11. 15.  3. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [15.  3.  0.  1.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -10.47531795501709






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [15.  3.  0.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [ 3. 25. 29.  3. 11.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.  6.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  5. 10.  4.] 
adversary cards in hand: [ 3. 25. 29.  3. 11.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0.  1.  6.] 
cards in discard: [10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 3. 25. 29.  3. 11.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 3. 25. 29.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 11.] 
expected returns: [[-4.585986 ]
 [ 1.2475033]
 [-1.441251 ]
 [-1.8470576]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  3. 11.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 8. 10.  8.  8.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.83590030670166



action possibilites: [-1] 
expected returns: [[-1.9894848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 11. 29.  0.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 8. 10.  8.  8.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.2475099563598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.996539]
 [-2.457833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3. 11. 29.  0.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 8. 10.  8.  8.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.9894847869873047






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 8. 10.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  8.  8.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [25.  0. 29. 10.  1.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 6.] 
cards in discard: [10. 15.  3.  0.  1.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [25.  0. 29. 10.  1.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 6.] 
cards in discard: [10. 15.  3.  0.  1.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [25.  0. 29. 10.  1.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [25.  0. 29. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[-0.1796174]
 [ 4.2774634]
 [ 1.0470614]
 [-2.7135212]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 10.  1.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 1.  0. 15. 16.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -2.457827568054199



action possibilites: [-1] 
expected returns: [[67.46258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  1.  8.  8.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 1.  0. 15. 16.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.277482986450195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[63.478844]
 [70.256256]
 [68.60957 ]
 [73.6978  ]
 [66.9204  ]
 [70.79714 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  1.  8.  8.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  2.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 1.  0. 15. 16.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.46257781982422



buy possibilites: [-1] 
expected returns: [[-17.109463]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  1.  8.  8.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [ 1.  0. 15. 16.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 73.69782257080078






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 15. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 15. 16.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  0  6  0  6  3  6 29  1 16  3  0  8  8 10  0
  0  1  8  8  0 11  0  0 11  0 15  3 15  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 25. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [10. 11. 11.  8.  8.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [10. 11. 11.  8.  8.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  4. 10.  4.] 
adversary cards in hand: [10. 11. 11.  8.  8.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3. 10.  4.] 
adversary cards in hand: [10. 11. 11.  8.  8.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 11. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8.  8.] 
expected returns: [[-7.961439]
 [-9.982788]
 [-8.814053]
 [-8.814053]
 [-9.762138]
 [-9.762138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8.  8.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  0.  0.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.10946273803711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-10.356736]
 [ -7.797845]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  8.  8.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15.  0.  0.  1.  0.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -7.961450576782227



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  1.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 15. 10.  1.  0.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8. 10. 11. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3. 10.  4.] 
adversary cards in hand: [15. 15. 10.  1.  0.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8. 10. 11. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  1.  0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [15. 15. 10.  1.  0.] 
adversary cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8. 10. 11. 11.  8.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15. 15. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10.] 
expected returns: [[ 2.5043635 ]
 [ 0.34648895]
 [ 0.34648895]
 [-0.39152193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 10.  1.  0.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8. 10. 11. 11.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [11.  6.  0. 10.  8.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -7.797853469848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-2.7908456 ]
 [-1.1151078 ]
 [-1.4471016 ]
 [-0.27304626]
 [-1.9885105 ]
 [ 0.90737295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15. 10.  1.  0.] 
cards in discard: [ 0. 11. 15.  3. 11. 29. 29.  0. 25.  3. 29.  3. 11. 29.  0. 11. 25.  0.
 29. 10.  1.  8.  8. 10. 11. 11.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [11.  6.  0. 10.  8.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 2.504359245300293



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [11.  6.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 10.  8.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  8.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [25.  8. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  8.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [25.  8. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  8.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [25.  8. 29. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  8. 29. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 29. 29.] 
expected returns: [[32.838753]
 [40.767075]
 [31.221281]
 [35.884308]
 [35.884308]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 29. 29.  1.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 0.907374382019043



action possibilites: [-1] 
expected returns: [[8.678667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  1. 10. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.76707458496094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[6.068062]
 [8.137586]
 [9.538122]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 29.  1. 10. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
adversary owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.678667068481445






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 3.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14 10  8  8  3 15  1  6  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0
  1  8  8  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [29.  8. 11. 15.  1.] 
adversary cards in discard: [25.  8. 29. 29.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [29.  8. 11. 15.  1.] 
adversary cards in discard: [25.  8. 29. 29.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [29.  8. 11. 15.  1.] 
adversary cards in discard: [25.  8. 29. 29.  1. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29.  8. 11. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11. 15.] 
expected returns: [[43.73684 ]
 [48.061287]
 [42.96489 ]
 [47.306786]
 [42.945564]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 11. 15.  1.] 
cards in discard: [25.  8. 29. 29.  1. 10. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.  8.  0.] 
adversary owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 9.538122177124023



action possibilites: [-1. 15. 10.] 
expected returns: [[18.069855]
 [17.119295]
 [15.922468]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1. 10.] 
cards in discard: [25.  8. 29. 29.  1. 10. 29.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.  8.  0.] 
adversary owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 48.71051788330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.908827]
 [15.661085]
 [14.512745]
 [18.03472 ]
 [13.282446]
 [15.429834]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1. 10.] 
cards in discard: [25.  8. 29. 29.  1. 10. 29.  8. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  1.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.  8.  0.] 
adversary owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 18.06986427307129



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 4 
Witch: 2 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15.  1. 10.] 
cards in discard: [25.  8. 29. 29.  1. 10. 29.  8. 11. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 11 29 25 10  8 29 10  8 25 29  8 10 29  8 15 15 15
 11 29 11  1  3 11  1 11 11 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 30. 24. 29.  8.  0.  7.  0.  0.  8.  4.  9. 10.  3.  9.  4.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [10. 15.  3.  0.  1.  6. 10.  8.  8.  8.  0.  6.  3. 10. 16.  1. 15.  0.
 22. 15.  0.  0.  1.  0. 16. 11.  6.  0. 10.  8.  8.  0.] 
adversary owned cards: [14 10  8  8 15  1  6  0  6  3  6 29  1 16  3  0  8  8 10  0  0  1  8  8
  0 11  0  0 11  0 15  3 15  0 10  3 10 22 16] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      60       0       0      20       0       0
       0       0       0       0       0      27       0] 
sum of rewards: 3000102 

action type: buy - action 11.0
Learning step: 120003.359375
desired expected reward: 120021.390625



