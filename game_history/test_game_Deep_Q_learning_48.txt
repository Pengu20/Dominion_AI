 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[116.289604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     120       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000135 

action type: buy - action 0.0
Learning step: 120003.5078125
desired expected reward: 120050.640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.76204 ]
 [117.21468 ]
 [112.59969 ]
 [ 97.214424]
 [119.898834]
 [117.0612  ]
 [112.44623 ]
 [114.47345 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.83536529541016



buy possibilites: [-1] 
expected returns: [[105.70247]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [15.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 119.8988265991211






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[111.756905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 105.70246887207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.86953 ]
 [115.9788  ]
 [111.63073 ]
 [ 96.966896]
 [113.694984]
 [118.571365]
 [115.81016 ]
 [120.190346]
 [103.90754 ]
 [111.462105]
 [111.01683 ]
 [113.79522 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.0291519165039



buy possibilites: [-1] 
expected returns: [[114.51824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.19034576416016






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 97.53713]
 [102.59116]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 114.51824188232422



action possibilites: [-1] 
expected returns: [[108.634766]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.92696380615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.03861 ]
 [109.76335 ]
 [105.25428 ]
 [ 89.786934]
 [112.72558 ]
 [109.50991 ]
 [105.00084 ]
 [109.0433  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 108.634765625



buy possibilites: [-1] 
expected returns: [[118.29588]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 8. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 112.72557830810547






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8. 15.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 8. 15.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[109.54891]
 [115.90884]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 118.29588317871094



action possibilites: [-1.] 
expected returns: [[118.016716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 116.88033294677734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[110.93693 ]
 [119.13142 ]
 [114.01389 ]
 [103.30686 ]
 [ 99.03455 ]
 [116.39055 ]
 [122.32619 ]
 [118.90075 ]
 [133.24579 ]
 [124.23971 ]
 [105.824005]
 [110.876305]
 [113.78323 ]
 [103.65214 ]
 [113.32011 ]
 [117.34712 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.01671600341797



buy possibilites: [-1] 
expected returns: [[148.19649]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [15.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 235 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 133.2457733154297






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [15.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [11. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[113.33465]
 [118.84477]
 [118.84477]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 15.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 148.1964874267578



action possibilites: [-1] 
expected returns: [[127.03713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 15.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.15306854248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.22538 ]
 [106.260544]
 [124.94973 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  3.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 15.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 127.0371322631836






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3. 15.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 3. 15.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0. 25.] 
adversary cards in discard: [10. 11. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[118.01731]
 [113.93228]
 [131.67996]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 25.] 
cards in discard: [10. 11. 11.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 124.94974517822266



action possibilites: [-1] 
expected returns: [[112.13677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3. 29.] 
cards in discard: [10. 11. 11.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3  6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.11355590820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.079704]
 [115.80664 ]
 [111.89021 ]
 [ 98.154976]
 [118.389885]
 [115.579414]
 [111.662964]
 [115.24732 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3. 29.] 
cards in discard: [10. 11. 11.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  8.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3  6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.13677215576172



buy possibilites: [-1] 
expected returns: [[131.18332]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3. 29.] 
cards in discard: [10. 11. 11.  3.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [15.  3.  3.  8.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3  6] -> size -> 15 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 118.38990020751953






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [15.  3.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  3.  8.  0.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  3  8  8  3  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[122.38227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 131.18331909179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[116.37209 ]
 [123.95808 ]
 [119.408646]
 [103.81626 ]
 [121.52223 ]
 [126.79371 ]
 [123.75715 ]
 [128.48688 ]
 [111.20132 ]
 [119.20773 ]
 [118.78729 ]
 [122.3025  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 123.8557357788086



buy possibilites: [-1] 
expected returns: [[121.52416]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [ 6.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 128.48684692382812






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6.  8. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [10. 11. 25. 11.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [10. 11. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 11.] 
expected returns: [[130.67561]
 [128.2795 ]
 [134.37378]
 [142.16733]
 [134.37378]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25. 11.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 121.52416229248047



action possibilites: [-1] 
expected returns: [[130.18982]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  0.  3. 11.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 142.0068359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.04617]
 [119.71329]
 [133.1444 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 11.  0.  3. 11.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 130.1898193359375






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25. 10. 11. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25. 10. 11. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [6. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 10.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0. 25. 10. 11. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [ 0. 29.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[102.22585]
 [106.96077]
 [ 99.01414]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 10.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 25. 10. 11. 11.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 15.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 133.14437866210938



action possibilites: [-1. 10.] 
expected returns: [[99.15542]
 [97.3028 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 15.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 105.92053985595703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 95.16192 ]
 [101.23158 ]
 [ 97.524055]
 [ 85.50025 ]
 [ 99.27894 ]
 [103.46689 ]
 [101.10475 ]
 [104.82368 ]
 [ 91.071754]
 [ 97.39723 ]
 [ 96.999146]
 [ 99.522545]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 15.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 99.15540313720703



buy possibilites: [-1] 
expected returns: [[129.4227]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 15.  0.] 
adversary cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 104.82369232177734






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 15.  0.] 
cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 15  3  8  8  3  6  0  6  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [6. 3. 3. 0. 3. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [25. 10.  3.  0.  0.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[137.61996]
 [148.97571]
 [136.13242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  0.  0.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  8. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 129.42269897460938



action possibilites: [-1] 
expected returns: [[112.04895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 29. 11.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.71275329589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[106.80519]
 [109.14183]
 [ 98.24749]
 [112.54586]
 [113.82726]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0. 29. 11.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 3. 6. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.0489501953125






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10.  3.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3. 11.] 
adversary cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10.  3.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[106.46095]
 [110.02825]
 [110.02825]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3. 11.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10.  3.  0.  0. 29. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 3.] 
adversary cards in discard: [6. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 113.82727813720703



action possibilites: [-1] 
expected returns: [[151.02087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10.  3.  0.  0. 29. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 3.] 
adversary cards in discard: [6. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 102 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 114.01094818115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[146.87955]
 [149.69286]
 [136.69339]
 [153.19482]
 [153.58197]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [29. 29.  0.  3. 10.  0.  0. 25. 10.  3.  0.  0. 29. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 8. 0. 3.] 
adversary cards in discard: [6. 3. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.0208740234375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [3. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0. 3.] 
cards in discard: [6. 3. 3. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 3 3 8 8 3 6 0 6 3 6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [6. 3. 3. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6. 3. 3. 6. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [6. 3. 3. 6. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 11. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[101.59839]
 [104.95602]
 [112.74319]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  7. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0] -> size -> 12 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.5819854736328



action possibilites: [-1] 
expected returns: [[89.90302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 113.7782211303711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[87.898224]
 [92.95662 ]
 [89.904854]
 [80.46035 ]
 [95.01299 ]
 [92.82786 ]
 [89.78308 ]
 [91.98017 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  7.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.90302276611328



buy possibilites: [-1] 
expected returns: [[120.28892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0. 29. 11.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 3. 0. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6] -> size -> 13 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 189 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 95.01299285888672






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0. 10.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  8.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0. 10.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 6. 0.] 
cards in discard: [6. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 29.  0. 10.  0.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [10. 29.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[115.60099]
 [111.65894]
 [121.49363]
 [111.65894]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0. 10.  0.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 120.2889175415039



action possibilites: [-1. 10. 10.] 
expected returns: [[113.224556]
 [110.219734]
 [110.219734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 120.32093048095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.58014 ]
 [116.991745]
 [112.54789 ]
 [ 97.29926 ]
 [119.77909 ]
 [116.81137 ]
 [112.36749 ]
 [115.37233 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  6.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 113.2245864868164



buy possibilites: [-1] 
expected returns: [[92.04917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 0. 6. 3.] 
adversary cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 119.77909088134766






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11. 29. 10.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 3.] 
cards in discard: [6. 8. 8. 3. 0. 6. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11.  0.  3.  3. 10.] 
adversary cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11. 29. 10.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11] -> size -> 22 
adversary victory points: 3
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[124.17657 ]
 [126.52999 ]
 [120.651634]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11. 29. 10.  0. 10.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 92.0491714477539



action possibilites: [-1] 
expected returns: [[112.8462]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11. 29. 10.  0. 10.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 128.74468994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[104.42087 ]
 [ 93.265915]
 [112.66393 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.] 
cards in discard: [11. 25.  0. 11.  0.  0. 29. 11. 11. 29. 10.  0. 10.  0.  3. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [6. 3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 112.84619903564453






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [6. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  0. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
adversary victory points: 3
player victory points: -2 





Player: 0 
cards in hand: [11. 10.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[105.56255 ]
 [108.40557 ]
 [103.408936]
 [109.50199 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [0. 6. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 112.66393280029297



action possibilites: [-1. 11. 10.] 
expected returns: [[107.38405]
 [110.26515]
 [104.67192]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [0. 6. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 109.1116714477539



action possibilites: [-1] 
expected returns: [[113.65475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [0. 6. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.53712463378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[110.74987 ]
 [116.362015]
 [113.07377 ]
 [101.68    ]
 [114.55897 ]
 [118.522   ]
 [116.19808 ]
 [119.73543 ]
 [107.02591 ]
 [112.90986 ]
 [112.63808 ]
 [115.678314]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  7. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [0. 6. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.65474700927734



buy possibilites: [-1] 
expected returns: [[135.96707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [0. 6. 3. 0. 8. 0.] 
adversary owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 313 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 119.73542022705078






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 6.] 
cards in discard: [0. 6. 3. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 6 0 6 3 6 0 6 8 0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [0. 6. 3. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 6. 3. 0. 8. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 6. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 10. 10. 11.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 25. 10. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 11.] 
expected returns: [[121.62262]
 [131.84956]
 [118.60379]
 [118.60379]
 [124.31434]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10. 10. 11.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0] -> size -> 14 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 135.96707153320312



action possibilites: [-1] 
expected returns: [[84.09001]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.  3. 11.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 128.55789184570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[77.94424 ]
 [68.50657 ]
 [83.630135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10. 11.  3. 11.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6] -> size -> 15 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 84.09001159667969






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [6. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3. 10. 29.] 
adversary cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[89.59837 ]
 [84.691734]
 [92.42596 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 29.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 83.630126953125



action possibilites: [-1. 10. 29.] 
expected returns: [[84.081924]
 [79.426796]
 [88.14634 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 29.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 92.84008026123047



action possibilites: [-1. 10.] 
expected returns: [[80.275475]
 [75.72004 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.1463394165039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[74.47242 ]
 [80.28202 ]
 [77.10386 ]
 [65.62481 ]
 [78.425575]
 [82.679016]
 [80.01834 ]
 [83.99426 ]
 [70.94947 ]
 [76.84018 ]
 [76.747345]
 [81.39562 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 80.27548217773438



buy possibilites: [-1] 
expected returns: [[144.37025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 10.  0.  0.  0. 25.  0. 10. 10. 11.  3. 11. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 0. 8. 8.] 
adversary cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 283 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 83.9942626953125






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29] -> size -> 26 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [6. 1. 0. 0. 0. 8. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 27. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29] -> size -> 26 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8. 8.] 
cards in discard: [6. 1. 0. 0. 0. 8. 6. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 11. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29] -> size -> 26 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[116.5269  ]
 [114.389046]
 [119.92064 ]
 [119.92064 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11. 11.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.37025451660156



action possibilites: [-1] 
expected returns: [[113.50732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 132 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 121.42032623291016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[110.88889 ]
 [113.003876]
 [103.072945]
 [116.0018  ]
 [115.48001 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.50731658935547



buy possibilites: [-1] 
expected returns: [[122.17442]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [6. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 116.00179290771484






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [6. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  0.  3.  0. 10.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [29.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[110.8473  ]
 [116.004944]
 [107.658745]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 10.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 122.17442321777344



action possibilites: [-1. 10. 29.] 
expected returns: [[117.292366]
 [113.44015 ]
 [122.4847  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10. 29.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 115.38370513916016



action possibilites: [-1. 10.] 
expected returns: [[141.25146]
 [138.00536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 122.48470306396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[136.64474]
 [142.92389]
 [139.09161]
 [126.85349]
 [140.79549]
 [145.57024]
 [142.69154]
 [147.11942]
 [132.62717]
 [138.88503]
 [138.6062 ]
 [142.30835]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 141.25146484375



buy possibilites: [-1] 
expected returns: [[144.28326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 10.  3.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 1. 8. 3. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0.] 
adversary owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 147.1194305419922






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 3 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 10. 25.  3.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 10. 25.  3.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 26. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 10. 25.  3.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 25. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 10. 10. 25.  3.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10. 10. 10. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 25.] 
expected returns: [[ 98.789665]
 [ 91.87955 ]
 [ 91.87955 ]
 [ 91.87955 ]
 [107.426   ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 25.  3.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  5. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0.] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3] -> size -> 18 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 144.28326416015625



action possibilites: [-1] 
expected returns: [[166.75876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  3.  0. 11.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0. 6.] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.42601776123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.71066]
 [154.6471 ]
 [167.33743]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10.  3.  0. 11.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 0.] 
adversary cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0. 6.] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6] -> size -> 19 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 166.75875854492188






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 29. 11.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 29. 11.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 0.] 
cards in discard: [0. 6. 3. 6. 0. 0. 3. 8. 0. 1. 0. 6. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 29. 11.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [29. 29. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 29.] 
expected returns: [[203.6374 ]
 [205.85056]
 [205.85056]
 [204.66943]
 [205.85056]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0. 29.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.33741760253906



action possibilites: [-1. 29. 11. 29.] 
expected returns: [[191.20512]
 [192.52615]
 [191.3676 ]
 [192.52615]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 29.  0.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 205.85060119628906



action possibilites: [-1. 11. 29. 11.] 
expected returns: [[169.51202]
 [170.63647]
 [172.37431]
 [170.63647]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29.  0. 11.] 
cards in discard: [10.  8. 11.  0. 10. 11.  0. 29. 29. 29.  0.  3.  0. 10.  3. 25. 10. 10.
 10.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 192.52615356445312



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[127.75704]
 [129.94867]
 [129.94867]
 [124.94076]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 172.37432861328125



action possibilites: [-1] 
expected returns: [[144.23676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 222 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 132.94027709960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[141.3306 ]
 [146.81413]
 [143.61226]
 [135.59576]
 [132.39174]
 [145.05583]
 [148.77136]
 [146.64952]
 [155.45073]
 [149.873  ]
 [137.71446]
 [141.6067 ]
 [143.44766]
 [136.11966]
 [143.20038]
 [145.90112]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  9.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.23675537109375



buy possibilites: [-1] 
expected returns: [[146.44675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.] 
cards in discard: [10. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 445 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 155.45074462890625






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25] -> size -> 31 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 8 8 0 3 6 0 6 8 0 0 6 1 3 0 3 6 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  5.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25] -> size -> 31 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 8.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 10.  3. 10.  8.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25] -> size -> 31 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [11. 10.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.  8.] 
expected returns: [[124.40481]
 [125.75515]
 [121.42188]
 [121.42188]
 [123.46728]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10.  8.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  3. 10.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 146.44674682617188



action possibilites: [-1] 
expected returns: [[95.69239]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  8.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 129.0731201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[87.66895 ]
 [78.108604]
 [96.049995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  8.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [6. 6. 1. 3. 6.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 95.69239044189453






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [6. 6. 1. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [11.  0.  0.  1.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 25.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 1. 3. 6.] 
cards in discard: [11.  0.  0.  1.  3.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 25.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 10.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[109.26089]
 [106.1984 ]
 [114.99735]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 25.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  4. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11] -> size -> 21 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 96.04999542236328



action possibilites: [-1] 
expected returns: [[96.945114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 29. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 114.99736785888672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[93.102394]
 [95.40386 ]
 [85.90359 ]
 [97.60244 ]
 [99.86968 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3. 29. 10.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 8. 0. 8. 3.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6] -> size -> 22 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.94511413574219






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 25. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 3.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
adversary victory points: 3
player victory points: -1 





Player: 0 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[164.10104]
 [160.00713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 99.86968231201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.67513]
 [163.82188]
 [161.67276]
 [153.35979]
 [165.58218]
 [163.58452]
 [161.43544]
 [165.52937]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  4.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 164.10104370117188



buy possibilites: [-1] 
expected returns: [[137.69998]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [10. 25. 29. 29. 29. 11.  0.  0. 11. 10. 10. 11. 10.  3. 10.  8. 25.  0.
  0. 10.  3. 29. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 169 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 165.58218383789062






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 24. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [11.  0.  0.  1.  3.  8.  6.  6.  1.  3.  6.  6.  3.  0.  8.  0.  8.  3.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [ 3. 11. 29. 29. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 29. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 11.] 
expected returns: [[108.51161 ]
 [110.163895]
 [111.54568 ]
 [111.54568 ]
 [110.163895]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 29. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.69998168945312



action possibilites: [-1. 11. 29. 11. 29.] 
expected returns: [[115.7745  ]
 [117.94537 ]
 [119.197235]
 [117.94537 ]
 [119.197235]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 111.0248031616211



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[105.990974]
 [107.27441 ]
 [107.27441 ]
 [108.728874]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 29.  3.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 119.19725799560547



action possibilites: [-1. 11. 11.  8.] 
expected returns: [[108.33961]
 [110.28881]
 [110.28881]
 [107.49917]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.72887420654297



action possibilites: [-1] 
expected returns: [[120.10769]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 192 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 113.84723663330078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[113.159615]
 [120.16811 ]
 [116.229095]
 [102.007   ]
 [122.97633 ]
 [119.906845]
 [115.96785 ]
 [120.708275]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  8.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  3.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.1076889038086



buy possibilites: [-1] 
expected returns: [[140.4016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  8.] 
cards in discard: [10. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 80  0  0  0  0  0  0  0 54  0] 
sum of rewards: 219 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 122.9763412475586






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [8. 0. 6. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  6  0  6  8  0  0  6  1  3  0  3  6  1 11  6  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 23. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [25. 10. 10.  0. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25. 10. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10. 10.] 
expected returns: [[129.5011 ]
 [136.36784]
 [125.40139]
 [125.40139]
 [125.40139]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 10.  0. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  3. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 1.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 140.40159606933594



action possibilites: [-1] 
expected returns: [[141.3991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  0. 11.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 1.] 
adversary cards in discard: [3. 8. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.36785888671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.27579]
 [139.739  ]
 [128.59679]
 [142.49182]
 [143.58698]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0. 11.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 1.] 
adversary cards in discard: [3. 8. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.3990936279297






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 1.] 
cards in discard: [3. 8. 0. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 1.] 
cards in discard: [3. 8. 0. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10. 10.  1. 10.  9.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 1.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [29. 11.  0. 25. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [29. 11.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25. 10.] 
expected returns: [[143.8058 ]
 [146.56749]
 [145.31071]
 [152.65631]
 [139.35037]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 25. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  2. 10.  2.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.5869903564453



action possibilites: [-1] 
expected returns: [[139.52475]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  1. 10.  2.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.65628051757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[135.40782]
 [140.59229]
 [137.70837]
 [123.93142]
 [142.7595 ]
 [140.39243]
 [137.5085 ]
 [141.15631]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 22. 30.  8.  1. 10.  2.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.52474975585938



buy possibilites: [-1] 
expected returns: [[139.46498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0. 10.  0.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [3. 8. 3. 3. 0.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6] -> size -> 26 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0 -10   0   0  54   0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 142.75950622558594






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 3. 0.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 3. 11. 10. 10. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11] -> size -> 36 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11. 10. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[120.96374 ]
 [121.5168  ]
 [117.163475]
 [117.163475]
 [117.163475]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10. 10. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  1. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 11.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 139.46498107910156



action possibilites: [-1] 
expected returns: [[128.34929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 11.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 112 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 124.1249008178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.30363]
 [111.60996]
 [128.02618]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [ 6.  3.  6.  6. 11.] 
adversary cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.3492889404297






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6.  6. 11.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 6. 6.] 
cards in discard: [ 3.  8.  0.  0.  6. 23.  0.  6.  0.  0.  1.  6.  0.  3.  8.  3.  3.  0.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [11. 29.  0. 29. 10.] 
adversary cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11. 29.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 10.] 
expected returns: [[105.94875]
 [106.63635]
 [107.91551]
 [107.91551]
 [100.43237]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 29. 10.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 128.02618408203125



action possibilites: [-1. 11. 10.] 
expected returns: [[106.16474]
 [108.27141]
 [102.40688]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  9.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 104.02803802490234



action possibilites: [-1] 
expected returns: [[120.33384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 159 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 111.67681884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
expected returns: [[114.18747 ]
 [119.84191 ]
 [116.672035]
 [108.12212 ]
 [122.107994]
 [119.63037 ]
 [120.333855]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10. 29. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  1.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 120.3338394165039



buy possibilites: [-1] 
expected returns: [[137.5101]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.] 
cards in discard: [10. 11. 29. 29. 29. 11.  3. 11.  3.  8. 25. 10. 10.  0. 10.  0. 11. 11.
 25. 29. 11.  0. 10.  0.  0. 10. 11.  3. 10. 10. 10. 29. 15. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [6. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  40   0   0   0   0 -40   0   0  54   0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 122.10798645019531






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  3  0  6  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6
 23  6  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[96.930016]
 [93.51551 ]
 [93.51551 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 137.51010131835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[91.8368  ]
 [96.86025 ]
 [94.08537 ]
 [83.921005]
 [96.665695]
 [97.37246 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [8. 0. 0. 6. 0.] 
adversary cards in discard: [0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0  0] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 96.92998504638672



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6
  0  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [15. 29. 11.  8. 25.] 
adversary cards in discard: [ 0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [15. 29. 11.  8. 25.] 
adversary cards in discard: [ 0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [15. 29. 11.  8. 25.] 
adversary cards in discard: [ 0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0. 8. 0. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6  0  0  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [15. 29. 11.  8. 25.] 
adversary cards in discard: [ 0.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [15. 29. 11.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 11.  8. 25.] 
expected returns: [[126.80743 ]
 [121.11497 ]
 [128.9133  ]
 [127.527794]
 [124.49435 ]
 [135.55803 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 11.  8. 25.] 
cards in discard: [ 0.  0. 10. 10.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 30.  8.  1. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8. 23.  3.  0.  0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 8. 6.] 
adversary owned cards: [ 8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6  0  0  0
  0] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 97.37244415283203



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 9 
Chapel: 1 
Witch: 2 
Poacher: 6 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 29. 11.  8. 10.  0.] 
cards in discard: [ 0.  0. 10. 10.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 11 25 10 11 29 29 10 11 11 10 10
 29 29 10  8 29 10 25 10 11 10 11 11 10 15 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 22. 30.  8.  0. 10.  0.  6.  8.  4. 10.  9.  0. 10.  8.] 
adversary cards in hand: [ 8. 23.  3.  0.  0.] 
adversary cards in discard: [0. 8. 0. 0. 0. 8. 6. 6.] 
adversary owned cards: [ 8  8  0  0  8  0  0  6  3  0  3  6  1 11  6  3  3  3  6 23  6  0  0  0
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      90       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000105 

action type: take_action - action 25.0
Learning step: 119998.7734375
desired expected reward: 120134.328125



