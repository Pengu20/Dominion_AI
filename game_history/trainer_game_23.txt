 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.86]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.479788780212402
desired expected reward: -4.4868364334106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.903059]
 [20.248758]
 [19.61838 ]
 [17.057549]
 [22.106298]
 [21.390978]
 [20.760595]
 [21.1241  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.572218656539917
desired expected reward: 20.691518783569336



buy possibilites: [-1] 
expected returns: [[20.384996]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.503049373626709
desired expected reward: 18.40001106262207






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.193424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5260911583900452
desired expected reward: 19.858905792236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.818628]
 [22.16433 ]
 [21.533949]
 [18.973116]
 [21.198677]
 [24.021864]
 [23.306543]
 [23.806015]
 [21.449886]
 [22.676163]
 [22.79559 ]
 [23.039669]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5862440466880798
desired expected reward: 21.83839225769043



buy possibilites: [-1] 
expected returns: [[23.242702]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5451478958129883
desired expected reward: 22.761394500732422






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 0. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.78021 ]
 [22.047083]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.613717794418335
desired expected reward: 22.628984451293945



action possibilites: [-1] 
expected returns: [[21.366772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 7
Learning step: 0.10312408208847046
desired expected reward: 19.144025802612305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.98896 ]
 [17.143448]
 [21.210001]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01409660279750824
desired expected reward: 21.380868911743164






Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [8.] 
adversary owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.056086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5714051127433777
desired expected reward: 20.63859748840332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.289642]
 [19.635344]
 [19.004963]
 [16.444128]
 [18.66969 ]
 [21.492876]
 [20.777557]
 [21.27703 ]
 [18.9209  ]
 [20.147179]
 [20.266602]
 [20.510685]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 0 8] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5540449619293213
desired expected reward: 19.91214370727539



buy possibilites: [-1] 
expected returns: [[21.377487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [8. 8. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.3949516713619232
desired expected reward: 19.752225875854492






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 8. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 8. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  7. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8. 8. 0. 0. 0. 3. 8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.122025]
 [18.758518]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5880958437919617
desired expected reward: 20.789390563964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.34876 ]
 [18.69446 ]
 [18.064085]
 [15.503263]
 [17.72881 ]
 [20.551996]
 [19.836676]
 [20.336147]
 [17.98002 ]
 [19.206297]
 [19.325722]
 [19.569803]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5349542498588562
desired expected reward: 18.96556854248047



buy possibilites: [-1] 
expected returns: [[21.215153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.40916338562965393
desired expected reward: 17.65492057800293






Player: 1 
cards in hand: [0. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8 8 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[17.497034]
 [17.13353 ]
 [17.763906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.598139762878418
desired expected reward: 20.61701202392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.556622]
 [15.226973]
 [12.800433]
 [16.97693 ]
 [16.644724]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [0 0 0 0 0 0 3 3 8 8 0] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4918392598628998
desired expected reward: 16.358707427978516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 3 3 8 8 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 0] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  6. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 8. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  3.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.511868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.41023069620132446
desired expected reward: 16.234493255615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.663464]
 [21.990047]
 [21.353462]
 [18.847742]
 [21.03255 ]
 [23.817945]
 [23.127945]
 [23.59845 ]
 [21.266195]
 [22.49136 ]
 [22.592781]
 [22.795738]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  3.  8.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5986522436141968
desired expected reward: 22.173826217651367



buy possibilites: [-1] 
expected returns: [[21.675003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  3.  8.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 1.0
Learning step: -0.44711390137672424
desired expected reward: 21.54293441772461






Player: 1 
cards in hand: [0. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3  1] -> size -> 11 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 29. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3  1] -> size -> 11 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0  8 10  3  1] -> size -> 11 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.029816]
 [18.362024]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0  8 10  3  1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6056475639343262
desired expected reward: 21.069355010986328



action possibilites: [-1] 
expected returns: [[17.568768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.14654210209846497
desired expected reward: 16.410873413085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[15.474096]
 [16.15939 ]
 [13.699731]
 [17.933872]
 [17.601665]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 28. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.09645761549472809
desired expected reward: 17.665225982666016



buy possibilites: [-1] 
expected returns: [[21.279324]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [3. 0. 8. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.42865127325057983
desired expected reward: 16.58803939819336






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [3. 0. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [3. 0. 8. 0. 3. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 3 3 8 8 0 8 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 27. 30.  8. 10. 10. 10.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [ 3.  0.  8.  0.  3.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  0  8  3 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  1.  0. 10.  0.] 
adversary cards in discard: [3. 8. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.659525]
 [21.355145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 10.  0.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0  8  3 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5599015355110168
desired expected reward: 20.71942138671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.347307]
 [21.67389 ]
 [21.037304]
 [18.528608]
 [20.716394]
 [23.501787]
 [22.811789]
 [23.282295]
 [20.950037]
 [22.175201]
 [22.276619]
 [22.479578]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  0.] 
cards in discard: [3. 8. 3. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0  8  3 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5752469301223755
desired expected reward: 21.30632781982422



buy possibilites: [-1] 
expected returns: [[23.176483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0. 10.  0.] 
cards in discard: [ 3.  8.  3.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8  8  0  8  3 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.4369029700756073
desired expected reward: 21.738298416137695






Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8  8  0  8  3 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[19.34045 ]
 [19.036072]
 [19.672657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6382476687431335
desired expected reward: 22.53823471069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.461756]
 [18.77621 ]
 [18.140247]
 [15.691094]
 [20.604109]
 [19.914108]
 [19.277523]
 [19.581902]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5391584038734436
desired expected reward: 19.10572052001953



buy possibilites: [-1] 
expected returns: [[19.433376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0.  0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [0. 8. 8.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0] -> size -> 11 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: 0.030764121562242508
desired expected reward: 18.806974411010742






Player: 1 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [0. 8. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [ 1.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [ 1.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8.  8. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [ 1.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [ 0.  8.  8. 14.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  1. 10.] 
adversary cards in discard: [ 1.  0. 10.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.751602]
 [23.447224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  1. 10.] 
cards in discard: [ 1.  0. 10.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 14.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4838068187236786
desired expected reward: 18.949569702148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[21.612915]
 [22.930391]
 [22.288801]
 [19.798634]
 [24.741545]
 [24.065657]
 [23.424067]
 [23.68468 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  1. 10.] 
cards in discard: [ 1.  0. 10.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [11. 14.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6114836931228638
desired expected reward: 22.89234733581543



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 14.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  9.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8. 10. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  8.  0.] 
cards in discard: [11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8. 10. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.838812]
 [19.578497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8. 10. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6510613560676575
desired expected reward: 23.033618927001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.036266]
 [18.698223]
 [16.268532]
 [20.469482]
 [20.088503]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8. 10. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5514705181121826
desired expected reward: 19.503162384033203



buy possibilites: [-1] 
expected returns: [[20.331675]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 3. 0.] 
adversary cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.424572944641113
desired expected reward: 6.84395694732666






Player: 1 
cards in hand: [8. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 3. 0.] 
cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  0.  1.] 
adversary cards in discard: [ 6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  0.  1.] 
adversary cards in discard: [ 6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0. 11. 14.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  0.  1.] 
adversary cards in discard: [ 6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [11.  0. 11. 14.  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  8. 10.  0.  1.] 
adversary cards in discard: [ 6.  3. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[22.44592 ]
 [22.825523]
 [22.187586]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  0.  1.] 
cards in discard: [ 6.  3. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5219911932945251
desired expected reward: 19.809682846069336



action possibilites: [-1.  8.] 
expected returns: [[23.729456]
 [24.110437]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 0.] 
cards in discard: [ 6.  3. 10.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.032743778079748154
desired expected reward: 22.32659912109375



action possibilites: [-1.] 
expected returns: [[25.063717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  3. 10.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.663887619972229
desired expected reward: 22.30660057067871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.56184 ]
 [24.879316]
 [24.237726]
 [21.742386]
 [23.923243]
 [26.690468]
 [26.014584]
 [26.465736]
 [24.145267]
 [25.372993]
 [25.462744]
 [25.633602]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  3. 10.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 28. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5628293752670288
desired expected reward: 25.62654685974121



buy possibilites: [-1] 
expected returns: [[24.23239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 6.  3. 10.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 39.5 

action type: buy - action 1.0
Learning step: 0.6930606365203857
desired expected reward: 25.572376251220703






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 8. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6  1] -> size -> 14 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [3. 0. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[21.641766]
 [22.022743]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  8 10  3  1  3 10  1  6  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6449846029281616
desired expected reward: 23.587404251098633



action possibilites: [-1] 
expected returns: [[19.800081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 12
Learning step: 0.03597988188266754
desired expected reward: 20.766679763793945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.817503]
 [16.026197]
 [19.889269]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04821733385324478
desired expected reward: 19.848299026489258



buy possibilites: [-1] 
expected returns: [[17.121286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 3. 8.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.09524837136268616
desired expected reward: 17.91275405883789






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3. 0. 0. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [3. 0. 0. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10. 10.] 
adversary cards in hand: [10.  1.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 3.  0.  0.  3.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [10.  1.  0.  3.  1.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10.  1.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.191154]
 [19.930544]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  3.  1.] 
cards in discard: [0. 8. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.45150575041770935
desired expected reward: 16.669780731201172



action possibilites: [-1. 10.] 
expected returns: [[22.613098]
 [22.396292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  1. 10.] 
cards in discard: [0. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.0999462902545929
desired expected reward: 19.65263557434082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.413824]
 [22.716524]
 [22.074617]
 [20.19021 ]
 [19.610933]
 [21.765322]
 [24.500708]
 [23.839916]
 [25.494108]
 [24.270494]
 [21.974392]
 [21.2025  ]
 [23.198006]
 [19.899801]
 [23.277094]
 [23.414814]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 10.] 
cards in discard: [0. 8. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.013537387363612652
desired expected reward: 22.62663459777832



buy possibilites: [-1] 
expected returns: [[20.16577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 10.] 
cards in discard: [ 0.  8.  3. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 14.0
Learning step: 0.24250876903533936
desired expected reward: 22.216901779174805






Player: 1 
cards in hand: [ 8. 14.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  8.  3. 11.] 
cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  8  0  8  3 11  0 14  3 11  0  0 15] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.] 
cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.] 
cards in discard: [ 3.  0.  0.  3.  8. 15.  0. 11.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[16.288782]
 [16.692743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.579307496547699
desired expected reward: 19.586462020874023





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[14.749011]
 [15.965784]
 [15.361721]
 [13.091844]
 [17.668371]
 [17.035276]
 [16.423338]
 [16.629297]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47422119975090027
desired expected reward: 16.01230239868164



buy possibilites: [-1] 
expected returns: [[17.316164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 6. 0.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4106506109237671
desired expected reward: 14.338360786437988






Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 14. 10.] 
adversary cards in discard: [0. 0. 8. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 14. 10.] 
adversary cards in discard: [0. 0. 8. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  3.  0. 14. 10.] 
adversary cards in discard: [0. 0. 8. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[19.850145]
 [18.466358]
 [19.6386  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 14. 10.] 
cards in discard: [0. 0. 8. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14. 15. 11.  0.  3.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4643852710723877
desired expected reward: 16.851778030395508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[18.294476]
 [19.544062]
 [18.921875]
 [16.606365]
 [21.287228]
 [20.640158]
 [20.013859]
 [20.225405]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 14. 10.] 
cards in discard: [0. 0. 8. 0. 6. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  8. 10.  9.] 
adversary cards in hand: [14. 15. 11.  0.  3.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5408365726470947
desired expected reward: 19.420825958251953



buy possibilites: [-1] 
expected returns: [[18.864286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0. 14. 10.] 
cards in discard: [ 0.  0.  8.  0.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [14. 15. 11.  0.  3.] 
adversary cards in discard: [8. 0. 0. 3.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.012340736575424671
desired expected reward: 20.00151824951172






Player: 1 
cards in hand: [14. 15. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15. 11.  0.  3.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 10.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  3.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  3.] 
cards in discard: [8. 0. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  5. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  3.] 
cards in discard: [8. 0. 0. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  1.  3.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[15.008546]
 [14.812024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8. 14. 15. 11.  0.  3.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
   45    0] 
sum of rewards: -260 

action type: discard_down_to_3_cards - action 5
Learning step: -8.148812294006348
desired expected reward: 8.751494407653809





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[13.32921 ]
 [13.923593]
 [11.727984]
 [15.519672]
 [15.134405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.] 
cards in discard: [10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  0.  3.  8. 14. 15. 11.  0.  3.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4547714591026306
desired expected reward: 14.690207481384277



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  8. 14. 15. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  3.  8.] 
adversary cards in discard: [10.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  8. 14. 15. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  4. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  3.  8.] 
adversary cards in discard: [10.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  8. 14. 15. 11.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0. 14.  3.  8.] 
adversary cards in discard: [10.  0. 10.  1.  3.] 
adversary owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0. 14.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
expected returns: [[17.831604]
 [17.625574]
 [16.46644 ]
 [18.238907]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.  3.  8.] 
cards in discard: [10.  0. 10.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3  3 10  1  6  1  0 14  0 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4173087477684021
desired expected reward: 14.717097282409668



action possibilites: [-1] 
expected returns: [[18.634258]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 14.] 
cards in discard: [10.  0. 10.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.13027335703372955
desired expected reward: 17.309818267822266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.17276 ]
 [15.447804]
 [19.1595  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 14.] 
cards in discard: [10.  0. 10.  1.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07619138807058334
desired expected reward: 18.71044921875






Player: 1 
cards in hand: [8. 8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 26. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 1. 6. 0.] 
adversary cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.681396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 15.  0.] 
adversary cards in discard: [3. 8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5047686100006104
desired expected reward: 18.227767944335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.060743]
 [19.32907 ]
 [18.698679]
 [16.85949 ]
 [16.305641]
 [18.397804]
 [21.080868]
 [20.43227 ]
 [22.065063]
 [20.842989]
 [18.594543]
 [17.834484]
 [19.796589]
 [16.567629]
 [19.86422 ]
 [19.970984]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 15.  0.] 
adversary cards in discard: [3. 8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.535716712474823
desired expected reward: 19.19832992553711



buy possibilites: [-1] 
expected returns: [[19.002129]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 0.] 
cards in discard: [10.  0. 10.  1.  3.  8. 10.  0. 14.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 5 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 8.  0.  3. 15.  0.] 
adversary cards in discard: [3. 8. 8. 8. 0. 0.] 
adversary owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.4922999143600464
desired expected reward: 17.568443298339844






Player: 1 
cards in hand: [ 8.  0.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 15.  0.] 
cards in discard: [3. 8. 8. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [3. 8. 8. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [3. 8. 8. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [ 3.  8.  8.  8.  0.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[14.561528]
 [14.401345]
 [14.401345]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5672850012779236
desired expected reward: 18.434843063354492



action possibilites: [-1. 10.] 
expected returns: [[18.317396]
 [18.152037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.2073814421892166
desired expected reward: 14.682605743408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.964823]
 [18.168863]
 [17.568264]
 [15.332914]
 [19.832579]
 [19.218227]
 [18.615309]
 [18.780666]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  3. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.09383228421211243
desired expected reward: 18.41122817993164



buy possibilites: [-1] 
expected returns: [[17.698633]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  2. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 11.] 
adversary cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.1192888617515564
desired expected reward: 19.337514877319336






Player: 1 
cards in hand: [ 0.  0.  3. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 11.] 
cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  2. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  2. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  2. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [ 3.  8.  8.  8.  0.  0. 10. 15.  8.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  1. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.657299]
 [19.481352]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  1. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 8
Learning step: -0.4286998510360718
desired expected reward: 15.736560821533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.94314 ]
 [19.215792]
 [18.57654 ]
 [16.210514]
 [20.980906]
 [20.331915]
 [19.69061 ]
 [19.86656 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 25. 30.  8.  9. 10.  8.  1. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5369030237197876
desired expected reward: 19.177087783813477



buy possibilites: [-1] 
expected returns: [[20.476175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 10.] 
cards in discard: [ 8. 10.  0.  6. 10.  0.  0.  0.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  1. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  8. 15.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.43229639530181885
desired expected reward: 18.144245147705078






Player: 1 
cards in hand: [11.  3.  8. 15.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 15.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  1. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 15.  3.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[15.421383]
 [14.139135]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 3.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6065577864646912
desired expected reward: 19.869617462158203



action possibilites: [-1] 
expected returns: [[21.32335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.246601402759552
desired expected reward: 14.489727020263672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.198874]
 [21.489168]
 [19.55757 ]
 [20.847866]
 [18.976799]
 [18.408266]
 [20.541761]
 [23.254288]
 [24.23848 ]
 [23.016403]
 [20.741913]
 [19.96868 ]
 [21.96399 ]
 [18.678383]
 [22.032211]
 [22.139936]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 8. 3.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.037628915160894394
desired expected reward: 21.360979080200195






Player: 1 
cards in hand: [0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 10.  0.] 
adversary cards in discard: [14.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3.] 
cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 10. 10.  0.] 
adversary cards in discard: [14.  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[18.837458]
 [19.290861]
 [18.666103]
 [18.666103]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10. 10.  0.] 
cards in discard: [14.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 10  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 14.  0.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6147226691246033
desired expected reward: 21.52521324157715



action possibilites: [-1] 
expected returns: [[19.052502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [14.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 14.  0.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.0932246595621109
desired expected reward: 18.654111862182617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.512936]
 [15.925792]
 [19.27095 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [14.  0.  3.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  8.  0. 14.  0.] 
adversary cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
adversary owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.06648101657629013
desired expected reward: 19.118982315063477






Player: 1 
cards in hand: [ 8.  8.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 14.  0.] 
cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  0  8  3  0 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  1.  0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.] 
cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  1.  0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.] 
cards in discard: [ 8. 11.  3.  8. 15.  3.  3.  8.  0.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8. 10.  1.  0.] 
adversary cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
adversary owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[22.230215]
 [22.723627]
 [22.087687]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  1.  0.] 
cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3 10  1  6  1  0 14  0 10  0  8  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4919634163379669
desired expected reward: 18.77898597717285



action possibilites: [-1] 
expected returns: [[17.079638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.03556474670767784
desired expected reward: 19.827945709228516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[15.94744 ]
 [17.15711 ]
 [16.551302]
 [14.315139]
 [16.264343]
 [18.869293]
 [18.627434]
 [16.449257]
 [17.613485]
 [17.670866]
 [17.75219 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  0.  3.  0.  1.  8. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  8.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12020278722047806
desired expected reward: 17.199840545654297



buy possibilites: [-1] 
expected returns: [[19.111547]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [14.  0.  3.  0.  1.  8. 10. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.21959243714809418
desired expected reward: 19.088886260986328






Player: 1 
cards in hand: [ 8.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 3. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11] -> size -> 14 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [1. 3. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[17.720722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [ 8.  3. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5361085534095764
desired expected reward: 18.575439453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[16.0773  ]
 [17.34601 ]
 [16.710072]
 [14.36802 ]
 [19.089205]
 [17.816341]
 [17.958872]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 27. 30. 24. 30.  8.  9. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [ 8.  3. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5016391277313232
desired expected reward: 17.330541610717773



buy possibilites: [-1] 
expected returns: [[17.374977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 3. 6.] 
cards in discard: [6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3. 14.  8.] 
adversary cards in discard: [ 8.  3. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.398603439331055
desired expected reward: 4.969416618347168






Player: 1 
cards in hand: [ 8. 11.  3. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3. 14.  8.] 
cards in discard: [ 8.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 11.  8.  8. 10.] 
adversary cards in discard: [6. 1. 3. 0. 3. 6.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  8.] 
cards in discard: [ 8.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 11. 10.] 
adversary cards in discard: [6. 1. 3. 0. 3. 6. 8. 8.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  8.] 
cards in discard: [ 8.  3. 10.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14. 11. 10.] 
adversary cards in discard: [6. 1. 3. 0. 3. 6. 8. 8.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [14. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10.] 
expected returns: [[19.220549]
 [17.942177]
 [20.314543]
 [19.085287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 10.] 
cards in discard: [6. 1. 3. 0. 3. 6. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 8.  3. 10.  0.  0. 14.  8. 11.  3.  8.] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 0
Learning step: -0.3754119277000427
desired expected reward: 13.944679260253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.562885 ]
 [15.9212055]
 [19.340946 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 10.] 
cards in discard: [6. 1. 3. 0. 3. 6. 8. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 8. 0. 8. 8.] 
adversary cards in discard: [ 8.  3. 10.  0.  0. 14.  8. 11.  3.  8.] 
adversary owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5404183268547058
desired expected reward: 18.757728576660156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 8. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8. 8.] 
cards in discard: [ 8.  3. 10.  0.  0. 14.  8. 11.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  3 14  3 11  0  0 15  0  8  8  3 10  8  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 8.  3. 10.  0.  0. 14.  8. 11.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 8.  3. 10.  0.  0. 14.  8. 11.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.005103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5704321265220642
desired expected reward: 18.7705135345459





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.668725]
 [14.81032 ]
 [14.239671]
 [12.588471]
 [12.097221]
 [13.96831 ]
 [16.409325]
 [17.34619 ]
 [16.180239]
 [14.143161]
 [13.452363]
 [15.237759]
 [12.320275]
 [15.291591]
 [15.367951]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44854557514190674
desired expected reward: 14.770143508911133



buy possibilites: [-1] 
expected returns: [[17.019264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 1.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 14.0
Learning step: -0.1520441621541977
desired expected reward: 13.991116523742676






Player: 1 
cards in hand: [ 8.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8.  3. 15.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 14  3 11  0 15  0  8  8  3 10  8  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  8.  3. 11. 10.] 
adversary cards in discard: [14.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  8.  3. 11. 10.] 
adversary cards in discard: [14.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  8.  3. 11. 10.] 
adversary cards in discard: [14.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  8.  3. 11. 10.] 
adversary cards in discard: [14.  6.  0.  0.  0.  1.] 
adversary owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 1.  8.  3. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[18.311085]
 [18.819904]
 [19.44932 ]
 [18.190327]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 11. 10.] 
cards in discard: [14.  6.  0.  0.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4615985155105591
desired expected reward: 16.55766487121582



action possibilites: [-1.  8. 11.] 
expected returns: [[17.518385]
 [18.01693 ]
 [18.63839 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 11.  0.] 
cards in discard: [14.  6.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09192552417516708
desired expected reward: 18.388641357421875



action possibilites: [-1.  8.] 
expected returns: [[19.279213]
 [19.788034]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3. 0.] 
cards in discard: [14.  6.  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  8  3  1  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: gain_card_n - action 0
Learning step: 0.7833177447319031
desired expected reward: 16.52730369567871



action possibilites: [-1] 
expected returns: [[17.477064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [14.  6.  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 1
Learning step: 1.278225064277649
desired expected reward: 19.787696838378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.043865]
 [14.39183 ]
 [17.874535]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [14.  6.  0.  0.  0.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.  8.] 
owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 14.  8.  0. 10.] 
adversary cards in discard: [0. 8. 0. 3.] 
adversary owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.2984932661056519
desired expected reward: 18.775556564331055






Player: 1 
cards in hand: [ 8. 14.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  8.  0. 10.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 14.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8. 14.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  8.  0. 11.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 14  3 11  0  0  8  8  3 10  8  8  0] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 14.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 14.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [0. 8. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 14.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.] 
cards in discard: [0. 8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11. 14.  6.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 14.  6.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.  8.] 
expected returns: [[ 8.997116]
 [10.021673]
 [ 7.808668]
 [ 9.453251]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  6.  3.  8.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  3  6  1  0 14  0 10  0  8  3 11  6 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5871385335922241
desired expected reward: 17.287395477294922



action possibilites: [-1] 
expected returns: [[9.168466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.3574029803276062
desired expected reward: 6.652932643890381





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.676718]
 [6.199166]
 [9.254591]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.25914597511291504
desired expected reward: 9.427611351013184



buy possibilites: [-1] 
expected returns: [[13.6231165]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11.  8.  8.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.3627412021160126
desired expected reward: 8.039459228515625






Player: 1 
cards in hand: [11.  8.  8.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  8.  3.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 11  0  0  8  8  3 10  8  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  0  0  8  3 10  8  8  0  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  0  0  8  3 10  8  8  0  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 11  0  0  8  3 10  8  8  0  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
adversary victory points: -1
player victory points: 2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[12.728369]
 [13.191527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.] 
adversary owned cards: [ 3 11  0  0  8  3 10  8  8  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4212716519832611
desired expected reward: 13.201845169067383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[11.330833]
 [12.447265]
 [11.888937]
 [ 9.77448 ]
 [14.015249]
 [12.869246]
 [12.979185]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 24. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.] 
adversary owned cards: [ 3 11  0  0  8  3 10  8  8  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.40249869227409363
desired expected reward: 12.407400131225586



buy possibilites: [-1] 
expected returns: [[10.283488]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [ 0.  8. 11.  3.] 
adversary owned cards: [ 3 11  0  0  8  3 10  8  8  0  0  0] -> size -> 12 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.33869150280952454
desired expected reward: 11.55024528503418






Player: 1 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [ 0.  8. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 11  0  0  8  3 10  8  8  0  0  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  0. 14.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 10  8  8  0  0  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  0. 14.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 10  8  8  0  0  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  0. 14.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8. 11.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [10.  1.  0. 14.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  1.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[11.011451]
 [10.905207]
 [ 9.845678]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 14.  6.] 
cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.34577465057373047
desired expected reward: 9.937713623046875



action possibilites: [-1] 
expected returns: [[10.615805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.25926023721694946
desired expected reward: 10.332784652709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 9.316749 ]
 [10.433005 ]
 [ 9.872767 ]
 [ 8.256146 ]
 [ 7.782763 ]
 [ 9.604337 ]
 [12.007896 ]
 [12.880364 ]
 [11.776814 ]
 [ 9.775971 ]
 [ 9.089806 ]
 [10.860559 ]
 [ 7.9925365]
 [10.905769 ]
 [10.953507 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24341966211795807
desired expected reward: 10.859224319458008



buy possibilites: [-1] 
expected returns: [[12.814736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  3.  8.  0.  3.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [11.  3.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 23.0 

action type: buy - action 15.0
Learning step: 0.49738162755966187
desired expected reward: 11.40315055847168






Player: 1 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 23. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 8. 6. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [3. 8. 6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[10.486601]
 [10.963842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.41925060749053955
desired expected reward: 12.395485877990723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 9.153914]
 [ 7.626561]
 [10.787334]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 22. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3] -> size -> 10 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.37060511112213135
desired expected reward: 10.311007499694824



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 10.  0.] 
adversary cards in discard: [3. 8. 6. 3. 0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 22. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 10.  0.] 
adversary cards in discard: [3. 8. 6. 3. 0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  0. 15. 10.  0.] 
adversary cards in discard: [3. 8. 6. 3. 0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6.  0. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[12.417519 ]
 [12.3697815]
 [12.324573 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 15. 10.  0.] 
cards in discard: [3. 8. 6. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 8. 8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3429301083087921
desired expected reward: 10.444403648376465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.095856]
 [11.668226]
 [ 9.494882]
 [12.763693]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 10.  0.] 
cards in discard: [3. 8. 6. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 8. 8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4031738042831421
desired expected reward: 12.080998420715332



buy possibilites: [-1] 
expected returns: [[13.19747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 15. 10.  0.] 
cards in discard: [3. 8. 6. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 10.  0. 11.] 
adversary cards in discard: [3. 3. 0. 0. 8. 8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.344302237033844
desired expected reward: 10.751553535461426






Player: 1 
cards in hand: [ 3.  0. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0. 11.] 
cards in discard: [3. 3. 0. 0. 8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  8. 14.  0.  0.] 
adversary cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0.] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[13.637751]
 [14.120907]
 [12.446761]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 14.  0.  0.] 
cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [10.  3.  0.  0. 11.  8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4033013582229614
desired expected reward: 12.794168472290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[12.572324]
 [13.712938]
 [13.137618]
 [11.004281]
 [12.8638  ]
 [15.35871 ]
 [15.113355]
 [13.038527]
 [14.146621]
 [14.193657]
 [14.243378]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 14.  0.  0.] 
cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10. 10.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [10.  3.  0.  0. 11.  8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4139339327812195
desired expected reward: 13.261506080627441



buy possibilites: [-1] 
expected returns: [[18.20627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 14.  0.  0.] 
cards in discard: [ 3.  8.  6.  3.  0.  0.  6.  0. 15. 10.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [10.  3.  0.  0. 11.  8.] 
adversary owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.5477651357650757
desired expected reward: 15.661118507385254






Player: 1 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [10.  3.  0.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  3 10  8  8  0  0  0  0  3  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 14.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 19 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  3.  0.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 14.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 19 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  3.  0.  0. 11.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 14.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 19 
adversary victory points: 0
player victory points: 2 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [15. 14.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 14.] 
expected returns: [[14.23513  ]
 [14.187557 ]
 [13.0455265]
 [13.0455265]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5497522354125977
desired expected reward: 17.656517028808594



action possibilites: [-1] 
expected returns: [[9.9812155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.12328101694583893
desired expected reward: 14.507339477539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[ 8.561483 ]
 [ 9.622275 ]
 [ 9.080469 ]
 [ 7.1191654]
 [ 8.829609 ]
 [11.123594 ]
 [10.903261 ]
 [ 8.989574 ]
 [10.029873 ]
 [10.072912 ]
 [10.118478 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  9.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.25368544459342957
desired expected reward: 10.23490047454834



buy possibilites: [-1] 
expected returns: [[11.8052225]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0. 14.] 
cards in discard: [29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 8. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 1.2068569660186768
desired expected reward: 12.110119819641113






Player: 1 
cards in hand: [0. 8. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  0  3  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [29. 15. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
adversary victory points: 0
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [29. 15. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 10  8  8  0  3] -> size -> 6 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [29. 15. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.332666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [29. 15. 14.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.34126922488212585
desired expected reward: 11.463953018188477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[13.689742]
 [14.806112]
 [14.228489]
 [12.174061]
 [13.967005]
 [16.428513]
 [16.185562]
 [14.132042]
 [15.242554]
 [15.285341]
 [15.309347]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [29. 15. 14.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  7.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.45381733775138855
desired expected reward: 14.933028221130371



buy possibilites: [-1] 
expected returns: [[17.700119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [29. 15. 14.  0. 14. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  0.  3. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3] -> size -> 6 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.322004109621048
desired expected reward: 16.106508255004883






Player: 1 
cards in hand: [ 8.  0.  3. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10. 11.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  8.] 
adversary cards in hand: [10.  0.  3.  1. 29.] 
adversary cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 10.] 
cards in discard: [15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  0  3 15] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  3.  1. 29.] 
adversary cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  3. 10.] 
cards in discard: [15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  0  3 15] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [10.  0.  3.  1. 29.] 
adversary cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[16.502157]
 [16.439564]
 [17.31979 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  1. 29.] 
cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3 15] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5031236410140991
desired expected reward: 17.19699478149414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[15.126877]
 [16.225798]
 [15.668833]
 [13.597975]
 [17.74347 ]
 [16.634468]
 [16.697063]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1. 29.] 
cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  6.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3 15] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47593969106674194
desired expected reward: 16.098539352416992



buy possibilites: [-1] 
expected returns: [[18.878345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  1. 29.] 
cards in discard: [29. 15. 14.  0. 14. 11.  0.  0.  0.  0.  6. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  5.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  0  3 15] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0.05591863393783569
desired expected reward: 17.79938507080078






Player: 1 
cards in hand: [15.  8. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 11.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  0  3 15] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  5.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8  8  3 15] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  5.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8  8  3 15] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  5.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  8.] 
cards in discard: [11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [11 10  8  8  3 15 11] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [14.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
expected returns: [[14.045644]
 [12.932385]
 [14.534686]
 [14.534686]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  8.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 8. 11.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5661018490791321
desired expected reward: 18.312244415283203



action possibilites: [-1] 
expected returns: [[16.129715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11 10  8  8  3 15 11] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.22560152411460876
desired expected reward: 13.350951194763184





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.615579]
 [15.197762]
 [12.984373]
 [16.317406]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11 10  8  8  3 15 11] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.12451686710119247
desired expected reward: 16.25423240661621



buy possibilites: [-1] 
expected returns: [[17.101671]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 8.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [11.  3. 10.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [11 10  8  8  3 15 11] -> size -> 7 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.19110016524791718
desired expected reward: 14.806678771972656






Player: 1 
cards in hand: [11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.] 
cards in discard: [8. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3 15 11] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 8.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 8.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6. 10.  0.  0.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[17.714275]
 [17.644423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11.  8. 15. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.476005882024765
desired expected reward: 16.62566566467285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[16.31486 ]
 [17.549828]
 [16.926373]
 [14.599938]
 [19.242378]
 [18.007412]
 [18.077267]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 21. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11.  8. 15. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4999796450138092
desired expected reward: 17.341697692871094



buy possibilites: [-1] 
expected returns: [[16.754932]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  0.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11.  8. 15. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.4218643307685852
desired expected reward: 16.504507064819336






Player: 1 
cards in hand: [11.  8. 15. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 15. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 15. 15. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11. 11.  0.  1.  0.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8. 15. 15. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11. 11.  0.  1.  0.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3] -> size -> 23 
adversary victory points: 1
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[16.819975]
 [17.95546 ]
 [17.95546 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  1.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11. 11.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4661835730075836
desired expected reward: 16.28874969482422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[15.404054]
 [16.603056]
 [15.995473]
 [13.767471]
 [15.706436]
 [18.252583]
 [18.007124]
 [15.889072]
 [17.049038]
 [17.092619]
 [17.117096]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  1.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  6.] 
adversary cards in hand: [11. 11.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.48131468892097473
desired expected reward: 16.444509506225586



buy possibilites: [-1] 
expected returns: [[20.069866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  0.  1.  0.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 11.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.507955014705658
desired expected reward: 17.60057258605957






Player: 1 
cards in hand: [11. 11.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  8  8  3 15 11 15] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 14. 29.  0. 29.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3 15 11 15] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 14. 29.  0. 29.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  3 15 11 15] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 14. 29.  0. 29.] 
adversary cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3. 14. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 29.] 
expected returns: [[17.28907 ]
 [16.147001]
 [18.140099]
 [18.140099]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 29.  0. 29.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 8.  3. 15. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  3 15 11 15] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5670813918113708
desired expected reward: 19.502784729003906



action possibilites: [-1] 
expected returns: [[16.07753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 15.  8.] 
adversary cards in discard: [15.  8.] 
adversary owned cards: [ 8  8  3 15 11 15] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.1441555917263031
desired expected reward: 15.966105461120605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[14.421576]
 [15.547459]
 [14.973905]
 [12.888896]
 [17.096804]
 [15.964537]
 [15.993185]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0. 29.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 15.  8.] 
adversary cards in discard: [15.  8.] 
adversary owned cards: [ 8  8  3 15 11 15] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1318410336971283
desired expected reward: 16.20937156677246



buy possibilites: [-1] 
expected returns: [[15.307265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0. 29.] 
cards in discard: [ 0. 14.  3.  6.  8.  8.  3.  0.  6. 10.  0.  0. 15. 11. 11.  0.  1.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 15.  8.] 
adversary cards in discard: [15.  8.] 
adversary owned cards: [ 8  8  3 15 11 15] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.1780790239572525
desired expected reward: 14.599655151367188






Player: 1 
cards in hand: [ 3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.] 
cards in discard: [15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  3 15 11 15] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  8. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 15 11 15] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  8. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 15 11 15] -> size -> 5 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  8. 11.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 11.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15.] 
expected returns: [[15.116394]
 [15.655786]
 [16.20387 ]
 [15.124669]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [15.  8.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 11 15] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4431000053882599
desired expected reward: 14.864165306091309





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.726878]
 [12.20616 ]
 [15.261044]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0. 15.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 20. 30.  8.  8. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [15.  8.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 11 15] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.46087169647216797
desired expected reward: 14.814573287963867



buy possibilites: [-1] 
expected returns: [[18.681143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 11.  0. 15.] 
cards in discard: [6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [15.  8.  8. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 11 15] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.320032119750977
desired expected reward: 2.886127471923828






Player: 1 
cards in hand: [15.  8.  8. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 15. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8. 15. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 11 15] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [29.  0. 14.  0. 14.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11 15] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [29.  0. 14.  0. 14.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15. 11.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 11 15] -> size -> 4 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [29.  0. 14.  0. 14.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29.  0. 14.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
expected returns: [[16.190754]
 [17.142145]
 [14.968114]
 [14.968114]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14.  0. 14.] 
cards in discard: [ 6.  3.  8. 11.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 8.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 11 15] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5404209494590759
desired expected reward: 18.140722274780273



action possibilites: [-1. 14. 14.] 
expected returns: [[15.835579]
 [14.698989]
 [14.698989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 14.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 8.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 11 15] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 2
Learning step: 0.19092409312725067
desired expected reward: 14.157076835632324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[14.35293 ]
 [15.497032]
 [14.91373 ]
 [12.779902]
 [17.070467]
 [15.91911 ]
 [15.948014]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 14.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 20. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 8.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 11 15] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.13855800032615662
desired expected reward: 15.974138259887695



buy possibilites: [-1] 
expected returns: [[15.545684]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 14.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 8.  8. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 11 15] -> size -> 4 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.22581781446933746
desired expected reward: 15.139547348022461






Player: 1 
cards in hand: [ 8.  8. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 15.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 11 15] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [6. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [6. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [6. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [6. 0. 8. 0. 1.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
adversary owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[19.871521]
 [20.46926 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 1.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  6  1  0 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4030168950557709
desired expected reward: 15.142666816711426



action possibilites: [-1] 
expected returns: [[19.308138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.15294718742370605
desired expected reward: 16.81255531311035





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[17.712963]
 [18.951967]
 [18.316544]
 [16.006636]
 [20.663239]
 [19.412846]
 [19.44446 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07075905054807663
desired expected reward: 19.378896713256836



buy possibilites: [-1] 
expected returns: [[18.301193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 1.0
Learning step: 0.6152667999267578
desired expected reward: 19.56723403930664






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  0. 15.  0.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  0. 15.  0.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  0. 15.  0.] 
adversary cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1] -> size -> 26 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [11. 29.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15.] 
expected returns: [[13.16702 ]
 [14.268569]
 [14.033759]
 [13.201383]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0. 15.  0.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  8.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5536333918571472
desired expected reward: 17.747560501098633



action possibilites: [-1] 
expected returns: [[16.93976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  0.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 6
Learning step: 0.8014547228813171
desired expected reward: 11.015213012695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[15.53225 ]
 [16.029669]
 [14.119298]
 [16.956543]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.  0.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1089552491903305
desired expected reward: 17.048715591430664



buy possibilites: [-1] 
expected returns: [[16.497662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 15.  0.] 
cards in discard: [ 6.  3.  8. 11.  0. 15. 10.  3. 29.  0. 14.  0. 14.  1.  8.  0.  1. 29.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.15725792944431305
desired expected reward: 15.689508438110352






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 0. 3. 6. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.504103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5539423823356628
desired expected reward: 15.943718910217285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[7.243602]
 [5.876704]
 [8.624539]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.33096709847450256
desired expected reward: 8.33450698852539



buy possibilites: [-1] 
expected returns: [[10.19736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 3.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.2602357566356659
desired expected reward: 6.983366012573242






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 15. 29.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 15. 29.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  0.  8. 15. 29.] 
adversary cards in discard: [0. 3. 0. 3. 6. 3.] 
adversary owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
expected returns: [[11.879203 ]
 [12.444499 ]
 [11.9138975]
 [12.749894 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 15. 29.] 
cards in discard: [0. 3. 0. 3. 6. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14  0 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6
  3  1 29  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32563579082489014
desired expected reward: 9.871724128723145



action possibilites: [-1] 
expected returns: [[13.904235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.] 
cards in discard: [0. 3. 0. 3. 6. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.23682475090026855
desired expected reward: 12.209148406982422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[12.511074]
 [13.598853]
 [13.042098]
 [11.002999]
 [12.779243]
 [15.098405]
 [14.864539]
 [12.94249 ]
 [13.998408]
 [14.030842]
 [13.996267]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.] 
cards in discard: [0. 3. 0. 3. 6. 3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  4.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1774948537349701
desired expected reward: 14.081729888916016



buy possibilites: [-1] 
expected returns: [[13.260169]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  3.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 19.5 

action type: buy - action 11.0
Learning step: 0.27127963304519653
desired expected reward: 15.369684219360352






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  3.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  8.  0. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 26. 30. 19. 30.  8.  7. 10.  3.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  8.  0. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11] -> size -> 29 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  7. 10.  3.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  8.  0. 11.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11] -> size -> 29 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11. 29.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 11.] 
expected returns: [[17.661465]
 [18.904282]
 [18.641361]
 [18.298725]
 [18.904282]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8.  0. 11.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  7. 10.  3.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3519311547279358
desired expected reward: 12.90823745727539



action possibilites: [-1] 
expected returns: [[17.095425]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 11.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.41671112179756165
desired expected reward: 16.50973892211914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.52234 ]
 [13.939232]
 [17.1667  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0. 11.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10374646633863449
desired expected reward: 17.19917106628418



buy possibilites: [-1] 
expected returns: [[15.926034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0. 11.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.15333835780620575
desired expected reward: 15.616171836853027






Player: 1 
cards in hand: [8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [14. 10. 29.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [14. 10. 29.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [14. 10. 29.  1.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [14. 10. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29.] 
expected returns: [[20.015493]
 [18.913603]
 [20.048029]
 [20.960726]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 10. 29.  1.  0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4154295027256012
desired expected reward: 15.510604858398438



action possibilites: [-1. 14. 29. 14.] 
expected returns: [[18.546307]
 [17.458654]
 [19.482346]
 [17.458654]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  1.  0. 14.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.04133142530918121
desired expected reward: 20.13360023498535



action possibilites: [-1. 29. 14.] 
expected returns: [[20.0956  ]
 [21.024614]
 [19.012535]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0. 14.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 14.0
Learning step: 0.7387637495994568
desired expected reward: 18.197418212890625



action possibilites: [-1] 
expected returns: [[19.895401]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 14.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 14.0
Learning step: 1.2885255813598633
desired expected reward: 20.30105972290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[18.63878 ]
 [19.7619  ]
 [18.060366]
 [19.183487]
 [17.54795 ]
 [17.075415]
 [18.910763]
 [21.304571]
 [22.163374]
 [21.058943]
 [19.077093]
 [18.361814]
 [20.170746]
 [17.250063]
 [20.200214]
 [20.139364]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 14.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 6. 26. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.2618560791015625
desired expected reward: 21.157257080078125



buy possibilites: [-1] 
expected returns: [[13.211881]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 14. 14.] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 59.5 

action type: buy - action 1.0
Learning step: 1.3308677673339844
desired expected reward: 21.0927677154541






Player: 1 
cards in hand: [8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 1.  6.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3] -> size -> 2 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 1.  6.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 1.  6.  0. 15.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
adversary owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0  1] -> size -> 32 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[20.396534]
 [20.4632  ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 15.  0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  0  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3
  1 29  0  0 11 11  0  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3317728042602539
desired expected reward: 12.880107879638672



action possibilites: [-1] 
expected returns: [[16.898613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.01353939063847065
desired expected reward: 20.476741790771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[15.386883]
 [16.460209]
 [14.839124]
 [15.905445]
 [14.353606]
 [13.898457]
 [15.645823]
 [17.98024 ]
 [18.838863]
 [17.73565 ]
 [15.804163]
 [15.123222]
 [16.85873 ]
 [14.066189]
 [16.887678]
 [16.827944]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0. 10.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.117324598133564
desired expected reward: 17.01593780517578



buy possibilites: [-1] 
expected returns: [[27.084103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [ 0.  3.  0.  3.  6.  3. 11. 15.  0.  8. 29. 11.  0. 11. 29.  8.  0. 11.
  1. 10. 14. 14. 29.  1.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 12.5  0. ] 
sum of rewards: 27.5 

action type: buy - action 25.0
Learning step: 0.5442171096801758
desired expected reward: 19.383079528808594






Player: 1 
cards in hand: [0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 6. 14.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25] -> size -> 32 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 6. 14.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25] -> size -> 32 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6. 14.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[13.888071]
 [12.85335 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8203443884849548
desired expected reward: 26.263757705688477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.532875]
 [11.018118]
 [13.996189]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4341513514518738
desired expected reward: 13.521697044372559



buy possibilites: [-1] 
expected returns: [[5.9253645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  6.  0.  3.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 0] -> size -> 3 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.46376991271972656
desired expected reward: 12.06910514831543






Player: 1 
cards in hand: [0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 11.  0.  1. 14.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 11.  0.  1. 14.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 11.  0.  1. 14.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0] -> size -> 33 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [11. 11.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[14.589714]
 [15.733236]
 [15.733236]
 [13.554962]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  1. 14.] 
cards in discard: [ 0.  6. 14.  6.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  2.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.16920863091945648
desired expected reward: 5.756155967712402



action possibilites: [-1] 
expected returns: [[15.509593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1. 14.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.4872484505176544
desired expected reward: 13.673990249633789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[14.231244]
 [15.342241]
 [14.759161]
 [12.717564]
 [16.884396]
 [15.749194]
 [15.687677]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1. 14.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3] -> size -> 2 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.14661520719528198
desired expected reward: 15.656208038330078






Player: 1 
cards in hand: [3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 3] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 29. 11. 25.  3.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 29. 11. 25.  3.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 29. 11. 25.  3.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 29. 11. 25.  3.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 25.] 
expected returns: [[13.505641]
 [14.467141]
 [14.721765]
 [15.606392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 25.  3.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.46494320034980774
desired expected reward: 15.222734451293945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.086608]
 [10.510983]
 [13.588283]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 25.  3.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  7. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.42667463421821594
desired expected reward: 13.12434196472168



buy possibilites: [-1] 
expected returns: [[11.990569]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 25.  3.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.339428901672363
desired expected reward: 1.1715545654296875






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  1.  8. 15.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [11. 29.  1.  8. 15.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [11. 29.  1.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 15.] 
expected returns: [[12.786732]
 [13.88086 ]
 [13.648277]
 [13.376827]
 [12.866684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1.  8. 15.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3685739040374756
desired expected reward: 11.621994972229004





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.624356]
 [12.110286]
 [10.201451]
 [12.948086]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  1.  8. 15.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.408441960811615
desired expected reward: 12.394549369812012



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [3. 1. 3. 0. 0.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [3. 1. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.880522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3296971023082733
desired expected reward: 12.618389129638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[18.123665]
 [19.304874]
 [18.69218 ]
 [16.471985]
 [18.404776]
 [20.91313 ]
 [20.652987]
 [18.577976]
 [19.731924]
 [19.759186]
 [19.667337]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  7. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5419053435325623
desired expected reward: 19.3386173248291



buy possibilites: [-1] 
expected returns: [[26.367476]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 0. 0.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 32  0] 
sum of rewards: 26 

action type: buy - action 14.0
Learning step: 0.49951907992362976
desired expected reward: 19.077497482299805






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 8. 15.  0. 29. 10.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
adversary victory points: 1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 8. 15.  0. 29. 10.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 8. 15.  0. 29. 10.] 
adversary cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 8. 15.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29. 10.] 
expected returns: [[15.612952]
 [16.258892]
 [15.700573]
 [16.552996]
 [15.674511]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 29. 10.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7721990942955017
desired expected reward: 25.59527587890625



action possibilites: [-1.  8. 15. 29.] 
expected returns: [[15.8281765]
 [16.465841 ]
 [15.914694 ]
 [16.756195 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 29.  0.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  1 14 10  8  3  6 14  0  0  3 15  0 29 29 11 11  0  3 15  0  6  3  1
 29  0  0 11 11  0  1 25  0 11  6 14] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.15137892961502075
desired expected reward: 15.82589054107666



action possibilites: [-1. 29.] 
expected returns: [[17.73253 ]
 [18.690857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.7145988941192627
desired expected reward: 18.302270889282227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.299942]
 [14.694715]
 [17.800938]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.] 
cards in discard: [ 0.  6. 14.  6.  0.  3. 11. 11. 11.  0.  1. 14.  6.  0. 29. 11. 25.  3.
 11. 29.  1.  8. 15. 14.  3.  1.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6920337080955505
desired expected reward: 18.424562454223633






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [14. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [14. 11.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [14. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
expected returns: [[10.714519 ]
 [ 9.7462435]
 [11.828028 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  6. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5678306818008423
desired expected reward: 17.233104705810547



action possibilites: [-1] 
expected returns: [[12.982876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.707254409790039
desired expected reward: 1.0785789489746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.665932]
 [10.17726 ]
 [13.029266]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.] 
cards in discard: [6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1855180561542511
desired expected reward: 13.168394088745117






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [10. 29.  8.  6.  8.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [10. 29.  8.  6.  8.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [10. 29.  8.  6.  8.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [10. 29.  8.  6.  8.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0.] 
adversary owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [10. 29.  8.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.  8.] 
expected returns: [[11.411105]
 [11.50224 ]
 [12.320591]
 [12.054531]
 [12.054531]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  8.  6.  8.] 
cards in discard: [ 6. 11. 14.  3.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.41473472118377686
desired expected reward: 12.614531517028809



action possibilites: [-1.  8.  8.] 
expected returns: [[14.980411]
 [15.624287]
 [15.624287]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8. 1.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  1 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0
 11 11  0  1 25  0 11  6 14  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 3
Learning step: 0.2921672463417053
desired expected reward: 10.961664199829102



action possibilites: [-1] 
expected returns: [[17.071081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.7870419025421143
desired expected reward: 15.527188301086426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.647968]
 [14.130632]
 [17.041517]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.7047510147094727
desired expected reward: 17.775833129882812






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 6.  1.  0. 14.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 6.  1.  0. 14.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 2. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 6.  1.  0. 14.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [ 6.  1.  0. 14.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 6.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[11.362076]
 [10.45155 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 14.  0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5450268983840942
desired expected reward: 16.496490478515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[10.147394]
 [11.166099]
 [10.630546]
 [ 8.72509 ]
 [10.38332 ]
 [12.558897]
 [12.328536]
 [10.530652]
 [11.533965]
 [11.553554]
 [11.44483 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 14.  0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  6. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.3742234408855438
desired expected reward: 11.059087753295898



buy possibilites: [-1] 
expected returns: [[14.161368]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  1.  0. 14.  0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 14.0
Learning step: 0.642774760723114
desired expected reward: 11.17342758178711






Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [11.  6.  0. 29. 25.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14] -> size -> 34 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [11.  6.  0. 29. 25.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14] -> size -> 34 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [11.  6.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 25.] 
expected returns: [[10.715279]
 [11.902502]
 [11.655802]
 [12.73636 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 29. 25.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4488704800605774
desired expected reward: 13.71249771118164



action possibilites: [-1. 11. 25. 11.] 
expected returns: [[13.884974]
 [15.135887]
 [16.00909 ]
 [15.135887]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 25. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  1.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0.296036958694458
desired expected reward: 10.760382652282715



action possibilites: [-1] 
expected returns: [[18.143768]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 5
Learning step: 1.1367906332015991
desired expected reward: 13.59408950805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[16.780916]
 [15.179203]
 [18.19887 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0.6843497157096863
desired expected reward: 18.82811737060547






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [29.  3. 14. 11. 11.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11] -> size -> 35 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [29.  3. 14. 11. 11.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11] -> size -> 35 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [29.  3. 14. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 11. 11.] 
expected returns: [[20.513798]
 [21.502228]
 [19.54253 ]
 [21.758402]
 [21.758402]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14. 11. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 25. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4737468361854553
desired expected reward: 17.725122451782227



action possibilites: [-1] 
expected returns: [[20.601925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 14. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 1
Learning step: 0.299034982919693
desired expected reward: 20.5418758392334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.276545]
 [17.695677]
 [20.66888 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  5. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.03674199804663658
desired expected reward: 20.6386661529541



buy possibilites: [-1] 
expected returns: [[22.297783]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 14. 11.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0   -2    0 -300
    0    0] 
sum of rewards: -287 

action type: buy - action 6.0
Learning step: -8.906743049621582
desired expected reward: 8.788933753967285






Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 37 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 37 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [ 0. 15.  1.  3.  0.] 
adversary cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
adversary owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 37 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[22.474787]
 [22.630499]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  3.  0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3  0 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11
 11  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5819672346115112
desired expected reward: 21.715816497802734



action possibilites: [-1] 
expected returns: [[27.525251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.0601002499461174
desired expected reward: 22.690597534179688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.079653]
 [27.243177]
 [25.465921]
 [26.629444]
 [24.942902]
 [24.449501]
 [26.344477]
 [29.701002]
 [28.555508]
 [26.513435]
 [25.748777]
 [27.658924]
 [24.599886]
 [27.676958]
 [27.525553]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 24. 30. 18. 30.  8.  4. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.08986976742744446
desired expected reward: 27.435380935668945



buy possibilites: [-1] 
expected returns: [[23.367323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 6. 11. 14.  3.  3.  0. 10. 29.  8.  6.  8. 14.  6.  1.  0. 14.  0.  0.
 11. 29. 11.  6. 25. 11.  1.  6. 11. 29.  3. 14. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 6 
card supply: [ 1. 24. 30. 18. 30.  8.  3. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -287.0 

action type: buy - action 6.0
Learning step: -9.098128318786621
desired expected reward: 15.351370811462402






Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  3. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [11.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 1. 24. 30. 18. 30.  8.  3. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [11.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6  6] -> size -> 37 
adversary victory points: -2
player victory points: 0 


Player 1 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 5 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 6 

Remodel: 0 
Workshop: 4 
Chapel: 2 
Witch: 1 
Poacher: 2 
Militia: 4 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 10  8  3  6 14  3 29 29 11 11  0  3 15  0  6  3  1 29  0  0 11 11
  0  1 25  0 11  6 14  6 14 11  1  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 18. 30.  8.  3. 10.  0.  0.  9.  7.  5. 10.  6. 10.  5.] 
adversary cards in hand: [8.] 
adversary cards in discard: [0.] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1
Learning step: -15.851018905639648
desired expected reward: 7.516304016113281



