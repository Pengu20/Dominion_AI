 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[333.85254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   4  40   0   0   0   0   0   0   0 -31   0   0   4   0] 
sum of rewards: 512 

action type: buy - action 8.0
Learning step: 22.17806053161621
desired expected reward: 90.61685180664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[314.3613 ]
 [318.76697]
 [319.05423]
 [312.17465]
 [324.32553]
 [319.60687]
 [319.89417]
 [334.43604]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.58042049407959
desired expected reward: 326.4861145019531



buy possibilites: [-1] 
expected returns: [[306.50406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 11.0
Learning step: -8.51993465423584
desired expected reward: 315.8055725097656






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[316.39554]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.222883224487305
desired expected reward: 298.28118896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[305.10773]
 [308.88998]
 [309.1075 ]
 [303.2104 ]
 [308.74615]
 [313.92114]
 [309.5977 ]
 [315.4218 ]
 [307.74902]
 [309.82837]
 [311.71823]
 [323.07718]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.015461921691895
desired expected reward: 311.087646484375



buy possibilites: [-1] 
expected returns: [[310.6877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -8.375946998596191
desired expected reward: 301.45245361328125






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  0.  3.  3.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[303.85477]
 [292.78604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.81287670135498
desired expected reward: 301.8748474121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[284.20004]
 [281.84927]
 [306.55267]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.761106491088867
desired expected reward: 297.9203186035156



buy possibilites: [-1] 
expected returns: [[327.90958]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 11.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -8.432036399841309
desired expected reward: 275.76800537109375






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[305.20126]
 [290.48013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.698745727539062
desired expected reward: 318.2108154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[298.4347 ]
 [302.42038]
 [302.76602]
 [296.72342]
 [302.2962 ]
 [308.33163]
 [303.33084]
 [310.0007 ]
 [301.16013]
 [303.67645]
 [305.81528]
 [318.86234]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [ 0.  3.  0.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [1. 3. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.469234466552734
desired expected reward: 298.2884216308594



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [1. 3. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [1. 3. 3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[323.61185]
 [305.07455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.801735877990723
desired expected reward: 310.06060791015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[292.85516]
 [298.4246 ]
 [298.87985]
 [290.1519 ]
 [298.2875 ]
 [305.67093]
 [299.54327]
 [307.67722]
 [296.9247 ]
 [299.9985 ]
 [302.5971 ]
 [318.53586]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.573539733886719
desired expected reward: 318.16082763671875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0.  3.] 
adversary cards in discard: [ 0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[338.8652 ]
 [328.16882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 0. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.4337739944458
desired expected reward: 310.10205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[321.9013 ]
 [326.42258]
 [319.82397]
 [327.00784]
 [342.7743 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 0. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.648390769958496
desired expected reward: 331.2207336425781



buy possibilites: [-1] 
expected returns: [[306.33807]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0.  3.] 
cards in discard: [ 0. 10.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -10.802462577819824
desired expected reward: 311.0989074707031






Player: 1 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [14.  3.  0.  1.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  3.  0.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  3.  0.  1.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [14.  3.  0.  1.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[310.5284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.873270988464355
desired expected reward: 297.4648132324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.80692]
 [279.159  ]
 [279.57492]
 [271.2126 ]
 [279.01065]
 [286.0885 ]
 [280.22394]
 [288.01514]
 [277.68207]
 [280.63986]
 [283.13074]
 [298.39297]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.040841102600098
desired expected reward: 289.19244384765625



buy possibilites: [-1] 
expected returns: [[334.9327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [14.  3.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -8.25436019897461
desired expected reward: 265.55255126953125






Player: 1 
cards in hand: [14.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[387.19247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: discard_down_to_3_cards - action 3
Learning step: -5.315399169921875
desired expected reward: 263.0619201660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[356.5788 ]
 [362.97357]
 [353.47006]
 [363.6961 ]
 [383.48782]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -11.590858459472656
desired expected reward: 375.22991943359375



buy possibilites: [-1] 
expected returns: [[297.3839]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  0.  0.  0.  0.  3. 10.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0.  0.  0.  0.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 8.0
Learning step: -11.6936674118042
desired expected reward: 352.00244140625






Player: 1 
cards in hand: [29.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [14. 14.  3.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [14. 14.  3.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0.  0.] 
cards in discard: [14. 14.  3.  1.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[246.94693]
 [237.87007]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.975672721862793
desired expected reward: 287.4082336425781



action possibilites: [-1] 
expected returns: [[256.87558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 17 

action type: gain_card_n - action 9
Learning step: -5.795382022857666
desired expected reward: 242.70626831054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[236.1726 ]
 [240.9874 ]
 [241.39989]
 [233.91212]
 [247.91414]
 [242.05603]
 [242.46852]
 [261.39783]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -6.821485996246338
desired expected reward: 250.05409240722656



buy possibilites: [-1] 
expected returns: [[242.70847]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 11.0
Learning step: -5.634768009185791
desired expected reward: 242.27940368652344






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [14. 14.  3.  1.  0.  0. 10. 29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[250.22777]
 [236.92987]
 [237.22038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.241738796234131
desired expected reward: 235.4667205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[231.59886]
 [235.90683]
 [236.23344]
 [229.2273 ]
 [241.02971]
 [236.7389 ]
 [237.02945]
 [250.03682]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -7.648355007171631
desired expected reward: 242.1684112548828



buy possibilites: [-1] 
expected returns: [[325.89874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -6.347222328186035
desired expected reward: 225.25164794921875






Player: 1 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [4.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[309.96893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0 -60   0   0   0   0   0   0  31   0] 
sum of rewards: -71 

action type: discard_down_to_3_cards - action 2
Learning step: -9.649296760559082
desired expected reward: 249.862548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[282.07977]
 [287.25183]
 [287.67322]
 [279.575  ]
 [294.01587]
 [288.3013 ]
 [288.7227 ]
 [306.218  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -10.54456615447998
desired expected reward: 291.28253173828125



buy possibilites: [-1] 
expected returns: [[283.70023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  0.  3.  0.  8.  0.  0.  0. 10.  3.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14.  0.  3.  0.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -24 

action type: buy - action 1.0
Learning step: -9.179336547851562
desired expected reward: 278.072509765625






Player: 1 
cards in hand: [14.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.  0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[226.13292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -11.173678398132324
desired expected reward: 272.52655029296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[208.32594]
 [213.13257]
 [213.457  ]
 [206.48438]
 [205.95169]
 [212.96585]
 [219.26392]
 [214.05327]
 [223.65898]
 [221.00554]
 [211.72423]
 [215.52306]
 [214.37769]
 [210.63681]
 [216.61046]
 [230.19391]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  1. 29.  0.] 
adversary cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -8.49894905090332
desired expected reward: 218.67140197753906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 29.  0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  0. 10.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [ 4. 14.  0.  0.  3.  0.  8. 14.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  8.  0. 10.] 
adversary cards in discard: [0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[243.93669]
 [232.99602]
 [233.10387]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14. 14.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -8.223660469055176
desired expected reward: 221.97024536132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[227.44353]
 [230.33849]
 [230.44638]
 [226.11456]
 [234.13702]
 [230.84393]
 [230.95178]
 [241.64632]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 10.] 
cards in discard: [0. 0. 0. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [14. 14.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -9.017550468444824
desired expected reward: 235.16746520996094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 14.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  0.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  8.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[245.99403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 4. 0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: discard_down_to_3_cards - action 3
Learning step: -10.784823417663574
desired expected reward: 271.6164245605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[228.80965]
 [233.38858]
 [226.72989]
 [233.91716]
 [248.32726]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  8. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 4. 0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -8.792624473571777
desired expected reward: 232.77354431152344



buy possibilites: [-1] 
expected returns: [[240.66977]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 4. 0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -34 

action type: buy - action 8.0
Learning step: -7.9807891845703125
desired expected reward: 225.93638610839844






Player: 1 
cards in hand: [0. 0. 0. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 4. 0.] 
cards in discard: [11. 14. 14.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  3. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4. 0.] 
cards in discard: [11. 14. 14.  3.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  3. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4. 0.] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  1.  3. 11.] 
adversary cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[194.67273]
 [186.6272 ]
 [186.6272 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  1.  3. 11.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29. 10.  3.  0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11 29] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -9.830110549926758
desired expected reward: 230.83966064453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.124  ]
 [184.65082]
 [178.12766]
 [185.15863]
 [198.3977 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  3. 11.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 29.  8. 10. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29. 10.  3.  0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11 29] -> size -> 22 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -7.557244777679443
desired expected reward: 187.115478515625



buy possibilites: [-1] 
expected returns: [[262.0398]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  1.  3. 11.] 
cards in discard: [ 0.  0.  0.  0.  0.  0.  0.  8.  0. 10. 10.  0.  8.  0.  3.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 29. 10.  3.  0.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11 29] -> size -> 22 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -353.0 

action type: buy - action 6.0
Learning step: -20.660490036010742
desired expected reward: 157.46719360351562






Player: 1 
cards in hand: [ 8. 29. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10.  3.  0.] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  0 14  3 14 10  0  4  8 11 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 8.  8. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.] 
expected returns: [[210.32794]
 [197.66747]
 [197.66747]
 [197.95685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1
Learning step: -10.613409042358398
desired expected reward: 251.4263916015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[192.55348]
 [197.51772]
 [190.41618]
 [198.10037]
 [212.63213]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 1.] 
adversary cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.213281631469727
desired expected reward: 204.61868286132812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  1.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  3.  1.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 1.] 
cards in discard: [11. 14. 14.  3.  0.  3. 29.  0.  0.  0.  4.  0.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  3.  1.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[238.67038]
 [229.90073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  1.] 
cards in discard: [ 8.  8. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -7.489132881164551
desired expected reward: 205.14297485351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[211.61502]
 [215.25194]
 [215.5597 ]
 [209.86858]
 [215.16498]
 [220.02075]
 [216.00806]
 [221.2859 ]
 [214.2707 ]
 [216.31578]
 [217.97566]
 [228.7021 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  1.] 
cards in discard: [ 8.  8. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.228842735290527
desired expected reward: 212.8678741455078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
adversary victory points: 2
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[240.95345]
 [229.28136]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: buy - action -1.0
Learning step: -8.36872386932373
desired expected reward: 220.33335876464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[216.50618]
 [221.3361 ]
 [221.73048]
 [214.17662]
 [227.91652]
 [222.33566]
 [222.7346 ]
 [239.58862]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8.  9. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1.0
Learning step: -8.769821166992188
desired expected reward: 226.77671813964844



buy possibilites: [-1] 
expected returns: [[216.87103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 29. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -354.0 

action type: buy - action 6.0
Learning step: -23.529232025146484
desired expected reward: 190.64736938476562






Player: 1 
cards in hand: [0. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 0.  3.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 0.  3.  0.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 29. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [10.  0.  0.  6.  0.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.  3. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[190.04646]
 [174.3521 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  0.] 
cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.  3. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29. 15.  4. 14.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.  0.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -9.879805564880371
desired expected reward: 206.99122619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[168.19148]
 [172.82031]
 [173.24875]
 [166.11528]
 [179.13531]
 [173.83664]
 [174.26512]
 [189.77512]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  0.] 
cards in discard: [ 8.  8. 10.  0.  0.  0. 11.  0.  3.  1.  6.  3. 11.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [11. 29. 15.  4. 14.] 
adversary cards in discard: [ 0.  3.  0.  0. 14.  3.  0.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3] -> size -> 20 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -8.648500442504883
desired expected reward: 181.39797973632812



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 29. 15.  4. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 15.  4. 14.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.  0.  0.  8.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  7.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  4. 14.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.  0.  0.  8.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  4. 14.] 
cards in discard: [ 0.  3.  0.  0. 14.  3.  0.  0.  8.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[206.93765]
 [196.65735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1.0
Learning step: -8.179471015930176
desired expected reward: 181.59564208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[186.3295 ]
 [190.43063]
 [190.7476 ]
 [184.33865]
 [196.07335]
 [191.25998]
 [191.57697]
 [206.29207]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -8.944205284118652
desired expected reward: 194.7182159423828



buy possibilites: [-1] 
expected returns: [[207.78067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  3.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -46 

action type: buy - action 1.0
Learning step: -7.146465301513672
desired expected reward: 183.2841339111328






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  3. 10.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[161.37706]
 [147.53778]
 [147.53778]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  3. 10.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 4. 14.  8. 11. 11.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -10.184220314025879
desired expected reward: 197.59645080566406



action possibilites: [-1. 10. 11.] 
expected returns: [[197.66705]
 [180.97018]
 [186.10114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10. 11.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 4. 14.  8. 11. 11.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action 10.0
Learning step: -5.084490776062012
desired expected reward: 138.85906982421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[179.72362]
 [177.50372]
 [201.82996]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10. 11.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 28. 29.  8.  8. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 4. 14.  8. 11. 11.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -7.763675212860107
desired expected reward: 189.90338134765625



buy possibilites: [-1] 
expected returns: [[278.06653]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 10. 11.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 4. 14.  8. 11. 11.] 
adversary cards in discard: [0. 0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -70.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -20.368690490722656
desired expected reward: 157.13507080078125






Player: 1 
cards in hand: [ 4. 14.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 14.  8. 11. 11.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0 14  3 14  0  4  8 11 29 15  3 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 11. 11.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 11. 11.] 
cards in discard: [0. 0. 3. 0. 3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 11. 11.] 
cards in discard: [0. 0. 3. 0. 3. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[244.63196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -12.149107933044434
desired expected reward: 265.91741943359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[224.7267 ]
 [229.22835]
 [229.56982]
 [222.53818]
 [229.1    ]
 [235.06303]
 [230.13863]
 [236.6566 ]
 [227.96057]
 [230.4801 ]
 [232.54349]
 [245.61746]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 15. 29.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: -10.662457466125488
desired expected reward: 233.96949768066406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 15. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 29.  0.  0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  0. 14.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0. 14.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  6.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  0. 14.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [8. 1. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[155.85526]
 [149.2142 ]
 [149.2142 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 8. 0.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 10  0  0  0  8 10 11  0  1  8  6  6  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -12.587489128112793
desired expected reward: 233.02996826171875



action possibilites: [-1] 
expected returns: [[213.46083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 11
Learning step: -4.341748237609863
desired expected reward: 134.5505828857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[196.07721]
 [201.13347]
 [193.84085]
 [201.73158]
 [215.61444]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 28. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1
Learning step: -8.221137046813965
desired expected reward: 205.2397003173828



buy possibilites: [-1] 
expected returns: [[192.86067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1.  0. 11.  0.  0.  3.  6. 10.  0.  3.  3. 10. 11.  6.  0.  0.  0.  0.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 1. 0.] 
adversary cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: -25 

action type: buy - action 3.0
Learning step: -6.967308044433594
desired expected reward: 194.16616821289062






Player: 1 
cards in hand: [3. 0. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 0.] 
cards in discard: [ 0.  0.  3.  0.  3.  0.  0.  8.  4. 11. 11. 11. 29.  3. 15.  0.  0. 14.
 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[143.54878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -9.070283889770508
desired expected reward: 183.79039001464844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[128.46748]
 [131.82329]
 [132.03827]
 [126.81209]
 [131.69746]
 [136.10352]
 [132.47652]
 [137.2808 ]
 [130.79755]
 [132.6915 ]
 [134.20958]
 [143.63765]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 27. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -6.729625701904297
desired expected reward: 136.50372314453125



buy possibilites: [-1] 
expected returns: [[155.26683]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 26. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [14.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -40.0 

action type: buy - action 3.0
Learning step: -5.108409881591797
desired expected reward: 126.92985534667969






Player: 1 
cards in hand: [14.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 26. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  1. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 25. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  1. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 25. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  1. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  0.] 
cards in discard: [3. 1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  6.  1. 10.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[118.763466]
 [109.2314  ]
 [105.130325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  1. 10.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -7.863650798797607
desired expected reward: 147.40318298339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[102.277596]
 [106.238434]
 [106.52885 ]
 [100.35145 ]
 [111.41247 ]
 [107.04888 ]
 [107.33928 ]
 [120.55048 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  1. 10.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  5.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -5.8626298904418945
desired expected reward: 109.9649429321289



buy possibilites: [-1] 
expected returns: [[177.15044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  1. 10.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  0.  3. 10.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -34 

action type: buy - action 11.0
Learning step: -3.284738540649414
desired expected reward: 108.12773132324219






Player: 1 
cards in hand: [ 4. 29.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  0.  3. 10.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29.  0.  3. 10.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 29.  0.  3. 10.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  1.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[172.89911]
 [164.27611]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -7.628993511199951
desired expected reward: 169.5214385986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[164.8657 ]
 [168.47488]
 [168.73846]
 [163.48102]
 [163.10994]
 [168.36644]
 [173.14632]
 [169.2084 ]
 [176.44858]
 [174.40814]
 [167.43156]
 [170.26387]
 [169.472  ]
 [166.58957]
 [171.10588]
 [182.25641]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 26. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -7.321938991546631
desired expected reward: 165.5771484375



buy possibilites: [-1] 
expected returns: [[186.8084]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  1.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 11.  0.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0] -> size -> 27 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -47.5 

action type: buy - action 1.0
Learning step: -6.595555305480957
desired expected reward: 161.8793182373047






Player: 1 
cards in hand: [ 3.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11.  0.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.  0.  0.  0. 11.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[176.51529]
 [166.43553]
 [166.2361 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  8.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.  0.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0. 11.  3.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -8.065942764282227
desired expected reward: 178.74244689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[159.2193 ]
 [162.82373]
 [157.5687 ]
 [163.21216]
 [172.8811 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.  8.] 
cards in discard: [ 3.  3.  0.  0.  0.  0. 11.  0. 11.  6.  1. 10.  1.  0.  0.  0. 11.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [1. 0. 8. 0. 3.] 
adversary cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0. 11.  3.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0  0] -> size -> 28 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -7.675329685211182
desired expected reward: 168.83999633789062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [1. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 3.] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0. 11.  3.  0. 11.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10
  3  1  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0. 11.  3.  0. 11.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  1. 11. 14.  0.  0.  0.  0.  4. 29.  0.  3. 10.  0. 11.  3.  0. 11.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[193.33665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -6.484688758850098
desired expected reward: 166.39642333984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[164.68895]
 [168.90569]
 [162.79372]
 [169.41028]
 [183.57204]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  7. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -7.207571506500244
desired expected reward: 173.63072204589844



buy possibilites: [-1] 
expected returns: [[108.11067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  6. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -34 

action type: buy - action 8.0
Learning step: -7.738023281097412
desired expected reward: 161.6722412109375






Player: 1 
cards in hand: [ 0.  0.  0.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  6. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8] -> size -> 27 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  6. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  1.  6.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8] -> size -> 27 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[121.742485]
 [115.63616 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  1.  6.] 
cards in discard: [8. 0. 0. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  6. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -4.858107566833496
desired expected reward: 103.2525634765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[109.99869 ]
 [112.57958 ]
 [112.73254 ]
 [108.700226]
 [112.47961 ]
 [115.88645 ]
 [113.08852 ]
 [116.811455]
 [111.77439 ]
 [113.24147 ]
 [114.41937 ]
 [121.717186]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  6.] 
cards in discard: [8. 0. 0. 3. 3. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  6. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -5.457518100738525
desired expected reward: 114.14778137207031



buy possibilites: [-1] 
expected returns: [[81.02844]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  1.  6.] 
cards in discard: [8. 0. 0. 3. 3. 6. 8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  5. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 4. 29.  3.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -40.0 

action type: buy - action 8.0
Learning step: -5.831286430358887
desired expected reward: 107.25724029541016






Player: 1 
cards in hand: [ 4. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 29.  3.  0.  0.] 
cards in discard: [ 0.  0.  0.  3. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  5. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  5. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  5. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  0.  3. 11.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[67.42276]
 [61.74641]
 [61.74641]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 11.  0.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10. 11. 11.  1.  0.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1
Learning step: -4.688565731048584
desired expected reward: 76.33987426757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[55.220074]
 [57.80202 ]
 [54.069363]
 [58.118416]
 [66.33003 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 11.  0.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10. 11. 11.  1.  0.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -4.093513488769531
desired expected reward: 63.32923126220703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 11. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  1.  0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  0.  0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1.  0.  0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 29.  8.  7. 10.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  1.  0.  0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8 16] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  1.  0.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 8.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[100.61282]
 [ 91.95934]
 [ 92.1326 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16. 10. 11. 11.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8 16] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -3.234445333480835
desired expected reward: 63.0955810546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[83.98475 ]
 [86.697014]
 [86.873825]
 [82.659485]
 [86.601776]
 [90.17484 ]
 [87.2381  ]
 [91.130974]
 [85.88319 ]
 [87.41492 ]
 [88.643105]
 [96.0379  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  0.  0. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3.  0.  8.] 
adversary cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16. 10. 11. 11.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8 16] -> size -> 26 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -5.087989330291748
desired expected reward: 95.52483367919922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0.  8.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16. 10. 11. 11.  1.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0  3 14  0  4  8 11 29 15  3 11  0  0 11 10  3  1  0  0
  8 16] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.  8.
  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16. 10. 11. 11.  1.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.  8.
  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0.  0.  0.  3. 15.  8. 29.  4.  3.  0.  0.  0. 16. 10. 11. 11.  1.  0.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  0.  3.  3.  1.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.  8.
  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [10.  0.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[101.01796]
 [ 90.02835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  1.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.  8.
  1.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: buy - action -1.0
Learning step: -4.7076263427734375
desired expected reward: 91.33027648925781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 89.024086]
 [ 91.28094 ]
 [ 91.444336]
 [ 87.99161 ]
 [ 95.28781 ]
 [ 91.77916 ]
 [ 92.01802 ]
 [104.49747 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  3.  1.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  8.  0.  0. 11.  1.  6. 11.  0.  3. 11.  0.  8.
  1.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -42 

action type: take_action - action -1.0
Learning step: -4.965453624725342
desired expected reward: 96.0525131225586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3. 14.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  8.] 
cards in discard: [3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8. 11.  3.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[87.20817]
 [73.61896]
 [77.99129]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 10  0  0  0 10 11  0  1  8  6  1  6  3  3
 11  1  8  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -6.0593791007995605
desired expected reward: 98.4380874633789



action possibilites: [-1] 
expected returns: [[182.43819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: trash_cards_n_from_hand - action 6
Learning step: -1.1368675231933594
desired expected reward: 60.69766616821289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[166.20903]
 [164.62901]
 [181.79257]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -7.337789058685303
desired expected reward: 175.10040283203125



buy possibilites: [-1] 
expected returns: [[210.20059]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 11.  0. 29.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -60.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -73.0 

action type: buy - action 0.0
Learning step: -7.020530700683594
desired expected reward: 159.18850708007812






Player: 1 
cards in hand: [ 3.  8. 11.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  0. 29.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3 11  0  0 11 10  3  1  0  0  8 16
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 1.] 
adversary cards in discard: [0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[161.02472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -10.109457969665527
desired expected reward: 200.0911407470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[138.03264]
 [142.14003]
 [142.48091]
 [136.6163 ]
 [136.24895]
 [142.03181]
 [147.6069 ]
 [143.02016]
 [151.4037 ]
 [149.02634]
 [140.98367]
 [144.24121]
 [143.36104]
 [139.99533]
 [145.22954]
 [157.1611 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 1.] 
cards in discard: [0. 8. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0] -> size -> 25 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -7.6963348388671875
desired expected reward: 150.1068572998047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [0. 8. 6. 0. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  4.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [0. 8. 6. 0. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  0.  6.  0. 10.] 
adversary cards in discard: [0. 8. 6. 0. 3. 0. 0. 0. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 1.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[78.265144]
 [64.97732 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [0. 8. 6. 0. 3. 0. 0. 0. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  3. 16.  4.  0.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -9.342168807983398
desired expected reward: 147.8189239501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[60.652588]
 [64.64531 ]
 [64.9697  ]
 [58.732647]
 [64.5357  ]
 [69.87923 ]
 [65.482925]
 [71.24316 ]
 [63.527462]
 [65.80734 ]
 [67.5951  ]
 [79.10171 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  6.  0. 10.] 
cards in discard: [0. 8. 6. 0. 3. 0. 0. 0. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1.  3. 16.  4.  0.] 
adversary cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0 11] -> size -> 26 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -5.4659881591796875
desired expected reward: 72.79914855957031



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3. 16.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 16.  4.  0.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 24. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 4.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.  0.  0.  0.  0. 11.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 4.] 
cards in discard: [ 3. 10.  0.  0.  3. 14.  8.  0.  8.  3.  0. 29. 11.  0.  0.  0.  0. 11.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  0.  1.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[115.97552 ]
 [106.121315]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  1.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -5.0661468505859375
desired expected reward: 74.03556060791016



action possibilites: [-1. 11.] 
expected returns: [[91.32925 ]
 [83.521385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 11.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action 10.0
Learning step: -5.957026958465576
desired expected reward: 100.164306640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[81.85288 ]
 [84.54441 ]
 [84.76459 ]
 [80.579895]
 [88.18241 ]
 [85.112076]
 [85.33226 ]
 [95.35422 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  1. 11.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -5.208933353424072
desired expected reward: 86.12033081054688






Player: 1 
cards in hand: [ 3.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 15.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[137.98128]
 [128.79735]
 [124.55382]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  0.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 14. 29. 11.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -5.420995235443115
desired expected reward: 89.93324279785156



action possibilites: [-1] 
expected returns: [[102.21845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 14. 29. 11.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: gain_card_n - action 0
Learning step: -8.290570259094238
desired expected reward: 120.51913452148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 85.62144]
 [ 89.85588]
 [ 83.80664]
 [ 90.31087]
 [102.34947]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 0.  8.  6.  0.  3.  0.  0.  0.  1.  1.  0.  6.  0. 10. 10.  3.  3.  0.
  1. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0. 14. 29. 11.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -5.629225254058838
desired expected reward: 96.58922576904297






Player: 1 
cards in hand: [ 8.  0. 14. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14. 29. 11.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14. 29. 11.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[139.04204]
 [125.02532]
 [125.02532]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1
  8  8  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -5.850428104400635
desired expected reward: 96.49903869628906



action possibilites: [-1] 
expected returns: [[136.93814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: trash_cards_n_from_hand - action 3
Learning step: -5.6164350509643555
desired expected reward: 115.33442687988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[122.88815]
 [121.26031]
 [139.91101]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  0.  3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.] 
adversary owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -6.519082069396973
desired expected reward: 130.41905212402344






Player: 1 
cards in hand: [ 0.  0. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.  3.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0
 11  3  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  4. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 23. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [8. 6. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[114.48965 ]
 [100.673965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 4.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3] -> size -> 28 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -8.723224639892578
desired expected reward: 131.1877899169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 85.840996]
 [ 89.20252 ]
 [ 89.49258 ]
 [ 84.41178 ]
 [ 94.315926]
 [ 89.96238 ]
 [ 90.28802 ]
 [103.437355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 4.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3] -> size -> 28 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -7.277472019195557
desired expected reward: 98.22149658203125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 11. 10.  3.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  3. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 11. 10.  3.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 4.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 1. 10. 11. 10.  3.] 
adversary cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 1. 10. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[100.42906 ]
 [ 86.986534]
 [ 90.846214]
 [ 86.986534]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11. 10.  3.] 
cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  1.  8.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -7.192685604095459
desired expected reward: 96.24467468261719



action possibilites: [-1. 11. 10.] 
expected returns: [[153.32481]
 [148.7636 ]
 [146.75127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10.  3.  0.] 
cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  1.  8.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -62 

action type: take_action - action 10.0
Learning step: -4.0526347160339355
desired expected reward: 82.93389892578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.71074]
 [140.68645]
 [140.8165 ]
 [137.7454 ]
 [143.23088]
 [141.08849]
 [141.21854]
 [147.8824 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 10.  3.  0.] 
cards in discard: [8. 0. 8. 8. 6. 0. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11. 10.  1.  8.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1.0
Learning step: -7.581334590911865
desired expected reward: 145.74349975585938






Player: 1 
cards in hand: [11. 10.  1.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.  8.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  8.  0.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  8.  0.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  8.  0.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 15.  8.  0. 14. 29. 11.  8.  3. 16.  0.  0.  3.  8.
  0.  3.  3.  0.  4. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 3.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[83.205696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -9.671993255615234
desired expected reward: 138.21043395996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[69.31211 ]
 [73.00112 ]
 [73.29049 ]
 [67.541245]
 [72.89509 ]
 [77.823364]
 [73.77381 ]
 [79.065445]
 [71.94047 ]
 [74.06318 ]
 [75.700645]
 [86.74522 ]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 22. 29.  8.  7.  9.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -6.532382488250732
desired expected reward: 76.6733169555664



buy possibilites: [-1] 
expected returns: [[154.82904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 3.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  8. 15. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -51 

action type: buy - action 16.0
Learning step: -2.7111001014709473
desired expected reward: 70.18396759033203






Player: 1 
cards in hand: [ 3.  8. 15. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15. 29.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1.  8. 15. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 15.  0. 16.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8 16  3  0 11
  3  0  8  3  8 29] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[124.55973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  1. 29. 11.] 
adversary cards in discard: [ 0. 29.  8.  3. 15.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -9.088858604431152
desired expected reward: 145.7401885986328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[101.97175 ]
 [105.568886]
 [105.84869 ]
 [100.58834 ]
 [100.241974]
 [105.46483 ]
 [110.26829 ]
 [106.32056 ]
 [113.55233 ]
 [111.4831  ]
 [104.53114 ]
 [107.34333 ]
 [106.60038 ]
 [103.67543 ]
 [108.19906 ]
 [118.47259 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  7.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  1. 29. 11.] 
adversary cards in discard: [ 0. 29.  8.  3. 15.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -7.878207683563232
desired expected reward: 116.68152618408203



buy possibilites: [-1] 
expected returns: [[136.98445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 8.  0.  8.  8.  6.  0.  0.  0. 10.  1. 11. 10.  3.  0. 16.  0.  0.  1.
  3.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [11.  3.  1. 29. 11.] 
adversary cards in discard: [ 0. 29.  8.  3. 15.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0] -> size -> 29 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -75.0 

action type: buy - action 29.0
Learning step: -6.242005825042725
desired expected reward: 105.2411117553711






Player: 1 
cards in hand: [11.  3.  1. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1. 29. 11.] 
cards in discard: [ 0. 29.  8.  3. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 11.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 29. 11.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 29. 11.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  8.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[98.714455]
 [89.272484]
 [92.35125 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  2. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1
Learning step: -8.85354232788086
desired expected reward: 128.1309051513672



action possibilites: [-1] 
expected returns: [[105.55865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -59 

action type: gain_card_n - action 6
Learning step: -4.798016548156738
desired expected reward: 79.66370391845703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.353  ]
 [ 95.3597 ]
 [105.69593]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 3.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  3.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1
Learning step: -6.143649101257324
desired expected reward: 99.41500091552734






Player: 1 
cards in hand: [ 3. 10.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10. 11.  0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10. 11.  0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  0.  3.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  8. 10. 11.  0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6.  8. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[144.49152]
 [132.2817 ]
 [132.6078 ]
 [136.4314 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10. 11.  0.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0  0  0 10 11  0  1  8  6  1  6  3  3 11  1  8  8
  0  0 16 29  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0  0] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -6.298774242401123
desired expected reward: 99.39717102050781



action possibilites: [-1] 
expected returns: [[102.52533]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0  0] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: trash_cards_n_from_hand - action 11
Learning step: -7.11651611328125
desired expected reward: 118.35020446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 96.47456 ]
 [ 95.552246]
 [104.60963 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  8. 14.  8.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
adversary owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0  0] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: take_action - action -1
Learning step: -6.0045623779296875
desired expected reward: 96.52076721191406






Player: 1 
cards in hand: [ 3.  0.  8. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  3 14  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0
  8  3  8 29  0 15  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 29.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 29.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 29.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0. 29.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 9 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[98.31468]
 [87.45816]
 [91.93964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 29.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.  8.  8.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0] -> size -> 30 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: buy - action -1.0
Learning step: -6.7505998611450195
desired expected reward: 97.8590087890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.459885]
 [81.71112 ]
 [81.96841 ]
 [76.91084 ]
 [85.97779 ]
 [82.40202 ]
 [82.659294]
 [93.31316 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0. 29.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.  8.  8.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0] -> size -> 30 
adversary victory points: 9
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1.0
Learning step: -6.614845275878906
desired expected reward: 91.69982147216797



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 16.  8.  3.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 25. 30. 22. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 16.  8.  3.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 0. 29.  8.  3. 15. 15.  0. 11.  3.  1. 29. 11.  0.  3. 10.  3.  0.  3.
  0.  8.  8.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3. 16.  8.  3.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 16.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[77.62689]
 [67.86978]
 [68.51434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.  8.  3.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29.  3.  0.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -7.159065246582031
desired expected reward: 86.1540756225586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[64.6538 ]
 [63.68013]
 [76.67382]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16.  8.  3.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29.  3.  0.  0.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -6.425506114959717
desired expected reward: 71.20138549804688



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  3.  0.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  4.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 4. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 4. 0.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[176.25511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: buy - action -1.0
Learning step: -4.017951011657715
desired expected reward: 72.6558609008789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[152.0234 ]
 [156.0165 ]
 [152.23448]
 [156.30806]
 [150.47714]
 [150.10555]
 [155.89366]
 [161.2149 ]
 [156.84972]
 [164.87408]
 [162.55331]
 [154.82053]
 [157.93805]
 [157.14127]
 [153.86446]
 [158.89413]
 [170.18707]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  8.  3.  3.  8.  6.  0.  0. 10.  0. 29.  6.  3. 16.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 6 
card supply: [11. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 29.  3.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0] -> size -> 32 
adversary victory points: 10
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -83 

action type: take_action - action -1.0
Learning step: -9.320246696472168
desired expected reward: 166.9348602294922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 25. 30. 21. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  3.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[75.43016]
 [69.21762]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -11.506628036499023
desired expected reward: 158.68043518066406



action possibilites: [-1.  8.] 
expected returns: [[104.70935]
 [ 92.02311]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16
 29  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action 29.0
Learning step: -4.845695495605469
desired expected reward: 64.3719253540039



action possibilites: [-1] 
expected returns: [[166.04189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: trash_cards_n_from_hand - action 4
Learning step: -3.2687814235687256
desired expected reward: 83.82569122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[149.52155]
 [151.95107]
 [152.08258]
 [148.56335]
 [148.33635]
 [151.84561]
 [155.18523]
 [152.42368]
 [157.81763]
 [156.15874]
 [151.15309]
 [153.04784]
 [152.55524]
 [150.57501]
 [153.6259 ]
 [161.60478]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1
Learning step: -7.440516948699951
desired expected reward: 158.6013641357422



buy possibilites: [-1] 
expected returns: [[107.34064]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 5 
card supply: [10. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  3. 11.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -90.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -9.21091365814209
desired expected reward: 140.31063842773438






Player: 1 
cards in hand: [ 8.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11.  0.  0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 29.  8.  1.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.  0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 20. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 29.  8.  1.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11.  0.  0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 0. 3. 1.] 
adversary cards in discard: [ 0. 29.  8.  1.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 12 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.87196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 29.  8.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 11.  3.  8.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3  3] -> size -> 34 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[  -5    0    2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -103 

action type: buy - action -1
Learning step: -7.9549126625061035
desired expected reward: 99.38572692871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 97.29311 ]
 [100.68521 ]
 [100.932205]
 [ 95.66382 ]
 [100.581245]
 [105.09902 ]
 [101.3932  ]
 [106.23448 ]
 [ 99.66778 ]
 [101.640205]
 [103.12661 ]
 [112.714226]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 29.  8.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 11.  3.  8.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3  3] -> size -> 34 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[  -5    0    2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -103 

action type: take_action - action -1.0
Learning step: -8.459628105163574
desired expected reward: 105.41233825683594



buy possibilites: [-1] 
expected returns: [[70.974464]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 1.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  8. 11.  3.  8.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
adversary owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3  3] -> size -> 34 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[  -5    0    2 -100    0    0    0    0    0    0    0    0    0    0
   32    0] 
sum of rewards: -71 

action type: buy - action 14.0
Learning step: -6.405369758605957
desired expected reward: 82.6405258178711






Player: 1 
cards in hand: [ 8.  8. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11.  3.  8.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  4  8 29 15  3  0  0 11 10  3  1  0  0  8  3  0 11  3  0  8  3  8
 29  0 15  0  0  0  3  0  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
adversary victory points: 2
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10. 11.  8.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
adversary owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[28.556166]
 [24.670969]
 [25.886818]
 [24.582373]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  8.  0.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  0  0  0 10  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8
  0 14] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1
Learning step: -7.593876838684082
desired expected reward: 63.38058853149414



action possibilites: [-1] 
expected returns: [[122.07677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.1330063343048096
desired expected reward: 22.46166229248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.098076]
 [115.00718 ]
 [125.84628 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10.  3.  0.  0.] 
adversary cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -7.020503997802734
desired expected reward: 115.05625915527344






Player: 1 
cards in hand: [ 3. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  0.  0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0. 29.  3.  0.  0.  4.  0.  3.  0.  3.  0. 29.  3.  3.  8.  3. 11.  0.
  0.  0.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 16.  0.  0.  0.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 3. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[54.05568]
 [49.78068]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 15.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0] -> size -> 32 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -9.756650924682617
desired expected reward: 116.08963012695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[49.873783]
 [50.90217 ]
 [50.943478]
 [49.3604  ]
 [52.28711 ]
 [51.096146]
 [51.13745 ]
 [54.767822]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  0.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 15.  1. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0] -> size -> 32 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -6.170192718505859
desired expected reward: 47.885501861572266



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0. 15.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  1. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6. 3. 8. 6.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  1. 15.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6. 3. 8. 6.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  1. 15.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 6. 3. 8. 6.] 
adversary cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
adversary owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [8. 6. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[34.48387 ]
 [28.678122]
 [28.678122]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 8. 6.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  0  0  0  1  8  6  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1.0
Learning step: -6.667893886566162
desired expected reward: 48.099937438964844



action possibilites: [-1] 
expected returns: [[23.074863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: trash_cards_n_from_hand - action 9
Learning step: -4.638012409210205
desired expected reward: 25.505924224853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.049058]
 [12.357546]
 [20.523993]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -73 

action type: take_action - action -1
Learning step: -4.416567325592041
desired expected reward: 18.658296585083008



buy possibilites: [-1] 
expected returns: [[46.73663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 29.  8.  1.  1. 14.  0.  3.  0.  3.  1.  8. 11.  0.  3. 16.  0.  0.
  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 10.  3.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -103 

action type: buy - action 0.0
Learning step: -4.750878810882568
desired expected reward: 8.298168182373047






Player: 1 
cards in hand: [11.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10.  3.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
adversary victory points: 2
player victory points: 11 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.  0.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 11.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
adversary victory points: 2
player victory points: 11 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[127.54081]
 [118.84362]
 [114.65837]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  4.  0.  3. 29.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: buy - action -1
Learning step: -4.2511210441589355
desired expected reward: 42.48550796508789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[107.09693 ]
 [111.17741 ]
 [105.29823 ]
 [111.69962 ]
 [124.551994]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 19. 29.  8.  7.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  4.  0.  3. 29.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -93 

action type: take_action - action -1.0
Learning step: -8.33431625366211
desired expected reward: 117.79776000976562



buy possibilites: [-1] 
expected returns: [[136.99203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  8.  0.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  4.  0.  3. 29.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1. -100.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -404.0 

action type: buy - action 6.0
Learning step: -22.382591247558594
desired expected reward: 82.9156494140625






Player: 1 
cards in hand: [ 0.  4.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  0.  3. 29.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 3. 0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 3. 0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  8.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 3. 0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 0. 0. 1. 3.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[162.83179]
 [153.4319 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 1. 3.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16] -> size -> 35 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: buy - action -1
Learning step: -8.453146934509277
desired expected reward: 128.5388946533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[138.45567]
 [141.1979 ]
 [141.3807 ]
 [137.1458 ]
 [141.1133 ]
 [144.75992]
 [141.77835]
 [145.65999]
 [140.32988]
 [141.96115]
 [143.12865]
 [150.85875]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 1. 3.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16] -> size -> 35 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: take_action - action -1.0
Learning step: -9.598422050476074
desired expected reward: 143.8108673095703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  1. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  3.  0.  0.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [29.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[126.39699]
 [120.56869]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8] -> size -> 36 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: buy - action -1.0
Learning step: -9.940710067749023
desired expected reward: 140.91806030273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[110.572395]
 [113.544   ]
 [113.73673 ]
 [109.18449 ]
 [117.45667 ]
 [114.36117 ]
 [124.3513  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0.  0.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 3.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8] -> size -> 36 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: take_action - action -1.0
Learning step: -8.859435081481934
desired expected reward: 117.53753662109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  6. 14.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  6. 14.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  6. 14.] 
adversary cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 1.  1.  0.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[63.736015]
 [50.511845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  6. 14.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3. 29.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8  0] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: buy - action -1.0
Learning step: -10.07812786102295
desired expected reward: 114.27315521240234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[53.509907]
 [56.87775 ]
 [57.14    ]
 [52.206486]
 [51.925797]
 [56.795597]
 [61.335564]
 [64.5062  ]
 [62.438766]
 [55.862167]
 [58.489307]
 [57.874435]
 [55.045586]
 [59.305893]
 [69.08233 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0.  6. 14.] 
cards in discard: [ 6.  3. 11.  0.  8.  0.  8.  0.  0.  1.  3. 29.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [8. 3. 0. 0. 3.] 
adversary cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.  0.  0.  8.  3.  3.] 
adversary owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8  0] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    1 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -104 

action type: take_action - action -1.0
Learning step: -6.988759517669678
desired expected reward: 56.747257232666016



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.  0.  0.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  4 29 15  3  0  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0
  0  0  3  0  3  3  0  0  1  0 16  8  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.  0.  0.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  3.  0. 15.  1. 15.  0. 10. 11.  3.  3.  0.  0. 16. 29.  0.  4.  0.
  3.  0.  8.  0.  0.  0. 29.  0.  0.  0.  0.  8.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 10 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[88.59158]
 [79.10163]
 [78.42202]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0  0  0  0  1  1  6  3  3 11  1  8  8  0  0 16 29  8  0 14  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  1.  3.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -94 

action type: buy - action -1.0
Learning step: -6.301779747009277
desired expected reward: 62.780548095703125



action possibilites: [-1] 
expected returns: [[118.55801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  1.  3.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: trash_cards_n_from_hand - action 11
Learning step: -5.6294169425964355
desired expected reward: 75.31001281738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[104.17025]
 [107.24605]
 [102.80672]
 [117.23034]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  1.  3.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1
Learning step: -7.674266815185547
desired expected reward: 110.88374328613281



buy possibilites: [-1] 
expected returns: [[84.18911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8.  1.  3.  4. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -115.0 

action type: buy - action 0.0
Learning step: -9.064257621765137
desired expected reward: 95.10599517822266






Player: 1 
cards in hand: [ 8.  1.  3.  4. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3.  4. 11.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15  0 10  3  1  0  0  3  0 11  3  0  8  3  8 29  0 15  0  0  0  3
  0  3  3  0  0  1  0 16  8  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 4.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 8. 1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[97.55447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 8. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [8. 1. 4.] 
adversary owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -6.805413722991943
desired expected reward: 77.38369750976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[81.787735]
 [84.93359 ]
 [85.15549 ]
 [80.29269 ]
 [89.03304 ]
 [85.82153 ]
 [98.60024 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 8. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  3.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [8. 1. 4.] 
adversary owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -7.4911651611328125
desired expected reward: 88.2440414428711



buy possibilites: [-1] 
expected returns: [[88.58019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0.  8.  1. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  0. 10.  0.] 
adversary cards in discard: [8. 1. 4.] 
adversary owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -77 

action type: buy - action 11.0
Learning step: -6.308598041534424
desired expected reward: 82.72444152832031






Player: 1 
cards in hand: [ 0.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 10.  0.] 
cards in discard: [8. 1. 4.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 6. 1.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 16.] 
cards in discard: [8. 1. 4.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 4 29 15  0 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3
  3  0  0  1  0 16  8  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 6. 1.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 1. 4. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 6. 1.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 1. 4. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [1. 0. 0. 6. 1.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[80.20112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 6. 1.] 
cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -7.374484539031982
desired expected reward: 81.2057113647461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[63.292633]
 [66.438644]
 [63.454636]
 [66.66927 ]
 [62.067135]
 [61.80243 ]
 [66.353386]
 [70.560905]
 [73.45966 ]
 [71.58326 ]
 [65.469864]
 [67.92224 ]
 [67.346275]
 [64.70761 ]
 [68.68452 ]
 [77.70526 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 6. 1.] 
cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.] 
adversary owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -7.159953594207764
desired expected reward: 73.04116821289062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  1.  0.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  2.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [ 8. 29.  0.  8.  0.] 
adversary cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 8. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8.] 
expected returns: [[20.465187]
 [ 9.26025 ]
 [13.866672]
 [ 9.26025 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  8.  0.] 
cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0 29  8  0 14  0  6  0 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 29.  3. 15.  0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0 11] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -8.278579711914062
desired expected reward: 69.42667388916016



action possibilites: [-1] 
expected returns: [[109.6186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 29.  3. 15.  0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0 11] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.474544882774353
desired expected reward: 2.344717502593994





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 90.447   ]
 [ 94.81068 ]
 [ 88.492744]
 [108.93276 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [ 0.  8.  1. 11.  3.  0.  3.  0.  0.  1.  0.  0.  6.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [15. 29.  3. 15.  0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0 11] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -6.96973180770874
desired expected reward: 102.64886474609375






Player: 1 
cards in hand: [15. 29.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  3. 15.  0.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3
  0  0  1  0 16  8  0  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 11.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 15.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 11.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 15.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  6. 10.  8.] 
adversary cards in hand: [11.  3. 11.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 15.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  3. 11.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [11.  3. 11.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 14.] 
expected returns: [[77.7407 ]
 [71.07624]
 [71.07624]
 [66.32094]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  6. 14.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  6.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -8.590354919433594
desired expected reward: 100.34239959716797



action possibilites: [-1] 
expected returns: [[101.1955]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6. 14.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -59 

action type: gain_card_n - action 6
Learning step: -3.697767734527588
desired expected reward: 56.795562744140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 83.55094 ]
 [ 81.92596 ]
 [100.421074]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6. 14.] 
cards in discard: [29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -6.719002723693848
desired expected reward: 94.47650146484375



buy possibilites: [-1] 
expected returns: [[41.607414]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6. 14.] 
cards in discard: [29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -105 

action type: buy - action 0.0
Learning step: -8.49138069152832
desired expected reward: 75.05956268310547






Player: 1 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [8. 1. 0. 3. 0.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  1.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [8. 1. 0. 3. 0.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [8. 1. 0. 3. 0.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [8. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[44.749855]
 [39.262722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 3. 0.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15. 11.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: -5.862761974334717
desired expected reward: 35.744651794433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
expected returns: [[37.72967 ]
 [39.28887 ]
 [39.381927]
 [36.989273]
 [39.23755 ]
 [42.02083 ]
 [38.76744 ]
 [39.70663 ]
 [40.360268]
 [46.04847 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 3. 0.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15. 11.  3.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.038631916046143
desired expected reward: 38.71122360229492



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15. 11.  3.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  1.  4.  0. 10. 16.  3.  0.  0.  1. 11. 29.  0.  0.  0.  8. 10. 15.
 29.  3. 15. 11.  3.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 8. 6. 0.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[51.45332]
 [42.95758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -5.955514430999756
desired expected reward: 40.092960357666016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
expected returns: [[39.26743 ]
 [41.835873]
 [41.98936 ]
 [38.053127]
 [42.522038]
 [50.879158]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 6. 0.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [4. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.298878192901611
desired expected reward: 45.15444564819336



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [4. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 3. 3. 3.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [0. 0. 1. 0. 1.] 
adversary cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.  0.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[57.150337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.  0.  0.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  1. 15.  0.  0.] 
adversary cards in discard: [0. 4. 0. 3. 3. 3.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -6.00807523727417
desired expected reward: 44.8710823059082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[54.491234]
 [56.16014 ]
 [54.55345 ]
 [56.271336]
 [53.836155]
 [53.70194 ]
 [56.10932 ]
 [59.9554  ]
 [58.925995]
 [55.603695]
 [56.933273]
 [56.633095]
 [55.191116]
 [57.345856]
 [62.150723]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 1.] 
cards in discard: [29.  0. 11.  3. 11.  6. 14.  8.  1.  0.  3.  0.  0.  0.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [11.  1. 15.  0.  0.] 
adversary cards in discard: [0. 4. 0. 3. 3. 3.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0] -> size -> 35 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -6.289645671844482
desired expected reward: 50.86069107055664



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  1. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 15.  0.  0.] 
cards in discard: [0. 4. 0. 3. 3. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  8. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 15.  0.  0.] 
cards in discard: [0. 4. 0. 3. 3. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  7.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  8. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 15.  0.  0.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 1.  8. 11. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 11. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.  8.] 
expected returns: [[103.467094]
 [ 94.25461 ]
 [ 97.289955]
 [ 97.289955]
 [ 94.25461 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11. 11.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16] -> size -> 36 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -5.617621898651123
desired expected reward: 56.53310012817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 90.66154 ]
 [ 93.6333  ]
 [ 89.349525]
 [103.25055 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8. 11. 11.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16] -> size -> 36 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: -7.729396343231201
desired expected reward: 95.73765563964844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  5. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [ 1.  8. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [ 1.  8. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  8.  0. 14.  1.] 
adversary cards in discard: [ 1.  8. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[92.40919]
 [87.68657]
 [86.87505]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  1.] 
cards in discard: [ 1.  8. 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 15. 16. 29. 29.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: -7.232321262359619
desired expected reward: 83.0196762084961



action possibilites: [-1] 
expected returns: [[84.80671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 1.  8. 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 15. 29.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 14.0
Learning step: -6.185601711273193
desired expected reward: 80.689453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[78.35691 ]
 [79.673256]
 [78.39341 ]
 [79.73787 ]
 [77.83197 ]
 [77.72938 ]
 [79.62372 ]
 [82.61134 ]
 [81.804756]
 [79.20376 ]
 [80.239296]
 [80.010345]
 [78.88528 ]
 [80.561325]
 [84.83403 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1.] 
cards in discard: [ 1.  8. 11. 11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [ 0. 15. 29.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: -6.151229381561279
desired expected reward: 78.65547943115234






Player: 1 
cards in hand: [ 0. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 29.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 1.  8. 11. 11.  8. 14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 1.  8. 11. 11.  8. 14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10] -> size -> 37 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 1. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [0. 1. 6. 3. 0.] 
adversary cards in discard: [ 1.  8. 11. 11.  8. 14.  0.  8.  0.  1.] 
adversary owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
adversary victory points: 0
player victory points: 9 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 3 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 4 

Remodel: 1 
Workshop: 4 
Chapel: 4 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0. 1. 6. 3. 0.] 
cards in discard: [ 1.  8. 11. 11.  8. 14.  0.  8.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  1  1  6  3  3 11  1  8  8  0  0  8  0 14  0  6  0 11 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 24. 30. 19. 29.  8.  6.  6.  0.  0. 10.  5.  7. 10.  4. 10.  8.] 
adversary cards in hand: [15.] 
adversary cards in discard: [ 0.  4.  0.  3.  3.  3. 16. 11.  1. 15.  0.  0. 10. 11.  0.  0.  0.  8.
 16. 29.  0.  0.  0.] 
adversary owned cards: [ 4 29 15 10  1  0  3  0  3  0  8  3  8 29  0 15  0  0  0  3  0  3  3  0
  0  1  0 16  8  0  0 11 10 11  0 16 10  0] -> size -> 38 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -90    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -595 

action type: buy - action -1.0
Learning step: -33.991703033447266
desired expected reward: 50.842342376708984



