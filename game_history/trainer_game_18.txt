 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[340.40454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -1  -70    0    0    0  -30    0    0    0   -5    0    0
    0    0] 
sum of rewards: -611 

action type: buy - action 0.0
Learning step: -33.17338180541992
desired expected reward: 19.294200897216797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[324.84628]
 [327.36887]
 [327.80606]
 [324.17154]
 [327.84195]
 [331.40622]
 [328.35983]
 [332.97406]
 [327.71976]
 [328.79703]
 [330.32898]
 [340.38077]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.727901458740234
desired expected reward: 331.4955139160156



buy possibilites: [-1] 
expected returns: [[308.00912]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -9.515104293823242
desired expected reward: 321.8910827636719






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [1. 0. 0. 3. 3. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [11.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[327.17606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.090787887573242
desired expected reward: 299.9183349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[312.03897]
 [314.8877 ]
 [315.38333]
 [311.2779 ]
 [319.45206]
 [316.0093 ]
 [316.50497]
 [330.19604]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [11.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.40627670288086
desired expected reward: 319.912353515625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.30978012084961
desired expected reward: 320.88623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[306.42038]
 [309.36765]
 [309.8809 ]
 [305.63327]
 [309.91928]
 [314.08112]
 [310.51932]
 [315.90826]
 [309.7728 ]
 [311.03256]
 [312.82138]
 [324.56085]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [1. 3. 3. 0. 8.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.28275203704834
desired expected reward: 315.1626281738281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 8.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 8.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 8.] 
cards in discard: [15.  0.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  0.  0.] 
adversary cards in discard: [3. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[341.43808]
 [331.59186]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  0.] 
cards in discard: [3. 0. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.20727825164795
desired expected reward: 315.35357666015625



action possibilites: [-1] 
expected returns: [[306.09277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 24 

action type: gain_card_n - action 7
Learning step: -9.536909103393555
desired expected reward: 342.9430236816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.24084]
 [294.17697]
 [294.5061 ]
 [291.71875]
 [297.25882]
 [294.9281 ]
 [295.2572 ]
 [304.83292]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 8 

action type: take_action - action -1
Learning step: -8.233887672424316
desired expected reward: 297.85888671875



buy possibilites: [-1] 
expected returns: [[336.07974]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 3.  0.  0.  0.  0. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 26 

action type: buy - action 1.0
Learning step: -5.847053050994873
desired expected reward: 288.32989501953125






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [3. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3. 0.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 3. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[339.7055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.734999656677246
desired expected reward: 326.3447570800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[314.43823]
 [317.76926]
 [318.36624]
 [313.55774]
 [318.41385]
 [322.83383]
 [319.0936 ]
 [324.68475]
 [318.26285]
 [319.69052]
 [321.55905]
 [333.46597]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.410204887390137
desired expected reward: 330.4337158203125



buy possibilites: [-1] 
expected returns: [[340.67523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 3.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 3. 1. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3  0] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -24.162694931030273
desired expected reward: 289.3950500488281






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [0. 3. 1. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  8 15  3  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [6. 0. 3. 0. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 3. 1. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [6. 0. 3. 0. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 3. 1. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [6. 0. 3. 0. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 3. 1. 3. 3. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [6. 0. 3. 0. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[334.22815]
 [323.06256]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [6. 0. 3. 0. 1. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -10.215089797973633
desired expected reward: 330.46014404296875



action possibilites: [-1] 
expected returns: [[357.86746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  0.  1.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 16 

action type: gain_card_n - action 9
Learning step: -6.921845436096191
desired expected reward: 308.555419921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[339.48547]
 [342.88156]
 [343.4825 ]
 [338.5839 ]
 [343.52646]
 [348.3241 ]
 [344.21072]
 [350.43338]
 [343.36478]
 [344.81168]
 [346.87714]
 [360.42746]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  0.  1.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -9.737489700317383
desired expected reward: 348.1299743652344



buy possibilites: [-1] 
expected returns: [[361.95673]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 6.  0.  3.  0.  1.  3. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -9.980246543884277
desired expected reward: 329.50518798828125






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 29. 30.  8.  9. 10.  9.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  0.] 
cards in discard: [11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [11.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [11.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[276.7796 ]
 [266.86533]
 [268.59485]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  9. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -12.729350090026855
desired expected reward: 349.2273864746094



action possibilites: [-1] 
expected returns: [[268.66406]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -304 

action type: gain_card_n - action 3
Learning step: -22.102628707885742
desired expected reward: 236.84878540039062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[253.50719]
 [256.60645]
 [252.80186]
 [257.17917]
 [269.43918]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 29. 30.  8.  8. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -7.806012153625488
desired expected reward: 260.8580627441406



buy possibilites: [-1] 
expected returns: [[276.07022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [11.  3.  0.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -8.163779258728027
desired expected reward: 245.34339904785156






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [11.  3.  0.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [11.  3.  0.  0. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  8.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [11.  3.  0.  0. 15.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[232.8855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -9.739967346191406
desired expected reward: 266.33026123046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[217.30447]
 [220.23692]
 [220.74686]
 [216.52072]
 [224.92511]
 [221.38307]
 [221.89297]
 [235.40384]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.867381572723389
desired expected reward: 226.0679168701172



buy possibilites: [-1] 
expected returns: [[248.00604]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -6 

action type: buy - action 10.0
Learning step: -5.814513683319092
desired expected reward: 216.07847595214844






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  1.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  9. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  1.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 1.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  1.] 
adversary cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  6.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[268.04056]
 [255.01912]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  1.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.732344150543213
desired expected reward: 240.27369689941406



action possibilites: [-1.] 
expected returns: [[354.22028]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -3 

action type: take_action - action 10.0
Learning step: -4.875591278076172
desired expected reward: 249.0353546142578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[327.35464]
 [330.9123 ]
 [331.55276]
 [326.54602]
 [326.41647]
 [331.60214]
 [336.64578]
 [332.32248]
 [340.37793]
 [338.8604 ]
 [331.4455 ]
 [334.40796]
 [332.963  ]
 [330.7252 ]
 [335.12827]
 [349.38318]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -10.372990608215332
desired expected reward: 343.8472900390625



buy possibilites: [-1] 
expected returns: [[381.01376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 1. 0.] 
cards in discard: [ 6.  0. 11.  0.  0. 29.  3. 10.  3.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -34.0 

action type: buy - action 0.0
Learning step: -9.49492073059082
desired expected reward: 317.85968017578125






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [29.  3.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  3.  0.  0.  3.  1. 22.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[239.0874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11. 11.  0.  8.  3.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -14.889599800109863
desired expected reward: 366.1241760253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[215.51787]
 [217.97047]
 [214.95404]
 [218.40479]
 [228.31773]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [11. 11.  0.  8.  3.] 
adversary cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22] -> size -> 16 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.676877021789551
desired expected reward: 220.81658935546875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [11. 11.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  8.  3.] 
cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 29. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 29.  6. 10.  3.] 
adversary cards in discard: [0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 29.  6. 10.  3.] 
adversary cards in discard: [0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 29.  6. 10.  3.] 
adversary cards in discard: [0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  8.  3.] 
cards in discard: [29.  3.  0.  0.  3.  1. 22. 15.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 1. 29.  6. 10.  3.] 
adversary cards in discard: [0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 1. 29.  6. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[265.36887]
 [258.57803]
 [254.72601]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  6. 10.  3.] 
cards in discard: [0. 6. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -7.309417724609375
desired expected reward: 221.00833129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[250.45248]
 [252.92006]
 [249.88503]
 [253.36487]
 [264.4055 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6. 10.  3.] 
cards in discard: [0. 6. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -9.125521659851074
desired expected reward: 254.20706176757812



buy possibilites: [-1] 
expected returns: [[275.1096]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  6. 10.  3.] 
cards in discard: [0. 6. 3. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -64.0 

action type: buy - action 0.0
Learning step: -9.532660484313965
desired expected reward: 240.91986083984375






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 11. 15.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0] -> size -> 21 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[225.89888]
 [214.58823]
 [211.31871]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  8.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.620518684387207
desired expected reward: 264.48907470703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[210.41148]
 [213.4851 ]
 [214.03555]
 [209.60161]
 [218.44571]
 [214.69283]
 [215.24327]
 [229.75638]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  9. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  8.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.951991558074951
desired expected reward: 214.74859619140625



buy possibilites: [-1] 
expected returns: [[214.25233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0. 22.  3.  8.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -32.0 

action type: buy - action 8.0
Learning step: -7.513965129852295
desired expected reward: 207.1788787841797






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 22.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  3.  8.] 
cards in discard: [ 3.  0.  1. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.  0. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  3.  8.] 
cards in discard: [ 3.  0.  1. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.  0. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[301.34583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.  0. 11.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -5.674615383148193
desired expected reward: 208.5777130126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[266.86093]
 [269.86612]
 [270.40842]
 [266.18204]
 [266.0709 ]
 [270.4445 ]
 [274.70154]
 [271.0513 ]
 [277.91937]
 [276.5737 ]
 [270.32166]
 [272.82285]
 [271.59357]
 [269.71487]
 [273.42963]
 [286.24808]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.  0. 11.  0. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8. 10.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -10.520513534545898
desired expected reward: 288.94622802734375



buy possibilites: [-1] 
expected returns: [[287.7223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  6.  3.  3.  0.  0.  1. 29.  6. 10.  3.  8.  0. 11.  0. 10.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  3. 29.  0.  0.] 
adversary cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 16 

action type: buy - action 25.0
Learning step: -6.62221622467041
desired expected reward: 271.297119140625






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 29.  0.  0.] 
cards in discard: [ 3.  0.  1. 11. 15.  0.  0. 22.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0.  8.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 3. 10.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[265.03543]
 [250.5274 ]
 [249.96191]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  8.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -10.342815399169922
desired expected reward: 277.3794860839844



action possibilites: [-1.  8.] 
expected returns: [[231.41788]
 [218.03647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 10.0
Learning step: -8.063908576965332
desired expected reward: 241.62332153320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[215.80348]
 [218.70071]
 [215.1759 ]
 [219.30222]
 [232.94041]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [15.  0.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -7.285797119140625
desired expected reward: 224.132080078125






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [15.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 28. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  0. 11.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3.  3. 25.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[309.80505]
 [302.0792 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 25.] 
cards in discard: [10.  3.  0.  8.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  8. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 22.  3.  3.] 
adversary cards in discard: [ 3. 15.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -7.021878719329834
desired expected reward: 225.91851806640625



action possibilites: [-1] 
expected returns: [[339.56558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 22.  3.  3.] 
adversary cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -22 

action type: take_action - action 25.0
Learning step: -8.416322708129883
desired expected reward: 290.7146301269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[320.90717]
 [324.40314]
 [325.05426]
 [319.99994]
 [325.0951 ]
 [330.0718 ]
 [325.8025 ]
 [332.24496]
 [324.96783]
 [326.4536 ]
 [328.58597]
 [343.132  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 0.] 
cards in discard: [10.  3.  0.  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [29.  0. 22.  3.  3.] 
adversary cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -10.782183647155762
desired expected reward: 328.78338623046875






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [29.  0. 22.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 22.  3.  3.] 
cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  3.  0.] 
cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0. 0. 3.] 
cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 22. 11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 0. 3.] 
cards in discard: [ 3. 15.  0.  0.  0. 11.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 22. 11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0. 0. 3.] 
cards in discard: [ 3. 15.  0.  0.  0. 11.  6. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 22. 11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[236.08617]
 [228.63608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -13.156946182250977
desired expected reward: 320.12017822265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[219.866  ]
 [221.63074]
 [221.93373]
 [219.3928 ]
 [221.95844]
 [224.44371]
 [222.31766]
 [225.5477 ]
 [221.87683]
 [222.62064]
 [223.69992]
 [230.96535]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 28. 30. 27. 30.  8.  7. 10.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.397490501403809
desired expected reward: 226.2464599609375



buy possibilites: [-1] 
expected returns: [[228.5261]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [3. 3. 0. 8. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -2 

action type: buy - action 16.0
Learning step: -6.056085109710693
desired expected reward: 215.90234375






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [10. 29.  1.  6.  0.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  8.  9.  9.] 
adversary cards in hand: [10. 29.  1.  6.  0.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8. 1.] 
cards in discard: [10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [10. 29.  1.  6.  0.] 
adversary cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [10. 29.  1.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[176.5373 ]
 [165.49377]
 [169.23087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  1.  6.  0.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 23.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -9.278958320617676
desired expected reward: 219.24713134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[159.08565]
 [161.33736]
 [161.7473 ]
 [158.49545]
 [165.18304]
 [162.23413]
 [162.64409]
 [174.47427]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  1.  6.  0.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  7.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 23.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -6.832135200500488
desired expected reward: 169.70513916015625



buy possibilites: [-1] 
expected returns: [[187.14406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  1.  6.  0.] 
cards in discard: [10.  3.  0.  8.  6.  0. 25.  0.  0.  3.  3.  0.  0. 16.  0.  0.  0.  0.
 11. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  6.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  0. 22. 23.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -16 

action type: buy - action 11.0
Learning step: -4.8484110832214355
desired expected reward: 160.3346405029297






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 22. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22. 23.] 
cards in discard: [10.  3.  3.  0.  8.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  6.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 22. 11.] 
cards in discard: [10.  3.  3.  0.  8.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  6.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22. 11.] 
cards in discard: [10.  3.  3.  0.  8.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10] -> size -> 23 
action values: 0 
buys: 2 
player value: 4 
card supply: [22. 28. 30. 27. 30.  8.  7.  9.  6.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22. 11.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  8.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 22. 11.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [25. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [25. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[230.57668]
 [227.00427]
 [224.02548]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  6. 29. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -6.011848449707031
desired expected reward: 181.1322021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[213.69913]
 [215.48569]
 [213.29295]
 [215.80844]
 [223.03696]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  6. 29. 15.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.184614181518555
desired expected reward: 219.11199951171875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 29. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29. 15.  0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 16.  0.  0.  6.] 
adversary cards in discard: [25. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 16.  0.  0.  6.] 
adversary cards in discard: [25. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 16.  0.  0.  6.] 
adversary cards in discard: [25. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 15.  0.  0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [29. 16.  0.  0.  6.] 
adversary cards in discard: [25. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [29. 16.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
expected returns: [[191.02866]
 [185.64072]
 [181.91153]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  0.  0.  6.] 
cards in discard: [25. 10.  0.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -8.707289695739746
desired expected reward: 214.3296661376953



action possibilites: [-1. 16.] 
expected returns: [[186.76929]
 [173.79025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  6.  0.] 
cards in discard: [25. 10.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 29.0
Learning step: -5.739892959594727
desired expected reward: 177.45721435546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[170.09485]
 [172.498  ]
 [172.94777]
 [169.47247]
 [172.97675]
 [176.40169]
 [173.4627 ]
 [177.89767]
 [172.89018]
 [173.91245]
 [175.37944]
 [185.41147]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  6.  0.] 
cards in discard: [25. 10.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  7.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -6.09034538269043
desired expected reward: 180.67892456054688



buy possibilites: [-1] 
expected returns: [[260.2824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  6.  0.] 
cards in discard: [25. 10.  0.  3.  0.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [11.  3.  0.  3.  0.] 
adversary cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -12.0 

action type: buy - action 8.0
Learning step: -3.416780471801758
desired expected reward: 170.04591369628906






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [11.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  3.  0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  1. 10.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  8.  1. 10.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 27. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  8.  1. 10.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [10.  3.  3.  0.  8.  1.  0.  8. 23.  0.  0.  0. 22. 11.  1. 29.  3.  6.
 15.  0.  0. 15.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  8.  1. 10.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [ 3.  8.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[137.85078]
 [129.43515]
 [129.74896]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  1. 10.  0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1
Learning step: -12.224762916564941
desired expected reward: 248.05764770507812



action possibilites: [-1.  8.] 
expected returns: [[195.39487]
 [186.65442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -23 

action type: take_action - action 10.0
Learning step: -3.3301894664764404
desired expected reward: 126.41876983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[178.32867]
 [180.11653]
 [180.43628]
 [177.8574 ]
 [180.45752]
 [182.98898]
 [180.81958]
 [184.10406]
 [180.3835 ]
 [181.13933]
 [182.23317]
 [189.37524]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  6.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -6.868999004364014
desired expected reward: 188.52586364746094



buy possibilites: [-1] 
expected returns: [[178.56555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0. 0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 8.  3.  3. 23. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -40.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -19.5 

action type: buy - action 11.0
Learning step: -6.000523567199707
desired expected reward: 176.98849487304688






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  3. 23. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  3. 23. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0
  8  1 15  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 10.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23. 10.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [11.  0.  3.  6.  0.] 
adversary cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [11.  0.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[83.71495]
 [76.7522 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  6.  0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 22. 11.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.815690040588379
desired expected reward: 169.74986267089844



action possibilites: [-1] 
expected returns: [[109.67482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 22. 11.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -5 

action type: gain_card_n - action 1
Learning step: -1.4647964239120483
desired expected reward: 72.18479919433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 97.49461 ]
 [ 99.710945]
 [ 97.00563 ]
 [100.10646 ]
 [110.268906]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0.] 
cards in discard: [25. 10.  0.  3.  0.  8. 29. 16.  0.  0.  6.  0. 11. 10.  3.  8.  1.  0.
  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 3.  6.  3. 22. 11.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -3.8934059143066406
desired expected reward: 105.78141784667969






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 3.  6.  3. 22. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 22. 11.] 
cards in discard: [ 0.  8.  3. 23. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 22. 11.] 
cards in discard: [ 0.  8.  3. 23. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1] -> size -> 28 
adversary victory points: 1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[238.67842]
 [230.48001]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  8.] 
adversary cards in hand: [ 0. 15.  1.  0.  1.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -1.9570598602294922
desired expected reward: 108.31185150146484



action possibilites: [-1] 
expected returns: [[175.87419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  1.  0.  1.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 2 

action type: gain_card_n - action 10
Learning step: -7.286470890045166
desired expected reward: 219.58633422851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[168.10342]
 [169.66084]
 [169.93079]
 [167.68704]
 [169.94891]
 [172.14265]
 [170.26306]
 [173.11601]
 [169.87866]
 [170.53304]
 [171.48831]
 [178.76817]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 26. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  1.  0.  1.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -5.63066291809082
desired expected reward: 170.2435302734375



buy possibilites: [-1] 
expected returns: [[191.43681]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [15.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  7.] 
adversary cards in hand: [ 0. 15.  1.  0.  1.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -1.0 

action type: buy - action 3.0
Learning step: -4.2392120361328125
desired expected reward: 165.69158935546875






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0. 15.  1.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  0.  1.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  7.] 
adversary cards in hand: [11.  8.  3. 16. 29.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15  3] -> size -> 30 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  0.  1.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8. 10.  9.  7.  9.  7.] 
adversary cards in hand: [11.  8.  3. 16. 29.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15  3] -> size -> 30 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  0.  1.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [11.  8.  3. 16. 29.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15  3] -> size -> 30 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [11.  8.  3. 16. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 16. 29.] 
expected returns: [[148.3959 ]
 [137.06332]
 [133.69405]
 [133.14154]
 [138.97017]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 16. 29.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29  1  6 10  0  6  0 10  0  0  8 25 16
 11  8 11  1 15  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  9.  7.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -7.589786052703857
desired expected reward: 183.84703063964844



action possibilites: [-1] 
expected returns: [[196.79536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: 22 

action type: gain_card_n - action 11
Learning step: -9.867810249328613
desired expected reward: 298.04632568359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[184.33646]
 [183.84691]
 [195.63126]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 29.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -5.744956016540527
desired expected reward: 191.0504150390625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 25.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 26. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 25.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 25.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[141.86702]
 [136.42656]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 25.  0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [29. 15.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14  1] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -7.795030117034912
desired expected reward: 187.83621215820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[133.00131]
 [135.11626]
 [135.49547]
 [132.44337]
 [135.5182 ]
 [138.51682]
 [135.94952]
 [139.83582]
 [135.43698]
 [136.32875]
 [137.62502]
 [146.07848]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 25.  0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  6.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [29. 15.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14  1] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -5.146240711212158
desired expected reward: 136.72076416015625



buy possibilites: [-1] 
expected returns: [[95.82922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 25.  0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  5.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [29. 15.  3.  0.  3.] 
adversary cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14  1] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -5.3567118644714355
desired expected reward: 123.90067291259766






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [29. 15.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  3.  0.  3.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8
  1 15  3  0 14  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  5.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  5.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  5.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.] 
cards in discard: [ 0.  8.  3. 23. 10.  3.  6.  3. 22. 11. 14.  0. 15.  1.  0.  1.  1.  0.
  0.  8.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [10.  0.  3. 11.  0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[72.9147 ]
 [66.34956]
 [67.83038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 1. 23.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -4.380073070526123
desired expected reward: 91.44915008544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.63274 ]
 [64.30767 ]
 [62.246037]
 [64.61536 ]
 [71.35653 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3. 11.  0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 1. 23.  0.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8] -> size -> 30 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -3.3192028999328613
desired expected reward: 69.59552001953125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 1. 23.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 11.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8] -> size -> 30 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0] -> size -> 31 
action values: 0 
buys: 2 
player value: 5 
card supply: [19. 25. 30. 25. 30.  8.  7.  9.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 0. 16.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3.] 
cards in discard: [ 0. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [6. 0. 1. 8. 0.] 
adversary cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [6. 0. 1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.506084]
 [49.162357]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 8. 0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1  6 10  0  6  0 10  0  0  8 25 16 11
  8 11  1 15  3 23  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  1.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1.0
Learning step: -3.5213241577148438
desired expected reward: 67.83522033691406



action possibilites: [-1] 
expected returns: [[183.11732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  1.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: trash_cards_n_from_hand - action 7
Learning step: 1.485912561416626
desired expected reward: 51.17045593261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[161.96075]
 [161.2106 ]
 [179.73825]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [15.  3. 11.  0.  0.  0.  0. 23. 16.  8.  3. 29.  8.  1.  0.  3. 25.  0.
 10.  0.  3. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 0. 10.  3. 14.  1.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -5.508556842803955
desired expected reward: 177.6087646484375






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 14.  1.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [ 6.  0.  0. 10.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  1.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  9.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  1.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  8.  7.] 
adversary cards in hand: [0. 0. 6.] 
adversary cards in discard: [10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
adversary victory points: 2
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.1156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: discard_down_to_3_cards - action 3
Learning step: -3.1249146461486816
desired expected reward: 167.8253936767578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[271.93713]
 [274.62512]
 [271.33673]
 [275.18338]
 [287.62506]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  7.  8.  5.  4.  9.  8.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22] -> size -> 34 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.518410682678223
desired expected reward: 282.5971984863281



buy possibilites: [-1] 
expected returns: [[222.13062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [10.  6.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  8.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22] -> size -> 34 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -25.268898010253906
desired expected reward: 246.06784057617188






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  8.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  0. 23.  8.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0. 23.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
expected returns: [[239.12564]
 [224.69781]
 [222.67073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 23.  8.] 
cards in discard: [10.  6.  6.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 8. 29.  3. 15.  8.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22 29] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.636143684387207
desired expected reward: 214.49447631835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[218.20757]
 [222.24901]
 [217.3096 ]
 [222.98853]
 [239.44344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 23.  8.] 
cards in discard: [10.  6.  6.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 8. 29.  3. 15.  8.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22 29] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.582948684692383
desired expected reward: 230.54269409179688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  3. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 15.  8.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8 15  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1
 15  3  0 14  1  8  0 16  0 22 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [16. 15.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [16. 15.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [16. 15.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  8.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [16. 15.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
adversary victory points: 1
player victory points: 4 





Player: 0 
cards in hand: [16. 15.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 10.] 
expected returns: [[127.04998 ]
 [118.27435 ]
 [120.01367 ]
 [118.948494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  0.  0. 10.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [22.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -10.935469627380371
desired expected reward: 228.5079803466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[119.154045]
 [121.09855 ]
 [118.7386  ]
 [121.4634  ]
 [130.0568  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  0. 10.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 25. 30. 25. 30.  8.  6.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [22.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -5.288445472717285
desired expected reward: 121.76154327392578



buy possibilites: [-1] 
expected returns: [[171.21022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  0. 10.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [22.  0.  3.  0.  0.] 
adversary cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -40.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -345.0 

action type: buy - action 6.0
Learning step: -19.197385787963867
desired expected reward: 99.54122924804688






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [22.  0.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  3.  0.  0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 8. 1. 0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8. 1. 0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  5.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 8. 1. 0.] 
cards in discard: [ 0. 16.  0. 23. 11.  1.  0.  0.  3. 22. 14.  0. 10.  3.  1. 29. 11.  3.
  6.  0.  0.  0.  8. 29.  3.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  1. 11.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  0.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[119.86404]
 [112.80066]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 11.  3.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -8.185595512390137
desired expected reward: 163.02462768554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[107.88739 ]
 [109.47907 ]
 [109.75337 ]
 [107.45997 ]
 [109.77253 ]
 [112.46057 ]
 [110.12333 ]
 [113.66477 ]
 [109.700226]
 [110.46407 ]
 [111.645   ]
 [119.3617  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.  3.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  4.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -5.728478908538818
desired expected reward: 114.13556671142578



buy possibilites: [-1] 
expected returns: [[132.16264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 11.  3.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  3.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -43.0 

action type: buy - action 8.0
Learning step: -4.6825079917907715
desired expected reward: 105.44083404541016






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 22.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0.  0.  1. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0.  1. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 25. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0.  0.  1. 14.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  0. 25.  3.] 
adversary cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[198.85814]
 [183.2284 ]
 [190.21297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 25.  3.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -4.548843860626221
desired expected reward: 127.61380004882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[180.67458]
 [184.27248]
 [179.87616]
 [184.9327 ]
 [200.78824]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 25.  3.] 
cards in discard: [10.  6.  6.  0.  0.  6.  0.  3.  0. 23.  8.  6. 16. 15.  0.  0. 10.  8.
  0.  0.  1. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1] -> size -> 37 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -7.974541664123535
desired expected reward: 190.8835906982422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  7.  8.  7.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0.  8.  3. 11. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 29.] 
expected returns: [[157.36555]
 [148.56761]
 [150.79787]
 [151.94063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0. 29. 15.  3.  8.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -8.854687690734863
desired expected reward: 191.93356323242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[146.7311 ]
 [146.2502 ]
 [158.09167]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0. 29. 15.  3.  8.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1.0
Learning step: -6.718942165374756
desired expected reward: 150.6466064453125



buy possibilites: [-1] 
expected returns: [[130.02884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 11. 29.] 
cards in discard: [0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0. 29. 15.  3.  8.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -75.0 

action type: buy - action 0.0
Learning step: -8.160905838012695
desired expected reward: 138.5701904296875






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 29. 15.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15.  3.  8.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0.  6.  1. 10. 25.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 15.  3.  8.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 0.  6.  1. 10. 25.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6.  1. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[123.53869 ]
 [114.183174]
 [118.07291 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 10. 25.] 
cards in discard: [ 0.  0.  8.  3. 11. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -6.07257604598999
desired expected reward: 123.95626068115234



action possibilites: [-1. 25.] 
expected returns: [[97.85992 ]
 [91.843895]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1. 25.  3.] 
cards in discard: [ 0.  0.  8.  3. 11. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  5.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10] -> size -> 38 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: -4.818655967712402
desired expected reward: 109.36451721191406



action possibilites: [-1. 11.  8.] 
expected returns: [[175.0294 ]
 [166.13104]
 [163.96988]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1.  3. 11.  8.] 
cards in discard: [ 0.  0.  8.  3. 11. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  4.  8.  4.  3.  9.  7.  9.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: -1.0397052764892578
desired expected reward: 90.8041763305664



action possibilites: [-1] 
expected returns: [[264.04578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 3. 8.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  4.  8.  4.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: -0.7074653506278992
desired expected reward: 163.26243591308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[244.44579]
 [246.95755]
 [247.4271 ]
 [243.84938]
 [251.19319]
 [247.99434]
 [248.46385]
 [260.616  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 3. 8.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  4.  8.  4.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -6.82800817489624
desired expected reward: 257.2177734375



buy possibilites: [-1] 
expected returns: [[223.16756]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 3. 8.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  4.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [ 6.  3.  1.  0. 11.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -50.    0.    0.   60.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -296.0 

action type: buy - action 6.0
Learning step: -21.97119903564453
desired expected reward: 221.878173828125






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1.  0. 11.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  4.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1.  0. 11.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  4.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1.  0. 11.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[142.51755]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [23.  0. 11. 11.  0.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -10.251733779907227
desired expected reward: 212.9158172607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[122.230576]
 [124.2573  ]
 [124.60765 ]
 [121.686134]
 [127.49372 ]
 [125.04689 ]
 [125.39723 ]
 [134.74515 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  6.  8.  7.] 
adversary cards in hand: [23.  0. 11. 11.  0.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -6.233548641204834
desired expected reward: 129.37652587890625



buy possibilites: [-1] 
expected returns: [[43.805733]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [23.  0. 11. 11.  0.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0  -1   0   0  18   0] 
sum of rewards: -29 

action type: buy - action 10.0
Learning step: -6.734233379364014
desired expected reward: 118.66300964355469






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [23.  0. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 11. 11.  0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 24. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 11.  0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 11.  0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0. 11.  0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 16.  3.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 16.  3.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[72.54021]
 [64.67803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [10.  8.  0.  8. 16.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -2.9383022785186768
desired expected reward: 40.867431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.73846 ]
 [61.364594]
 [59.37155 ]
 [61.659657]
 [69.1652  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  3.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [10.  8.  0.  8. 16.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1.0
Learning step: -4.51162052154541
desired expected reward: 68.02860260009766



buy possibilites: [-1] 
expected returns: [[93.58514]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  6.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [10.  8.  0.  8. 16.] 
adversary cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -40 

action type: buy - action 8.0
Learning step: -2.9773178100585938
desired expected reward: 58.682350158691406






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [10.  8.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  0.  8. 16.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 23.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.  8.  8. 16. 22.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 16. 22.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  8  3  0  0 11 11 29 22  3  0  0  3  6 23 10  0  8  1 15
  3  0 14  1  8  0 16  0 22 29  0 11  1 10  6 11  1  0] -> size -> 42 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 23.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 23.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 23.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 22. 29.  0.  3.  3.  0.  0.  1. 14. 10.  1.  0.  0.  0.  3.  0. 29.
 15.  3.  8.  6. 11.  6.  3.  1.  0. 11.  1.  0. 11. 23.  0. 11.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 10.  8.  8. 23.] 
adversary cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  8.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 23.] 
expected returns: [[46.460594]
 [38.29969 ]
 [37.99157 ]
 [37.99157 ]
 [38.99868 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8. 23.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -6.066701889038086
desired expected reward: 87.5184326171875



action possibilites: [-1.  8.  8. 23.] 
expected returns: [[67.54653 ]
 [58.858894]
 [58.858894]
 [59.91986 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8. 23.  3.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 10.0
Learning step: -1.8226597309112549
desired expected reward: 36.4770393371582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[54.512276]
 [54.03652 ]
 [65.69657 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 23.  3.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 23. 30. 25. 30.  8.  3.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1.0
Learning step: -3.3544487953186035
desired expected reward: 64.19208526611328



buy possibilites: [-1] 
expected returns: [[34.550835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  8. 23.  3.] 
cards in discard: [ 0.  0.  8.  3. 11. 29. 14.  6. 10. 25. 11.  0.  6.  1.  3.  8. 10.  0.
  0.  6.  6.  0.  8.  0. 16.  3.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -50.    0.    0.   20.    0.    0.    0.    0.   -3.
    0. -300.    0.    0.] 
sum of rewards: -340.0 

action type: buy - action 6.0
Learning step: -18.9244327545166
desired expected reward: 35.112091064453125






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 38 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 23. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 38 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 6.  0.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 38 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[147.95206]
 [139.4772 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11
  1 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -1.335038423538208
desired expected reward: 33.215797424316406



action possibilites: [-1] 
expected returns: [[157.27792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [14. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 15.0
Learning step: -5.285107135772705
desired expected reward: 134.1920928955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[140.4514 ]
 [143.02882]
 [143.51875]
 [139.91191]
 [139.8206 ]
 [143.55016]
 [147.6626 ]
 [144.08737]
 [150.84277]
 [149.5539 ]
 [143.45845]
 [145.75397]
 [144.57733]
 [142.92117]
 [146.37372]
 [158.56693]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -6.4176225662231445
desired expected reward: 150.8603057861328



buy possibilites: [-1] 
expected returns: [[215.40073]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 5 
card supply: [13. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [1. 3. 3. 0. 1.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20. -30.   0.   0.   0.  -3.   0.   0.
   0.   0.] 
sum of rewards: -70.0 

action type: buy - action 0.0
Learning step: -5.676054000854492
desired expected reward: 134.7753448486328






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [1. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 1.  0.  0. 14.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 3.  8. 14.  1.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 1.  0.  0. 14.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 22. 30. 25. 30.  8.  2.  8.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 3.  8. 14.  1.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 3.  8. 14.  1.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  8. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[74.629456]
 [66.43431 ]
 [66.017784]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 14.  1.  0.] 
cards in discard: [ 0. 15.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [6. 3. 0. 0. 1.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -12.05512523651123
desired expected reward: 203.34559631347656



action possibilites: [-1] 
expected returns: [[107.30021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 1. 0.] 
cards in discard: [ 0. 15.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action 14.0
Learning step: -2.7366349697113037
desired expected reward: 63.281158447265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 95.80864 ]
 [ 97.80185 ]
 [ 98.15498 ]
 [ 95.35519 ]
 [ 95.27874 ]
 [ 98.175835]
 [100.99723 ]
 [ 98.58136 ]
 [103.080826]
 [102.23774 ]
 [ 98.091385]
 [ 99.748634]
 [ 98.93448 ]
 [ 97.68589 ]
 [100.15412 ]
 [108.1391  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0.] 
cards in discard: [ 0. 15.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  7.  8.  8.  5.  8.  7.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -4.962875843048096
desired expected reward: 102.33733367919922



buy possibilites: [-1] 
expected returns: [[192.30182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 1. 0.] 
cards in discard: [ 0. 15.  6.  0.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -50.   0.   0.  20.   0.   0.   0.   0.  -4.   0.   0.
   8.   0.] 
sum of rewards: -33.0 

action type: buy - action 29.0
Learning step: -2.162801742553711
desired expected reward: 94.62904357910156






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [16.  3.  6.  0.  3.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [16.  3.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[168.629  ]
 [157.74588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  0.  3.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  1.  0. 11. 11.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0] -> size -> 43 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1
Learning step: -8.781912803649902
desired expected reward: 183.51991271972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[153.87003]
 [153.37253]
 [166.83678]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  0.  3.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  1.  0. 11. 11.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0] -> size -> 43 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -7.707299709320068
desired expected reward: 160.92169189453125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11. 11.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  8.  8.  5.  8.  7.] 
adversary cards in hand: [ 6. 23.  8. 29. 25.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 6. 23.  8. 29. 25.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 6. 23.  8. 29. 25.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 11.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 6. 23.  8. 29. 25.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [ 6. 23.  8. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 29. 25.] 
expected returns: [[74.1333  ]
 [69.46773 ]
 [68.73681 ]
 [71.043175]
 [71.5744  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  8. 29. 25.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 25 16 11  8 11  1
 15  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0] -> size -> 45 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -9.587923049926758
desired expected reward: 157.24887084960938



action possibilites: [-1] 
expected returns: [[86.92179]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23. 29.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0] -> size -> 45 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: trash_cards_n_from_hand - action 2
Learning step: -3.3567230701446533
desired expected reward: 65.89254760742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[78.4228  ]
 [78.135445]
 [84.97573 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23. 29.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0] -> size -> 45 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -37 

action type: take_action - action -1
Learning step: -4.375182628631592
desired expected reward: 82.5466079711914






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [11.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  3.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
adversary victory points: -2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  2.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  2.  2.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
adversary victory points: -2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [11.  6.  0. 11.  0.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
adversary victory points: -2
player victory points: 3 





Player: 0 
cards in hand: [11.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[129.61536]
 [120.29453]
 [120.29453]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0. 11.  0.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10. 15.  3.  0. 29.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: buy - action -1.0
Learning step: -4.309166431427002
desired expected reward: 80.66656494140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[111.17475 ]
 [113.80359 ]
 [110.597725]
 [114.27992 ]
 [126.293724]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  0.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 22. 30. 25. 30.  8.  2.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10. 15.  3.  0. 29.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -6.714794158935547
desired expected reward: 122.90058898925781



buy possibilites: [-1] 
expected returns: [[127.3321]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0. 11.  0.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 22. 30. 25. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10. 15.  3.  0. 29.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -60.    0.    0.    0.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -372.0 

action type: buy - action 6.0
Learning step: -21.26491355895996
desired expected reward: 89.33280944824219






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [10. 15.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  3.  0. 29.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1. 15. 29. 23.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29. 23.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 25. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1. 15. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 23.  0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
action values: 2 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 25. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 23.  0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 25. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  0. 23.  0.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  8.  3.  6. 10.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  8.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[162.08508]
 [151.62743]
 [152.02911]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  6. 10.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29  6 10  0  6  0 10  0  0  8 16 11  8 11  1 15
  3 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 29. 11. 22.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.759141445159912
desired expected reward: 120.57295989990234



action possibilites: [-1] 
expected returns: [[133.10573]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 29. 11. 22.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.892787456512451
desired expected reward: 143.86053466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[116.98356 ]
 [116.385574]
 [131.24292 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 29. 11. 22.] 
adversary cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -6.250255107879639
desired expected reward: 126.85547637939453






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 29. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 11. 22.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29. 11.  8.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8. 10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 11.  8.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8. 10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 22. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29. 11.  8.] 
cards in discard: [ 1.  0.  0. 14.  3.  0. 16.  1.  3.  3.  0.  1.  0.  1.  0.  6.  3.  0.
 14.  0. 11.  0.  1.  0. 11. 11.  8. 11.  6.  0.  0.  0.  3. 10. 29. 15.
  3.  0. 23.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22.  8. 10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [10.  0.  0. 10.  8.] 
adversary cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [10.  0.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
expected returns: [[71.92603 ]
 [65.00916 ]
 [65.00916 ]
 [64.779205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  8.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -8.40078067779541
desired expected reward: 122.84217071533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[62.951584]
 [64.48926 ]
 [62.60285 ]
 [64.77921 ]
 [71.92603 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  8.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 24. 30.  8.  1.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.462081432342529
desired expected reward: 66.46395874023438



buy possibilites: [-1] 
expected returns: [[89.1097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  8.] 
cards in discard: [ 0. 15.  6.  0.  0. 29. 14.  3.  8.  1.  0. 16.  3.  6.  0.  3.  8.  6.
 23. 29.  6. 11.  6.  0. 11.  0.  8.  0.  3. 10.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  6.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -70.    0.    0.    0.    0.    0.    0.    0.   -4.
    0. -300.    0.    0.] 
sum of rewards: -382.0 

action type: buy - action 6.0
Learning step: -19.514249801635742
desired expected reward: 28.870084762573242






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  6.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  1. 10.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  1. 10.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  7.  8.  5.  8.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  1. 10.] 
cards in discard: [14.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[114.67029]
 [106.96204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 8.  1.  3. 14. 11.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -5.854004383087158
desired expected reward: 83.25569915771484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[106.46489 ]
 [108.06496 ]
 [108.35824 ]
 [110.64695 ]
 [108.69806 ]
 [108.99134 ]
 [116.479805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 8.  1.  3. 14. 11.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1.0
Learning step: -7.15155553817749
desired expected reward: 107.51873016357422



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  3. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3. 14. 11.] 
cards in discard: [14.  0.  0.  6.  1. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 6.  0. 29.  3.  3.] 
adversary cards in discard: [0. 0. 6. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  3. 11.] 
cards in discard: [14.  0.  0.  6.  1. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [29.  3.  3.] 
adversary cards in discard: [0. 0. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3. 11.] 
cards in discard: [14.  0.  0.  6.  1. 10.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14] -> size -> 50 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  6.  6.  8.  5.  8.  7.] 
adversary cards in hand: [29.  3.  3.] 
adversary cards in discard: [0. 0. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  3. 11.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29.] 
cards in deck: 39 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [29.  3.  3.] 
adversary cards in discard: [0. 0. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[129.2044 ]
 [120.65773]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.] 
cards in discard: [0. 0. 6. 0. 8. 6. 0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: discard_down_to_3_cards - action 4
Learning step: -6.5643134117126465
desired expected reward: 103.12093353271484



action possibilites: [-1.] 
expected returns: [[208.76364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [0. 0. 6. 0. 8. 6. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: discard_n_cards - action 1
Learning step: -3.9233779907226562
desired expected reward: 110.4878158569336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[192.29248]
 [194.89183]
 [195.36469]
 [205.87405]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [0. 0. 6. 0. 8. 6. 0. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  1.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -8.884836196899414
desired expected reward: 199.87879943847656






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  1.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 1.  0.  6. 14. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 1.  0.  6. 14. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 21. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 1.  0.  6. 14. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 1.  0.  6. 14. 15.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0.  6. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[129.66609 ]
 [118.58365 ]
 [120.871025]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  6. 14. 15.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3
 23  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1.0
Learning step: -11.41134262084961
desired expected reward: 194.4627227783203



action possibilites: [-1] 
expected returns: [[117.79519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action 15.0
Learning step: -6.2931599617004395
desired expected reward: 114.57787322998047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[111.174835]
 [112.34128 ]
 [112.53691 ]
 [110.90398 ]
 [112.551994]
 [114.25013 ]
 [112.78923 ]
 [115.52243 ]
 [115.0104  ]
 [112.49402 ]
 [113.49031 ]
 [112.99355 ]
 [112.256775]
 [113.73811 ]
 [118.54856 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  1.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1
Learning step: -6.227956295013428
desired expected reward: 111.56723022460938



buy possibilites: [-1] 
expected returns: [[89.313065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 14.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [16.  0. 29.  0.  0.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3.] 
adversary owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.  20.   0.   0.   0.   0.  -4.   0.   0.
   2.   0.] 
sum of rewards: -60.0 

action type: buy - action 8.0
Learning step: -6.629918098449707
desired expected reward: 106.15931701660156






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [16.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 29.  0.  0.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0
 14  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3
  1 14 29  1] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 4 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  8.  5.  8.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0. 23.  6.  3.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 23.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[93.93344]
 [87.86449]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 23.  6.  3.  6.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 23.  3. 14.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: buy - action -1
Learning step: -6.314035415649414
desired expected reward: 82.99903106689453



action possibilites: [-1.] 
expected returns: [[91.89688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 23.  3. 14.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -57 

action type: take_action - action 23.0
Learning step: -5.175544261932373
desired expected reward: 82.68893432617188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[77.73697 ]
 [79.18081 ]
 [79.43213 ]
 [81.71236 ]
 [79.997696]
 [88.1997  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8] -> size -> 39 
action values: 0 
buys: 2 
player value: 3 
card supply: [11. 20. 30. 24. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 23.  3. 14.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -5.6562981605529785
desired expected reward: 86.24058532714844



buy possibilites: [ 0. -1.] 
expected returns: [[80.03056 ]
 [95.140366]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 23.  3. 14.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0  -5   0   0   4   0] 
sum of rewards: -48 

action type: buy - action 3.0
Learning step: -4.35004186630249
desired expected reward: 75.08209991455078



buy possibilites: [-1] 
expected returns: [[27.131678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 0.  1. 23.  3. 14.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.  20. -30.   0.   0.   0.  -6.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -7.5410661697387695
desired expected reward: 72.48949432373047






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 23.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 23.  3. 14.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 8.  6.  3. 11.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14.  3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
action values: 1 
buys: 1 
player value: 1 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [ 8.  6.  3. 11.  8.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [8. 6. 8.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23] -> size -> 52 
action values: 0 
buys: 2 
player value: 6 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  2.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [8. 6. 8.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 


buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [23. 14.] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [8. 6. 8.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[51.09685]
 [47.35624]
 [47.35624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 8.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [29.  0.  0.  0. 22.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: discard_down_to_3_cards - action 9
Learning step: -3.709157705307007
desired expected reward: 25.450435638427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[45.959908]
 [50.760536]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [29.  0.  0.  0. 22.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.811683177947998
desired expected reward: 46.285179138183594



buy possibilites: [-1] 
expected returns: [[57.916023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 8.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [29.  0.  0.  0. 22.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: -104 

action type: buy - action 0.0
Learning step: -6.19488525390625
desired expected reward: 39.76502990722656






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [29.  0.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  0. 22.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [16. 29. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 22.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 20. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [16. 29. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  0. 22.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [16. 29. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
adversary victory points: -2
player victory points: 4 





Player: 0 
cards in hand: [16. 29. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.  8.] 
expected returns: [[28.087143]
 [26.099798]
 [26.770075]
 [26.21484 ]
 [26.164368]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 10.  8.  0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -5.642797946929932
desired expected reward: 52.273223876953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.72134 ]
 [28.087145]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 10.  8.  0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -4.146520137786865
desired expected reward: 23.94062042236328



buy possibilites: [-1] 
expected returns: [[57.756256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 10.  8.  0.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -60.   0.   0.   0. -30.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: -105.0 

action type: buy - action 0.0
Learning step: -5.236551284790039
desired expected reward: 20.484783172607422






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 1. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [11.  0. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.  0. 16. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 1. 3.] 
cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 19. 30. 23. 30.  8.  0.  7.  1.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [11.  0. 10.  0.  6.] 
adversary cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.  0. 16. 29. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0  0] -> size -> 43 
adversary victory points: -2
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 1 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 3 
Chapel: 6 
Witch: 1 
Poacher: 1 
Militia: 0 
Market: 0 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [11.  0. 10.  0.  6.] 
cards in discard: [ 0.  0.  6.  0.  8.  6.  0.  3. 29.  3.  0.  8. 15.  1.  6. 14.  3.  0.
 23.  0.  6.  3.  6.  0.  3. 11.  0.  8.  6.  8.  0. 16. 29. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29 10  0  6  0 10  0  0  8 16 11  8 11  1 15  3 23
  8  6  6  8  0 14  6 10  8  6  0 29  6  6  8  3  0  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 23. 30.  8.  0.  7.  0.  0.  9.  5.  6.  7.  5.  8.  7.] 
adversary cards in hand: [0. 1. 6. 1. 3.] 
adversary cards in discard: [14.  0.  0.  6.  1. 10. 29. 14.  8.  1.  3. 11.  1. 10.  0.  0.  0.  1.
  3. 16.  0. 23. 29. 15.  0. 11. 23. 14.  0.  1.  3.  3.  1. 29.  0.  0.
  0. 22. 11.] 
adversary owned cards: [ 0  0  3  1  3  0  0 11 11 29  3  0  0  3  6 23 10  0  8  1 15  3  0 14
  1  8  0  0 22 29  0 11  1 10  6 11  1  0  0  1 16  0 14  0 11  8  3  1
 14 29  1 23 11  1 11] -> size -> 55 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -567 

action type: buy - action -1
Learning step: -31.237812042236328
desired expected reward: 26.518444061279297



