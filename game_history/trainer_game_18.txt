 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.661526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   0   0   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: buy - action -1
Learning step: 14.073294639587402
desired expected reward: 39.96346664428711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.198915]
 [23.027306]
 [22.544308]
 [21.071005]
 [24.18648 ]
 [23.841084]
 [23.358086]
 [23.883507]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6268461346626282
desired expected reward: 23.404951095581055



buy possibilites: [-1] 
expected returns: [[23.692526]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 3.0
Learning step: -0.5175577998161316
desired expected reward: 22.026752471923828






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [3. 3. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.158747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5943824052810669
desired expected reward: 23.098142623901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.202501]
 [25.030897]
 [24.547895]
 [23.074593]
 [24.597345]
 [26.190065]
 [25.84467 ]
 [26.417803]
 [24.711575]
 [25.361677]
 [25.539968]
 [25.8871  ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [3. 3. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6446622610092163
desired expected reward: 24.72613525390625



buy possibilites: [-1] 
expected returns: [[24.684963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.5166581869125366
desired expected reward: 24.84501838684082






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 1.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.066505]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6037997007369995
desired expected reward: 24.08116340637207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[25.696617]
 [26.525005]
 [26.042011]
 [24.5687  ]
 [26.091455]
 [27.684177]
 [27.338783]
 [27.911917]
 [26.205687]
 [26.855785]
 [27.034075]
 [27.381208]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6871336102485657
desired expected reward: 26.622312545776367



buy possibilites: [-1] 
expected returns: [[28.72941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [14.  0.  0.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.519014835357666
desired expected reward: 26.336772918701172






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 0. 29.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [14.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [14.  0.  0.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.] 
cards in discard: [14.  0.  0.  0.  3.  1.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3.  0.] 
adversary cards in discard: [10.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.481401]
 [25.95598 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  0.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.734663188457489
desired expected reward: 27.994747161865234



action possibilites: [-1.] 
expected returns: [[27.958437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.03903339430689812
desired expected reward: 26.04753303527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.31767 ]
 [26.663063]
 [25.189758]
 [27.959839]
 [28.002264]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10460557788610458
desired expected reward: 27.853832244873047



buy possibilites: [-1] 
expected returns: [[27.094198]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [10.  0.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: -0.05504098907113075
desired expected reward: 26.262630462646484






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.594862]
 [24.069439]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7045601010322571
desired expected reward: 26.389638900756836



action possibilites: [-1.] 
expected returns: [[27.057936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.005663680844008923
desired expected reward: 24.287151336669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.251675]
 [26.080065]
 [25.597067]
 [24.12376 ]
 [27.239235]
 [26.893843]
 [26.410845]
 [26.936268]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.08557628095149994
desired expected reward: 26.97235870361328



buy possibilites: [-1] 
expected returns: [[26.169788]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: 0.021351413801312447
desired expected reward: 25.618417739868164






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [10.  0.  1.  3.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [ 3. 10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[25.504303]
 [25.001562]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6684318780899048
desired expected reward: 25.50135612487793





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.33867 ]
 [25.157135]
 [24.677141]
 [23.223146]
 [26.301273]
 [25.962805]
 [25.482807]
 [25.985552]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6515059471130371
desired expected reward: 24.945945739746094



buy possibilites: [-1] 
expected returns: [[23.550753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [ 3. 10.  3.  0.  3.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 14. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.1174311414361
desired expected reward: 25.039703369140625






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 8. 14. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  0.  0.] 
cards in discard: [14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.611927]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.6541668176651001
desired expected reward: 25.16081428527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.521673]
 [25.340134]
 [24.860142]
 [23.406149]
 [26.484272]
 [26.145805]
 [25.66581 ]
 [26.168552]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 28. 30.  8. 10. 10. 10.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6538968682289124
desired expected reward: 25.087305068969727



buy possibilites: [-1] 
expected returns: [[26.4388]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 1. 0. 0. 1.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.12692080438137054
desired expected reward: 26.35735321044922






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [14. 14.  8. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [14. 14.  8. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 1.] 
cards in discard: [14. 14.  8. 29.  0.  0.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.295013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6663147807121277
desired expected reward: 25.772485733032227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.768076]
 [25.106546]
 [23.652552]
 [26.39221 ]
 [26.41496 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.673284649848938
desired expected reward: 25.693307876586914



buy possibilites: [-1] 
expected returns: [[28.232065]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0.  3.  3.  0.] 
adversary cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.36675968766212463
desired expected reward: 24.73978614807129






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [10.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  3.  0.] 
cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [14. 14.  8. 29.  0.  0.  1.  3.  1.  0.  0.  1. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 10.  0.  0.] 
adversary cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [ 1.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.484625]
 [27.981884]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.  0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.699361264705658
desired expected reward: 27.532703399658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.224691]
 [28.043158]
 [27.56316 ]
 [26.109167]
 [27.61263 ]
 [29.187294]
 [28.84883 ]
 [29.408745]
 [27.722342]
 [28.368834]
 [28.540812]
 [28.871574]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  9.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7083112001419067
desired expected reward: 27.835704803466797



buy possibilites: [-1] 
expected returns: [[29.98348]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  0.] 
cards in discard: [ 3.  0. 11.  0.  0.  0.  3.  3.  0.  0.  3.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0.24256427586078644
desired expected reward: 29.65130615234375






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 14.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
adversary victory points: 6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  8. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
adversary victory points: 6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.] 
adversary cards in discard: [3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
adversary victory points: 6
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.909153]
 [28.40641 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [3. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 5
Learning step: -0.6218599081039429
desired expected reward: 25.186426162719727



action possibilites: [-1. 11.] 
expected returns: [[29.554605]
 [29.886805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.08514329791069031
desired expected reward: 28.412134170532227





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.990866]
 [28.319647]
 [26.893675]
 [29.588293]
 [29.584879]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [3. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1353088766336441
desired expected reward: 29.41929817199707



buy possibilites: [-1] 
expected returns: [[28.801401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.] 
cards in discard: [3. 3. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  8.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.054394721984863
desired expected reward: 17.839279174804688






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [10.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  8.] 
cards in discard: [14. 14.  0.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 14  8 10  1 14  1 10 14] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [14. 14.  0.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [14. 14.  0.  0. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  0.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[27.930395]
 [27.45926 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 29.  1.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7219083905220032
desired expected reward: 28.079492568969727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.557482]
 [27.36081 ]
 [26.886263]
 [25.47085 ]
 [28.483692]
 [28.15491 ]
 [27.680367]
 [28.151497]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  9. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 29.  1.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7008222341537476
desired expected reward: 27.30988311767578



buy possibilites: [-1] 
expected returns: [[25.536745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.  0.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  1.  0. 29.  1.] 
adversary cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.6665114164352417
desired expected reward: 27.4883975982666






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1.  1.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 29.  1.] 
cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 1. 3.] 
cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 3.] 
cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14] -> size -> 18 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 3.] 
cards in discard: [14. 14.  0.  0. 14.  0.  8. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 8 
card supply: [28. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 1.] 
adversary cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.159103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6095333695411682
desired expected reward: 24.92721176147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.76024 ]
 [28.56357 ]
 [28.089022]
 [26.663048]
 [28.13862 ]
 [29.686451]
 [29.357666]
 [29.898977]
 [28.242718]
 [28.883121]
 [29.046047]
 [29.354254]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  9. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7225449085235596
desired expected reward: 28.47450065612793



buy possibilites: [-1] 
expected returns: [[26.191214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 1.] 
cards in discard: [ 3.  3.  6. 10.  0.  0. 11.  8.  3.  0. 10.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 14.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.674883842468262
desired expected reward: 16.98816680908203






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [ 1. 14.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8. 10.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [25.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  3.] 
adversary cards in discard: [29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.142096]
 [24.474295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.] 
cards in discard: [29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -600
   30    0] 
sum of rewards: -575 

action type: discard_down_to_3_cards - action 3
Learning step: -17.62294578552246
desired expected reward: 3.363269805908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.748468]
 [21.651278]
 [24.342484]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6] -> size -> 22 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  8. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6336819529533386
desired expected reward: 23.608964920043945



buy possibilites: [-1] 
expected returns: [[26.100554]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.] 
cards in discard: [29.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.525482177734375
desired expected reward: 12.125795364379883






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [25. 14.  1.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 1. 0. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 14.  1.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 14.  1.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  8.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  6. 10. 10.] 
adversary cards in hand: [8. 1. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[24.283216]
 [24.286627]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -900
   30    0] 
sum of rewards: -875 

action type: discard_down_to_3_cards - action 5
Learning step: -26.784635543823242
desired expected reward: -0.4422607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.226645]
 [24.029974]
 [23.555428]
 [22.129456]
 [25.152855]
 [24.82407 ]
 [24.349527]
 [24.820662]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.625805139541626
desired expected reward: 23.718170166015625



buy possibilites: [-1] 
expected returns: [[22.790161]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0.  1.  8.] 
adversary cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.0820792019367218
desired expected reward: 24.26744842529297






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [10.  3.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.  8.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1.  8. 14.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [25. 14.  1.  0.  3.  3. 29. 14.  0.  0.  0.  0. 22.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.978634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -900
   39    0] 
sum of rewards: -866 

action type: discard_down_to_3_cards - action 1
Learning step: -26.502464294433594
desired expected reward: -1.3937129974365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[20.59874 ]
 [19.583862]
 [22.060055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 1.  0. 29.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5888163447380066
desired expected reward: 21.39191436767578



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 1.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29.  0.  1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  6.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  6.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22] -> size -> 22 
action values: 0 
buys: 1 
player value: 9 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  9.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  6.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 1.] 
cards in discard: [25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [10.  6.  0.  0.  6.] 
adversary cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [10.  6.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.372364]
 [19.949614]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  0.  6.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 14.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5996672511100769
desired expected reward: 21.460384368896484



action possibilites: [-1. 10.] 
expected returns: [[21.451809]
 [21.029058]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  6. 10.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 14.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.07498008757829666
desired expected reward: 20.02459144592285



action possibilites: [-1.] 
expected returns: [[18.72688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 3 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 14.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.6157605648040771
desired expected reward: 21.644817352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.166685]
 [17.903856]
 [17.464012]
 [16.169237]
 [18.942415]
 [18.640614]
 [18.200771]
 [18.623522]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  9.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 14.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6782393455505371
desired expected reward: 19.405118942260742



buy possibilites: [-1] 
expected returns: [[19.158587]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 6. 0.] 
cards in discard: [29.  0.  6.  3. 11.  3.  3.  0. 10.  8.  1.  0.  0.  3.  3.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  8.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 14.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 1.2228926420211792
desired expected reward: 20.16530990600586






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 14.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  8.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  8.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  8.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [3. 0. 6.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.298058]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14. 25.  0. 22.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -900
   48    0] 
sum of rewards: -857 

action type: discard_down_to_3_cards - action 1
Learning step: -26.17234230041504
desired expected reward: -1.188638687133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.838835]
 [24.787518]
 [27.352642]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [11.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0. 14. 25.  0. 22.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6947004199028015
desired expected reward: 26.654706954956055



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 0. 14. 25.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 25. 22.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 25.  0. 22.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [10.  3. 11.  8.  0.] 
adversary cards in discard: [11.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 22.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 22.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.858467]
 [23.188793]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 14. 29.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -900
   39    0] 
sum of rewards: -866 

action type: discard_down_to_3_cards - action 2
Learning step: -26.460905075073242
desired expected reward: -2.357290267944336



action possibilites: [-1] 
expected returns: [[25.491943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 14. 29.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.2780803143978119
desired expected reward: 23.93091583251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.181526]
 [23.166649]
 [25.64284 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 10. 14. 29.] 
adversary cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05653347074985504
desired expected reward: 25.435409545898438






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 14. 29.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14. 29.  0.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 29.  0.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  8.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14. 29.  0.] 
cards in discard: [25. 29.  1.  0.  0.  1.  1. 11. 14.  3.  8.  0.  3. 14.  0. 25.  0. 22.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 3. 0. 0. 1.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.58124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 14.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6423053741455078
desired expected reward: 24.371307373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.309345]
 [24.032932]
 [23.606394]
 [22.319983]
 [23.651   ]
 [25.053057]
 [24.75601 ]
 [25.241491]
 [23.74971 ]
 [24.329473]
 [24.473297]
 [24.748425]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  7. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 14.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6319402456283569
desired expected reward: 23.949298858642578



buy possibilites: [-1] 
expected returns: [[25.141138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 14.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.55561637878418
desired expected reward: 12.764366149902344






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  7.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 14.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.246454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3.  0. 22. 14.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -1200    48     0] 
sum of rewards: -1157 

action type: discard_down_to_3_cards - action 5
Learning step: -35.26272201538086
desired expected reward: -10.102420806884766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.787268]
 [18.087317]
 [16.785816]
 [19.248554]
 [19.240894]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  6. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3.  0. 22. 14.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5338399410247803
desired expected reward: 18.712614059448242



buy possibilites: [-1] 
expected returns: [[19.152483]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3.  0. 22. 14.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.452473640441895
desired expected reward: 7.333342552185059






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 22. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 22. 14.  0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [29.  3.  6. 10.  6.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 22. 14.  0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [29.  3.  6. 10.  6.] 
adversary cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  3.  6. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[14.328309]
 [14.813323]
 [13.917502]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  6. 10.  6.] 
cards in discard: [11.  0.  3.  0.  6. 10.  8. 10. 11.  3.  0.  6.  3.  3.  0.  0.  1. 10.
  0.  6.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  3. 11.  1.  8.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5729009509086609
desired expected reward: 18.57958221435547



action possibilites: [-1. 10.] 
expected returns: [[28.019112]
 [27.580671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  3. 11.  1.  8.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0.29795950651168823
desired expected reward: 15.111283302307129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.720142]
 [27.030993]
 [25.682655]
 [28.234022]
 [28.226105]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  3. 11.  1.  8.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.10298005491495132
desired expected reward: 27.91613006591797



buy possibilites: [-1] 
expected returns: [[26.902878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  6.  0.] 
cards in discard: [3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1.  3. 11.  1.  8.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 3.0
Learning step: 0.16155052185058594
desired expected reward: 27.192541122436523






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 1.  3. 11.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 11.  1.  8.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  5. 10.  7.  6.  8.  7.  7. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  5. 10.  7.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 26. 30. 26. 30.  8.  5. 10.  7.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 8.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  7.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.597492]
 [20.17854 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  7.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7425722479820251
desired expected reward: 26.16030502319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.34751 ]
 [20.068676]
 [19.642138]
 [18.36497 ]
 [21.088806]
 [20.791756]
 [20.36522 ]
 [20.784174]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  7.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5551623702049255
desired expected reward: 20.04233169555664



buy possibilites: [-1] 
expected returns: [[20.835548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 1. 10.  0.  3.  0.] 
adversary cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.02389085665345192
desired expected reward: 21.064912796020508






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 1. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3.  0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  8.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 29.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  8.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
action values: 2 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  8.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  8.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0. 0.] 
cards in discard: [ 8. 14.  0.  8.  0. 14.  3.  0. 22. 14.  0. 29.  1. 11.  1.  3.  1.  8.
 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  8.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3. 11.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[14.789922]
 [15.086514]
 [14.797313]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  8.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5. 10.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 22. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6182982921600342
desired expected reward: 20.21725082397461



action possibilites: [-1] 
expected returns: [[22.704336]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 22. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.8052734732627869
desired expected reward: 12.909342765808105





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.359259]
 [20.405045]
 [22.764631]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 8.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 22. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.0026433563325554132
desired expected reward: 22.701692581176758






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 1. 22. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29. 25. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  6. 11. 10.  3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  6. 11. 10.  3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 22. 29. 25. 25.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  6. 11. 10.  3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  6. 11. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[14.899973 ]
 [15.1778145]
 [14.50826  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11. 10.  3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 23.  0.  3.  0.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6762245893478394
desired expected reward: 22.088407516479492



action possibilites: [-1. 11.] 
expected returns: [[14.961023]
 [15.239594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 11.  3.  3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 23.  0.  3.  0.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.17359791696071625
desired expected reward: 14.68185806274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.64555 ]
 [12.724202]
 [14.998931]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  3.  3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16] -> size -> 31 
action values: 2 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 23.  0.  3.  0.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.14849938452243805
desired expected reward: 15.109522819519043



buy possibilites: [-1] 
expected returns: [[14.684979]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 11.  3.  3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 1. 23.  0.  3.  0.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.777533531188965
desired expected reward: 3.946669578552246






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 1. 23.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  0.  3.  0.] 
cards in discard: [ 0.  1. 22. 29. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  3.  0.] 
cards in discard: [ 0.  1. 22. 29. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 26. 30.  8.  4.  9.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  3.  0.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.41962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  8. 29. 14.  3.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4286433756351471
desired expected reward: 14.256336212158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.99047 ]
 [14.669783]
 [14.27244 ]
 [13.455866]
 [13.074778]
 [14.312548]
 [15.634111]
 [15.35214 ]
 [16.360146]
 [15.81147 ]
 [14.411189]
 [14.050907]
 [14.954799]
 [13.381922]
 [15.090502]
 [15.353533]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  7.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  8. 29. 14.  3.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4552895724773407
desired expected reward: 14.964329719543457



buy possibilites: [-1] 
expected returns: [[15.952455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [ 3. 29.  3.  6. 10.  6.  0. 11. 10.  0.  6.  0.  0. 16. 11.  3.  6.  0.
  8.  6. 10.  3.  6. 11.  3.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 3.  8. 29. 14.  3.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 3.0 

action type: buy - action 14.0
Learning step: -0.17483490705490112
desired expected reward: 14.236353874206543






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  8. 29. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 29. 14.  3.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29. 14.  3.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 29. 14.  3.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 0.  6.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.584467]
 [24.166082]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [14. 29.  0.  0. 11.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.37219393253326416
desired expected reward: 15.580260276794434



action possibilites: [-1. 10.] 
expected returns: [[27.768337]
 [27.334818]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [14. 29.  0.  0. 11.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.01476430892944336
desired expected reward: 24.18084716796875



action possibilites: [-1.] 
expected returns: [[25.93434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 3 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [14. 29.  0.  0. 11.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.502265989780426
desired expected reward: 27.83708381652832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.357431]
 [24.663994]
 [23.360514]
 [25.837849]
 [25.839386]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 0. 6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [14. 29.  0.  0. 11.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5346519947052002
desired expected reward: 26.468992233276367






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [14. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 11.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29.  0.  0. 11.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [10. 16.  0.  6. 11.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 11.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [10. 16.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  6.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [10. 16.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 11.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [10. 16.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [10. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[19.92649 ]
 [19.511797]
 [18.843874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 14.  0. 10.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -1800    61     0] 
sum of rewards: -1744 

action type: discard_down_to_3_cards - action 9
Learning step: -52.70835876464844
desired expected reward: -32.92857360839844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.524046]
 [17.555271]
 [19.941635]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  4.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 14.  0. 10.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5490586161613464
desired expected reward: 19.377431869506836



buy possibilites: [-1] 
expected returns: [[18.084635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 1.  1. 14.  0. 10.] 
adversary cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action 6.0
Learning step: -9.478583335876465
desired expected reward: 7.8038225173950195






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 1.  1. 14.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 14.  0. 10.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 8. 11.  0. 10.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0. 10.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 10.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9. 10.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  0. 10.] 
cards in discard: [ 0.  1. 22. 29. 25. 25. 16.  1. 23.  0.  3.  0.  0.  3.  8. 29. 14.  3.
 11. 14. 29.  0.  0. 11. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[16.912653]
 [16.901434]
 [17.19361 ]
 [16.49888 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1 11  3 29  6  8  6  6 10
 11 10  6  6  3 11 16  6 14  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [1. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0     0
     0 -2100    52     0] 
sum of rewards: -2053 

action type: discard_down_to_3_cards - action 6
Learning step: -61.95610809326172
desired expected reward: -43.82345199584961



action possibilites: [-1] 
expected returns: [[20.044584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [1. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.1974063664674759
desired expected reward: 15.632798194885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.598566]
 [17.644411]
 [20.00701 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [1. 0. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.04817716404795647
desired expected reward: 20.092761993408203






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [1. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  6.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 8. 8.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  5.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 1. 3. 0. 3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.207792]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  5.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [16. 29. 14.  0. 25.] 
adversary cards in discard: [8. 1. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5905284285545349
desired expected reward: 19.416481018066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.006491]
 [14.708355]
 [14.301667]
 [13.052956]
 [14.340622]
 [15.711238]
 [15.416061]
 [15.891841]
 [14.449159]
 [15.009375]
 [15.151023]
 [15.427395]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  5.  8.  6.  6.  9.  4.  9.  9.] 
adversary cards in hand: [16. 29. 14.  0. 25.] 
adversary cards in discard: [8. 1. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4486345946788788
desired expected reward: 14.75915813446045



buy possibilites: [-1] 
expected returns: [[15.268739]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [16. 29. 14.  0. 25.] 
adversary cards in discard: [8. 1. 0. 0. 8. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 15.0
Learning step: 0.5157910585403442
desired expected reward: 15.666813850402832






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [16. 29. 14.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 14. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 14.  0. 25.] 
cards in discard: [8. 1. 0. 0. 8. 8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  3.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15] -> size -> 34 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29. 14.  0.  1. 15.] 
cards in discard: [8. 1. 0. 0. 8. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  2.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6] -> size -> 35 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 29. 14.  0.  1. 15.] 
cards in discard: [8. 1. 0. 0. 8. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  2.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  3. 14.  0.  3.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6] -> size -> 35 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3. 14.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[14.222024]
 [13.290527]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.  0.  3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  2.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 23.  0.  1.  3.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -305 

action type: buy - action -1
Learning step: -9.46264362335205
desired expected reward: 5.806095123291016



action possibilites: [-1] 
expected returns: [[17.709175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  2.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [23.  0.  3.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 0.23723052442073822
desired expected reward: 13.52775764465332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[16.359161]
 [17.07484 ]
 [16.654337]
 [15.395433]
 [18.114368]
 [17.808386]
 [17.386847]
 [17.820148]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  2.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [23.  0.  3.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10020910203456879
desired expected reward: 17.809383392333984



buy possibilites: [-1] 
expected returns: [[16.653315]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  1.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [23.  0.  3.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.   -1.
    0. -300.    0.    0.] 
sum of rewards: -286.0 

action type: buy - action 6.0
Learning step: -8.867003440856934
desired expected reward: 6.528430938720703






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  1.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 29.  6.  3.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6. 14.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  1.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 29.  6.  3.  6.] 
adversary cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6. 14.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6] -> size -> 36 
adversary victory points: -2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[12.582632]
 [13.042992]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  6.  3.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6. 14.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  1.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [11. 29. 29. 14.  0.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5145815014839172
desired expected reward: 16.13873291015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.148434 ]
 [10.2203045]
 [12.541464 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  3.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6. 14.  3.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  1.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [11. 29. 29. 14.  0.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4061933159828186
desired expected reward: 12.176438331604004



buy possibilites: [-1] 
expected returns: [[12.766189]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  6.  3.  6.] 
cards in discard: [10. 10.  0.  6.  3.  0.  6.  0. 11.  6. 10. 16.  6.  0.  6.  8. 10. 15.
  0.  1.  3.  0.  3.  6.  6. 14.  3.  3.  0.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [11. 29. 29. 14.  0.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: -9.371395111083984
desired expected reward: 0.8489093780517578






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11. 29. 29. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 14.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 6.  0. 10. 15. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [ 6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [ 6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 0. 10. 15.] 
adversary cards in discard: [ 6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 0. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[20.514647]
 [20.107927]
 [20.24619 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15.] 
cards in discard: [ 6. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  8.  0. 22.  1.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[   -5     0     0     0     0     0     0     0     0     0     0    -2
     0 -3000    43     0] 
sum of rewards: -2964 

action type: discard_down_to_3_cards - action 5
Learning step: -89.20641326904297
desired expected reward: -72.54208374023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.162443]
 [20.547089]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.] 
cards in discard: [ 6. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  8.  0. 22.  1.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5555105209350586
desired expected reward: 19.959136962890625



buy possibilites: [-1] 
expected returns: [[21.728746]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15.] 
cards in discard: [ 6. 11.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  8.  0. 22.  1.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -3.  0.  0.  0.  0.] 
sum of rewards: -8.0 

action type: buy - action 0.0
Learning step: -0.5867214798927307
desired expected reward: 18.575721740722656






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  0. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 22.  1.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 22.  1.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [6. 0. 6. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [6. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.63457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [11. 14.  0.  3.  0.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.  3.  8.  0. 22.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6061994433403015
desired expected reward: 21.122547149658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.253288]
 [17.539972]
 [18.612104]
 [18.62707 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0. 6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [11. 14.  0.  3.  0.] 
adversary cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.  3.  8.  0. 22.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5186521410942078
desired expected reward: 18.115917205810547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [11. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  3.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.  3.  8.  0. 22.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.  3.  8.  0. 22.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  0.] 
cards in discard: [ 8.  1.  0.  0.  8.  8. 25. 16. 29. 14.  0.  1. 15.  0.  1. 23.  0.  3.
  1. 14. 11. 29. 29.  0.  3.  8.  0. 22.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 1.  0.  3. 10.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 1.  0.  3. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[16.020449]
 [15.609802]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  1.  1. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5423220992088318
desired expected reward: 18.084747314453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[14.766026]
 [15.43392 ]
 [15.04712 ]
 [16.421234]
 [16.129517]
 [15.734119]
 [16.144768]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  1.  1. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.464516818523407
desired expected reward: 15.55593204498291



buy possibilites: [-1] 
expected returns: [[13.675306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3.  1.  1. 25. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: -9.0 

action type: buy - action 0.0
Learning step: -0.5693899989128113
desired expected reward: 14.196635246276855






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 3.  1.  1. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 25. 10.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  3.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 25.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  3.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 25.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  3.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 25.  1.] 
cards in discard: [15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 3. 29.  0.  3.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 3. 29.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[10.941828]
 [11.373337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [14. 15.  0.  1. 22.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15] -> size -> 38 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4426514804363251
desired expected reward: 13.232654571533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.606226]
 [10.941089]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  3.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [14. 15.  0.  1. 22.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15] -> size -> 38 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.368979811668396
desired expected reward: 10.572848320007324



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [14. 15.  0.  1. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  0.  1. 22.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 16. 14. 10.  3.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15.  0.  1. 22.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 16. 14. 10.  3.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 15.  0.  1. 22.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6. 16. 14. 10.  3.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
adversary victory points: -3
player victory points: 4 





Player: 0 
cards in hand: [ 6. 16. 14. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14. 10.] 
expected returns: [[13.17115  ]
 [12.128971 ]
 [12.2382145]
 [12.771331 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16. 14. 10.  3.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11
 10  6  6  3 11 16  6 14  6 15  6  6  6  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  8.  5.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15  1] -> size -> 39 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3449229300022125
desired expected reward: 10.596165657043457



action possibilites: [-1] 
expected returns: [[11.561974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 10.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15  1] -> size -> 39 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0  9  0] 
sum of rewards: 20 

action type: gain_card_n - action 4
Learning step: 0.42090198397636414
desired expected reward: 10.437527656555176





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.368202]
 [11.716544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14. 10.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  8. 16.  3. 14.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15  1] -> size -> 39 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22050149738788605
desired expected reward: 11.782475471496582






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 16.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.  3. 14.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  8  1 14  1 10 14  0 25 29 22 25 11
  8  8 29  1 23  0 16  0 11 15  8  1  3 15  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [3. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.331532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [25.  0.  0.  0.  1.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.30953577160835266
desired expected reward: 10.724359512329102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[14.944146 ]
 [15.2268715]
 [16.273817 ]
 [16.294632 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [25.  0.  0.  0.  1.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4739743173122406
desired expected reward: 15.85755729675293



buy possibilites: [-1] 
expected returns: [[15.400288]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [25.  0.  0.  0.  1.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. -5.  0.  0.  0.  0.] 
sum of rewards: -10.0 

action type: buy - action 0.0
Learning step: -0.5866214036941528
desired expected reward: 14.357525825500488






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.  1.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6.  8. 10. 11.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0] -> size -> 40 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  1.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  8.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6.  8. 10. 11.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0] -> size -> 40 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0.  0.  1.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 6.  8. 10. 11.  6.] 
adversary cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0] -> size -> 40 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [ 6.  8. 10. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
expected returns: [[12.82173 ]
 [12.801128]
 [12.427881]
 [13.08094 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10. 11.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  7.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.47716212272644043
desired expected reward: 14.923125267028809



action possibilites: [-1] 
expected returns: [[10.494747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -6  0  0 16  0] 
sum of rewards: 25 

action type: gain_card_n - action 9
Learning step: 0.45656922459602356
desired expected reward: 13.91075611114502





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.182543]
 [10.494747]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23984114825725555
desired expected reward: 10.734588623046875



buy possibilites: [-1] 
expected returns: [[10.630384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 10.  6.] 
cards in discard: [ 6. 11.  0.  0. 10. 15.  6.  0.  6.  0.  6.  0.  1.  0.  3. 10.  6.  3.
 29.  0.  3.  6. 11. 16.  6. 14. 10.  0.  3.  0.  3.  0.  6. 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  6.] 
adversary cards in hand: [ 0.  3. 11. 11.  0.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -7  0  0  0  0] 
sum of rewards: 8 

action type: buy - action 0.0
Learning step: 0.07614275068044662
desired expected reward: 9.258685111999512






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11. 11.  0.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  6.  9.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  5.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  4.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
adversary victory points: -4
player victory points: 4 





Player: 0 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[16.71598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  4.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 29.  8. 23. 29.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.29339373111724854
desired expected reward: 10.336990356445312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[15.50289 ]
 [15.790812]
 [16.865639]
 [16.887642]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  4.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 29.  8. 23. 29.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.47941669821739197
desired expected reward: 16.23656463623047



buy possibilites: [-1] 
expected returns: [[15.105309]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [ 8. 29.  8. 23. 29.] 
adversary cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -8  0  0  8  0] 
sum of rewards: -5 

action type: buy - action 8.0
Learning step: -0.497363418340683
desired expected reward: 16.368274688720703






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 8. 29.  8. 23. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 23. 29.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 23. 29.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1.  8. 29.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8. 29.  0.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
action values: 1 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1.  8.  8. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  8.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
action values: 1 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  8.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8] -> size -> 43 
action values: 1 
buys: 2 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
adversary victory points: -4
player victory points: 4 


buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 29.  8.] 
cards in discard: [15. 10.  3.  1.  1. 25.  1.  1. 14. 15.  0.  1. 22.  1.  0. 16.  0.  3.
 14. 25. 25.  0.  0.  0.  1. 14.  8. 11.  0.  3. 11.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [23. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [16.  3.  3.  6.  6.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
adversary victory points: -4
player victory points: 5 





Player: 0 
cards in hand: [16.  3.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[15.875729]
 [14.782726]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  3.  6.  6.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10
  6  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  6.] 
adversary cards in hand: [ 0.  3. 14.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.44105470180511475
desired expected reward: 14.664254188537598



action possibilites: [-1] 
expected returns: [[13.678688]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  3. 14.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -8  0  0 16  0] 
sum of rewards: 23 

action type: gain_card_n - action 9
Learning step: 0.25868281722068787
desired expected reward: 19.4234619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.286665]
 [13.705553]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15.] 
cards in deck: 32 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0.  3. 14.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1775883287191391
desired expected reward: 13.856276512145996






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  0. 29.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6. 11.  6. 10.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0. 29.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6. 11.  6. 10.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 14.  0. 29.] 
cards in discard: [0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6. 11.  6. 10.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 6. 11.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[11.269001]
 [11.517342]
 [10.882181]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6. 10.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [25. 11.  0.  1. 25.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.43504682183265686
desired expected reward: 13.01512336730957



action possibilites: [-1] 
expected returns: [[14.352026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [25. 11.  0.  1. 25.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -9  0  0  0  0] 
sum of rewards: 6 

action type: gain_card_n - action 0
Learning step: 0.031804244965314865
desired expected reward: 9.994871139526367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.971605 ]
 [14.3524275]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 10.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [25. 11.  0.  1. 25.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.16434024274349213
desired expected reward: 14.516366004943848






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [25. 11.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0.  1. 25.] 
cards in discard: [ 0.  0.  3. 14.  0. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1. 25.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1. 25.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 24. 30.  8.  0.  8.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1. 25.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10. 11.  0.  0.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [ 0. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[13.450061]
 [13.06002 ]
 [13.700487]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1. 29. 23.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.43921220302581787
desired expected reward: 13.913216590881348



action possibilites: [-1. 11.  8.] 
expected returns: [[12.815031]
 [13.066275]
 [12.78903 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  8.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6
  6  3 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1. 29. 23.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1939155012369156
desired expected reward: 13.253935813903809



action possibilites: [-1. 11.] 
expected returns: [[11.106775]
 [11.349936]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1. 29. 23.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.83896404504776
desired expected reward: 11.811928749084473



action possibilites: [-1] 
expected returns: [[13.64679]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1. 29. 23.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0 -8  0  0  0  0] 
sum of rewards: 47 

action type: gain_card_n - action 0
Learning step: 1.2584493160247803
desired expected reward: 11.086512565612793





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.426336]
 [13.74494 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1. 29. 23.  0.  3.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 1.3793799877166748
desired expected reward: 15.026169776916504






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 1. 29. 23.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 23.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 23.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [15.  6.  6. 14.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [15.  6.  6. 14.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 22. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [15.  6.  6. 14.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  0.  3.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [15.  6.  6. 14.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
adversary victory points: -5
player victory points: 5 





Player: 0 
cards in hand: [15.  6.  6. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[12.773333]
 [12.521375]
 [11.893501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  6. 14.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8. 16. 22.  0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4313972294330597
desired expected reward: 13.313542366027832





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.526859]
 [12.814346]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  6. 14.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8. 16. 22.  0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.40405675768852234
desired expected reward: 12.36927604675293



buy possibilites: [-1] 
expected returns: [[11.038544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  6. 14.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8. 16. 22.  0.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -9  0  0  0  0] 
sum of rewards: -14 

action type: buy - action 0.0
Learning step: -0.6499010324478149
desired expected reward: 10.876957893371582






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 16. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 16. 22.  0.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  1.  0.  8. 25.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 15.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  1.  0.  8. 25.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 15.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 21. 30. 24. 30.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  1.  0.  8. 25.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4.] 
cards in deck: 16 
card top of deck: [] 
played cards: [22. 15.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 21. 30. 24. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 29.  0.  0. 11.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
adversary victory points: -5
player victory points: 8 





Player: 0 
cards in hand: [ 0. 29.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[12.001798]
 [12.411501]
 [12.250191]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 11.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10.  0. 14.  1.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.352434366941452
desired expected reward: 10.68610954284668



action possibilites: [-1] 
expected returns: [[11.426839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10.  0. 14.  1.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -10   0   0   4   0] 
sum of rewards: 9 

action type: gain_card_n - action 2
Learning step: 0.07974440604448318
desired expected reward: 10.420990943908691





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[10.106505]
 [10.748137]
 [10.384267]
 [11.677787]
 [11.400024]
 [11.036155]
 [11.426839]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10.  0. 14.  1.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22385384142398834
desired expected reward: 11.6506929397583



buy possibilites: [-1] 
expected returns: [[11.319138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 0. 10.  0. 14.  1.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0  18   0] 
sum of rewards: 22 

action type: buy - action 1.0
Learning step: 0.456406831741333
desired expected reward: 11.204544067382812






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 14.  1.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  1. 15.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  1. 15.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 20. 30. 23. 29.  8.  0.  7.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  1. 15.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 3.  0. 15.  0.  6.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
adversary victory points: -4
player victory points: 8 





Player: 0 
cards in hand: [ 3.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[17.069838]
 [16.803783]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3
 11 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3114582598209381
desired expected reward: 11.007678985595703



action possibilites: [-1] 
expected returns: [[13.473527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.08735852688550949
desired expected reward: 16.891141891479492





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[12.08712  ]
 [12.748809 ]
 [12.3729725]
 [12.402184 ]
 [13.743394 ]
 [13.444685 ]
 [13.918208 ]
 [12.521643 ]
 [13.053405 ]
 [13.197711 ]
 [13.473526 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1841946840286255
desired expected reward: 13.657721519470215



buy possibilites: [-1] 
expected returns: [[13.530047]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 4 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 1.  8.  0.  8. 29.] 
adversary cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -11.   0.   0.
   0.   0.] 
sum of rewards: 4.0 

action type: buy - action 0.0
Learning step: -0.10054804384708405
desired expected reward: 11.986571311950684






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  8. 29.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6.  0.  6. 10.  1.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8. 14.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6.  0.  6. 10.  1.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 14.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16] -> size -> 49 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  4.  9.  5.] 
adversary cards in hand: [ 6.  0.  6. 10.  1.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  8. 14.] 
cards in discard: [ 0.  0.  3. 14.  0. 29. 16. 25. 11.  0.  1. 25.  0.  3. 14.  1. 29.  1.
 23.  0.  3.  4. 22. 15.  8.  1. 16.  0.  1.  0.  8. 25. 16. 10.  0.  0.
 14.  1. 15.  8. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 6.  0.  6. 10.  1.] 
adversary cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
adversary victory points: -4
player victory points: 8 





Player: 0 
cards in hand: [ 6.  0.  6. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[14.90496 ]
 [14.499711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 10.  1.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.40110138058662415
desired expected reward: 13.128946304321289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[13.535304]
 [14.200896]
 [13.823453]
 [15.165301]
 [14.877152]
 [14.499711]
 [14.904961]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  1.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  4.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.4440935254096985
desired expected reward: 14.46086597442627



buy possibilites: [-1] 
expected returns: [[15.043111]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 10.  1.] 
cards in discard: [ 8.  3.  0.  3.  0.  3. 15. 16.  3.  6.  6.  0. 11.  6.  6. 10.  0.  0.
 10.  8. 11.  0.  0. 15.  6.  6. 14.  6.  3.  1. 11.  0. 29.  0.  0.  0.
 15.  3.  0.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [14.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -12   0   0  18   0] 
sum of rewards: 1 

action type: buy - action 11.0
Learning step: -0.26700639724731445
desired expected reward: 14.898294448852539






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [14.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 6.  0. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  1.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 6.  0. 10.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  0. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[13.44947 ]
 [13.037091]
 [13.037091]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  1. 10.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 1. 15.  1. 14. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4623831808567047
desired expected reward: 14.580727577209473



action possibilites: [-1. 10.] 
expected returns: [[12.852935]
 [12.440557]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 10.  6.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 1. 15.  1. 14. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.1921110451221466
desired expected reward: 13.229203224182129



action possibilites: [-1.] 
expected returns: [[15.641287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 6. 0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 3 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 1. 15.  1. 14. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.8410167694091797
desired expected reward: 13.281573295593262





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.441264]
 [15.131251]
 [14.739974]
 [14.770482]
 [16.131002]
 [15.832295]
 [16.305817]
 [14.895331]
 [15.441013]
 [15.58532 ]
 [15.861136]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 6. 0.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [ 1. 15.  1. 14. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.7441611289978027
desired expected reward: 16.385448455810547






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 1. 15.  1. 14. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1. 14. 25.] 
cards in discard: [14.  1.  3.  3. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [16.  6.  3. 29.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  1. 25.] 
cards in discard: [14.  1.  3.  3. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1. 25.] 
cards in discard: [14.  1.  3.  3. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  5.  9.  3.  9.  5.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  1. 25.] 
cards in discard: [14.  1.  3.  3. 11. 14.] 
cards in deck: 40 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [6. 3. 0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 





Player: 0 
cards in hand: [6. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[14.42522]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [8. 1. 0. 0. 1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14] -> size -> 51 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.496629923582077
desired expected reward: 16.10652732849121





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.168307]
 [14.544434]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [8. 1. 0. 0. 1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14] -> size -> 51 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.43874266743659973
desired expected reward: 14.083907127380371



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14] -> size -> 51 
action values: 0 
buys: 1 
player value: 6 
card supply: [16. 20. 30. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14  2] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0. 11.  8.  3.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
adversary victory points: -4
player victory points: 8 





Player: 0 
cards in hand: [ 0. 11.  8.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[12.596952]
 [12.842093]
 [12.571145]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  6  8  6  6 10 11 10  6  6  3 11
 16  6 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [29.  0. 15.  8. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14  2] -> size -> 52 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4529360830783844
desired expected reward: 14.091497421264648



action possibilites: [-1] 
expected returns: [[15.951367]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [29.  0. 15.  8. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14  2] -> size -> 52 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.30378150939941406
desired expected reward: 10.760709762573242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[14.466826 ]
 [15.8934965]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [29.  0. 15.  8. 25.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14  2] -> size -> 52 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1323486566543579
desired expected reward: 16.083715438842773






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [29.  0. 15.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 15.  8. 25.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 14  1 14  1 10 14  0 25 29 22 25 11  8
  8 29  1 23  0 16  0 11 15  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4
 16 10 14  2] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [10. 15.  6. 15.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [10. 15.  6. 15.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2] -> size -> 48 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [10. 15.  6. 15.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [10. 15.  6. 15.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [10. 15.  6. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 15.] 
expected returns: [[8.533115]
 [8.155501]
 [8.285765]
 [8.285765]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  6. 15.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5390390157699585
desired expected reward: 15.35445785522461



action possibilites: [-1] 
expected returns: [[11.322501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 15.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.32031333446502686
desired expected reward: 8.606077194213867





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.063823]
 [11.350268]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 15.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [ 0.  1. 29.  0.  0.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.22409971058368683
desired expected reward: 11.546601295471191






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 0.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  9.  5.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 29.  0.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  8.  5.] 
adversary cards in hand: [11.  0.  6.  6.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [11.  0.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[9.431189]
 [9.676329]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6.  0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  3.  8.  5.] 
adversary cards in hand: [25.  3.  0.  0. 11.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.389936238527298
desired expected reward: 10.960333824157715



action possibilites: [-1] 
expected returns: [[9.903074]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [25.  3.  0.  0. 11.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -11   0   0   9   0] 
sum of rewards: 13 

action type: gain_card_n - action 8
Learning step: 0.2118208408355713
desired expected reward: 9.617201805114746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[8.616626]
 [8.887574]
 [9.877267]
 [9.903073]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [25.  3.  0.  0. 11.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2520017623901367
desired expected reward: 10.155076026916504



buy possibilites: [-1] 
expected returns: [[10.399636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [25.  3.  0.  0. 11.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -12.   0.   0.
   0.   0.] 
sum of rewards: 3.0 

action type: buy - action 0.0
Learning step: -0.05930262431502342
desired expected reward: 8.557324409484863






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [25.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 11.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
adversary victory points: -3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 14.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 14.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  3.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 14.  0.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [ 0.  0. 11. 10.  6.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
adversary victory points: -3
player victory points: 8 





Player: 0 
cards in hand: [ 0.  0. 11. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[8.28769  ]
 [8.53283  ]
 [7.9081106]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  5.] 
adversary cards in hand: [ 8. 16. 23.  0.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3748299479484558
desired expected reward: 10.024806022644043



action possibilites: [-1] 
expected returns: [[9.071876]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 8. 16. 23.  0.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -13   0   0  16   0] 
sum of rewards: 18 

action type: gain_card_n - action 9
Learning step: 0.3703380823135376
desired expected reward: 9.256938934326172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[7.8026714]
 [8.069973 ]
 [9.051002 ]
 [9.071876 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 29. 23. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 8. 16. 23.  0.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26828524470329285
desired expected reward: 9.340160369873047



buy possibilites: [-1] 
expected returns: [[8.208003]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 8. 16. 23.  0.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -14   0   0   8   0] 
sum of rewards: 9 

action type: buy - action 3.0
Learning step: 0.11408483237028122
desired expected reward: 8.18405818939209






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [ 8. 16. 23.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 23.  0.  1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 23.  0.  1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [3. 3. 6. 0. 8.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[8.295451]
 [8.274577]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [14.  3. 10. 16.  3.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.30922552943229675
desired expected reward: 7.898777484893799





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.0296764]
 [8.295451 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 8.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [14.  3. 10. 16.  3.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.31707754731178284
desired expected reward: 7.9783735275268555



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [14.  3. 10. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10. 16.  3.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [15.  3.  0. 11.  3.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16.  3.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0. 11.  3.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 16.  3.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0. 11.  3.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 16.  3.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0. 11.  3.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
adversary victory points: -2
player victory points: 8 





Player: 0 
cards in hand: [ 0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[11.907668]
 [12.168624]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 22. 29.  8.  0.  6.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 4. 16. 29. 22.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 6
Learning step: -0.3579484522342682
desired expected reward: 10.796151161193848



action possibilites: [-1] 
expected returns: [[10.885558]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 29. 22. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 4. 16. 29. 22.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -15   0   0  16   0] 
sum of rewards: 16 

action type: gain_card_n - action 3
Learning step: 0.2685847282409668
desired expected reward: 11.12570571899414





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.573926]
 [10.885558]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 20. 29. 22. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 4. 16. 29. 22.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23222273588180542
desired expected reward: 11.117780685424805



buy possibilites: [-1] 
expected returns: [[11.071715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 20. 29. 22. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 4. 16. 29. 22.  1.] 
adversary cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[ -5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   0.   0.] 
sum of rewards: -1.0 

action type: buy - action 0.0
Learning step: -0.2009647637605667
desired expected reward: 9.372961044311523






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [ 4. 16. 29. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 16. 29. 22.  1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 22. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 16. 29. 22.  1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 20. 29. 22. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 16. 29. 22.  1.] 
cards in discard: [14.  1.  3.  3. 11. 14. 14.  1. 15.  1. 25.  2.  8.  1.  0.  0.  1.  0.
  8. 22.  0.  1. 29.  0.  0.  8. 25.  3.  0.  0. 11. 14.  0.  8. 16. 23.
  0.  1.  0. 14.  3. 10. 16.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0.  1.  0. 14.  0.] 
adversary cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [ 0.  1.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[8.40171  ]
 [7.5414944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 14.  0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0  3] -> size -> 53 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3975464105606079
desired expected reward: 10.674168586730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[7.1339035]
 [7.750297 ]
 [7.399806 ]
 [6.6497693]
 [7.4265385]
 [8.648136 ]
 [8.380836 ]
 [9.292661 ]
 [8.80381  ]
 [7.541494 ]
 [7.2059712]
 [8.030344 ]
 [6.5939913]
 [8.1592865]
 [8.40171  ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 14.  0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0] -> size -> 51 
action values: 0 
buys: 1 
player value: 5 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  8.  4.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0  3] -> size -> 53 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.31678226590156555
desired expected reward: 8.08492660522461



buy possibilites: [-1] 
expected returns: [[9.0502205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 14.  0.] 
cards in discard: [10. 10.  6.  0.  1.  6.  0. 16. 29.  6.  3.  0.  8.  0.  3. 15. 10.  6.
 15.  6. 10.  0. 11.  0.  6.  6.  0. 15.  3. 11.  0.  0. 10.  6.  3.  3.
  6.  0.  8. 15.  3. 16.  0. 11.  0.  3. 22.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0 22] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 0.  1.  0.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0  3] -> size -> 53 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0 -17   0   0  50   0] 
sum of rewards: 28 

action type: buy - action 22.0
Learning step: 0.7372075319290161
desired expected reward: 7.331198692321777






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0.  8. 10.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 14  1 14  1 10 14  0 29 22 25 11  8  8 29  1
 23  0 16  0 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2
  0 22  8  0  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [16.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0 22] -> size -> 52 
adversary victory points: -2
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [16.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0 22] -> size -> 52 
adversary victory points: -2
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [16.  6.  8.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0 22] -> size -> 52 
adversary victory points: -2
player victory points: 9 





Player: 0 
cards in hand: [16.  6.  8.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.] 
expected returns: [[9.470113]
 [8.483541]
 [9.448999]
 [9.094413]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  8.  6. 10.] 
cards in discard: [] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6  6 10 10  6  6  3 11 16  6
 14  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15
  3 16  0 22] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  2.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 8.  8. 25.  0.  1.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
adversary victory points: 9
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.32497552037239075
desired expected reward: 8.725244522094727



action possibilites: [-1] 
expected returns: [[9.064188]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.] 
cards in discard: [8.] 
cards in deck: 47 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 8.  8. 25.  0.  1.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -17   0   0   4   0] 
sum of rewards: 2 

action type: gain_card_n - action 2
Learning step: -0.20336194336414337
desired expected reward: 11.747836112976074





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.6987915]
 [9.047919 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.] 
cards in discard: [8.] 
cards in deck: 47 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8] -> size -> 52 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 8.  8. 25.  0.  1.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26741117238998413
desired expected reward: 9.331599235534668



buy possibilites: [-1] 
expected returns: [[12.174842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.] 
cards in discard: [8. 0.] 
cards in deck: 47 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 8.  8. 25.  0.  1.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -18   0   0   0   0] 
sum of rewards: -3 

action type: buy - action 0.0
Learning step: -0.19312791526317596
desired expected reward: 7.505663871765137






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [ 8.  8. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 25.  0.  1.] 
cards in discard: [8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8  8 29  1 23  0 16  0
 11  8  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 11.  6.  6. 15.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.] 
cards in discard: [8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 11.  6.  6. 15.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.] 
cards in discard: [8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  1.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 11.  6.  6. 15.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.] 
cards in discard: [8. 8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 11.  6.  6. 15.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 6. 11.  6.  6. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[11.024494]
 [11.286193]
 [10.771668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  6.  6. 15.] 
cards in discard: [ 8.  0. 16.  8.  6. 10.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 0. 10. 29. 14.  1.] 
adversary cards in discard: [ 8.  8.  8. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8] -> size -> 48 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3989136517047882
desired expected reward: 11.775928497314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.662293]
 [10.995167]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  6.  6. 15.] 
cards in discard: [ 8.  0. 16.  8.  6. 10.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 0. 10. 29. 14.  1.] 
adversary cards in discard: [ 8.  8.  8. 25.  1.] 
adversary owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8] -> size -> 48 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.37088361382484436
desired expected reward: 10.653609275817871



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 29. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 14.  1.] 
cards in discard: [ 8.  8.  8. 25.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 15.  6. 15.  0.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29. 14.  1.] 
cards in discard: [ 8.  8.  8. 25.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  2.  7.  4.] 
adversary cards in hand: [ 6. 15.  6. 15.  0.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29. 14.  1.] 
cards in discard: [ 8.  8.  8. 25.  1. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8
 10] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 6. 15.  6. 15.  0.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 





Player: 0 
cards in hand: [ 6. 15.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15.] 
expected returns: [[12.331071]
 [12.090145]
 [12.090145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  6. 15.  0.] 
cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 3.  2. 22. 22. 16.] 
adversary cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.] 
adversary owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8
 10] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3517279028892517
desired expected reward: 10.643438339233398





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.108387]
 [12.37998 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  6. 15.  0.] 
cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 3.  2. 22. 22. 16.] 
adversary cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.] 
adversary owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8
 10] -> size -> 49 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.39528295397758484
desired expected reward: 11.935786247253418



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [ 3.  2. 22. 22. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 22. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  2. 22. 22. 16.] 
cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 22 25 11  8 29  1 23  0 16  0 11  8
  1  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8
 10] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 8.  0. 10.  0. 11.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.  6. 15.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  2. 22.] 
cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 25 11  8 29  1 23  0 16  0 11  8  1
  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8 10
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 8.  0. 10.  0. 11.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.  6. 15.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  2. 22.] 
cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 25 11  8 29  1 23  0 16  0 11  8  1
  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8 10
  0] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  1.  7.  4.] 
adversary cards in hand: [ 8.  0. 10.  0. 11.] 
adversary cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.  6. 15.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
adversary victory points: -1
player victory points: 9 


Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 2 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 4 
Chapel: 2 
Witch: 0 
Poacher: 1 
Militia: 1 
Market: 0 
Village: 3 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  0. 10.  0. 11.] 
cards in discard: [ 8.  0. 16.  8.  6. 10.  6. 11.  6.  6. 15.  6. 15.  6. 15.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10 10  0  3  1  3 29  8  6 10 10  6  6  3 11 16  6 14
  6 15  6  6  6  0  0 11  0 15  0  8 15  0  0  0  3  1  0 11 10  0 15  3
 16  0 22  8  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 29. 21. 29.  8.  0.  5.  3.  0.  7.  6.  4.  9.  0.  7.  4.] 
adversary cards in hand: [ 3.  2. 22.] 
adversary cards in discard: [ 8.  8.  8. 25.  1. 10.  0. 10. 29. 14.  1.  0. 10.] 
adversary owned cards: [ 0  0  3  3  3 14  1 14  1 14  0 29 25 11  8 29  1 23  0 16  0 11  8  1
  3 15  1  1  0 25 14  8  3  0 16  1  4 16 10 14  2  0 22  8  0  3  8 10
  0 10] -> size -> 50 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.52139949798584
desired expected reward: -3.141420364379883



