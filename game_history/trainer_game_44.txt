 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.28854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    1  -30    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -534 

action type: buy - action -1.0
Learning step: -28.41663932800293
desired expected reward: 5.916101455688477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[287.7035 ]
 [296.95493]
 [294.7523 ]
 [274.53424]
 [290.8597 ]
 [306.23834]
 [297.77612]
 [302.87537]
 [285.86197]
 [295.75238]
 [296.3448 ]
 [312.85513]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.161847114562988
desired expected reward: 305.1450500488281



buy possibilites: [-1] 
expected returns: [[286.5383]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -22.92959976196289
desired expected reward: 251.6046142578125






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.49365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -8.233359336853027
desired expected reward: 278.304931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[305.44446]
 [313.00848]
 [310.61655]
 [294.32513]
 [321.89084]
 [313.86346]
 [311.5844 ]
 [329.11584]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -10.205321311950684
desired expected reward: 311.73052978515625



buy possibilites: [-1] 
expected returns: [[295.68665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 0. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -21.0 

action type: buy - action 8.0
Learning step: -10.090224266052246
desired expected reward: 303.77325439453125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 0. 3. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[280.52774]
 [268.12265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: buy - action -1
Learning step: -9.756388664245605
desired expected reward: 285.9302673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[258.76904]
 [264.8001 ]
 [247.01888]
 [267.712  ]
 [280.7033 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -9.233734130859375
desired expected reward: 271.36761474609375



buy possibilites: [-1] 
expected returns: [[293.6877]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -4 

action type: buy - action 3.0
Learning step: -6.832033634185791
desired expected reward: 257.9681091308594






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [3. 8. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.41803]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 8. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -8.01481819152832
desired expected reward: 285.6728820800781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[299.2638 ]
 [308.73257]
 [306.7378 ]
 [287.29593]
 [302.3044 ]
 [319.4021 ]
 [309.51688]
 [315.62692]
 [297.5515 ]
 [307.74966]
 [308.63184]
 [328.13742]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3. 8. 0. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6 8 3] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.820908546447754
desired expected reward: 313.2710266113281



buy possibilites: [-1] 
expected returns: [[258.37094]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0.  3.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 11.0
Learning step: -10.531760215759277
desired expected reward: 308.870361328125






Player: 1 
cards in hand: [1. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [14.  0.  0.  0.  0.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[263.3129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.55648136138916
desired expected reward: 250.814453125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[238.28722]
 [247.68549]
 [245.26944]
 [224.99901]
 [256.13113]
 [248.5217 ]
 [246.26636]
 [261.90665]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.300941467285156
desired expected reward: 256.6798095703125



buy possibilites: [-1] 
expected returns: [[250.36034]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 1.0
Learning step: -6.451165676116943
desired expected reward: 241.2342987060547






Player: 1 
cards in hand: [1. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 3.] 
cards in discard: [14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [1. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.30295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -6.530858516693115
desired expected reward: 243.82948303222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[277.48843]
 [281.68622]
 [268.0113 ]
 [284.63312]
 [294.5493 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.90097713470459
desired expected reward: 283.86163330078125



buy possibilites: [-1] 
expected returns: [[269.58276]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [1. 0. 0. 3. 6. 0. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [14.  1.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -323.0 

action type: buy - action 6.0
Learning step: -22.786653518676758
desired expected reward: 231.25865173339844






Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [14.  1.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  1.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  1.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10. 10.  9.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [14.  1.  0.  0.  3.  3. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [11.  8.  0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[298.71356]
 [291.37762]
 [282.7291 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.] 
cards in discard: [3. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [14. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0    0    0    0    0    0    0    0 -600
   13    0] 
sum of rewards: -610 

action type: discard_down_to_3_cards - action 4
Learning step: -36.70730209350586
desired expected reward: 218.4557342529297



action possibilites: [-1] 
expected returns: [[244.64857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [ 3.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [14. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 13 

action type: gain_card_n - action 4
Learning step: -8.283706665039062
desired expected reward: 280.4822998046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[227.32841]
 [217.20045]
 [248.31023]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [ 3.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [14. 15.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 16 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -7.175023078918457
desired expected reward: 237.4735565185547






Player: 1 
cards in hand: [14. 15.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [3. 6. 3. 1. 3.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [3. 6. 3. 1. 3.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [3. 6. 3. 1. 3.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.] 
cards in discard: [3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [3. 6. 3. 1. 3.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[301.20676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 1. 3.] 
cards in discard: [ 3.  0. 16. 11.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -7.235015869140625
desired expected reward: 241.07521057128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[280.44507]
 [286.86682]
 [268.4776 ]
 [289.49527]
 [302.82587]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 1. 3.] 
cards in discard: [ 3.  0. 16. 11.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [ 3. 15. 14.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -10.391371726989746
desired expected reward: 293.18621826171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 3. 15. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.  3.  6.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [ 3. 15. 14.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [6. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  0. 16. 11.  8.  0.  3.  6.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[238.8351]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16. 11.  8.  0.  3.  6.  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [22. 14.  3.  0.  3.] 
adversary cards in discard: [ 3. 15. 14.  3.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1.0
Learning step: -11.388083457946777
desired expected reward: 291.4377136230469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[219.75821]
 [226.66919]
 [224.98322]
 [209.73425]
 [222.14314]
 [232.89758]
 [227.3253 ]
 [230.64761]
 [218.4209 ]
 [225.75604]
 [226.09714]
 [237.29102]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16. 11.  8.  0.  3.  6.  3.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [22. 14.  3.  0.  3.] 
adversary cards in discard: [ 3. 15. 14.  3.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -8.58362102508545
desired expected reward: 231.55892944335938



buy possibilites: [-1] 
expected returns: [[249.62415]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 0.] 
cards in discard: [ 3.  0. 16. 11.  8.  0.  3.  6.  3.  1.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [22. 14.  3.  0.  3.] 
adversary cards in discard: [ 3. 15. 14.  3.  0.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -63.0 

action type: buy - action 0.0
Learning step: -8.521367073059082
desired expected reward: 211.23683166503906






Player: 1 
cards in hand: [22. 14.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 14.  3.  0.  3.] 
cards in discard: [ 3. 15. 14.  3.  0.  0.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16  0] -> size -> 18 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 14.  3.  0.  3.] 
cards in discard: [ 3. 15. 14.  3.  0.  0.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 8. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16  0] -> size -> 18 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[268.90692]
 [253.0991 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6  8  3 11  1  6 16  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: buy - action -1
Learning step: -8.255392074584961
desired expected reward: 241.36875915527344



action possibilites: [-1] 
expected returns: [[279.91776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: trash_cards_n_from_hand - action 1
Learning step: -7.340902805328369
desired expected reward: 241.44015502929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[266.63046]
 [270.91708]
 [257.48068]
 [273.93887]
 [283.10638]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [0. 1. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1
Learning step: -9.103434562683105
desired expected reward: 270.8143310546875






Player: 1 
cards in hand: [0. 1. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10. 10.  9.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [6. 3. 1. 0. 0.] 
adversary cards in discard: [8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
adversary victory points: 1
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [6. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[311.7644]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: buy - action -1.0
Learning step: -9.356534004211426
desired expected reward: 273.7498474121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[284.43677]
 [289.51428]
 [287.66675]
 [276.785  ]
 [286.0203 ]
 [294.39746]
 [290.19968]
 [292.60727]
 [283.00494]
 [288.42722]
 [288.59857]
 [297.67975]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [8. 0. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  8.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -10.552630424499512
desired expected reward: 286.3454895019531



buy possibilites: [-1] 
expected returns: [[259.44144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1. 0. 0.] 
cards in discard: [8. 0. 3. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -355.0 

action type: buy - action 6.0
Learning step: -25.751819610595703
desired expected reward: 251.03321838378906






Player: 1 
cards in hand: [ 0.  3.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 22.  3.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 16.  3. 11.  6.] 
adversary cards in discard: [8. 0. 3. 0. 6. 6. 3. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3.  0. 15. 14.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 16.  3. 11.  6.] 
adversary cards in discard: [8. 0. 3. 0. 6. 6. 3. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3.  0. 15. 14.] 
cards in discard: [10.  0.  1.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  9.  9.  9.] 
adversary cards in hand: [ 0. 16.  3. 11.  6.] 
adversary cards in discard: [8. 0. 3. 0. 6. 6. 3. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3.  0. 15. 14.] 
cards in discard: [10.  0.  1.  3.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0. 16.  3. 11.  6.] 
adversary cards in discard: [8. 0. 3. 0. 6. 6. 3. 1. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[273.44168]
 [246.27838]
 [264.77646]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3. 11.  6.] 
cards in discard: [8. 0. 3. 0. 6. 6. 3. 1. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3 11  1  6 16  0  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9. 10. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -9.812919616699219
desired expected reward: 249.62850952148438



action possibilites: [-1] 
expected returns: [[195.82867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6.] 
cards in discard: [ 8.  0.  3.  0.  6.  6.  3.  1.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: -10 

action type: gain_card_n - action 8
Learning step: -9.447787284851074
desired expected reward: 257.630859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[179.90855]
 [170.74649]
 [199.63277]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 8.  0.  3.  0.  6.  6.  3.  1.  0.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  7.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -7.403904914855957
desired expected reward: 188.42477416992188



buy possibilites: [-1] 
expected returns: [[251.49147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6.] 
cards in discard: [ 8.  0.  3.  0.  6.  6.  3.  1.  0.  0. 25.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -346.0 

action type: buy - action 6.0
Learning step: -20.178768157958984
desired expected reward: 150.56771850585938






Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[240.70616]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[   -5     0    -1   -60     0     0     0   -60     0     0     0     0
     0 -1200    45     0] 
sum of rewards: -1281 

action type: discard_down_to_3_cards - action 0
Learning step: -70.25841522216797
desired expected reward: 162.573486328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[228.05588]
 [234.42719]
 [232.35864]
 [218.58694]
 [240.32573]
 [235.20177]
 [233.2375 ]
 [244.20499]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  9.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -10.117514610290527
desired expected reward: 231.35726928710938



buy possibilites: [-1] 
expected returns: [[281.6145]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  8.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0. 22.  3.] 
adversary cards in discard: [ 1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -64.0 

action type: buy - action 8.0
Learning step: -8.623761177062988
desired expected reward: 226.57798767089844






Player: 1 
cards in hand: [10.  0.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 22.  3.] 
cards in discard: [ 1. 14.  0.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  8.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 16.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3.  3. 10.  3.] 
cards in discard: [ 1. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 14. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  8.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 16.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3.  3. 10.  3.] 
cards in discard: [ 1. 14.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 14. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  8.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 16.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3.  3. 10.  3.] 
cards in discard: [ 1. 14.  0.  0.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22. 14. 10. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  6. 16.  3.] 
adversary cards in discard: [8. 0. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[198.45291]
 [176.27925]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 16.  3.] 
cards in discard: [8. 0. 8. 0. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  7.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -13.258572578430176
desired expected reward: 268.3559265136719



action possibilites: [-1] 
expected returns: [[205.29388]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [8. 0. 8. 0. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   4   0] 
sum of rewards: -42 

action type: gain_card_n - action 3
Learning step: -7.7378129959106445
desired expected reward: 204.32196044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[180.61282]
 [169.29233]
 [208.12024]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [8. 0. 8. 0. 0. 0. 8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  6.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -8.365351676940918
desired expected reward: 196.92852783203125



buy possibilites: [-1] 
expected returns: [[155.52242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [8. 0. 8. 0. 0. 0. 8. 6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -70    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -357 

action type: buy - action 6.0
Learning step: -22.81536293029785
desired expected reward: 146.47695922851562






Player: 1 
cards in hand: [0. 1. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 27. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 1. 0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[144.42436]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 14.] 
adversary cards in discard: [1. 0. 1. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -8.3917875289917
desired expected reward: 147.13063049316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[136.45934]
 [142.3056 ]
 [140.83516]
 [128.08502]
 [138.4331 ]
 [148.10838]
 [142.86394]
 [146.01599]
 [135.24571]
 [141.504  ]
 [141.85008]
 [152.37517]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  6.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 14.] 
adversary cards in discard: [1. 0. 1. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -7.853837013244629
desired expected reward: 135.8943328857422



buy possibilites: [-1] 
expected returns: [[154.9311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  0.  8.  0.  0.  0.  8.  6. 16.  3.  6.  3.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 10.  0. 14.] 
adversary cards in discard: [1. 0. 1. 3. 1. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -75.0 

action type: buy - action 8.0
Learning step: -7.407247066497803
desired expected reward: 135.45669555664062






Player: 1 
cards in hand: [ 8.  0. 10.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0. 14.] 
cards in discard: [1. 0. 1. 3. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  6. 25.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [1. 0. 1. 3. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [1. 0. 1. 3. 1. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 26. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 10.  0.] 
cards in discard: [1. 0. 1. 3. 1. 0. 1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 0.] 
adversary cards in discard: [25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[159.56592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0.] 
cards in discard: [25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 22.  3.] 
adversary cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -70     0     0     0   -30     0     0     0     0
     0 -1500    53     0] 
sum of rewards: -1554 

action type: discard_down_to_3_cards - action 1
Learning step: -82.54208374023438
desired expected reward: 86.41419982910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[150.87282]
 [153.78044]
 [144.17192]
 [155.9824 ]
 [162.64233]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  5.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 22.  3.] 
adversary cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -8.403358459472656
desired expected reward: 151.8514404296875



buy possibilites: [-1] 
expected returns: [[112.27126]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0.] 
cards in discard: [25.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10.  0. 22.  3.] 
adversary cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -69 

action type: buy - action 8.0
Learning step: -8.723017692565918
desired expected reward: 147.25938415527344






Player: 1 
cards in hand: [ 3. 10.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 22.  3.] 
cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 23 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  3.  3. 14.] 
cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 23 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  3.  3.  3. 14.] 
cards in discard: [ 1.  0.  1.  3.  1.  0.  1. 14.  8.  0. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [8. 3. 6. 6. 0.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 23 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [8. 3. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[132.28984 ]
 [125.627174]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 6. 6. 0.] 
cards in discard: [25.  3.  8.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 14.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -6.620619297027588
desired expected reward: 105.65064239501953



action possibilites: [-1] 
expected returns: [[152.5157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [25.  3.  8.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 14.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: trash_cards_n_from_hand - action 1
Learning step: -5.889808654785156
desired expected reward: 123.5384292602539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[136.31627]
 [126.72053]
 [157.50871]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [25.  3.  8.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 14.  1. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -7.310605049133301
desired expected reward: 145.20509338378906






Player: 1 
cards in hand: [ 3. 14.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  1. 15.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [ 0.  0.  8.  8. 16.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 25. 30. 27. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 15.  0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[110.687675]
 [101.616486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: discard_down_to_3_cards - action 3
Learning step: -10.06966495513916
desired expected reward: 151.8264923095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 95.07961 ]
 [ 99.559616]
 [ 87.043655]
 [101.708786]
 [110.779976]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -7.617009162902832
desired expected reward: 102.35151672363281



buy possibilites: [-1] 
expected returns: [[101.17978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 1. 8. 3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -117.0 

action type: buy - action 0.0
Learning step: -7.815544128417969
desired expected reward: 77.02623748779297






Player: 1 
cards in hand: [0. 0. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8. 3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3. 14.  3.  1. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 14.  3.  1. 15.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[113.71101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [14.  0.  0. 10.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -6.350491523742676
desired expected reward: 94.82928466796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[100.60002 ]
 [106.32122 ]
 [104.780045]
 [ 93.152016]
 [112.295074]
 [106.842094]
 [105.400085]
 [116.54221 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [14.  0.  0. 10.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -7.149452209472656
desired expected reward: 106.56156158447266



buy possibilites: [-1] 
expected returns: [[105.5239]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [25.  3.  8.  0.  6.  0.  8.  3.  6.  6.  8. 16.  0.  0.  0.  8.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [14.  0.  0. 10.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 1.0
Learning step: -5.8917741775512695
desired expected reward: 100.42945861816406






Player: 1 
cards in hand: [14.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  8. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [8. 8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[156.5703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 22.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -70     0     0     0   -60     0     0     0     0
     0 -1500    57     0] 
sum of rewards: -1580 

action type: discard_down_to_3_cards - action 0
Learning step: -79.91250610351562
desired expected reward: 7.195884704589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[143.27293]
 [149.25691]
 [147.58084]
 [134.69714]
 [155.02808]
 [149.85355]
 [148.25482]
 [159.01599]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  8.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 22.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -8.155781745910645
desired expected reward: 144.86264038085938



buy possibilites: [-1] 
expected returns: [[128.0508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 22.  3.] 
adversary cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 10.0
Learning step: -7.4815993309021
desired expected reward: 140.7732391357422






Player: 1 
cards in hand: [ 3.  0.  1. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 22.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  3. 16.  8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1
 10] -> size -> 25 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 22.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  3. 16.  8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1
 10] -> size -> 25 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  1. 22.  3.] 
cards in discard: [ 3. 14.  3.  1. 15.  0.  0.  8. 14. 14.  0.  0. 10.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 3.  6.  3. 16.  8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1
 10] -> size -> 25 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  3. 16.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[89.11243]
 [75.62851]
 [79.32803]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 16.  8.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -8.475564956665039
desired expected reward: 119.57523345947266



action possibilites: [-1] 
expected returns: [[134.26552]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 16.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.140029430389404
desired expected reward: 71.08003234863281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[121.42694 ]
 [112.977325]
 [138.29161 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 16.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [ 0. 14.  0.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -68 

action type: take_action - action -1
Learning step: -7.309059143066406
desired expected reward: 126.95645904541016






Player: 1 
cards in hand: [ 0. 14.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  1. 10.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  9.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.  1. 10.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 0. 1. 6.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[69.175125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [14.  0.  3.  3. 15.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1.0
Learning step: -9.767090797424316
desired expected reward: 128.52452087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[58.528946]
 [62.203434]
 [61.140507]
 [53.250523]
 [59.76808 ]
 [65.57897 ]
 [62.55894 ]
 [64.296844]
 [57.623867]
 [61.548004]
 [61.654827]
 [67.79769 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 24. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [14.  0.  3.  3. 15.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -6.454819679260254
desired expected reward: 62.322509765625



buy possibilites: [-1] 
expected returns: [[107.85249]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 1. 6.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [14.  0.  3.  3. 15.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.    0.   -3.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -83.5 

action type: buy - action 1.0
Learning step: -4.85849142074585
desired expected reward: 57.34495162963867






Player: 1 
cards in hand: [14.  0.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  3. 15.] 
cards in discard: [15.  0. 14.  0.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8.  6.  0. 25.  8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
adversary victory points: -3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [15.  0. 14.  0.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [15.  0. 14.  0.  1. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 15.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [6. 0. 8.] 
adversary cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[56.056957]
 [46.269855]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8.] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  6  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  3.  3.  1.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[   -5     0    -3   -80     0     0     0   -30     0     0     0     0
     0 -1500    57     0] 
sum of rewards: -1561 

action type: discard_down_to_3_cards - action 4
Learning step: -79.88981628417969
desired expected reward: -20.007427215576172



action possibilites: [-1] 
expected returns: [[29.957277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  3.  3.  1.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.254930019378662
desired expected reward: 37.32444381713867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.921175]
 [15.19828 ]
 [29.782541]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  3.  3.  1.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -3.855883836746216
desired expected reward: 26.10139274597168



buy possibilites: [-1] 
expected returns: [[106.896904]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8.  8. 10.  0.  0.  0.  8.  6.  3. 16.  1.  6.  0.  0.  1.  6. 25.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 0. 10.  3.  3.  1.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action 0.0
Learning step: -2.9408786296844482
desired expected reward: 16.980297088623047






Player: 1 
cards in hand: [ 0. 10.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3.  1.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [25.  0.  1.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [25.  0.  1.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [25.  0.  1.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [25.  0.  1.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [25.  0.  1.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[103.34789 ]
 [102.381195]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  1.  6.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  5.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 14.  0.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1] -> size -> 25 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -6.956672668457031
desired expected reward: 99.94023132324219



action possibilites: [-1] 
expected returns: [[106.75288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 14.  0.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1  6] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: -54 

action type: take_action - action 25.0
Learning step: -5.246921539306641
desired expected reward: 93.73030090332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[76.59263 ]
 [80.85938 ]
 [74.61954 ]
 [79.14248 ]
 [72.64076 ]
 [70.727   ]
 [77.924835]
 [84.34125 ]
 [81.44324 ]
 [87.68092 ]
 [83.1557  ]
 [75.24537 ]
 [76.29523 ]
 [79.770615]
 [72.06891 ]
 [79.81603 ]
 [86.121735]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  8.] 
adversary cards in hand: [ 8. 22.  0. 14.  0.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1  6] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -6.410444736480713
desired expected reward: 100.3424301147461



buy possibilites: [-1] 
expected returns: [[84.30908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 3. 1. 0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 8. 22.  0. 14.  0.] 
adversary cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1  6] -> size -> 26 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -70.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -49.0 

action type: buy - action 15.0
Learning step: -4.543848037719727
desired expected reward: 75.27220153808594






Player: 1 
cards in hand: [ 8. 22.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 22.  0. 14.  0.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 14 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0
  1  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  6.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  6.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  6.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [15.  0. 14.  0.  1. 10.  0. 14.  0.  3.  3. 15.  1. 10.  0.  3.  3.  1.
  3.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 6.  0.  0. 16.  6.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[85.1719 ]
 [72.81696]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0. 16.  6.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  1. 14.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -5.821107387542725
desired expected reward: 78.48797607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[68.705284]
 [72.19995 ]
 [62.587498]
 [73.42455 ]
 [82.908325]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.  6.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 26. 30.  8.  4.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  1. 14.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -5.894512176513672
desired expected reward: 77.52011108398438



buy possibilites: [-1] 
expected returns: [[72.19108]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  0. 16.  6.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 30. 26. 30.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 8.  1. 14.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -378.0 

action type: buy - action 6.0
Learning step: -20.405075073242188
desired expected reward: 42.182430267333984






Player: 1 
cards in hand: [ 8.  1. 14.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  1.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 30.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 8. 0. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15  6] -> size -> 26 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14.  1.  1.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 22. 30. 26. 30.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 8. 0. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15  6] -> size -> 26 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14.  1.  1.] 
cards in discard: [4.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 26. 29.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [8. 3. 8. 0. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15  6] -> size -> 26 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [8. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
expected returns: [[30.428843]
 [24.561346]
 [24.561346]
 [24.561346]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8. 0. 8.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  8  3  1  6 16  0  6 25  6  8  8  6  8  8  0  1 10  1  0
 15  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [15. 10. 14.  3. 15.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -8.421103477478027
desired expected reward: 63.76997375488281



action possibilites: [-1] 
expected returns: [[48.79503]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [15. 10. 14.  3. 15.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: trash_cards_n_from_hand - action 8
Learning step: -4.550665855407715
desired expected reward: 20.42041015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.684658]
 [31.498655]
 [50.101894]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  3.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [15. 10. 14.  3. 15.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -5.93849515914917
desired expected reward: 42.85653305053711



buy possibilites: [-1] 
expected returns: [[51.22277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [15. 10. 14.  3. 15.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -399 

action type: buy - action 6.0
Learning step: -20.013652801513672
desired expected reward: 4.309625625610352






Player: 1 
cards in hand: [15. 10. 14.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 14. 15.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 14.  3. 15.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [0. 1. 8. 6. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  3. 15.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3. 15.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  4.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  3. 15.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [1. 6. 8.] 
adversary cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
adversary owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [1. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[52.99227 ]
 [46.232346]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 8.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  1  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: discard_down_to_3_cards - action 7
Learning step: -5.97650671005249
desired expected reward: 16.922433853149414



action possibilites: [-1] 
expected returns: [[70.939224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: trash_cards_n_from_hand - action 1
Learning step: -5.717837810516357
desired expected reward: 41.56157302856445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.9689  ]
 [51.487946]
 [70.65435 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [15. 25.  0.  1.  6.  3.  1.  0.  6.  6.  0.  0. 16.  6.  6.  8.  3.  0.
  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [0. 3. 1. 3. 3.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -7.146618843078613
desired expected reward: 63.792606353759766






Player: 1 
cards in hand: [0. 3. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [16.  6.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  9.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [16.  6.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 3.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  8.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [16.  6.  1.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [16.  6.  1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
expected returns: [[69.03505 ]
 [59.279404]
 [61.25835 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  1.  0. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0  1 10  1  0 15  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  8.  3.  9. 10.  7. 10.  7.  9.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1.0
Learning step: -8.129931449890137
desired expected reward: 62.5244255065918



action possibilites: [-1] 
expected returns: [[121.38187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.] 
cards in discard: [22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
   25    0] 
sum of rewards: -74 

action type: gain_card_n - action 13
Learning step: -3.558492422103882
desired expected reward: 48.23318862915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[108.14521]
 [100.97393]
 [123.87683]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 22. 30. 26. 29.  8.  2.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -8.513381958007812
desired expected reward: 112.86848449707031



buy possibilites: [-1] 
expected returns: [[85.213264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.] 
cards in discard: [22.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -23.631399154663086
desired expected reward: 77.342529296875






Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 6.  0.  6. 15. 25.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 6.  0.  6. 15. 25.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 22. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 6.  0.  6. 15. 25.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 4.  8.  1. 14.  1.  1.  8. 14. 15. 10.  3. 15. 11.  0.  3.  1.  3.  3.
  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 6.  0.  6. 15. 25.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[18.660152]
 [15.28936 ]
 [19.031784]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 15. 25.] 
cards in discard: [22.  6. 16.  6.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 15.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: buy - action -1
Learning step: -10.355502128601074
desired expected reward: 74.8577651977539



action possibilites: [-1] 
expected returns: [[20.370232]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 25.] 
cards in discard: [22.  6. 16.  6.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 15.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action 15.0
Learning step: -5.821518898010254
desired expected reward: 9.775456428527832





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[17.82602 ]
 [18.974392]
 [18.503443]
 [16.067507]
 [19.923674]
 [19.15516 ]
 [18.695799]
 [20.429092]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 25.] 
cards in discard: [22.  6. 16.  6.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  8.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 15.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1
Learning step: -6.0967230796813965
desired expected reward: 14.273508071899414



buy possibilites: [-1] 
expected returns: [[25.282768]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6. 25.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 15.  0.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -92 

action type: buy - action 11.0
Learning step: -4.888009548187256
desired expected reward: 15.03565788269043






Player: 1 
cards in hand: [ 1. 15.  0.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  6. 22.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  6. 22.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  3.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15.  0.  6. 22.] 
cards in discard: [8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  2.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [8. 0. 0. 3. 6.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
adversary victory points: -5
player victory points: 7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.329615]
 [17.09081 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  2.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [0. 1. 1. 8. 4.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: buy - action -1
Learning step: -7.3421220779418945
desired expected reward: 17.94064712524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.192713]
 [15.550161]
 [11.982862]
 [15.905359]
 [19.144167]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  2.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [0. 1. 1. 8. 4.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: take_action - action -1.0
Learning step: -7.168567180633545
desired expected reward: 13.161046981811523



buy possibilites: [-1] 
expected returns: [[-7.2823215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 3. 6.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [0. 1. 1. 8. 4.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -122 

action type: buy - action 8.0
Learning step: -7.059120178222656
desired expected reward: 8.84623908996582






Player: 1 
cards in hand: [0. 1. 1. 8. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 8. 4.] 
cards in discard: [ 8.  1. 15.  0.  6. 22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [6. 8. 3. 0. 8.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11
  8] -> size -> 25 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 8. 4.] 
cards in discard: [ 8.  1. 15.  0.  6. 22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  7.] 
adversary cards in hand: [6. 8. 3. 0. 8.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11
  8] -> size -> 25 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 8. 4.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [6. 8. 3. 0. 8.] 
adversary cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11
  8] -> size -> 25 
adversary victory points: -5
player victory points: 7 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [6. 8. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.961706]
 [20.755672]
 [20.755672]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 3. 0. 8.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  6 16  0  6 25  6  8  6  8  8  0 10  1  0 15  6  6 22  6 11
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: buy - action -1
Learning step: -5.651395320892334
desired expected reward: -12.933716773986816



action possibilites: [-1] 
expected returns: [[8.411118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: trash_cards_n_from_hand - action 5
Learning step: -5.712481498718262
desired expected reward: 13.322148323059082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[3.4665308]
 [1.3822577]
 [8.664604 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  1.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -5.266542911529541
desired expected reward: 3.1445746421813965



buy possibilites: [-1] 
expected returns: [[30.703829]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [22.  6. 16.  6.  0. 10. 11. 15.  6.  6. 25.  8.  8.  0.  0.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 1.  0.  3. 10.  3.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -19.878278732299805
desired expected reward: -18.496017456054688






Player: 1 
cards in hand: [ 1.  0.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 10.  3.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 6. 22.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  3. 14.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [ 6. 22.  6.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [22.  0.  1.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  6.] 
adversary cards in hand: [22.  0.  1.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  5.] 
adversary cards in hand: [22.  0.  1.] 
adversary cards in discard: [6. 6.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
adversary victory points: -5
player victory points: 7 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [22.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[44.407867]
 [36.944016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  1.] 
cards in discard: [6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  5.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: discard_down_to_3_cards - action 6
Learning step: -5.517404079437256
desired expected reward: -7.011756896972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[39.1952  ]
 [41.14755 ]
 [40.63952 ]
 [43.08336 ]
 [41.342747]
 [40.8725  ]
 [44.513165]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  1.] 
cards in discard: [6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  7.  8.  5.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: take_action - action -1.0
Learning step: -7.759578704833984
desired expected reward: 36.16393280029297



buy possibilites: [-1] 
expected returns: [[8.497555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  1.] 
cards in discard: [ 6.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0.  3.  1. 10.  0.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -120    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -112 

action type: buy - action 10.0
Learning step: -7.452430248260498
desired expected reward: 33.42006301879883






Player: 1 
cards in hand: [ 0.  3.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 10.  0.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 10.  6.  3. 15.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
adversary victory points: -5
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 10.  0.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 21. 30. 26. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 10.  6.  3. 15.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
adversary victory points: -5
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 10.  0.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 10.  6.  3. 15.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
adversary victory points: -5
player victory points: 8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  6.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[0.38872337]
 [1.3707409 ]
 [1.2223032 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  3. 15.] 
cards in discard: [ 6.  6. 10. 22.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0. 15. 11.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: buy - action -1
Learning step: -7.402273654937744
desired expected reward: 1.0952811241149902



action possibilites: [-1. 15.] 
expected returns: [[8.362316 ]
 [6.7729163]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3. 15.  0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0. 15. 11.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    1] 
sum of rewards: -119 

action type: take_action - action 10.0
Learning step: -5.847757816314697
desired expected reward: -4.477003574371338





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[6.8080096]
 [8.8535385]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3. 15.  0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0. 15. 11.  3.  8.] 
adversary cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.  0.  3.  1. 10.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1.0
Learning step: -6.241268634796143
desired expected reward: 2.1210455894470215






Player: 1 
cards in hand: [ 0. 15. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11.  3.  8.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.  0.  3.  1. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
adversary victory points: -5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 11.  3.  8.] 
cards in discard: [ 8.  1. 15.  0.  6. 22. 15.  0.  1.  1.  8.  4. 15. 10. 14.  1.  0.  3.
  3.  3.  0.  3.  1. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  6.  0.  0.  0.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.] 
adversary owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
adversary victory points: -5
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [16.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[52.956223]
 [49.415665]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  0.  0.  0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0  6 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0.  1.  4.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -140 

action type: buy - action -1.0
Learning step: -6.289859771728516
desired expected reward: 2.563671112060547



action possibilites: [-1] 
expected returns: [[30.40569]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0.  1.  4.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: gain_card_n - action 0
Learning step: -6.298081398010254
desired expected reward: -5.653903007507324





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[24.770681]
 [26.953247]
 [26.126364]
 [28.95331 ]
 [27.22557 ]
 [26.420961]
 [30.006542]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  1.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0.  1.  4.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -109 

action type: take_action - action -1
Learning step: -6.356311321258545
desired expected reward: 24.04937744140625



buy possibilites: [-1] 
expected returns: [[-2.3310268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 0.  1.  4.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0.    0.    2.    0.] 
sum of rewards: -107.0 

action type: buy - action 8.0
Learning step: -6.763726711273193
desired expected reward: 20.461835861206055






Player: 1 
cards in hand: [ 0.  1.  4.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  4.  3. 14.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [25.  8.  6.  8.  3.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
adversary victory points: -4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 4. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
adversary owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
adversary victory points: -4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  9. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
adversary owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
adversary victory points: -4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 4. 3.] 
cards in discard: [25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [25.  8.  3.] 
adversary cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
adversary owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
adversary victory points: -4
player victory points: 8 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [25.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[-2.537782  ]
 [-0.55352616]
 [-1.843255  ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8.  3.] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3 16  0 25  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10
  0  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 22.  0.  3.  0.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
adversary victory points: 8
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -129 

action type: discard_down_to_3_cards - action 3
Learning step: -6.257517337799072
desired expected reward: -10.83338737487793



action possibilites: [-1] 
expected returns: [[46.030712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 22.  0.  3.  0.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.896419525146484
desired expected reward: -6.254210472106934





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[35.62318 ]
 [45.788136]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 6.  6. 10. 22.  0.  1. 10.  6.  6.  3. 15.  0.  0.  8. 16.  0.  0.  0.
  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 6. 22.  0.  3.  0.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
adversary victory points: 8
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -120 

action type: take_action - action -1
Learning step: -7.382405757904053
desired expected reward: 38.64830780029297






Player: 1 
cards in hand: [ 6. 22.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  0.  3.  0.] 
cards in discard: [25. 14.  0.  1.  4.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  8.  8.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
adversary victory points: -5
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3. 8. 0.] 
cards in discard: [25. 14.  0.  1.  4.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  8.  8.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
adversary victory points: -5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3. 8. 0.] 
cards in discard: [25. 14.  0.  1.  4.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 25. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  8.  8.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
adversary victory points: -5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3. 8. 0.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [16.  8.  8.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
adversary victory points: -5
player victory points: 9 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [16.  8.  8.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8. 11.] 
expected returns: [[30.060314]
 [25.817434]
 [27.147743]
 [27.147743]
 [28.21552 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8.  6. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8. 10.  7. 10.  6.  8.  5.] 
adversary cards in hand: [15.  1.  1. 11. 15.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: buy - action -1.0
Learning step: -9.168610572814941
desired expected reward: 36.61952590942383



action possibilites: [-1] 
expected returns: [[-4.9383736]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  8.  6.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  9.  7. 10.  6.  8.  5.] 
adversary cards in hand: [15.  1.  1. 11. 15.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -114 

action type: gain_card_n - action 5
Learning step: -7.07642126083374
desired expected reward: 18.229734420776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.445722 ]
 [-4.9383736]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  8.  6.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  9.  7. 10.  6.  8.  5.] 
adversary cards in hand: [15.  1.  1. 11. 15.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -130 

action type: take_action - action -1
Learning step: -6.358494758605957
desired expected reward: -11.296868324279785



buy possibilites: [-1] 
expected returns: [[-4.893652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  8.  6.] 
cards in discard: [29.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  9.  7. 10.  6.  8.  5.] 
adversary cards in hand: [15.  1.  1. 11. 15.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -160 

action type: buy - action 0.0
Learning step: -7.887821197509766
desired expected reward: -12.33354377746582






Player: 1 
cards in hand: [15.  1.  1. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  1. 11. 15.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  9.  7. 10.  6.  8.  5.] 
adversary cards in hand: [22. 15.  0.  0.  8.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
adversary victory points: -5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1. 11. 15.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  9.  7. 10.  6.  8.  5.] 
adversary cards in hand: [22. 15.  0.  0.  8.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
adversary victory points: -5
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  1. 11. 15.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [22. 15.  0.  0.  8.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
adversary victory points: -5
player victory points: 9 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [22. 15.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.  8.] 
expected returns: [[-6.0899277]
 [-4.6219025]
 [-5.5965505]
 [-5.8541007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  0.  0.  8.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 10.  3.  3. 10.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: buy - action -1
Learning step: -7.379394054412842
desired expected reward: -12.273046493530273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-5.1943016]
 [-5.459635 ]
 [-5.857275 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.  0.  0.  8.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 10.  3.  3. 10.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: take_action - action -1.0
Learning step: -7.318567752838135
desired expected reward: -13.419925689697266



buy possibilites: [-1] 
expected returns: [[13.192812]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 15.  0.  0.  8.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 10.  3.  3. 10.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -140.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -180.0 

action type: buy - action 0.0
Learning step: -8.443446159362793
desired expected reward: -13.637747764587402






Player: 1 
cards in hand: [ 1. 10.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  3. 10.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 10.  0.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 1.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  6.  0. 10.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[2.3689961]
 [0.8922653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 10.  0.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [14. 15.  8.  3.  0.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15. 10. 10.  1.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: buy - action -1
Learning step: -8.122478485107422
desired expected reward: 5.070333480834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-0.21476746]
 [ 0.30842733]
 [ 1.8249555 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 10.  0.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [14. 15.  8.  3.  0.] 
adversary cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15. 10. 10.  1.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: take_action - action -1.0
Learning step: -7.603301525115967
desired expected reward: -5.234307289123535



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14. 15.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 15.  8.  3.  0.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15. 10. 10.  1.  3.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 15 14 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0
  4  8 11  1  8 15 15  3 25  3 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1.  8. 10.  6.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15. 10. 10.  1.  3.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1.  8. 10.  6.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [25. 14.  0.  1.  4.  3.  3. 22.  6.  0.  3.  0.  3.  8.  0. 29. 15.  1.
  1. 11. 15. 10. 10.  1.  3.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1.  8. 10.  6.  0.] 
adversary cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
adversary victory points: -5
player victory points: 9 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 1.  8. 10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[18.945868]
 [15.971489]
 [15.720745]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 10.  6.  0.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  6  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8
 29  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 8.  1. 14. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -140    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -150 

action type: buy - action -1.0
Learning step: -7.210139751434326
desired expected reward: -5.385187149047852



action possibilites: [-1] 
expected returns: [[31.304731]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  0  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 8.  1. 14. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: trash_cards_n_from_hand - action 7
Learning step: -5.94181489944458
desired expected reward: 7.9816107749938965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.789957]
 [25.402311]
 [32.98802 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [29.  0. 11. 16.  8.  8.  6.  0. 22. 15.  0.  0.  8.  3.  6.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  0  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 8.  1. 14. 15.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1
Learning step: -6.902590274810791
desired expected reward: 24.402141571044922






Player: 1 
cards in hand: [ 8.  1. 14. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14. 15.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [8. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 14. 15.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [8. 0. 6. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0
  0] -> size -> 25 
adversary victory points: -4
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [8. 0. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-4.977053]
 [-4.857847]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  6  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 25.  8. 15.  6.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -130    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -139 

action type: buy - action -1.0
Learning step: -8.709999084472656
desired expected reward: 24.27802276611328



action possibilites: [-1] 
expected returns: [[27.295008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 25.  8. 15.  6.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: trash_cards_n_from_hand - action 1
Learning step: -4.545203685760498
desired expected reward: -9.358380317687988





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[15.774305]
 [22.13031 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 25.  8. 15.  6.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1
Learning step: -6.336289882659912
desired expected reward: 20.958717346191406






Player: 1 
cards in hand: [11. 25.  8. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.  8. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  8. 15.  6.] 
cards in discard: [ 8.  1. 14. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  0. 16.  0.  8.] 
adversary cards in discard: [8. 0. 6. 6.] 
adversary owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  8. 15.  6.] 
cards in discard: [ 8.  1. 14. 15.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  0. 16.  0.  8.] 
adversary cards in discard: [8. 0. 6. 6.] 
adversary owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 25.  8. 15.  6.] 
cards in discard: [ 8.  1. 14. 15.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  0. 16.  0.  8.] 
adversary cards in discard: [8. 0. 6. 6.] 
adversary owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[-5.260537 ]
 [-5.0849524]
 [-5.3131742]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  0.  8.] 
cards in discard: [8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1.0
Learning step: -7.623868465423584
desired expected reward: 14.506427764892578



action possibilites: [-1] 
expected returns: [[34.3907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: trash_cards_n_from_hand - action 2
Learning step: -4.377173900604248
desired expected reward: -9.357889175415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[25.514742]
 [27.360294]
 [33.32058 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1
Learning step: -6.470130920410156
desired expected reward: 27.920570373535156



buy possibilites: [-1] 
expected returns: [[10.382223]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [8. 0. 6. 6. 0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 3.  3.  3. 10. 10.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -120.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -138.0 

action type: buy - action 0.0
Learning step: -7.668117046356201
desired expected reward: 12.3662109375






Player: 1 
cards in hand: [ 3.  3.  3. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10. 10.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 15.  0. 22. 29.] 
adversary cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 15.  0. 22. 29.] 
adversary cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0] -> size -> 34 
action values: 2 
buys: 1 
player value: 0 
card supply: [18. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 15.  0. 22. 29.] 
adversary cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [11. 15.  0. 22. 29.] 
adversary cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [11. 15.  0. 22. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 22. 29.] 
expected returns: [[32.119728]
 [31.75454 ]
 [30.624233]
 [28.63225 ]
 [31.437996]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 22. 29.] 
cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 15.  0.  3.  3.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1
Learning step: -6.222780227661133
desired expected reward: 4.159442901611328



action possibilites: [-1] 
expected returns: [[4.3646774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 29.  8.  1.  0.] 
cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 15.  0.  3.  3.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: LIBRARY: skip_action_card - action 1
Learning step: -6.8466081619262695
desired expected reward: 24.049663543701172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-2.3619308 ]
 [-1.0804392 ]
 [-1.164209  ]
 [-1.9168118 ]
 [ 0.43715835]
 [-0.18874788]
 [-2.4467854 ]
 [-1.0601808 ]
 [-0.89541173]
 [ 2.3251507 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0. 29.  8.  1.  0.] 
cards in discard: [8. 0. 6. 6. 0. 8. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  6.  8.  5.] 
adversary cards in hand: [ 1. 15.  0.  3.  3.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1
Learning step: -5.635003566741943
desired expected reward: -1.2703261375427246



buy possibilites: [-1] 
expected returns: [[31.60669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0. 29.  8.  1.  0.] 
cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 1. 15.  0.  3.  3.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
adversary owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5.     0.    -3.  -120.     0.     0.    20.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -103.5 

action type: buy - action 10.0
Learning step: -4.4108405113220215
desired expected reward: -5.471019744873047






Player: 1 
cards in hand: [ 1. 15.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  0.  3.  3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8
 11  1  8 15 15  3 25  3 29  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  8.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8. 10.  6.  6.] 
adversary cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 10.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[17.068266]
 [11.690335]
 [10.958647]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  6.  6.] 
cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 1.  0.  0. 22.  1.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1
Learning step: -7.680005073547363
desired expected reward: 23.926685333251953



action possibilites: [-1.  8. 10.] 
expected returns: [[47.818718]
 [43.89176 ]
 [43.335747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  6. 10.] 
cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 1.  0.  0. 22.  1.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action 10.0
Learning step: -4.933291912078857
desired expected reward: 6.025355815887451





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.523514]
 [47.116173]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6.  6. 10.] 
cards in discard: [ 8.  0.  6.  6.  0.  8.  3.  0.  0. 10. 22. 11. 15.  0. 29.  8.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 1.  0.  0. 22.  1.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -6.802879333496094
desired expected reward: 41.01583480834961






Player: 1 
cards in hand: [ 1.  0.  0. 22.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 22.  1.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 8. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 22.  1.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  8.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 8. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0. 22.  1.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 8. 11. 15. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 8. 11. 15. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15. 10.] 
expected returns: [[5.726142 ]
 [3.1528928]
 [4.457032 ]
 [3.2474954]
 [3.1168416]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15. 10.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1.0
Learning step: -8.666013717651367
desired expected reward: 38.45014953613281



action possibilites: [-1.  8. 11. 15. 10.] 
expected returns: [[26.781637]
 [26.546946]
 [26.857782]
 [26.070765]
 [26.143097]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15.  0. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action 10.0
Learning step: -4.959799289703369
desired expected reward: -1.8429601192474365



action possibilites: [-1.  8. 15. 10.] 
expected returns: [[22.288383]
 [20.551659]
 [20.566538]
 [20.462944]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0. 10.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   40    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -79 

action type: gain_card_n - action 1
Learning step: -4.797529697418213
desired expected reward: 21.605295181274414



action possibilites: [-1.  8. 15.  8.] 
expected returns: [[13.861642]
 [11.120129]
 [11.035529]
 [11.120129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -68 

action type: take_action - action 10.0
Learning step: -4.156669616699219
desired expected reward: 16.306270599365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.655901]
 [14.914376]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -68 

action type: take_action - action -1.0
Learning step: -3.804053544998169
desired expected reward: 10.057584762573242



buy possibilites: [-1] 
expected returns: [[6.060603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 15.  0.  8.] 
cards in discard: [1. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10. 11. 10.] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3. -120.    0.    0.   60.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -98.0 

action type: buy - action 0.0
Learning step: -5.188425064086914
desired expected reward: 5.467474937438965






Player: 1 
cards in hand: [29.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  0.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
adversary victory points: -3
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 8.  1. 14. 15.  8.  0. 11. 25.  8. 15.  6.  0. 10.  3.  3.  3. 10.  3.
 25. 15.  1.  3.  3. 29.  1.  0.  0. 22.  1.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[-3.1238728]
 [-4.8016224]
 [-4.9923167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8.  1. 25.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1
Learning step: -6.799157619476318
desired expected reward: -0.7385544776916504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.5777984]
 [-4.263105 ]
 [-4.183942 ]
 [-3.2485619]
 [-4.134615 ]
 [-2.1341348]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  5.  8.  5.] 
adversary cards in hand: [ 0.  8.  1. 25.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: take_action - action -1.0
Learning step: -6.327301502227783
desired expected reward: -9.451163291931152



buy possibilites: [-1] 
expected returns: [[-0.8460891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  8.  1. 25.  4.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -110 

action type: buy - action 10.0
Learning step: -5.312306880950928
desired expected reward: -9.44691276550293






Player: 1 
cards in hand: [ 0.  8.  1. 25.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 25.  4.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [8. 6. 1. 0. 6.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
adversary victory points: -3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 1. 4. 8. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [8. 6. 1. 0. 6.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
adversary victory points: -3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4. 8. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  7.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [8. 6. 1. 0. 6.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
adversary victory points: -3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 1. 4. 8. 0.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [8. 6. 1. 0. 6.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
adversary victory points: -3
player victory points: 9 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [8. 6. 1. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-5.3503866]
 [-5.1004896]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 1. 0. 6.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  1  0 15  6  6 22  6 11  8  6 10  0  8 29  0  0  0
 10  1  0 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  0. 15.  8.  3.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
adversary victory points: 9
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -128 

action type: buy - action -1
Learning step: -6.475188732147217
desired expected reward: -7.321277618408203



action possibilites: [-1] 
expected returns: [[14.627421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  0. 15.  8.  3.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: trash_cards_n_from_hand - action 11
Learning step: -3.704256772994995
desired expected reward: -9.036782264709473





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.992047]
 [13.985526]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  0. 15.  8.  3.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -86 

action type: take_action - action -1
Learning step: -4.749415397644043
desired expected reward: 9.878005981445312



buy possibilites: [-1] 
expected returns: [[-3.527297]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  0. 15.  8.  3.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
adversary owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -116.0 

action type: buy - action 0.0
Learning step: -6.428966522216797
desired expected reward: 4.563082695007324






Player: 1 
cards in hand: [ 0.  0. 15.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  8.  3.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3 22  3 10 10  1  8  1  1  3  0 14  0 15  0  1  6  0  4  8 11
  1  8 15 15  3 25  3 29  0  0 25 29 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [0. 3. 0. 6. 0.] 
adversary cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.  8.  0.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-5.3503866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 3.  1.  0.  1. 14.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.744019031524658
desired expected reward: -8.271316528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.5870876]
 [-5.046156 ]
 [-4.801614 ]
 [-5.332526 ]
 [-4.853224 ]
 [-5.3503866]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 0.] 
cards in discard: [ 1.  0. 10. 11. 10.  8. 15.  0.  8. 10.  0. 10.  0.  0.  8.  0.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 3.  1.  0.  1. 14.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.64461088180542
desired expected reward: -9.994997024536133



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  1.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  1. 14.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 1. 11. 29.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1. 14.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 20. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 1. 11. 29.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  1. 14.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 1. 11. 29.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 29.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 22.] 
expected returns: [[55.340405]
 [53.598507]
 [52.858086]
 [49.19379 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 29.  6. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 15. 29.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -3.343998432159424
desired expected reward: -8.694385528564453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[49.14346 ]
 [50.15711 ]
 [54.183712]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  6. 22.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 15. 29.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -6.413954257965088
desired expected reward: 48.92646026611328



buy possibilites: [-1] 
expected returns: [[-5.3503866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11. 29.  6. 22.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 3. 29.  1. 15. 29.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -126.0 

action type: buy - action 0.0
Learning step: -8.877557754516602
desired expected reward: 40.26591491699219






Player: 1 
cards in hand: [ 3. 29.  1. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1. 15. 29.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  8.  0.  6. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1. 29.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  8.  0.  6. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1. 29.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  8.  0.  6. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1. 29.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [ 0.  8.  0.  6. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.] 
adversary owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-5.3435364]
 [-5.096326 ]
 [-4.848754 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  6. 10.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0  8  8  0 10  0 15 22  6 11  8  6 10  0  8 29  0  0  0 10  1  0
 10  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  6.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.646986961364746
desired expected reward: -9.997373580932617



action possibilites: [-1] 
expected returns: [[28.448322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  1. 11. 29.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  6.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 10
Learning step: -2.1724400520324707
desired expected reward: -7.021697044372559





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.435547]
 [27.682629]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  1. 11. 29.  6. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  6.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -4.095977783203125
desired expected reward: 24.352344512939453



buy possibilites: [-1] 
expected returns: [[18.98524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  6.  3. 10.  0.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action 0.0
Learning step: -5.49461030960083
desired expected reward: 17.94095230102539






Player: 1 
cards in hand: [15.  6.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3. 10.  0.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
adversary owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
adversary owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
adversary owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  6.  3.  0.  3.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [15.  0. 10.  0.  0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
adversary owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[-6.735265 ]
 [-6.075189 ]
 [-6.1091323]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 10.  0.  0.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  0  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [25. 10.  3.  0. 11.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -5.341011047363281
desired expected reward: 13.644229888916016



action possibilites: [-1] 
expected returns: [[44.900978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [25. 10.  3.  0. 11.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action 15.0
Learning step: -1.9359686374664307
desired expected reward: -8.011157035827637





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[39.345833]
 [41.52996 ]
 [41.302605]
 [37.227886]
 [40.15164 ]
 [44.033165]
 [45.436855]
 [43.025368]
 [39.039326]
 [40.15091 ]
 [41.450813]
 [37.568565]
 [41.62167 ]
 [46.243664]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  8.  5.] 
adversary cards in hand: [25. 10.  3.  0. 11.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -4.562747478485107
desired expected reward: 40.33823013305664



buy possibilites: [-1] 
expected returns: [[0.46279335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [25. 10.  3.  0. 11.] 
adversary cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: -15 

action type: buy - action 22.0
Learning step: -2.6180150508880615
desired expected reward: 34.95054244995117






Player: 1 
cards in hand: [25. 10.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10.  3.  0. 11.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 24 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  3.  0. 11.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 24 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 10.  3.  0. 11.] 
cards in discard: [11. 25.  0.  8.  1.  4.  8.  0.  8. 15.  1.  3.  1.  0.  1. 14.  0. 15.
  3. 29.  1. 29.  0. 10. 15.  6.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
adversary owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 24 
adversary victory points: 0
player victory points: 8 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-5.523718 ]
 [-5.2030935]
 [-4.9486876]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8  0 15 22 11  8  6 10  0  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 25.  1.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -4.390529155731201
desired expected reward: -3.9277358055114746



action possibilites: [-1] 
expected returns: [[-5.415033]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 15 22 11  8  6 10  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 25.  1.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.1271166801452637
desired expected reward: -8.021553039550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.573885 ]
 [-5.3712196]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  8 15 22 11  8  6 10  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 25.  1.  3. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: -3.0908756256103516
desired expected reward: -8.505908966064453






Player: 1 
cards in hand: [ 0. 25.  1.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  3. 22.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 3  8  8 15 22 11  8  6 10  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 22 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  1.  3. 22.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [8. 8. 0. 3. 0.] 
adversary cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.  8.  0. 10.] 
adversary owned cards: [ 3  8  8 15 22 11  8  6 10  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 22 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [8. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-5.530219 ]
 [-5.2166348]
 [-5.2166348]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 3. 0.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  8 15 22 11  8  6 10  8 29  0  0  0 10  1  0 10  0  0  0 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [6. 8. 0. 8. 1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1.0
Learning step: -4.101098537445068
desired expected reward: -9.472318649291992



action possibilites: [-1] 
expected returns: [[-5.530219]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [6. 8. 0. 8. 1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: trash_cards_n_from_hand - action 10
Learning step: -3.67633318901062
desired expected reward: -8.638272285461426





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.6484737]
 [-5.530219 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  1. 11. 29.  6. 22.  0.  8. 22. 15. 10.  0.  0.  8.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [6. 8. 0. 8. 1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -3.6377170085906982
desired expected reward: -9.167936325073242






Player: 1 
cards in hand: [6. 8. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 8. 1.] 
cards in discard: [ 0. 25.  1.  3. 22.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  8  1  1  3 14  0 15  0  1  6  0  4  8 11  1  8 15
 15  3 25  3 29  0  0 25 29 11  1  0  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [22. 29. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 25.  1.  3. 22.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [22. 29. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 25.  1.  3. 22.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [22. 29. 10.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [22. 29. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29. 10. 10.] 
expected returns: [[-7.1410265]
 [-6.4455504]
 [-7.3041983]
 [-7.144708 ]
 [-7.144708 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 29. 10.  0. 10.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [11.  3. 15.  0. 11.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -4.682474136352539
desired expected reward: -10.212693214416504



action possibilites: [-1. 10.] 
expected returns: [[-5.3139277]
 [-5.0356073]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [22. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [11.  3. 15.  0. 11.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: discard_n_cards - action 4
Learning step: -3.574981451034546
desired expected reward: -10.402222633361816



action possibilites: [-1. 10.] 
expected returns: [[-1.9538639]
 [-2.7405725]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [22. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 2 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [11.  3. 15.  0. 11.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action 10.0
Learning step: -2.6007802486419678
desired expected reward: -7.636386871337891





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-2.7401054]
 [-2.5913615]
 [-2.4722412]
 [-2.164709 ]
 [-2.4516275]
 [-1.5891967]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [22. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [11.  3. 15.  0. 11.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -2.754364252090454
desired expected reward: -4.708229064941406



buy possibilites: [-1] 
expected returns: [[-5.8646116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [22. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [11.  3. 15.  0. 11.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -86.0 

action type: buy - action 0.0
Learning step: -4.294948577880859
desired expected reward: -7.0350518226623535






Player: 1 
cards in hand: [11.  3. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 15.  0. 11.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  0  1  6  0  4  8 11  1  8 15 15  3 25
  3 29  0  0 25 29 11  1  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 22.  6. 15.  0.] 
adversary cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 22.  6. 15.  0.] 
adversary cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 11.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [ 0. 22.  6. 15.  0.] 
adversary cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.] 
expected returns: [[32.906937]
 [34.700558]
 [34.07547 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  6. 15.  0.] 
cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [15. 10.  4.  1.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -3.743631362915039
desired expected reward: -9.608242988586426



action possibilites: [-1] 
expected returns: [[25.710009]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  0.  8.  8.  8.] 
cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [15. 10.  4.  1.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: LIBRARY: skip_action_card - action 1
Learning step: -2.9554173946380615
desired expected reward: -8.27756404876709





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.908154]
 [22.810825]
 [25.150928]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  0.  8.  8.  8.] 
cards in discard: [22. 10.  0. 29. 10.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [15. 10.  4.  1.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -4.5602850914001465
desired expected reward: 21.149723052978516






Player: 1 
cards in hand: [15. 10.  4.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  4.  1.  1.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [10.  0.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1. 15. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  4.  1.  1. 14.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [10.  0.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  4.  1.  1. 14.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  5.] 
adversary cards in hand: [10.  0.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  4.  1.  1. 14.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [10.  0.  1.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [10.  0.  1.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[-5.7082114]
 [-5.1037006]
 [-5.368931 ]
 [-5.6919456]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.  8. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [25.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1.0
Learning step: -6.180516719818115
desired expected reward: 18.970415115356445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.7148886]
 [-5.309656 ]
 [-5.0453873]
 [-5.69129  ]
 [-5.103045 ]
 [-5.697516 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8. 11.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  6.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [25.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.631227970123291
desired expected reward: -10.3668212890625



buy possibilites: [-1] 
expected returns: [[-7.7911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  1.  8. 11.] 
cards in discard: [11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [25.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0 15] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -78 

action type: buy - action 11.0
Learning step: -3.7907352447509766
desired expected reward: -9.482025146484375






Player: 1 
cards in hand: [25.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3.  8.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  0  4  8 11  1  8 15 15  3 25  3
 29  0  0 25 29 11  1  0  0  0 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22.  8. 29. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22.  8. 29. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22.  8. 29. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22.  8. 29. 15.  6.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [22.  8. 29. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 29. 15.] 
expected returns: [[-5.7490864]
 [-3.7622814]
 [-5.2183065]
 [-5.4219437]
 [-4.9408164]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8. 29. 15.  6.] 
cards in discard: [11. 10.  0.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.522557258605957
desired expected reward: -12.313657760620117



action possibilites: [-1] 
expected returns: [[-7.337241]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  8. 29.  6.] 
cards in discard: [11. 10.  0.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action 15.0
Learning step: -3.7180469036102295
desired expected reward: -8.658863067626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.285015]
 [-7.348994]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  8. 29.  6.] 
cards in discard: [11. 10.  0.  1.  8. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1
Learning step: -3.5861802101135254
desired expected reward: -10.923421859741211



buy possibilites: [-1] 
expected returns: [[-6.1894283]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  8. 29.  6.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 10.  0.  1.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -106 

action type: buy - action 0.0
Learning step: -5.1164164543151855
desired expected reward: -11.573331832885742






Player: 1 
cards in hand: [ 1.  3. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.  1.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  1.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  9.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  1.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[-6.613301 ]
 [-5.8383465]
 [-5.7388935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.6267499923706055
desired expected reward: -10.816178321838379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-5.0312185]
 [-5.6522694]
 [-5.4202995]
 [-6.072144 ]
 [-5.458658 ]
 [-6.2020373]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.5958333015441895
desired expected reward: -11.20913314819336



buy possibilites: [-1] 
expected returns: [[-11.415312]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15.  0. 29.  0.] 
adversary cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -90.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -126.0 

action type: buy - action 0.0
Learning step: -6.305283546447754
desired expected reward: -11.336503982543945






Player: 1 
cards in hand: [ 0. 15.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 29.  0.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22. 10.  0.  8.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
adversary victory points: -1
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22. 10.  0.  8.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
adversary victory points: -1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1. 15. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22. 10.  0.  8.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
adversary victory points: -1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 25.  1.  3. 22.  8.  6. 15. 11.  3. 11. 15. 10. 15.  4.  1.  1. 14.
  0.  8.  3.  3. 16.  1.  3. 10.  0.  1. 15. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 5. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [22. 10.  0.  8.  0.] 
adversary cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
adversary victory points: -1
player victory points: 8 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [22. 10.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.  8.] 
expected returns: [[-6.4562635]
 [-4.097025 ]
 [-5.539522 ]
 [-5.8330865]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 10.  0.  8.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 4. 15.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: buy - action -1
Learning step: -4.351681709289551
desired expected reward: -15.766993522644043





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-4.825252 ]
 [-5.238606 ]
 [-6.2120347]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  0.  8.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 19. 30. 24. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 4. 15.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -96 

action type: take_action - action -1.0
Learning step: -4.598872184753418
desired expected reward: -11.055134773254395



buy possibilites: [-1] 
expected returns: [[-8.146845]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22. 10.  0.  8.  0.] 
cards in discard: [11. 10.  0.  1.  8. 11.  0. 15. 22.  8. 29.  6.  0.  0.  0.  8. 10.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 4. 15.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -77 

action type: buy - action 3.0
Learning step: -3.7713735103607178
desired expected reward: -9.009979248046875






Player: 1 
cards in hand: [ 4. 15.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4. 15.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  8. 22.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4. 15.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  8. 22.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
adversary victory points: 0
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 22.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.  8.] 
expected returns: [[ 1.1116927]
 [-1.111503 ]
 [-1.6512929]
 [-1.111503 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.  0.  8.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 6. 25. 10.  8.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -85 

action type: buy - action -1
Learning step: -3.857043981552124
desired expected reward: -12.003889083862305



action possibilites: [-1] 
expected returns: [[-6.1135793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  8.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 6. 25. 10.  8.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: LIBRARY: skip_action_card - action 1
Learning step: -2.111706495285034
desired expected reward: -7.628688812255859





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.749095 ]
 [-5.445942 ]
 [-5.194627 ]
 [-5.977771 ]
 [-5.255452 ]
 [-6.1128736]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8.  6.  0. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 19. 30. 23. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 6. 25. 10.  8.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.0666277408599854
desired expected reward: -8.180207252502441



buy possibilites: [-1] 
expected returns: [[-8.039573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  8.  6.  0. 10.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [22. 10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 6. 25. 10.  8.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -32.0 

action type: buy - action 3.0
Learning step: -1.5211591720581055
desired expected reward: -6.715785503387451






Player: 1 
cards in hand: [ 6. 25. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 10.  8.  0.] 
cards in discard: [ 4. 15.  0. 29.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1. 25.  8.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25.  8.  0.  0.] 
cards in discard: [ 4. 15.  0. 29.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1.  8. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  0.  1. 22.] 
cards in discard: [ 4. 15.  0. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0.  0.  1. 22.] 
cards in discard: [ 4. 15.  0. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  7. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  0.  0.  1. 22.] 
cards in discard: [ 4. 15.  0. 29.  3. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 11.  8. 29.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
adversary victory points: 1
player victory points: 8 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29.] 
expected returns: [[-6.1045604]
 [-5.969385 ]
 [-5.5790544]
 [-5.742683 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  8. 29.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -74 

action type: buy - action -1
Learning step: -3.4294495582580566
desired expected reward: -11.469022750854492



action possibilites: [-1. 11.] 
expected returns: [[-6.4535246]
 [-6.261001 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: discard_n_cards - action 5
Learning step: -2.5984675884246826
desired expected reward: -7.344887733459473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-4.9502206]
 [-5.7314157]
 [-5.4377904]
 [-6.2610016]
 [-5.505147 ]
 [-6.4535246]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -2.505600690841675
desired expected reward: -8.959125518798828



buy possibilites: [-1] 
expected returns: [[-6.4535246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 10.  1.  3. 14.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
adversary victory points: 8
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -70.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -4.09769344329834
desired expected reward: -9.047914505004883






Player: 1 
cards in hand: [ 0. 10.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  3. 14.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [10.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 8 


action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3. 14.  3.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [10.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 14.  3.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 19. 30. 22. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [10.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3. 14.  3.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 19. 30. 21. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [10.  1.  3.  0. 11.] 
adversary cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [10.  1.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-6.422363 ]
 [-5.505147 ]
 [-6.2536154]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0. 11.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 19. 30. 21. 29.  8.  0.  8.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15. 11. 15.  8.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -4.013327121734619
desired expected reward: -10.466852188110352



action possibilites: [-1] 
expected returns: [[-15.013422]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  3.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 19. 30. 21. 29.  8.  0.  7.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15. 11. 15.  8.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -48 

action type: gain_card_n - action 3
Learning step: -2.4659125804901123
desired expected reward: -7.903702735900879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-12.998129]
 [-13.872812]
 [-13.544456]
 [-14.492743]
 [-13.612106]
 [-14.719771]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 19. 30. 21. 29.  8.  0.  7.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15. 11. 15.  8.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1
Learning step: -2.7609188556671143
desired expected reward: -17.774341583251953



buy possibilites: [-1] 
expected returns: [[-6.4535246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  3.  0.] 
cards in discard: [ 3. 22. 10.  0.  8.  0.  8.  6.  0. 10.  0.  8.  0. 29.  0. 11.  0. 16.
  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  7.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0. 15. 11. 15.  8.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -46 

action type: buy - action 1.0
Learning step: -1.7515639066696167
desired expected reward: -15.624375343322754






Player: 1 
cards in hand: [ 0. 15. 11. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 15.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 11. 15.  8.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  7.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 22.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 15.  8.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 22.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15. 15.  8.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 0.  0. 22.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 22.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8. 15.] 
expected returns: [[-6.533675 ]
 [-4.1235085]
 [-5.839512 ]
 [-5.5004272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 22.  8. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [29.  1.  1.  3.  3.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -4.000177383422852
desired expected reward: -10.453701972961426





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-4.998063 ]
 [-5.5003967]
 [-6.548134 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  8. 15.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [29.  1.  1.  3.  3.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.000728130340576
desired expected reward: -10.534402847290039



buy possibilites: [-1] 
expected returns: [[-8.107205]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 22.  8. 15.] 
cards in discard: [0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [29.  1.  1.  3.  3.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -114.0 

action type: buy - action 0.0
Learning step: -5.632508754730225
desired expected reward: -10.630571365356445






Player: 1 
cards in hand: [29.  1.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  1.  3.  3.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 11.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 11.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  5.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1. 11.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [0. 0. 6. 3. 1.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-5.7422943]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 15.  0.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1
Learning step: -3.9238412380218506
desired expected reward: -12.031046867370605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-4.7932186]
 [-5.2641115]
 [-5.227205 ]
 [-4.9805136]
 [-5.7561526]
 [-5.5178833]
 [-4.7076583]
 [-5.2270956]
 [-5.2391357]
 [-6.1892185]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 3. 1.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 1.  3. 15.  0.  0.] 
adversary cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: take_action - action -1.0
Learning step: -4.0315423011779785
desired expected reward: -9.773836135864258



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1.  3. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 15.  0.  0.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
  0 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  4.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [ 4. 15.  0. 29.  3. 14. 10. 25.  6.  8.  0.  0.  1. 22.  3. 10.  0.  1.
  3. 14.  3. 16. 11.  0. 15. 15.  8.  3.  3. 11. 29.  1.  1. 11. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 8.  8. 10.  8.  0.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
adversary owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 8.  8. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 10.  8.] 
expected returns: [[-6.4535246]
 [-5.7971187]
 [-5.7971187]
 [-5.505147 ]
 [-5.7971187]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 10.  8.  0.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -4.022380828857422
desired expected reward: -10.211596488952637



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-6.4535246]
 [-5.797118 ]
 [-5.797118 ]
 [-5.797118 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8. 0. 0.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8 15 22 11  8  6 10  8 29  0 10  1  0 10  0  0  0 22  0 11  0  0  3
  3  0 16  1  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -63 

action type: take_action - action 10.0
Learning step: -3.00876522064209
desired expected reward: -8.513912200927734



action possibilites: [-1.] 
expected returns: [[-4.5183706]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: trash_cards_n_from_hand - action 7
Learning step: -2.055478096008301
desired expected reward: -6.637289047241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-3.2902193]
 [-4.5407963]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [11.  3. 11.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -2.0617802143096924
desired expected reward: -6.580150604248047






Player: 1 
cards in hand: [11.  3. 11.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0. 16.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8 11  1  8 15 15  3  3 29  0
 25 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 0. 16. 10. 10. 29.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
adversary owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 0. 16. 10. 10. 29.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
adversary owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 0. 16. 10. 10. 29.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
adversary owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.] 
cards in discard: [0. 0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 0. 16. 10. 10. 29.] 
adversary cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
adversary owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
adversary victory points: 1
player victory points: 9 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0. 16. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10. 29.] 
expected returns: [[-6.3304605]
 [-5.1152725]
 [-5.3867874]
 [-5.3867874]
 [-5.847126 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10. 10. 29.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 0.  0. 16.  3. 11.  0.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0  0] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -84 

action type: buy - action -1.0
Learning step: -4.098940849304199
desired expected reward: -8.639738082885742



action possibilites: [-1. 16. 10. 29.] 
expected returns: [[-11.79338  ]
 [-10.324361 ]
 [-10.650853 ]
 [-11.2249775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10. 29.  0.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 0.  0. 16.  3. 11.  0.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0  0] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -63 

action type: take_action - action 10.0
Learning step: -3.1276931762695312
desired expected reward: -8.514482498168945





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-10.228582]
 [-10.803295]
 [-12.018504]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 10. 29.  0.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 0.  0. 16.  3. 11.  0.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0  0] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: take_action - action -1.0
Learning step: -2.8577041625976562
desired expected reward: -14.651083946228027



Player 1 won the game! 



Player 0 bought cards:
Copper: 16 
Silver: 4 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 9 

Remodel: 0 
Workshop: 3 
Chapel: 6 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 4 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 16. 10. 29.  0.] 
cards in discard: [ 0.  0.  0. 22.  8. 15.  0.  0.  6.  3.  1. 10.  8.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 22 11  8  6 10  8 29 10  1 10  0  0  0 22  0 11  0  0  3  3  0 16  1
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 18. 30. 21. 29.  8.  0.  6.  4.  0.  7.  7.  6. 10.  4.  7.  3.] 
adversary cards in hand: [ 1. 15. 10.  1.  3.] 
adversary cards in discard: [ 0.  0. 16.  3. 11.  0.] 
adversary owned cards: [ 3  3 22  3 10 10  1  1  3 14 15  1  6  4  8  1  8 15 15  3  3 29  0 25
 29 11  1  0  0  0 15  0 16  0 14  3 16 11 15  0  0] -> size -> 41 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5 -500    1  -80    0    0   20  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -594 

action type: buy - action 0.0
Learning step: -29.18857192993164
desired expected reward: -39.417152404785156



