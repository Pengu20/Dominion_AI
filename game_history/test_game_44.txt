 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.159588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0        0        0
        0        0        0        0        0        0        8        0] 
sum of rewards: -3000207 

action type: buy - action 8.0
Learning step: -120004.46875
desired expected reward: -120099.6796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  9.947509]
 [ 20.626665]
 [ 15.874584]
 [-34.30581 ]
 [ 14.894356]
 [ 19.538115]
 [ 12.449725]
 [ 26.991734]
 [ 15.625551]
 [ 16.02613 ]
 [ 21.959072]
 [ 10.571689]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.539457321166992



buy possibilites: [-1] 
expected returns: [[3.5914392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.99173355102539






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [10.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.16990805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.5914392471313477





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ -0.5670066 ]
 [  9.538829  ]
 [  4.9544477 ]
 [-42.195915  ]
 [  8.326267  ]
 [  1.7323513 ]
 [  5.1765804 ]
 [  0.29991317]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.015177249908447266



buy possibilites: [-1] 
expected returns: [[-1.1835668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 9.538827896118164






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[12.614963]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.1835668087005615





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.816455 ]
 [ 21.584574 ]
 [-11.085476 ]
 [ 17.186874 ]
 [ -4.1961155]
 [-31.02318  ]
 [ 16.364437 ]
 [ 20.505497 ]
 [ 14.172823 ]
 [ 24.716614 ]
 [ 27.355875 ]
 [ 17.009832 ]
 [ 21.841408 ]
 [ 17.367735 ]
 [  1.911231 ]
 [ 22.747063 ]
 [ 12.494497 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.645824432373047



buy possibilites: [-1] 
expected returns: [[14.798798]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  3.  0.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 27.35586929321289






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[7.0206203]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.798797607421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  6.759739 ]
 [ 17.19036  ]
 [ 12.590467 ]
 [-39.882046 ]
 [ 16.173422 ]
 [  9.207609 ]
 [ 12.810324 ]
 [  7.6116257]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 6.28889274597168



buy possibilites: [-1] 
expected returns: [[5.142189]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [29.  0.  0.  0.  0.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 17.190357208251953






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  1. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 3.  3.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[48.454777]
 [62.079903]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.142189025878906



action possibilites: [-1.] 
expected returns: [[27.865236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 58.52333068847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 27.879818]
 [ 37.845295]
 [ 33.426895]
 [-19.537735]
 [ 32.73259 ]
 [ 36.901207]
 [ 30.693626]
 [ 43.53393 ]
 [ 33.391   ]
 [ 33.750385]
 [ 39.04921 ]
 [ 28.914436]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.865236282348633



buy possibilites: [-1] 
expected returns: [[15.737921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 0.] 
cards in discard: [29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 43.53392791748047






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  0.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  9. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11. 10.  0.  0.  0.  3. 29. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  0.] 
adversary cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-4.358324]
 [ 8.678742]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  0.] 
cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.737920761108398



action possibilites: [-1.] 
expected returns: [[21.478443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 9.415777206420898





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 19.992891 ]
 [ 29.604713 ]
 [ -3.7526548]
 [ 25.347813 ]
 [  2.9627647]
 [-24.44974  ]
 [ 24.75277  ]
 [ 28.51701  ]
 [ 21.987932 ]
 [ 32.454674 ]
 [ 34.94371  ]
 [ 25.331247 ]
 [ 29.827263 ]
 [ 25.656223 ]
 [  9.587146 ]
 [ 30.642796 ]
 [ 21.23115  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 29.  3.  3.  1.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.478443145751953



buy possibilites: [-1] 
expected returns: [[20.71078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [29. 29.  3.  3.  1.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 34.94371032714844






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-7.4099627]
 [ 5.4909487]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.710779190063477



action possibilites: [-1.] 
expected returns: [[11.701893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.243823051452637





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 11.725282]
 [ 21.523623]
 [ 17.238516]
 [ -5.629724]
 [-33.467594]
 [ 16.572523]
 [ 20.528028]
 [ 13.737873]
 [ 24.491108]
 [ 26.792488]
 [ 17.186329]
 [ 21.78198 ]
 [ 17.525259]
 [  1.194171]
 [ 22.674892]
 [ 12.910244]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  5. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.701892852783203



buy possibilites: [-1] 
expected returns: [[19.529016]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10.  3. 11.  0.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 17.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.792478561401367






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 11.  0.] 
cards in discard: [ 3.  0.  0.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  1.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 3.  0.  0.  0. 10.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  1.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 3.  0.  0.  0. 10.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  1.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.] 
cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  1.] 
adversary cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 2.966898]
 [16.092855]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  1.] 
cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.529016494750977



action possibilites: [-1. 29.] 
expected returns: [[28.471777]
 [41.800926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  1. 29.] 
cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.643020629882812



action possibilites: [-1.] 
expected returns: [[34.75825]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.80093002319336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 33.78371 ]
 [ 43.416935]
 [  9.82611 ]
 [ 39.225365]
 [ 16.46874 ]
 [-10.755658]
 [ 38.601162]
 [ 42.41832 ]
 [ 35.714252]
 [ 46.30353 ]
 [ 48.727997]
 [ 39.19583 ]
 [ 43.653206]
 [ 39.525764]
 [ 23.282347]
 [ 44.48756 ]
 [ 35.033356]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [29. 29.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  4. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.75825119018555



buy possibilites: [-1] 
expected returns: [[12.98908]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 1. 1.] 
cards in discard: [29. 29.  0.  3.  0.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  0. 29.] 
adversary cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 48.72800064086914






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 29.] 
cards in discard: [ 3.  0.  0.  0. 10.  3. 10.  3. 11.  0. 10.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-9.056099 ]
 [ 2.8321133]
 [ 2.8321133]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.989080429077148



action possibilites: [-1. 29.] 
expected returns: [[ 2.4159265]
 [16.528706 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.2773780822753906



action possibilites: [-1. 29.] 
expected returns: [[43.29579 ]
 [57.695023]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 16.52871322631836



action possibilites: [-1. 29.] 
expected returns: [[28.809132]
 [41.737198]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 57.69501876831055



action possibilites: [-1.] 
expected returns: [[35.031246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.73720169067383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 36.57416 ]
 [ 46.575737]
 [ 11.180399]
 [ 42.31801 ]
 [ 18.273891]
 [ 48.979717]
 [-10.87052 ]
 [ 41.565014]
 [ 45.788414]
 [ 38.932602]
 [ 49.80641 ]
 [ 52.2104  ]
 [ 42.24245 ]
 [ 46.875015]
 [ 42.605495]
 [ 25.57936 ]
 [ 47.83555 ]
 [ 37.662136]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 9 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.031246185302734



buy possibilites: [-1] 
expected returns: [[38.490997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 0 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 47.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 52.210384368896484






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [29.  0. 11.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [29.  0. 11.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  8. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [29.  0. 11.  3.  0. 11. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[30.11879 ]
 [43.489464]
 [43.489464]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29.  3.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.490997314453125



action possibilites: [-1. 29.] 
expected returns: [[25.580536]
 [38.033485]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  3.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.748374938964844



action possibilites: [-1.] 
expected returns: [[63.995575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.033477783203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[66.37033 ]
 [75.25797 ]
 [71.37479 ]
 [50.23904 ]
 [24.363737]
 [70.841995]
 [74.35054 ]
 [68.38274 ]
 [77.912415]
 [80.13172 ]
 [71.38923 ]
 [75.4764  ]
 [71.69242 ]
 [56.607002]
 [76.24453 ]
 [67.56411 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.995574951171875



buy possibilites: [-1] 
expected returns: [[56.160713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 1.] 
cards in discard: [29. 29. 29. 29. 29.  0.  0.  0.  0.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  3. 10.  0.  3.] 
adversary cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 80.13172149658203






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.  3.] 
cards in discard: [29.  0. 11.  3.  0. 11. 11. 10.  0. 10.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 8.988877]
 [20.884716]
 [20.884716]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  1.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 56.16071319580078



action possibilites: [-1. 29.] 
expected returns: [[12.57431 ]
 [26.375923]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 19.358884811401367



action possibilites: [-1.] 
expected returns: [[35.931583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 26.37592124938965





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.6942  ]
 [47.695778]
 [12.299274]
 [43.438053]
 [19.39393 ]
 [50.09975 ]
 [-9.521711]
 [42.685066]
 [46.908463]
 [40.05264 ]
 [50.92645 ]
 [53.330433]
 [43.362495]
 [47.995056]
 [43.725548]
 [26.699389]
 [48.955585]
 [38.78218 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 8 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  1. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 35.931583404541016



buy possibilites: [-1] 
expected returns: [[38.561996]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
  32.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.33042907714844






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  0. 29.  0.  1.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29.  0. 29.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 9.0183525]
 [23.210314 ]
 [23.210314 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  1.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.56199645996094



action possibilites: [-1.] 
expected returns: [[66.73864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 16.24810028076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[67.07787 ]
 [76.606316]
 [72.356895]
 [48.481956]
 [19.77596 ]
 [71.81998 ]
 [75.56032 ]
 [69.5243  ]
 [79.44292 ]
 [72.39856 ]
 [76.82979 ]
 [72.72227 ]
 [55.669586]
 [77.64153 ]
 [68.314514]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10. 10.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 66.73863983154297



buy possibilites: [-1] 
expected returns: [[60.964714]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  3. 10. 29.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 175 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 79.4428939819336






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [11.  0.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 10. 29.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 29.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 29.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 29.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29.  3.  0. 29.  3.] 
adversary cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29.  3.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 93.25202 ]
 [104.068695]
 [104.068695]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.  3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  0.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 60.96471405029297



action possibilites: [-1. 29.] 
expected returns: [[125.64587]
 [137.20935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  0.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 99.8344497680664



action possibilites: [-1.] 
expected returns: [[116.25834]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  0.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 132.60745239257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[113.52039 ]
 [122.393974]
 [118.68019 ]
 [ 64.06205 ]
 [121.71827 ]
 [115.7212  ]
 [119.14453 ]
 [115.14728 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3. 29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  0.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 116.25833892822266



buy possibilites: [-1] 
expected returns: [[34.602867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [29. 29. 29.  0.  1.  0.  0.  0. 29. 25. 29.  0.  0.  1.  3. 29. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0. 10.  0.] 
adversary cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: -1 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 122.39397430419922






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [11. 10.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10.  0.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 10.  0.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0. 10.  0.] 
cards in discard: [ 3.  3. 11.  0.  3.  0.  1.  0. 11.  0.  3. 10. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 29.] 
expected returns: [[-20.364662 ]
 [ -9.0458145]
 [ -9.0458145]
 [ -9.0458145]
 [ -9.0458145]
 [ -9.0458145]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.602867126464844



action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[-16.193981 ]
 [ -5.2772684]
 [ -5.2772684]
 [ -5.2772684]
 [ -5.2772684]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: -21.61939239501953



action possibilites: [-1. 29. 29.] 
expected returns: [[-4.52026 ]
 [ 7.188589]
 [ 7.188589]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.] 
cards in discard: [29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -9.582940101623535



action possibilites: [-1.] 
expected returns: [[10.511566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 3 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.6765995025634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 10.125517  ]
 [ 19.46608   ]
 [ 15.383183  ]
 [ -7.069298  ]
 [-34.929104  ]
 [ 14.850895  ]
 [ 18.431225  ]
 [ 11.880471  ]
 [ 22.16219   ]
 [ 15.402657  ]
 [ 19.675987  ]
 [ 15.712732  ]
 [ -0.27681446]
 [ 20.44703   ]
 [ 11.506676  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  9.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.511566162109375



buy possibilites: [-1] 
expected returns: [[52.305172]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [29. 29. 29. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 215 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 22.162189483642578






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [11.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7. 10.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 25.  0.  1.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 25.  0.  1.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8. 10. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 25.  0.  1.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [8. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8. 10. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  3. 25.  0.  1.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 1.  3. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[ 9.995929]
 [19.627113]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25.  0.  1.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8. 10. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0] -> size -> 25 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.305171966552734



action possibilites: [-1] 
expected returns: [[92.39694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 1. 3. 1.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.240419387817383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 92.73196 ]
 [101.383415]
 [ 69.38452 ]
 [ 97.61386 ]
 [ 75.8278  ]
 [ 48.913185]
 [ 97.19738 ]
 [100.42696 ]
 [ 94.439415]
 [103.81273 ]
 [ 97.693665]
 [101.570015]
 [ 97.97353 ]
 [ 82.53902 ]
 [102.262794]
 [ 94.16311 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 3. 1.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 7 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  8.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.39694213867188



buy possibilites: [-1] 
expected returns: [[77.09939]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 1. 3. 1.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6] -> size -> 26 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: -12.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 103.81270599365234






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29. 29.] 
adversary cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[62.20443]
 [73.51565]
 [73.51565]
 [73.51565]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 29.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 77.0993881225586



action possibilites: [-1. 29.] 
expected returns: [[ 6.8101997]
 [18.868168 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.14722442626953



action possibilites: [-1.] 
expected returns: [[52.216484]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1. 29.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.177129745483398





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.122025]
 [56.98348 ]
 [53.07489 ]
 [30.281078]
 [ 2.293087]
 [52.681854]
 [56.121456]
 [50.00724 ]
 [59.60226 ]
 [53.203705]
 [57.2026  ]
 [53.502434]
 [37.37712 ]
 [57.96321 ]
 [49.62231 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1. 29.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  7.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.21648406982422



buy possibilites: [-1] 
expected returns: [[15.428257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29. 29. 29. 25. 29. 29. 29.  0.  0. 25. 25.  1.  3.  0.  1.  3.  1. 29.
  3. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 11. 10.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 225 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 59.602264404296875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 27. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 26. 30. 26. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
adversary victory points: 3
player victory points: 7 





Player: 0 
cards in hand: [25.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[-9.777523 ]
 [-1.1469412]
 [ 0.7568631]
 [ 0.7568631]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.42825698852539



action possibilites: [-1. 25. 29.] 
expected returns: [[-6.4309735]
 [ 3.9487872]
 [ 6.173319 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.] 
cards in discard: [29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 26. 30. 25. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -3.6754534244537354



action possibilites: [-1. 25.] 
expected returns: [[ 9.839874]
 [20.030857]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [29.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 25. 30.  8.  9. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3] -> size -> 29 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.1329536437988281



action possibilites: [-1] 
expected returns: [[16.711893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.030853271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 16.121693]
 [ 25.93806 ]
 [ 21.589634]
 [-29.271194]
 [ 20.86916 ]
 [ 24.912945]
 [ 18.442451]
 [ 21.50115 ]
 [ 21.850464]
 [ 27.080019]
 [ 17.09414 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [29.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.71189308166504



buy possibilites: [-1] 
expected returns: [[38.469032]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.] 
cards in discard: [29.  1. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [11. 10.  3. 29.  0.] 
adversary cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6] -> size -> 30 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 63 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 27.08002281188965






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [11. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 29.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 29.  0.] 
cards in discard: [ 8.  0. 11.  0.  0.  3.  3.  6. 15.  0.  0.  3.  1. 10.  3.  3. 11.  3.
  0. 10.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 29. 29.  3. 29.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 1. 29. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[60.503983]
 [72.56352 ]
 [72.56352 ]
 [72.56352 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.469032287597656



action possibilites: [-1. 29. 29.] 
expected returns: [[78.86115]
 [89.67896]
 [89.67896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.  3.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 67.8878402709961



action possibilites: [-1. 29. 29.] 
expected returns: [[117.73051]
 [128.18002]
 [128.18002]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 85.37638092041016



action possibilites: [-1. 29.] 
expected returns: [[65.44515]
 [77.34898]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 124.16156005859375



action possibilites: [-1.] 
expected returns: [[26.855099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 4 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 72.73703002929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 24.933044  ]
 [ 33.753418  ]
 [  0.70876074]
 [ 29.979553  ]
 [  7.258648  ]
 [-20.309837  ]
 [ 29.546413  ]
 [ 32.900143  ]
 [ 26.754658  ]
 [ 36.29238   ]
 [ 30.070358  ]
 [ 33.96389   ]
 [ 30.36008   ]
 [ 14.352621  ]
 [ 34.699787  ]
 [ 26.492943  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  6.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.855098724365234



buy possibilites: [-1] 
expected returns: [[14.106634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [0. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.   80.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 47.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 36.29234313964844






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  7. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  0.  1.  0.  0.] 
adversary cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [29.  0.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[19.865128]
 [30.13871 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  1.  0.  0.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.106634140014648



action possibilites: [-1. 25.] 
expected returns: [[36.389675]
 [45.810513]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  8. 10.  7.  9.  5.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.14710235595703



action possibilites: [-1] 
expected returns: [[13.77046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  5.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 45.81050491333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 13.994513  ]
 [ 22.26186   ]
 [ -6.6367574 ]
 [ 18.789356  ]
 [ -0.77391696]
 [-25.016333  ]
 [ 18.391693  ]
 [ 21.35106   ]
 [ 14.78108   ]
 [ 24.507584  ]
 [ 18.84465   ]
 [ 22.431559  ]
 [ 19.101202  ]
 [  5.200939  ]
 [ 23.069834  ]
 [ 15.608017  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25] -> size -> 28 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  5.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.77046012878418



buy possibilites: [-1] 
expected returns: [[13.43029]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.  1. 15. 29. 29. 25.  0.  0. 29. 25.  3.  3. 25.  3. 25. 29. 29. 29.
 29.  1.  1. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  0.  3.  3. 10.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -90.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 7.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 24.507579803466797






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  3. 10.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  3. 10.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [29.  1. 29.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  1. 29.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-9.22458  ]
 [ 3.3113365]
 [ 3.3113365]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  3.  1.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.430290222167969



action possibilites: [-1. 29.] 
expected returns: [[12.469137]
 [25.169582]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -1.6173628568649292



action possibilites: [-1.] 
expected returns: [[24.075138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 20.17536735534668





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 22.53589 ]
 [ 31.81496 ]
 [ 27.714571]
 [-20.107439]
 [ 30.65902 ]
 [ 24.040768]
 [ 28.014482]
 [ 23.894684]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 26. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.075138092041016



buy possibilites: [-1] 
expected returns: [[30.091156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [1. 1. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 11.  3.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 29 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 31.814964294433594






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 29. 29. 15.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  9.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 29. 29. 15.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 29. 29. 15.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 1.  0. 29. 29. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 15.] 
expected returns: [[67.364746]
 [79.932365]
 [79.932365]
 [76.04517 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 29. 15.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.091156005859375



action possibilites: [-1. 29. 15. 25.] 
expected returns: [[37.836918]
 [50.397587]
 [46.461086]
 [48.11154 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 15. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 75.05857849121094



action possibilites: [-1. 15. 25.] 
expected returns: [[35.78985]
 [44.62613]
 [46.32759]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  7. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8] -> size -> 34 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.523555755615234



action possibilites: [-1] 
expected returns: [[43.12631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 46.32756042480469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[41.4732   ]
 [50.45065  ]
 [46.621696 ]
 [-1.6947402]
 [46.071617 ]
 [49.605762 ]
 [43.195766 ]
 [46.627087 ]
 [46.932045 ]
 [51.460793 ]
 [42.77952  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  8.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.12630844116211



buy possibilites: [-1] 
expected returns: [[53.137264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [10.  3.  3.  0. 29.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 51.46080017089844






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [10.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0. 29.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  8.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  3.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  7.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [25.  0.  0. 29.  0.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [25.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-42.38344 ]
 [-39.138847]
 [-38.59237 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29.  0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  7.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 53.137264251708984



action possibilites: [-1. 25.] 
expected returns: [[18.087894]
 [26.011272]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  0.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  6. 10.  7.  7.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8] -> size -> 36 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -37.41709518432617



action possibilites: [-1] 
expected returns: [[-11.3783045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.011272430419922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[-11.707751 ]
 [ -3.1840222]
 [ -6.8177123]
 [-51.97966  ]
 [ -7.2405405]
 [ -4.1584315]
 [-10.718756 ]
 [ -6.7706027]
 [ -6.5031605]
 [ -2.3501136]
 [-10.144739 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  7.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.378304481506348



buy possibilites: [-1] 
expected returns: [[-2.7845707]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  3.  6. 11.  0.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6] -> size -> 37 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 15.0
Learning step: 0
desired expected reward: -2.35011625289917






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  6. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 11.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29. 15. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29. 15. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 11.  0.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [29.  0.  3. 29. 25.] 
adversary cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29. 15. 29. 25.  0.  0.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [29.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[11.109047]
 [23.136623]
 [23.136623]
 [20.859787]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29. 25.] 
cards in discard: [ 1.  1.  1. 29. 29.  3.  0.  3.  1. 25. 15. 29. 29. 25.  0. 15.  0. 25.
 29. 15. 29. 25.  0.  0.  0. 25. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.7845706939697266



action possibilites: [-1. 25. 29.] 
expected returns: [[-9.82314   ]
 [ 0.06823063]
 [ 2.3925953 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 29.] 
cards in discard: [29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.460956573486328



action possibilites: [-1. 25.] 
expected returns: [[30.266472]
 [41.16362 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.] 
cards in discard: [29. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 25. 30.  8.  5. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.483337879180908



action possibilites: [-1] 
expected returns: [[45.951866]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 25.] 
cards in discard: [29. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 25. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.16363525390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[43.784157 ]
 [53.33701  ]
 [49.104607 ]
 [ 0.8159208]
 [52.24297  ]
 [45.682613 ]
 [49.365208 ]
 [44.89579  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 25.] 
cards in discard: [29. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.951866149902344



buy possibilites: [-1] 
expected returns: [[68.8753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15. 25.] 
cards in discard: [29. 29.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0. 15. 10.  1.  8.] 
adversary cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 109 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 53.33700942993164






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0. 15. 10.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15. 10.  1.  8.] 
cards in discard: [10.  0.  6.  0.  3.  0.  6.  3.  0.  3.  3. 10.  8.  0. 11. 11.  3.  0.
  6.  0.  8. 29. 10.  3.  3.  0.  6.  0.  0.  3.  6. 11.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  3. 29.  1.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  3. 29.  1.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  1.  8.  3.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  3. 29.  1.  0.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15.  3. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[20.658232]
 [28.587492]
 [32.202377]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 29.  1.  0.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.87529754638672



action possibilites: [-1. 15. 29.] 
expected returns: [[85.90296]
 [93.36672]
 [96.71113]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0. 29.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.703184127807617



action possibilites: [-1. 15.] 
expected returns: [[ 95.22725]
 [101.78993]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25
 25 25 15 25 25  1 15 15  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 92.51964569091797



action possibilites: [-1] 
expected returns: [[8.123637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 101.7899169921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  6.326516 ]
 [ 14.833406 ]
 [ 11.118689 ]
 [ -9.615559 ]
 [-35.33089  ]
 [ 10.671562 ]
 [ 13.867504 ]
 [  7.889681 ]
 [ 17.235172 ]
 [ 11.161498 ]
 [ 15.015757 ]
 [ 11.438549 ]
 [ -3.3121724]
 [ 15.699049 ]
 [  7.74586  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  4.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.123637199401855



buy possibilites: [-1] 
expected returns: [[10.575325]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 11.  3.  8.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 335 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.235157012939453






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  8.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  0. 25.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  8.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 24. 30. 25. 30.  8.  4. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  0. 25.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  8.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 25. 30.  8.  4. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [15.  0. 25.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [15.  0. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 25.] 
expected returns: [[-28.971806]
 [-22.177048]
 [-20.870377]
 [-20.870377]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0. 25.  0. 25.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  4. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0. 11. 29.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0] -> size -> 40 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 10.575325012207031



action possibilites: [-1] 
expected returns: [[40.44812]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0. 25. 25. 29.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0. 11. 29.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -20.870376586914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[37.45622  ]
 [42.091503 ]
 [-5.2550397]
 [38.52818  ]
 [39.342686 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 25. 25. 29.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 24. 30. 25. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0. 11. 29.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.4481201171875



buy possibilites: [-1] 
expected returns: [[35.661854]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0. 25. 25. 29.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [10.  0. 11. 29.  0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 42.09151840209961






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [10.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11. 29.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  1. 29.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  1. 29.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  7.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  1. 29.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0.  0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  6.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 1.  1. 29.  0. 25.] 
adversary cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 1.  1. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[ 8.970569]
 [18.577019]
 [16.74781 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1. 29.  0. 25.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  6.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  3. 11.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11] -> size -> 42 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.6618537902832



action possibilites: [-1. 25.] 
expected returns: [[12.713909]
 [20.575676]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  1.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 24. 30.  8.  3. 10.  6.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  3. 11.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11] -> size -> 42 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.82400131225586



action possibilites: [-1] 
expected returns: [[-17.46811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  1. 29.  0.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  3. 11.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.575672149658203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-20.266613]
 [-12.45737 ]
 [-38.956997]
 [-15.888974]
 [-33.400856]
 [-55.52323 ]
 [-16.286285]
 [-13.521362]
 [-19.47209 ]
 [-10.397141]
 [-15.876424]
 [-12.326831]
 [-15.635304]
 [-28.256752]
 [-11.762577]
 [-18.91845 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 29.  0.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  3.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  3. 11.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.468109130859375



buy possibilites: [-1] 
expected returns: [[0.61069965]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  1. 29.  0.] 
cards in discard: [29. 29.  1. 29. 29. 25.  0.  3. 15. 25.  1.  3. 25. 29. 29. 15.  3.  3.
 25. 15.  0.  0. 25. 25. 29.  1. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 0.  6.  3.  3. 11.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -10.397132873535156






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  3. 11.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 25.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  3. 11.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [ 3. 25.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-8.47201  ]
 [ 1.4936476]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  2. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6] -> size -> 43 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.6106996536254883



action possibilites: [-1] 
expected returns: [[22.620949]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6] -> size -> 44 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.4936528205871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[ 20.169056]
 [ 28.945015]
 [ 25.142427]
 [-22.408157]
 [ 24.656672]
 [ 28.004211]
 [ 21.802057]
 [ 25.174198]
 [ 25.463943]
 [ 29.868523]
 [ 21.518667]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  6.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6] -> size -> 44 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.620948791503906



buy possibilites: [-1] 
expected returns: [[15.8623295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 29. 29.] 
cards in discard: [15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [0. 6. 6. 0. 0.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6] -> size -> 44 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 253 

action type: buy - action 15.0
Learning step: 0
desired expected reward: 29.868534088134766






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 0. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [25. 25. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[ 9.576832]
 [17.80894 ]
 [17.80894 ]
 [17.80894 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  1.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  1. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0] -> size -> 45 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.862329483032227



action possibilites: [-1] 
expected returns: [[36.062115]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  1. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.80892562866211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[32.25187 ]
 [40.468796]
 [36.97833 ]
 [39.594044]
 [33.647   ]
 [37.417248]
 [34.036453]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  1. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.06211471557617



buy possibilites: [-1] 
expected returns: [[40.03658]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  1. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [6. 6. 6. 0. 8.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 46 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 199 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 40.46876907348633






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [6. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 8.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8
  0  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [15.  3. 25. 15.  0.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [15.  3. 25. 15.  0.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6] -> size -> 45 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [15.  3. 25. 15.  0.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [15.  3. 25. 15.  0.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [15.  3. 25. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 15.] 
expected returns: [[13.091312]
 [19.692432]
 [20.948948]
 [19.692432]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 25. 15.  0.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.03657913208008



action possibilites: [-1] 
expected returns: [[43.11201]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 15.  0. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.948949813842773





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[40.519928]
 [42.212265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3. 15.  0. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3. 10. 10.  0.  3.] 
adversary cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.11201095581055






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10.  0.  3.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  1. 29. 29. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  3.  3.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  1. 29. 29. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
action values: 3 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  1. 29. 29. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 23. 30. 24. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  1. 29. 29. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [10.  0. 15.  1.  8.  3.  0.  3. 11.  3.  8.  0.  6.  0. 11. 29. 10. 11.
  0.  0.  6.  0.  6.  3.  3. 11.  6.  0.  0.  6.  6.  0.  0.  6.  0.  8.
  6.  6.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 3.  1. 29. 29. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 3.  1. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[-4.7699275]
 [ 5.319992 ]
 [ 5.319992 ]
 [ 3.325574 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29. 29. 25.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.21226501464844



action possibilites: [-1. 29. 29.] 
expected returns: [[-21.334156]
 [-10.735743]
 [-10.735743]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 29.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 3.392282009124756



action possibilites: [-1. 25.] 
expected returns: [[-19.025433]
 [-10.503952]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.873086929321289



action possibilites: [-1] 
expected returns: [[-12.156014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -10.503948211669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.07978  ]
 [ -7.2013106]
 [-10.531904 ]
 [-29.584852 ]
 [-10.89349  ]
 [ -8.072394 ]
 [-14.17477  ]
 [ -5.0701246]
 [-10.462148 ]
 [ -7.042552 ]
 [-10.217478 ]
 [-23.735582 ]
 [ -6.4415765]
 [-13.54899  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  2.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.156014442443848



buy possibilites: [-1] 
expected returns: [[15.468281]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [3. 6. 1. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  60   0   0   0   0 -30   0   0 250   0] 
sum of rewards: 425 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -5.070137023925781






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 6. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  1. 15. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29. 25. 29. 29. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  1. 15. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29. 25. 29. 29. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 1. 3. 0.] 
cards in discard: [0.] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [ 0.  3.  1. 15. 25.] 
adversary cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29. 25. 29. 29. 25.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [ 0.  3.  1. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-6.9575996 ]
 [ 0.90209055]
 [ 2.3974152 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 15. 25.] 
cards in discard: [15. 25.  3.  1.  0.  0. 29. 29.  1. 25. 25. 25.  0.  1. 29. 29. 25. 15.
  3. 15.  0. 29. 29.  3. 25.  1. 29. 25. 29. 29. 25.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3  0] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.468280792236328



action possibilites: [-1] 
expected returns: [[-0.04570079]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 15.  3.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3  0] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.3974099159240723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  0.3857727]
 [  9.321481 ]
 [  5.458908 ]
 [-15.501878 ]
 [  4.901103 ]
 [  8.375029 ]
 [  1.9477248]
 [ 11.94417  ]
 [  5.4399967]
 [  9.532027 ]
 [  5.7404957]
 [ -9.209505 ]
 [ 10.286935 ]
 [  1.6488171]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 15.  3.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 23. 30. 23. 30.  8.  0. 10.  6.  7.  1.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3  0] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.045700788497924805



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 6 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 9 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 4 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0.  3.  1. 15.  3.  1.] 
cards in discard: [25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 29  1 29  1 29 29 29 29 29 29 29 25  1 25 25
 25 15 25 25  1 15 15  1 25  3 25 15  1 25 25] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 23. 30.  8.  0. 10.  6.  7.  0.  0. 10. 10.  6. 10.  5.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [0. 3. 6. 1. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10 29 10 11 11  3 10  3 11  3  1  0  0  8  0
  6 15  3  3  6  0 10  6  8  6  8  6  0  6  0  6 11  6  6  0  6  0  3  0] -> size -> 48 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     150       0       0      20       0       0
       0       0     -40       0       0     125       0] 
sum of rewards: 3000250 

action type: buy - action 25.0
Learning step: 120009.515625
desired expected reward: 120021.4609375



