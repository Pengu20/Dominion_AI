 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.74822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -30        0        0       40        0
        0        0        0        0        0        0       27        0] 
sum of rewards: -2999968 

action type: buy - action 11.0
Learning step: -299994.34375
desired expected reward: -300018.90625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[74.05932 ]
 [90.4387  ]
 [84.76003 ]
 [66.562965]
 [94.12119 ]
 [83.25617 ]
 [77.63249 ]
 [70.44294 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.33817291259766



buy possibilites: [-1] 
expected returns: [[59.51402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 94.1211929321289






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  0.  3.  3.  0.  0. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[73.712685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 59.51401901245117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 77.20546 ]
 [ 93.95048 ]
 [ 88.21349 ]
 [ 69.20223 ]
 [ 81.62256 ]
 [ 97.76259 ]
 [ 86.628105]
 [105.952126]
 [ 78.3992  ]
 [ 80.89111 ]
 [ 95.14422 ]
 [ 73.54819 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 72.35401916503906



buy possibilites: [-1] 
expected returns: [[34.18093]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  3.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 105.95211029052734






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 11.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[28.089062]
 [48.47445 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.180931091308594



action possibilites: [-1.] 
expected returns: [[32.103027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 47.08675003051758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.525757]
 [44.950916]
 [41.410137]
 [29.6203  ]
 [37.22877 ]
 [47.446697]
 [40.38118 ]
 [53.30722 ]
 [35.271572]
 [36.840397]
 [45.69673 ]
 [32.346508]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.10302734375



buy possibilites: [-1] 
expected returns: [[31.570156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 53.307220458984375






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.  0.  0. 14.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [ 0.  8. 11.  0.  0. 14.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 11.] 
adversary cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[42.27981 ]
 [60.294018]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 11.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.57015609741211



action possibilites: [-1] 
expected returns: [[32.06235]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 61.80925369262695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[38.084724]
 [50.91045 ]
 [46.432735]
 [32.478836]
 [53.93595 ]
 [45.092323]
 [40.787434]
 [35.685246]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.06235122680664



buy possibilites: [-1] 
expected returns: [[20.527718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 29.  0.  0.  3.  0.  3. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.935943603515625






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0.  0.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[12.552836]
 [25.610008]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  3.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.52771759033203



action possibilites: [-1] 
expected returns: [[19.507008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  3.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 27.897418975830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.129932]
 [33.616776]
 [30.107868]
 [18.296787]
 [35.92488 ]
 [29.070091]
 [25.53117 ]
 [21.010704]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  7.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  3.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.507007598876953



buy possibilites: [-1] 
expected returns: [[14.650674]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 11.  3.] 
adversary cards in discard: [3. 8. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 35.92488479614258






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 11.  3.] 
cards in discard: [3. 8. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 11.  3.] 
cards in discard: [3. 8. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  9. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0. 11.  3.] 
cards in discard: [3. 8. 3. 3. 0. 0. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0. 10.] 
adversary cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 3. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[23.789932]
 [44.645664]
 [28.210224]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0. 10.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.650673866271973



action possibilites: [-1. 10.] 
expected returns: [[48.25496 ]
 [54.210567]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.  0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.239654541015625



action possibilites: [-1. 29.] 
expected returns: [[37.29483]
 [59.26868]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 29.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 54.210567474365234



action possibilites: [-1. 11.] 
expected returns: [[64.86487 ]
 [86.296394]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11] -> size -> 17 
action values: 2 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.268680572509766



action possibilites: [-1.] 
expected returns: [[37.716343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0  27   0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.70352172851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[48.437065]
 [58.78589 ]
 [55.300663]
 [46.99915 ]
 [44.13695 ]
 [50.774815]
 [61.237103]
 [54.089878]
 [67.20241 ]
 [65.64123 ]
 [49.128395]
 [56.18645 ]
 [50.66118 ]
 [46.466503]
 [59.560234]
 [46.713608]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8. 10.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.71634292602539



buy possibilites: [-1] 
expected returns: [[37.543232]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10. 11. 11.  0.  0.  3.  0. 10. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 10. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 67.20240020751953






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 3.  8.  3.  3.  0.  0.  8.  0. 14.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25] -> size -> 19 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 3.9070635]
 [15.655566 ]
 [ 7.299654 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.54323196411133



action possibilites: [-1] 
expected returns: [[15.704057]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 15.817317008972168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.820175]
 [28.003628]
 [17.482376]
 [26.940842]
 [20.098782]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.704056739807129



buy possibilites: [-1] 
expected returns: [[24.588497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  3.  0.] 
cards in discard: [10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [8. 3. 3. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 28.003623962402344






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 14  0  8  3  3  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10. 11.  3. 11.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10. 11.  3. 11.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 10. 11.  3. 11.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3] -> size -> 21 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 11.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11. 11.] 
expected returns: [[33.22949]
 [37.43819]
 [37.43819]
 [48.17505]
 [48.17505]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11.  3. 11.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.588497161865234



action possibilites: [-1] 
expected returns: [[27.660519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3. 11.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 44.35251998901367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.647923]
 [33.708508]
 [38.212036]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 11.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.660518646240234



buy possibilites: [-1] 
expected returns: [[20.560062]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  3. 11.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 40.647918701171875






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [8. 0. 8. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 29.] 
adversary cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[27.685745]
 [42.051907]
 [42.051907]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 29.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.560062408447266



action possibilites: [-1. 29. 25.] 
expected returns: [[29.351273]
 [50.28546 ]
 [52.401676]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 25.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8. 10. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 40.6618766784668



action possibilites: [-1] 
expected returns: [[89.087746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  9. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 52.40168762207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 88.049   ]
 [ 95.9932  ]
 [ 93.43481 ]
 [ 86.624405]
 [ 83.630005]
 [ 89.896614]
 [ 97.84732 ]
 [ 92.4615  ]
 [102.6739  ]
 [100.97926 ]
 [ 88.629074]
 [ 94.00837 ]
 [ 89.903114]
 [ 85.995384]
 [ 96.57328 ]
 [ 86.6417  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 27. 30.  8.  9. 10.  6.  8.  9.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 89.0877456665039



buy possibilites: [-1] 
expected returns: [[35.383915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [10.  3. 11. 10.  0.  3.  0. 10.  0. 11. 10. 10.  3. 11. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 14.  0.] 
adversary cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6] -> size -> 17 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 102.67391204833984






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14.  0.] 
cards in discard: [8. 0. 8. 0. 0. 3. 0. 0. 0. 6. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 26. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25] -> size -> 24 
adversary victory points: 4
player victory points: 3 





Player: 0 
cards in hand: [ 3. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ 8.209191]
 [11.445366]
 [19.763046]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.383914947509766



action possibilites: [-1] 
expected returns: [[-7.4474277]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 26. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.467639923095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-2.0470548]
 [ 4.8146477]
 [-6.351198 ]
 [ 3.2965827]
 [-3.4055536]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 26. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.447427749633789



buy possibilites: [-1] 
expected returns: [[-9.939751]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [10.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 4.814661979675293






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 6.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  6.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 25. 11.  3.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  5.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 25. 11.  3.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  5.  8.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 25. 11.  3.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [11.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  5.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [10.  0. 25. 11.  3.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [10.  0. 25. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 11.] 
expected returns: [[ 4.5492735]
 [ 7.0095873]
 [21.815403 ]
 [16.182335 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 11.  3.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  9. 10.  5.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8] -> size -> 20 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -9.939750671386719



action possibilites: [-1] 
expected returns: [[-5.8568583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  3.  0.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8. 10.  5.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.632888793945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-4.298242 ]
 [ 5.1791134]
 [ 2.3279266]
 [-8.709958 ]
 [ 7.1191607]
 [ 0.9735522]
 [-1.9796774]
 [-5.7249928]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3.  0.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 25. 30.  8.  8. 10.  5.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.856858253479004



buy possibilites: [-1] 
expected returns: [[13.128823]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.  3.  0.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [14.  3.  0.  3.  0.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6] -> size -> 21 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 129 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 7.1191558837890625






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [14.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 25. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29. 10.  0.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 25. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29. 10.  0.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  0.  3.  0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [29.  3. 29. 10.  0.] 
adversary cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
adversary victory points: 5
player victory points: 3 





Player: 0 
cards in hand: [29.  3. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
expected returns: [[ 7.936017]
 [27.855137]
 [27.855137]
 [12.272517]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 10.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.128823280334473



action possibilites: [-1. 29. 10.] 
expected returns: [[56.24631 ]
 [72.07317 ]
 [59.681828]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.855140686035156



action possibilites: [-1. 10.] 
expected returns: [[35.312668]
 [37.875706]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 72.07316589355469



action possibilites: [-1. 11.] 
expected returns: [[ 3.7271023]
 [13.079631 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11] -> size -> 27 
action values: 2 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  4. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 37.87567138671875



action possibilites: [-1.] 
expected returns: [[10.788511]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0 27  0] 
sum of rewards: 162 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 14.819127082824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[12.832864]
 [23.438011]
 [20.31361 ]
 [10.968525]
 [ 7.958107]
 [14.857804]
 [26.121109]
 [18.620453]
 [31.364162]
 [29.48484 ]
 [13.631717]
 [20.474201]
 [15.496062]
 [10.220764]
 [24.241138]
 [11.537906]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  8.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.788511276245117



buy possibilites: [-1] 
expected returns: [[50.47085]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3. 11.  3. 10.  0.  0. 11. 25. 10.  0. 11.  3.  0.  0. 10. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [8. 0. 0. 8. 3.] 
adversary cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0  60   0   0  80   0   0   0   0   0   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 31.364131927490234






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 3.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11 14  0  8  3  3  8  0  6  3 11  8  6  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [11.  8. 11.  6.  0.  0.  3.  6.  3. 14.  3.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 0. 25. 10.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25. 10.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 10.] 
expected returns: [[-18.300953]
 [ -9.498894]
 [-16.695171]
 [-16.695171]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 10.  3. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 30.  8.  8. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 50.47085189819336



action possibilites: [-1] 
expected returns: [[-21.24252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -13.411105155944824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-21.451927]
 [-22.266594]
 [-21.4249  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3. 10.  3.  3.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 24. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.24251937866211






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 24. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 30. 30. 24. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [6. 3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [11. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[45.483814]
 [50.88786 ]
 [46.757442]
 [51.938587]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0.  0.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -21.42490005493164



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[72.94232 ]
 [93.3323  ]
 [78.840614]
 [93.3323  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  3. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 51.938594818115234



action possibilites: [-1] 
expected returns: [[64.83981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 152 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 98.08661651611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[72.899376]
 [84.37722 ]
 [80.668335]
 [67.50586 ]
 [87.01135 ]
 [79.28798 ]
 [75.56222 ]
 [70.833824]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  4.  7.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.83981323242188



buy possibilites: [-1] 
expected returns: [[35.985264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  7.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 3. 11.  0.  0.  3.] 
adversary cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 179 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 87.01133728027344






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  7.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  7.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  0.  3.] 
cards in discard: [6. 3. 0. 0. 0. 0. 0. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 29. 10.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
adversary victory points: 5
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  3. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[24.451153]
 [42.75058 ]
 [28.753483]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29. 10.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.98526382446289



action possibilites: [-1. 10.] 
expected returns: [[41.633564]
 [44.9461  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 42.75059127807617



action possibilites: [-1. 11.] 
expected returns: [[30.98677 ]
 [45.335392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  2. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 44.94609069824219



action possibilites: [-1.] 
expected returns: [[16.95604]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 27  0] 
sum of rewards: 172 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 47.98529815673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.075462]
 [36.77534 ]
 [31.752586]
 [13.060349]
 [40.976627]
 [29.1661  ]
 [24.143349]
 [17.932343]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  3.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 16.956039428710938



buy possibilites: [-1] 
expected returns: [[95.487404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 8.  0. 11.  3. 14.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  0 90  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 199 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 40.97663879394531






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 11.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3. 14.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11 14  0  3  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 25.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 25.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [10.  0.  0. 10. 25.] 
adversary cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [10.  0.  0. 10. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25.] 
expected returns: [[ 5.1912107]
 [ 7.668065 ]
 [ 7.668065 ]
 [17.177822 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 25.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  7. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8] -> size -> 21 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 95.4874038696289



action possibilites: [-1] 
expected returns: [[125.053856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 10. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 23. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.177814483642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[140.92892]
 [145.0701 ]
 [137.3645 ]
 [144.24084]
 [140.15118]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 23. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 125.0538558959961



buy possibilites: [-1] 
expected returns: [[6.1352444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10. 10. 11.] 
cards in discard: [25.  0. 10.  3. 10.  3.  3. 10. 11. 29. 11. 10.  0.  0. 11. 10. 11. 29.
 10. 11.  0.  3.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 145.07003784179688






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 6.  3.  0.  0.  0.  0.  0.  8.  3. 11.  0.  0.  3.  8. 11.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 22. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  3.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
adversary victory points: 6
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[ 6.137413]
 [12.292714]
 [13.243232]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  6. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6] -> size -> 22 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.135244369506836



action possibilites: [-1] 
expected returns: [[-12.450431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 13.621466636657715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-16.31074 ]
 [-13.62483 ]
 [-14.297962]
 [-17.094528]
 [-12.838935]
 [-14.936878]
 [-15.610017]
 [-16.293255]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  2.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.450430870056152



buy possibilites: [-1] 
expected returns: [[-20.32027]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  0.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 8.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
adversary victory points: 0
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 249 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -12.838932991027832






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 25. 29.  3.  3.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 8.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 3. 25. 29.  3.  3.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
adversary victory points: 6
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 25. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-13.49229  ]
 [ -7.9312086]
 [ -8.541189 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  3.  3.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  5. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6] -> size -> 23 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.320270538330078



action possibilites: [-1] 
expected returns: [[11.452941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  3. 10. 10.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -7.93120002746582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[11.579949 ]
 [ 7.1518097]
 [10.779258 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  3. 10. 10.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.452940940856934



buy possibilites: [-1] 
expected returns: [[101.93185]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  3. 10. 10.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 24 
adversary victory points: -1
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -10   0   0   0   0] 
sum of rewards: 215 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 11.57995319366455






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  0  3  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 11.  0.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
adversary victory points: 6
player victory points: -3 





Player: 0 
cards in hand: [ 0. 25.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[-18.56215  ]
 [  2.927328 ]
 [ -2.7336454]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 11.  0.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 22. 30.  8.  4. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0] -> size -> 22 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 101.93184661865234



action possibilites: [-1] 
expected returns: [[88.72199]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.  3.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 22. 30.  8.  3. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 2.927328109741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 82.58076 ]
 [102.701866]
 [ 95.606544]
 [ 72.828964]
 [108.78146 ]
 [ 92.91542 ]
 [ 87.15185 ]
 [ 79.598366]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.  3.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 22. 30.  8.  3. 10.  1.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.72199249267578



buy possibilites: [-1] 
expected returns: [[70.18322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  0.  3.  3.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 11.  0.] 
adversary cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6] -> size -> 23 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 319 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 108.7813949584961






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11] -> size -> 37 
adversary victory points: 6
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 30. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11] -> size -> 37 
adversary victory points: 6
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 11.  0.] 
cards in discard: [6. 3. 6. 0. 0. 8. 6. 0. 8. 0. 6. 1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11] -> size -> 37 
adversary victory points: 6
player victory points: -4 





Player: 0 
cards in hand: [11.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[14.538007]
 [19.817944]
 [15.559119]
 [19.817944]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10. 10.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 70.18321990966797



action possibilites: [-1] 
expected returns: [[46.536964]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 21.539913177490234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[48.58488 ]
 [55.36222 ]
 [44.485447]
 [54.06771 ]
 [47.18328 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 22. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
adversary victory points: -4
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.536964416503906



buy possibilites: [-1] 
expected returns: [[43.263195]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [0. 6. 3. 6. 3.] 
adversary cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 55.362239837646484






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 3.] 
cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 10. 11. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3] -> size -> 39 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 3.] 
cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 10. 11. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3] -> size -> 39 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 3.] 
cards in discard: [ 6.  3.  6.  0.  0.  8.  6.  0.  8.  0.  6.  1.  0.  8.  0. 11.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [10. 10. 10. 11. 11.] 
adversary cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3] -> size -> 39 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [10. 10. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 11. 11.] 
expected returns: [[38.66785 ]
 [41.18132 ]
 [41.18132 ]
 [41.18132 ]
 [49.230152]
 [49.230152]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  9.] 
adversary cards in hand: [ 0.  8.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.2631950378418



action possibilites: [-1] 
expected returns: [[51.396458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  8.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 359 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 51.015872955322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[53.468243]
 [47.18337 ]
 [51.39648 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  8.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 51.39645767211914



buy possibilites: [-1] 
expected returns: [[38.461723]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 10. 11.] 
cards in discard: [11. 25. 11.  3.  0.  0. 10.  0.  0. 25.  3. 29.  3.  3. 10. 10. 11. 25.
  0.  0. 11.  0.  3.  3. 15.  3. 11.  0.  0. 10. 11. 15.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0.  8.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -60   0   0   0   0] 
sum of rewards: 285 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 53.46821975708008






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  0  8  0  6  3 11  8  6  3  0  6  3  8  6  6  6  0  6  1
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
adversary victory points: 7
player victory points: -3 





Player: 0 
cards in hand: [ 0. 11. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 29.] 
expected returns: [[27.392467]
 [39.273888]
 [30.745602]
 [30.745602]
 [39.69831 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.46172332763672



action possibilites: [-1. 10. 10.] 
expected returns: [[10.783578]
 [14.993043]
 [14.993043]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.] 
cards in discard: [11.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.00468826293945



action possibilites: [-1. 10. 25.] 
expected returns: [[18.513325]
 [25.15672 ]
 [41.645863]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 25.] 
cards in discard: [11.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  3. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 14.993048667907715



action possibilites: [-1. 10. 10.] 
expected returns: [[-18.190334]
 [-17.290775]
 [-17.290775]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10.  0.] 
cards in discard: [11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  2. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.645877838134766



action possibilites: [-1. 10. 25.] 
expected returns: [[-21.083729]
 [-20.666752]
 [-17.493736]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0. 25.] 
cards in discard: [11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 10. 25. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  2. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6] -> size -> 24 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -17.290786743164062



action possibilites: [-1. 10. 11.] 
expected returns: [[ 4.4951773]
 [ 7.3366985]
 [15.210372 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3. 11.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10. 25. 10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  8.  9. 10.  1. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0 100   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -17.493736267089844



action possibilites: [-1] 
expected returns: [[9.339813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [11. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10. 25. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0 120   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 17.281368255615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.788074 ]
 [24.14682  ]
 [20.846401 ]
 [11.757118 ]
 [15.713132 ]
 [18.97873  ]
 [30.927975 ]
 [15.320779 ]
 [16.653862 ]
 [25.039295 ]
 [14.4509535]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [11. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10. 25. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  8.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0 120   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.339813232421875



buy possibilites: [-1] 
expected returns: [[62.146076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [11. 15. 29.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29. 10. 25. 10. 25. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [0. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6
  6] -> size -> 25 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0 120   0   0   0   0 -80   0   0 128   0] 
sum of rewards: 463 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 30.927989959716797






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [0. 8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  8  0  3 11  8  6  3  0  6  3  8  6  6  6  0  6  0  0  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
adversary victory points: 7
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 0. 6. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10. 11. 11.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
adversary victory points: 7
player victory points: -4 





Player: 0 
cards in hand: [10. 25. 10. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 11. 11.] 
expected returns: [[-2.4780977]
 [ 1.360002 ]
 [21.039124 ]
 [ 1.360002 ]
 [14.853503 ]
 [14.853503 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 11. 11.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  1. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [0. 8. 0. 6. 6. 8. 0.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6] -> size -> 22 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 62.14607620239258



action possibilites: [-1] 
expected returns: [[-26.316303]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 11.  3. 15.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [0. 8. 0. 6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 21.039154052734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.753788]
 [-23.441948]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.  3. 15.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [0. 8. 0. 6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -26.316303253173828



buy possibilites: [-1] 
expected returns: [[49.67272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 11.  3. 15.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  6. 11.  0.  3.] 
adversary cards in discard: [0. 8. 0. 6. 6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -90   0   0   0   0] 
sum of rewards: 255 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -21.753799438476562






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  6. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [0. 8. 0. 6. 6. 8. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 11.  0.  3.] 
cards in discard: [0. 8. 0. 6. 6. 8. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10.  0. 10.  0.  3.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[51.221523]
 [51.855507]
 [51.855507]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  3.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.67272186279297



action possibilites: [-1. 10.] 
expected returns: [[54.356995]
 [53.85285 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 51.85551834106445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[56.874622]
 [56.243217]
 [56.286636]
 [56.123913]
 [56.74145 ]
 [57.501354]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 3. 6. 0. 6.] 
adversary cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.35702133178711






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [3. 3. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 11.  0. 15.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 11.  0. 15.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 6.] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 11.  0. 15.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 





Player: 0 
cards in hand: [ 3. 11.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
expected returns: [[49.819942]
 [49.26115 ]
 [48.9333  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0. 15.  0.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.  3.  3.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6  0] -> size -> 24 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.501380920410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[48.747547]
 [49.38189 ]
 [48.6268  ]
 [49.819942]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0. 15.  0.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 0. 8.] 
adversary cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.  3.  3.  6.  0.
  6.] 
adversary owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6  0] -> size -> 24 
adversary victory points: -5
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.820003509521484



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 8.] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.  3.  3.  6.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8  0  3 11  8  3  0  6  3  8  6  6  6  0  6  0  0  6  6  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3. 29.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.  3.  3.  6.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3. 29.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0.  8.  0.  6.  6.  8.  0.  6.  0.  6. 11.  0.  3.  0.  3.  3.  6.  0.
  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  3. 29.  0.] 
adversary cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
adversary victory points: 7
player victory points: -3 





Player: 0 
cards in hand: [ 0. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-1.9868436]
 [ 4.085908 ]
 [18.915878 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3. 29.  0.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 49.820003509521484



action possibilites: [-1. 10.] 
expected returns: [[-10.783874]
 [ -8.73106 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  3.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 14.219588279724121



action possibilites: [-1. 11.] 
expected returns: [[-10.344171 ]
 [ -2.2197847]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -8.731067657470703



action possibilites: [-1.] 
expected returns: [[4.0787516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   60    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -4.151075839996338





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[4.5801926]
 [4.0787516]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1] -> size -> 45 
action values: 1 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 4.078751564025879



buy possibilites: [-1] 
expected returns: [[-4.147012]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [11. 15. 29. 29. 10. 25. 10. 25. 11.  0.  0. 10.  0.  3.  0. 25. 10. 10.
 11. 11.  3. 15. 10.  0. 10.  0.  3.  0.  3. 11.  0. 15.  0.  0.  0.  1.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29. 10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 6. 8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  300.    0.    0.   60.    0.    0.    0.    0. -110.
    0.    0.    0.    0.] 
sum of rewards: 245.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 4.580203056335449






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [3. 6. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  3. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0] -> size -> 46 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  3. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0] -> size -> 46 
adversary victory points: 7
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  3. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 11. 10.] 
expected returns: [[45.74501 ]
 [68.673325]
 [68.673325]
 [68.673325]
 [51.68698 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 8.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.147012233734131



action possibilites: [-1] 
expected returns: [[-21.81771]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 11. 10.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 8.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: 222 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 64.1171646118164





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.367146]
 [-21.992104]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11. 10.] 
cards in discard: [1.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 8.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.817710876464844



buy possibilites: [-1] 
expected returns: [[-13.553228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 11. 10.] 
cards in discard: [1. 0.] 
cards in deck: 41 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 6.  6.  0. 11.  0.] 
adversary cards in discard: [3. 6. 8. 0. 8.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -130    0    0
    0    0] 
sum of rewards: 185 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -21.36712646484375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 6.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [3. 6. 8. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 29.  3.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [3. 6. 8. 0. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 27. 30. 21. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 29.  3.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  0.] 
cards in discard: [3. 6. 8. 0. 8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  0. 15. 29.  3.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [ 3.  0. 15. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29.] 
expected returns: [[46.601665]
 [70.08228 ]
 [82.059425]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15. 29.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.553228378295898



action possibilites: [-1. 15.] 
expected returns: [[19.404335]
 [43.230648]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  0.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25
 10  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.5334701538086



action possibilites: [-1] 
expected returns: [[40.30282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: 43.230682373046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[42.614742]
 [59.60368 ]
 [54.35296 ]
 [45.5748  ]
 [51.722553]
 [69.386856]
 [43.740456]
 [46.524197]
 [60.83597 ]
 [41.215847]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  7.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.302818298339844



buy possibilites: [-1] 
expected returns: [[-23.469257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29.] 
cards in deck: 35 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -130    0    0
  128    0] 
sum of rewards: 303 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 69.38683319091797






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10.  0. 10. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [ 0. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[11.165965]
 [18.34438 ]
 [18.34438 ]
 [18.34438 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 10. 10.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -23.469257354736328



action possibilites: [-1. 10. 10.] 
expected returns: [[ 8.608714 ]
 [12.0616865]
 [12.0616865]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 18.34438705444336



action possibilites: [-1. 10.] 
expected returns: [[32.854755]
 [38.88063 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 3 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 12.06171703338623



action possibilites: [-1. 10.] 
expected returns: [[24.273716]
 [33.599358]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 10.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 4 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 38.88064193725586



action possibilites: [-1.] 
expected returns: [[12.491197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 5 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 33.599369049072266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[17.752743]
 [42.578495]
 [34.38049 ]
 [21.149437]
 [29.153175]
 [58.3581  ]
 [19.258675]
 [22.862053]
 [44.815228]
 [15.832179]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  6.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.491196632385254



buy possibilites: [-1] 
expected returns: [[-4.821793]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10. 10. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   80    0    0    0    0 -140    0    0
  128    0] 
sum of rewards: 333 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 58.3581428527832






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [6. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 8. 0.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
adversary victory points: 7
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3.] 
cards in discard: [ 3.  6.  8.  0.  8.  3.  6.  6.  0. 11.  0.  1.  0.  3.  6.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0. 25. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
adversary victory points: 7
player victory points: -2 





Player: 0 
cards in hand: [ 0. 11.  0. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[10.487857]
 [19.722706]
 [22.88948 ]
 [19.722706]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 25. 11.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.821793079376221



action possibilites: [-1] 
expected returns: [[66.43032]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  0.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.88949966430664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[67.12416 ]
 [74.8922  ]
 [72.730576]
 [71.318565]
 [69.156944]
 [66.43032 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  0.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 26. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 66.4303207397461



buy possibilites: [-1] 
expected returns: [[34.835617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  0.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 8. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
adversary victory points: -2
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: 189 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 74.89221954345703






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 8. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  0. 15. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
adversary victory points: 7
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 20. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  0. 15. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
adversary victory points: 7
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 6. 0. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 29.  0. 15. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [ 3. 29.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 11.] 
expected returns: [[-21.703857]
 [-13.633107]
 [-16.135181]
 [-14.994664]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 15. 11.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1.  6.  0.  3.] 
adversary cards in discard: [3. 3. 8. 6. 0. 0.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.83561706542969



action possibilites: [-1. 15. 11. 15.] 
expected returns: [[38.07446 ]
 [50.02341 ]
 [51.830803]
 [50.02341 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1.  6.  0.  3.] 
adversary cards in discard: [3. 3. 8. 6. 0. 0.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -16.590965270996094



action possibilites: [-1] 
expected returns: [[9.975385]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1.  6.  0.  3.] 
adversary cards in discard: [3. 3. 8. 6. 0. 0.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 142 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 49.247440338134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.71333 ]
 [ 9.975373]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1.  6.  0.  3.] 
adversary cards in discard: [3. 3. 8. 6. 0. 0.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.975384712219238



buy possibilites: [-1] 
expected returns: [[-2.3851252]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1.  6.  0.  3.] 
adversary cards in discard: [3. 3. 8. 6. 0. 0.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5.    0.    0.  240.    0.    0.   40.    0.    0.    0.    0. -170.
    0.    0.    0.    0.] 
sum of rewards: 105.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 10.713338851928711






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [11.  1.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  6.  0.  3.] 
cards in discard: [3. 3. 8. 6. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10. 25. 29. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  6.  0.  3.] 
cards in discard: [3. 3. 8. 6. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 10. 25. 29. 11.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
adversary victory points: 7
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10. 25. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29. 11.] 
expected returns: [[11.647007]
 [13.346583]
 [19.930035]
 [19.095669]
 [18.448196]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25. 29. 11.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.385125160217285



action possibilites: [-1] 
expected returns: [[-10.459226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11.  1.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 19.93004608154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-10.085848 ]
 [ -5.102214 ]
 [ -6.1897316]
 [ -7.019886 ]
 [ -8.412773 ]
 [-10.459215 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29. 11.  1.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 24. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.45922565460205



buy possibilites: [-1] 
expected returns: [[1.5615892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29. 11.  1.  3.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 0. 6. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -180    0    0
   54    0] 
sum of rewards: 129 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -5.102217197418213






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.  1. 25.  0. 10. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
adversary victory points: 7
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  6.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.  1. 25.  0. 10. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
adversary victory points: 7
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6. 6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 11.  0. 25. 10.] 
adversary cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.  1. 25.  0. 10. 29. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
adversary victory points: 7
player victory points: -1 





Player: 0 
cards in hand: [10. 11.  0. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 10.] 
expected returns: [[-39.686417]
 [-39.41588 ]
 [-37.036716]
 [-36.291958]
 [-39.41588 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 25. 10.] 
cards in discard: [ 1.  0. 11.  3. 11. 11. 10.  0.  3. 29. 29. 15.  3. 29. 10. 10. 10. 10.
  0.  0.  0.  3.  0.  1. 25.  0. 11.  0. 11.  0.  3.  3.  0.  1.  0. 29.
 11. 15. 15.  1. 25.  0. 10. 29. 11.  1.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 1.561589241027832



action possibilites: [-1] 
expected returns: [[-14.400819]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  1. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -36.29195022583008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-4.696094 ]
 [10.994129 ]
 [ 6.979764 ]
 [ 3.9026766]
 [-0.1923058]
 [-5.7417545]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  1. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.400818824768066



buy possibilites: [-1] 
expected returns: [[36.561638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  0. 10.  1. 10.] 
cards in discard: [1.] 
cards in deck: 46 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 0. 0. 8. 6.] 
adversary cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
adversary owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
adversary victory points: -1
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  240    0    0   20    0    0    0    0 -190    0    0
   54    0] 
sum of rewards: 119 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 10.994142532348633






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [6. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 8. 6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  3 11  8  3  0  3  8  6  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
adversary victory points: 7
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
adversary victory points: 7
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3.  3.  8.  6.  0.  0. 11.  1.  6.  0.  3.  8.  8.  0.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0.  0.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
adversary victory points: 7
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-4.529984 ]
 [ 1.4588165]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.56163787841797



action possibilites: [-1.] 
expected returns: [[49.43857]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 1.4588165283203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.48532 ]
 [68.27069 ]
 [61.29527 ]
 [37.240482]
 [47.673534]
 [56.9641  ]
 [84.891464]
 [80.569084]
 [44.695263]
 [61.06403 ]
 [49.940075]
 [35.10521 ]
 [70.15295 ]
 [39.414886]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  7.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 49.438568115234375



buy possibilites: [-1] 
expected returns: [[-6.70634]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25.] 
cards in deck: 40 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -200    0    0
  250    0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 84.89146423339844






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [29. 11. 15.  1.  3.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
adversary victory points: 7
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [29. 11. 15.  1.  3.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
adversary victory points: 7
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 11. 15.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 15.] 
expected returns: [[44.46403]
 [82.97845]
 [76.90078]
 [72.41938]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 15.  1.  3.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [0. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.7063398361206055



action possibilites: [-1. 11. 15. 25.] 
expected returns: [[20.181461]
 [42.02096 ]
 [39.065754]
 [48.393673]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 25.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [0. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 83.54334259033203



action possibilites: [-1] 
expected returns: [[-8.294315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  0. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [0. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 48.393680572509766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.4734583 ]
 [ 0.26725197]
 [-1.7532554 ]
 [-8.294331  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 22. 30. 19. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [0. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: -8.294315338134766



buy possibilites: [-1] 
expected returns: [[49.693127]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 15.  0. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 6. 8.] 
adversary cards in discard: [0. 8. 6. 3. 3.] 
adversary owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
adversary victory points: 0
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -210    0    0
   16    0] 
sum of rewards: 81 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 0.2672548294067383






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 8.] 
cards in discard: [0. 8. 6. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  6  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
adversary victory points: 8
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 8. 6. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 8. 6. 3. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  5.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 8. 6. 3. 3. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3. 29. 11.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
adversary victory points: 8
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[ 82.87345]
 [111.73412]
 [116.23264]
 [111.73412]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 29. 11.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 49.6931266784668



action possibilites: [-1. 11.] 
expected returns: [[43.46932 ]
 [56.000423]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3] -> size -> 56 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 22. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 105.98555755615234



action possibilites: [-1] 
expected returns: [[72.124374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  210    0    0   40    0    0    0    0 -220    0    0
   27    0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 53.54185104370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[70.949066]
 [70.83128 ]
 [70.26058 ]
 [72.12434 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [3. 0. 0. 6. 6.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
adversary victory points: 1
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.12437438964844






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
adversary victory points: 8
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 18. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
adversary victory points: 8
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 6.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
adversary victory points: 8
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 8.445617]
 [54.542984]
 [65.31507 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11. 29.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 17. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 72.12437438964844



action possibilites: [-1.] 
expected returns: [[-8.997719]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 17. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.709712982177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.814256  ]
 [ 1.8317633 ]
 [-0.58718705]
 [-8.997739  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 21. 30. 17. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -8.997718811035156



buy possibilites: [-1] 
expected returns: [[-22.79607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 8.  0.  3. 11.  3.] 
adversary cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
adversary owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
adversary victory points: 2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  210    0    0   20    0    0    0    0 -230    0    0
   16    0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 1.8318238258361816






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3. 11.  3.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  3 11  8  3  3  8  0  6  0  0  6  6  6  0  3  1  0  3  8  0  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [15. 11.  0.  1. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
adversary victory points: 9
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [15. 11.  0.  1. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
adversary victory points: 9
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0. 8. 6. 3. 3. 8. 8. 0. 0. 8. 3. 3. 0. 0. 6. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [15. 11.  0.  1. 29.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
adversary victory points: 9
player victory points: 1 





Player: 0 
cards in hand: [15. 11.  0.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
expected returns: [[128.234  ]
 [143.3793 ]
 [145.95145]
 [148.66228]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  1. 29.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.796070098876953



action possibilites: [-1. 15. 11.] 
expected returns: [[-45.37324 ]
 [-31.185032]
 [-28.625198]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 21. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 149.4065704345703



action possibilites: [-1] 
expected returns: [[23.21386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  240    0    0   40    0    0    0    0 -240    0    0
   27    0] 
sum of rewards: 62 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -32.289344787597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[25.103104]
 [36.78963 ]
 [34.075443]
 [23.213795]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 30. 16. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.21385955810547



buy possibilites: [-1] 
expected returns: [[31.419968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 8. 0. 1. 6.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[  -5    0    0  270    0    0   40    0    0    0    0 -250    0    0
   16    0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.789703369140625






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 8. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [25. 11.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 1. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [25. 11.  0. 10.  0.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
adversary victory points: 10
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[-43.66746 ]
 [-37.021656]
 [-38.811035]
 [-42.634014]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  0. 10.  0.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.419967651367188



action possibilites: [-1] 
expected returns: [[-63.8072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.  0. 11. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -37.02164840698242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-64.34761 ]
 [-59.30054 ]
 [-61.250935]
 [-63.807217]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0. 11. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 30. 15. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 10 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -63.80720138549805



buy possibilites: [-1] 
expected returns: [[4.3198795]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.  0. 11. 10.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 6. 0. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -260    0    0
   16    0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -59.30051040649414






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [6. 6. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 1. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 10. 15.  3.  1.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
adversary victory points: 11
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 1. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 10. 15.  3.  1.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
adversary victory points: 11
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 0.] 
cards in discard: [0. 8. 0. 1. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3. 10. 15.  3.  1.] 
adversary cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
adversary victory points: 11
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10. 15.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[-25.609001]
 [-22.45282 ]
 [-14.301818]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  3.  1.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.319879531860352



action possibilites: [-1] 
expected returns: [[-55.644283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  1.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -14.301815032958984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-54.720913]
 [-42.425934]
 [-45.831997]
 [-55.64429 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 20. 30. 14. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
adversary victory points: 1
player victory points: 11 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -55.644283294677734



buy possibilites: [-1] 
expected returns: [[-24.039333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  1.] 
cards in discard: [ 1. 25. 10. 11.  0. 10.  1. 10. 25. 10.  0.  0.  0.  0.  0.  1.  3.  3.
 29. 25. 11. 15.  0. 10. 11.  1.  1. 29. 11.  0.  3. 11. 29.  3. 29.  3.
  3.  0.  1.  3.  1.  3. 29. 11. 15.  0.  3. 25. 11.  0. 10.  0. 11. 10.
  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 8. 6. 3.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
adversary owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -270    0    0
   16    0] 
sum of rewards: 91 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -42.42593002319336






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 6. 3.] 
cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3 3 8 0 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
adversary victory points: 12
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
adversary victory points: 12
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 11. 29.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
adversary victory points: 12
player victory points: 1 





Player: 0 
cards in hand: [11. 11. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29. 10.] 
expected returns: [[-87.91475 ]
 [-70.076454]
 [-70.076454]
 [-65.45573 ]
 [-83.17759 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.  0. 10.] 
cards in discard: [] 
cards in deck: 57 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -24.03933334350586



action possibilites: [-1. 11. 10.] 
expected returns: [[-69.87046 ]
 [-50.688667]
 [-64.710594]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [11. 10.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 20. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -73.13219451904297



action possibilites: [-1] 
expected returns: [[-57.53365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [11. 10.  1.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 19. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -280    0    0
   27    0] 
sum of rewards: 112 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -54.27828598022461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-55.536312]
 [-44.097073]
 [-47.106113]
 [-56.88446 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [11. 10.  1.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1] -> size -> 63 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 19. 30. 13. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 12 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -57.53364944458008



buy possibilites: [-1] 
expected returns: [[-70.43201]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [11. 10.  1.  3.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 3. 3. 0.] 
adversary cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  360    0    0   40    0    0    0    0 -290    0    0
   16    0] 
sum of rewards: 121 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -44.09705352783203






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1. 11.  0.  0.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3] -> size -> 64 
adversary victory points: 13
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 3. 3. 0.] 
cards in discard: [0. 8. 0. 1. 6. 0. 6. 6. 0. 3. 0. 8. 6. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 19. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  1. 11.  0.  0.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3] -> size -> 64 
adversary victory points: 13
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11.  1. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[ 5.5728407]
 [38.852703 ]
 [38.852703 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  0.  0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: -70.4320068359375



action possibilites: [-1] 
expected returns: [[53.861774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1.] 
cards in deck: 51 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1] -> size -> 65 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -300    0    0
   27    0] 
sum of rewards: 102 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 32.69921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[56.30779 ]
 [74.65887 ]
 [69.4255  ]
 [60.183895]
 [66.55189 ]
 [85.16909 ]
 [57.867367]
 [61.379803]
 [76.08319 ]
 [53.86179 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1.] 
cards in deck: 51 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1] -> size -> 65 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  5.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 53.86177444458008



buy possibilites: [-1] 
expected returns: [[40.775585]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29.] 
cards in deck: 51 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 6. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -310    0    0
  128    0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 85.16907501220703






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 6. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [8 3 3 8 6 0 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 25.  1.  0. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
adversary victory points: 13
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 25.  1.  0. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
adversary victory points: 13
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 25.  1.  0. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
adversary victory points: 13
player victory points: 2 





Player: 0 
cards in hand: [ 0. 25.  1.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
expected returns: [[43.15492 ]
 [82.958534]
 [69.32667 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  1.  0. 15.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.77558517456055



action possibilites: [-1] 
expected returns: [[14.003556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 15.  0. 25.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.95855712890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[14.660214]
 [29.916588]
 [26.03704 ]
 [11.636434]
 [16.662613]
 [22.78304 ]
 [39.019764]
 [36.278355]
 [15.861474]
 [25.015625]
 [18.88525 ]
 [10.730081]
 [31.002811]
 [14.003524]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 15.  0. 25.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29] -> size -> 66 
action values: 0 
buys: 1 
player value: 5 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  6.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.003556251525879



buy possibilites: [-1] 
expected returns: [[71.05097]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 15.  0. 25.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25.] 
cards in deck: 44 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25] -> size -> 67 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 6. 3. 3. 6.] 
adversary cards in discard: [8. 3.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -320    0    0
  250    0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 39.0197639465332






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [0. 6. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25] -> size -> 67 
adversary victory points: 13
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [8. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 18. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25] -> size -> 67 
adversary victory points: 13
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 6.] 
cards in discard: [8. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 18. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3.  0. 11.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25] -> size -> 67 
adversary victory points: 13
player victory points: 2 





Player: 0 
cards in hand: [ 3.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[63.328716]
 [77.70811 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 11.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25] -> size -> 67 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 18. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 71.05097198486328



action possibilites: [-1] 
expected returns: [[6.472187]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1] -> size -> 68 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -330    0    0
   27    0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 74.38894653320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.360753]
 [6.47219 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1] -> size -> 68 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.472187042236328



buy possibilites: [-1] 
expected returns: [[31.407436]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 0. 3. 8.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
adversary owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
adversary victory points: 2
player victory points: 13 

Reward from previous game state: 
[  -5.    0.    0.  330.    0.    0.   20.    0.    0.    0.    0. -340.
    0.    0.    0.    0.] 
sum of rewards: 5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 7.360739707946777






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 8.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [3 3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
adversary victory points: 13
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
adversary victory points: 13
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 17. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
adversary victory points: 13
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [10. 25. 10.  0. 10.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
adversary victory points: 13
player victory points: 1 





Player: 0 
cards in hand: [10. 25. 10.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 10.] 
expected returns: [[-6.9788704]
 [-3.0464046]
 [18.361214 ]
 [-3.0464046]
 [-3.0464046]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10.  0. 10.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 3. 1. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 31.40743637084961



action possibilites: [-1] 
expected returns: [[-7.3167048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  0.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 3. 1. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.361228942871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-7.1431203 ]
 [ 2.3352537 ]
 [-0.56894207]
 [-7.3167214 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0] -> size -> 69 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 16. 30. 12. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 3. 1. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
adversary victory points: 1
player victory points: 13 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: -7.316704750061035



buy possibilites: [-1] 
expected returns: [[-40.161755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3] -> size -> 70 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 0. 3. 1. 6.] 
adversary cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -350    0    0
   16    0] 
sum of rewards: 71 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 2.335292339324951






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 1. 6.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 16. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  3.  3.  1.  1.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3] -> size -> 70 
adversary victory points: 14
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1. 6.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 16. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  3.  3.  1.  1.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3] -> size -> 70 
adversary victory points: 14
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 1. 6.] 
cards in discard: [8. 3. 0. 0. 6. 3. 3. 6. 1. 8. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 16. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11.  3.  3.  1.  1.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3] -> size -> 70 
adversary victory points: 14
player victory points: 1 





Player: 0 
cards in hand: [11.  3.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[72.48809]
 [86.09634]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.  1.  1.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3] -> size -> 70 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 16. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: -40.1617546081543



action possibilites: [-1] 
expected returns: [[104.7111]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1] -> size -> 71 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -360    0    0
   27    0] 
sum of rewards: 72 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 82.63648986816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.90606 ]
 [123.45009 ]
 [118.48533 ]
 [110.23846 ]
 [115.98561 ]
 [133.24231 ]
 [108.14808 ]
 [111.007744]
 [124.685295]
 [104.71107 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1] -> size -> 71 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  4.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: 104.71109771728516



buy possibilites: [-1] 
expected returns: [[35.336025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 1.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -370    0    0
  128    0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 133.24234008789062






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [25. 10. 29.  1.  0.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
adversary victory points: 14
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [25. 10. 29.  1.  0.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
adversary victory points: 14
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 10. 29.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 29.] 
expected returns: [[16.24747 ]
 [41.464043]
 [21.0065  ]
 [38.998444]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 10. 29.  1.  0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 8. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.33602523803711



action possibilites: [-1] 
expected returns: [[-73.005264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  1.  0.  3.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 8. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 41.46406173706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-72.680046]
 [-63.571014]
 [-65.785164]
 [-67.71496 ]
 [-69.98724 ]
 [-73.00527 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  1.  0.  3.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29] -> size -> 72 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 15. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 8. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -73.00526428222656



buy possibilites: [-1] 
expected returns: [[-87.57635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  1.  0.  3.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1] -> size -> 73 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 14. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 8. 3. 6.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -380    0    0
   54    0] 
sum of rewards: 79 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -63.571006774902344






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [0. 1. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 8. 3. 6.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 14. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1] -> size -> 73 
adversary victory points: 14
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 6.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 14. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1] -> size -> 73 
adversary victory points: 14
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 8. 3. 6.] 
cards in discard: [0. 3. 3. 0. 0. 1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 13. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1] -> size -> 73 
adversary victory points: 14
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-23.212147]
 [-15.700723]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1] -> size -> 73 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 13. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 385 

action type: buy - action -1
Learning step: 0
desired expected reward: -87.57634735107422



action possibilites: [-1] 
expected returns: [[-12.038588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1] -> size -> 74 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 12. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[  -5    0    0  390    0    0   20    0    0    0    0 -390    0    0
   27    0] 
sum of rewards: 42 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -17.17905616760254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-11.44506  ]
 [ -7.7756453]
 [ -8.548931 ]
 [-12.038579 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1] -> size -> 74 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 12. 30. 11. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
adversary victory points: 1
player victory points: 14 

Reward from previous game state: 
[ -5   0   0 390   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 405 

action type: take_action - action -1
Learning step: 0
desired expected reward: -12.03858757019043



buy possibilites: [-1] 
expected returns: [[16.355019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
adversary owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  420    0    0   20    0    0    0    0 -400    0    0
   16    0] 
sum of rewards: 51 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -7.7756476402282715






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 0 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 29.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
adversary victory points: 15
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 29.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
adversary victory points: 15
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 29.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
adversary victory points: 15
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [0. 3. 3. 0. 0. 1. 0. 1. 8. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 10.  1. 29.  3.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
adversary victory points: 15
player victory points: 1 





Player: 0 
cards in hand: [ 1. 10.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[47.200253]
 [55.10304 ]
 [79.00629 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  1. 29.  3.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.355018615722656



action possibilites: [-1. 10.] 
expected returns: [[-5.37443  ]
 [-1.2269721]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 69.66470336914062



action possibilites: [-1.] 
expected returns: [[-1.2957127]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -1.226957082748413





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.7881942 ]
 [ 4.809291  ]
 [ 3.6688137 ]
 [ 0.35694313]
 [ 2.654108  ]
 [ 9.031234  ]
 [-0.18821335]
 [ 1.2914472 ]
 [ 5.210186  ]
 [-1.2957108 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3] -> size -> 75 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  3.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.2957127094268799



buy possibilites: [-1] 
expected returns: [[-73.46197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 1. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  420    0    0   40    0    0    0    0 -410    0    0
  128    0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 9.031234741210938






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 0. 1. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 15. 10. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
adversary victory points: 15
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 15. 10. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
adversary victory points: 15
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 6. 6.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 8. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 29. 15. 10. 15.] 
adversary cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
adversary victory points: 15
player victory points: 1 





Player: 0 
cards in hand: [ 1. 29. 15. 10. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 10. 15.] 
expected returns: [[-0.9820454]
 [10.037307 ]
 [ 6.3596497]
 [ 1.2093797]
 [ 6.3596497]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 15. 10. 15.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6.] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 415 

action type: buy - action -1
Learning step: 0
desired expected reward: -73.46196746826172



action possibilites: [-1. 10. 15.] 
expected returns: [[-28.194996]
 [-25.362995]
 [-18.312887]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 15.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6.] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 435 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.780831336975098



action possibilites: [-1] 
expected returns: [[-46.918667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6.] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action 15.0
Learning step: 0
desired expected reward: -18.3128662109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-46.535328]
 [-41.12326 ]
 [-42.579403]
 [-43.6307  ]
 [-45.08685 ]
 [-46.918667]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0. 15. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29] -> size -> 76 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 12. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6.] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 420   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 455 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.91866683959961



buy possibilites: [-1] 
expected returns: [[-47.07669]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.] 
cards in discard: [11. 10.  1.  3. 29. 11.  0. 10.  1. 29. 11.  1. 11.  0.  0. 25. 25.  0.
  1.  0. 15.  0. 25.  1.  0. 11.  3.  3.  0.  3.  3. 25. 10. 10.  0. 10.
  0.  3.  1. 29. 11.  3.  3.  1.  1.  1. 25. 10. 29.  1.  0.  3.  3.  1.
  3. 11.  0.  0.  3.  3. 10.  1. 29. 29. 10.  1.  3.  0. 15. 11.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 3. 8. 1. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6.] 
adversary owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
adversary victory points: 1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  420    0    0   40    0    0    0    0 -420    0    0
   54    0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -41.12324523925781






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 1. 3.] 
cards in discard: [0. 0. 0. 1. 6. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [3 8 6 6 6 0 3 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
adversary victory points: 15
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [0. 0. 0. 1. 6. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 0. 0. 1. 6. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  4.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
adversary victory points: 15
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
adversary victory points: 15
player victory points: -1 





Player: 0 
cards in hand: [ 1.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-59.19911]
 [-47.27055]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 72 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: -47.076690673828125



action possibilites: [-1.] 
expected returns: [[-66.451935]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1.] 
cards in discard: [0. 0.] 
cards in deck: 71 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -50.52260208129883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-65.90769 ]
 [-57.427177]
 [-59.679653]
 [-67.54051 ]
 [-64.65926 ]
 [-61.365475]
 [-48.781696]
 [-51.256424]
 [-65.24664 ]
 [-60.061665]
 [-63.617966]
 [-68.22803 ]
 [-56.767868]
 [-66.45196 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [0. 0.] 
cards in deck: 71 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1] -> size -> 77 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  5.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -66.45193481445312



buy possibilites: [-1] 
expected returns: [[78.95704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1.] 
cards in discard: [ 0.  0. 25.] 
cards in deck: 71 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -430    0    0
  250    0] 
sum of rewards: 315 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -48.78168869018555






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [29. 10. 29.  0. 10.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 11. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [29. 10. 29.  0. 10.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
adversary victory points: 15
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [29. 10. 29.  0. 10.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
adversary victory points: 15
player victory points: -1 





Player: 0 
cards in hand: [29. 10. 29.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29. 10.] 
expected returns: [[-36.21502 ]
 [ -4.91493 ]
 [-31.983353]
 [ -4.91493 ]
 [-31.983353]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 29.  0. 10.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1.] 
cards in deck: 66 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.95703887939453



action possibilites: [-1. 10. 10.] 
expected returns: [[-42.595722]
 [-34.03816 ]
 [-34.03816 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10.] 
cards in deck: 65 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -18.84162139892578



action possibilites: [-1. 10.] 
expected returns: [[-26.93546 ]
 [-18.366465]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10.] 
cards in deck: 64 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -34.0381965637207



action possibilites: [-1.] 
expected returns: [[-4.196789]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10.] 
cards in deck: 63 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 3 
buys: 0 
player value: 1 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 535 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -18.366497039794922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-1.012248  ]
 [26.763454  ]
 [16.35165   ]
 [-4.7699447 ]
 [ 3.5792136 ]
 [11.541412  ]
 [52.521946  ]
 [46.817818  ]
 [ 0.63547134]
 [17.777111  ]
 [ 4.3931847 ]
 [-6.2453284 ]
 [29.276432  ]
 [-4.196748  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10.] 
cards in deck: 63 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25] -> size -> 78 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  4.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 535 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -4.196788787841797



buy possibilites: [-1] 
expected returns: [[-95.21981]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25.] 
cards in deck: 63 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 3. 0. 8. 6.] 
adversary cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   60    0    0    0    0 -440    0    0
  250    0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 52.52188491821289






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [1. 3. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 29. 29. 11.  1.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  3.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 29. 29. 11.  1.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
adversary victory points: 15
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 8. 6.] 
cards in discard: [0. 0. 0. 1. 6. 6. 8. 8. 1. 1. 0. 0. 8. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 29. 29. 11.  1.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
adversary victory points: 15
player victory points: -1 





Player: 0 
cards in hand: [ 0. 29. 29. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[-46.150703]
 [-33.445763]
 [-33.445763]
 [-36.036926]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 11.  1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1.] 
cards in deck: 58 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: -95.21981048583984



action possibilites: [-1. 29.] 
expected returns: [[-61.429726]
 [-45.856888]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.] 
cards in deck: 57 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -39.17268753051758



action possibilites: [-1.] 
expected returns: [[-5.8082457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -51.22677230834961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[-4.906624  ]
 [ 3.9217863 ]
 [ 1.4087405 ]
 [-0.11975384]
 [-2.6327982 ]
 [-5.808254  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25] -> size -> 79 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 10. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 515 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -5.808245658874512



buy possibilites: [-1] 
expected returns: [[32.19676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1.] 
cards in deck: 56 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  9. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [8. 1. 6. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   40    0    0    0    0 -450    0    0
   54    0] 
sum of rewards: 119 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 3.921788215637207






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8. 1. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 8. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [8 6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  9. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 25.  3.  1.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
adversary victory points: 15
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  9. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 25.  3.  1.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8.  9. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 25.  3.  1.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
adversary victory points: 15
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0.] 
cards in discard: [1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  8. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [11. 25.  3.  1.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
adversary victory points: 15
player victory points: -1 





Player: 0 
cards in hand: [11. 25.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[157.30222]
 [172.00728]
 [176.22466]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  3.  1.  0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
cards in deck: 51 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  8. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.19675827026367



action possibilites: [-1] 
expected returns: [[28.127808]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  0. 25.  3.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  8. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 176.2246551513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[28.625748]
 [35.943302]
 [33.9846  ]
 [32.549446]
 [30.590736]
 [28.12778 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  0. 25.  3.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1] -> size -> 80 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8.  8. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.1278076171875



buy possibilites: [-1] 
expected returns: [[43.52316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  0. 25.  3.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1.] 
cards in deck: 49 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1] -> size -> 81 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  7. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -460    0    0
   54    0] 
sum of rewards: 89 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 35.94333267211914






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [6. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 3. 0.] 
cards in discard: [1. 8. 1. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  7. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1] -> size -> 81 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 3. 0.] 
cards in discard: [1. 8. 1. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8.  7. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 0. 11.  3.  3. 11.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1] -> size -> 81 
adversary victory points: 15
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 11.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[-16.436787]
 [  6.453264]
 [  6.453264]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3. 11.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1] -> size -> 81 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8.  7. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 1. 0. 1. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.52315902709961



action possibilites: [-1] 
expected returns: [[-44.89392]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1] -> size -> 82 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8.  6. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 1. 0. 1. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -470    0    0
   27    0] 
sum of rewards: 52 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 0.9463658332824707





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-44.81658 ]
 [-44.893925]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1] -> size -> 82 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8.  6. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 1. 0. 1. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.8939208984375



buy possibilites: [-1] 
expected returns: [[-49.740314]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0.] 
cards in deck: 44 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [6. 1. 0. 1. 0.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5.    0.    0.  480.    0.    0.   20.    0.    0.    0.    0. -480.
    0.    0.    0.    0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -44.81657028198242






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [6. 1. 0. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 1. 0.] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
adversary victory points: 15
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 1. 0.] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  2.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
adversary victory points: 15
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 1. 0.] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 3.  3. 10.  0.  0.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
adversary victory points: 15
player victory points: -1 





Player: 0 
cards in hand: [ 3.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-58.92912 ]
 [-55.501347]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.  0.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 475 

action type: buy - action -1
Learning step: 0
desired expected reward: -49.74031448364258



action possibilites: [-1.] 
expected returns: [[-65.97431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: -55.501346588134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-65.69756 ]
 [-54.260403]
 [-57.287567]
 [-64.38861 ]
 [-59.80095 ]
 [-48.73708 ]
 [-64.811745]
 [-62.546528]
 [-53.281628]
 [-65.97431 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0] -> size -> 83 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  2.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 480   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 495 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -65.97431182861328



buy possibilites: [-1] 
expected returns: [[40.260326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [0. 1. 0. 3. 8.] 
adversary cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
adversary owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
adversary victory points: -1
player victory points: 15 

Reward from previous game state: 
[  -5    0    0  480    0    0   20    0    0    0    0 -490    0    0
  128    0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -48.73710632324219






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [0. 1. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 8.] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [6 6 6 1 0 3 8 0 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 29. 29.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
adversary victory points: 15
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 29. 29.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
adversary victory points: 15
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [1. 8. 1. 6. 0. 6. 8. 8. 3. 0. 8. 6. 1. 0. 1. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [ 1. 15.  3. 29. 29.] 
adversary cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
adversary victory points: 15
player victory points: -2 





Player: 0 
cards in hand: [ 1. 15.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29.] 
expected returns: [[-46.441147]
 [-36.914223]
 [-33.539886]
 [-33.539886]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15.  3. 29. 29.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
adversary victory points: -2
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 510   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 505 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.26032638549805



action possibilites: [-1. 15. 29.] 
expected returns: [[-154.71205]
 [-149.21078]
 [-147.73547]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29.  1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.  1.  3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
adversary victory points: -2
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 510   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 525 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -32.96493911743164



action possibilites: [-1.] 
expected returns: [[-109.70396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.  1.  3. 15.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
adversary victory points: -2
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 510   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 545 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -149.64553833007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-109.189384]
 [ -96.28391 ]
 [ -99.58016 ]
 [-107.499084]
 [-102.328064]
 [ -91.89761 ]
 [-108.17906 ]
 [-105.62432 ]
 [ -95.402336]
 [-109.70399 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.  1.  3. 15.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29] -> size -> 84 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  1.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
adversary victory points: -2
player victory points: 15 

Reward from previous game state: 
[ -5   0   0 510   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 545 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -109.7039566040039



Player 0 won the game! 



Player 0 bought cards:
Copper: 9 
Silver: 7 
Gold: 0 
Estate: 12 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 8 
Chapel: 0 
Witch: 7 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1.] 
cards in discard: [ 0.  0. 25. 29.  1.  3.  1. 29. 10. 25. 29. 10. 10.  0.  0.  1. 11.  1.
  1.  1.  1. 29. 29.  0.  1. 25. 11.  3.  1.  0. 25.  3.  1.  0. 11.  0.
  3.  3. 11. 29. 10.  3.  3.  0.  0.  1.  1.  3. 15.  0. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 11 29 29 10 11 10 11 10 25 10  3 10  0 25 10
  3 11 10 25 10 11 10 11  3 11  0 11 15  3 15  0 15 29  0  1  0  1  0 29
 29  1  1  0  1  1 25  3  1  3  1  3  3  3  1  3  1 29 25  1  0  3  1 29
  1  1  3 29  1 25 25  1  1  1  0 29 29] -> size -> 85 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7.  6. 30. 10. 30.  8.  0. 10.  0.  1.  3.  0.  9. 10.  1. 10.  7.] 
adversary cards in hand: [1. 1. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [6 6 6 8 8 3 0 0 1 0 1 0 0 8 1 8 1 8] -> size -> 18 
adversary victory points: -2
player victory points: 15 

Reward from previous game state: 
[     -5 3000000       0     510       0       0      40       0       0
       0       0    -500       0       0      64       0] 
sum of rewards: 3000109 

action type: buy - action 29.0
Learning step: 300020.09375
desired expected reward: 299928.1875



