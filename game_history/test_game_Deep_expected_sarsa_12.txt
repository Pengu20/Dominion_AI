 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[93.20249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0      30       0       0      20       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000045 

action type: buy - action 0.0
Learning step: 119998.8359375
desired expected reward: 120072.90625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[87.19324 ]
 [90.89828 ]
 [88.85676 ]
 [84.23131 ]
 [91.54524 ]
 [89.881714]
 [87.84018 ]
 [93.090614]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 95.09385681152344



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[102.77624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 93.09063720703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.23694 ]
 [101.93854 ]
 [ 99.895294]
 [ 95.28482 ]
 [102.393295]
 [102.59027 ]
 [100.91665 ]
 [107.90533 ]
 [ 97.96452 ]
 [ 98.881805]
 [101.66359 ]
 [104.147865]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 104.06385803222656



buy possibilites: [-1] 
expected returns: [[113.51076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  3.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.90533447265625






Player: 1 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[104.84003]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 113.51075744628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 99.88807 ]
 [103.601074]
 [101.55607 ]
 [ 96.92171 ]
 [104.05138 ]
 [104.25018 ]
 [102.582184]
 [109.53713 ]
 [ 99.615814]
 [100.53717 ]
 [103.32882 ]
 [105.803444]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 106.35628509521484



buy possibilites: [-1] 
expected returns: [[112.39503]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 109.53713989257812






Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [4.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  3. 29.] 
adversary cards in discard: [29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[120.616325]
 [124.35002 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3. 29.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 112.39502716064453



action possibilites: [-1.] 
expected returns: [[124.46048]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.06647491455078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[119.38868 ]
 [123.167145]
 [121.086006]
 [116.369804]
 [123.62602 ]
 [123.82792 ]
 [122.130585]
 [129.20866 ]
 [119.111725]
 [120.049446]
 [122.89019 ]
 [125.40795 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  7. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 124.46047973632812



buy possibilites: [-1] 
expected returns: [[136.58278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  3.  0.  0.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: 23 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 129.2086639404297






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 4. 29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 4. 29.  0.  0.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[89.44737]
 [92.79915]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 136.58277893066406



action possibilites: [-1.] 
expected returns: [[100.33896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 93.63046264648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 94.81815 ]
 [ 98.27537 ]
 [ 96.37205 ]
 [ 92.05799 ]
 [ 98.69921 ]
 [ 98.89171 ]
 [ 97.32698 ]
 [103.99211 ]
 [ 94.566826]
 [ 95.42367 ]
 [ 98.02404 ]
 [100.37983 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  6. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 100.33895874023438



buy possibilites: [-1] 
expected returns: [[123.548615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 4. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: -7 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 103.99211883544922






Player: 1 
cards in hand: [0. 3. 4. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10. 10. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 4. 0. 3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  0.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[123.91557]
 [127.43633]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.54861450195312



action possibilites: [-1. 29.] 
expected returns: [[151.01122]
 [154.83481]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 127.57815551757812



action possibilites: [-1.] 
expected returns: [[160.37155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 154.83480834960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[157.43599]
 [160.83598]
 [155.56262]
 [158.96263]
 [156.59155]
 [154.71819]
 [161.25089]
 [161.43018]
 [159.90353]
 [167.19128]
 [166.30289]
 [157.18575]
 [161.9331 ]
 [158.03018]
 [158.5331 ]
 [160.58572]
 [162.84924]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9. 10.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 160.37155151367188



buy possibilites: [-1] 
expected returns: [[159.28917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 29.] 
adversary cards in discard: [8. 0. 3. 4. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -150.     0.     0.    40.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -52.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 167.19126892089844






Player: 1 
cards in hand: [ 0.  0.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 29.] 
cards in discard: [8. 0. 3. 4. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 3. 4. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8. 0. 3. 4. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 29.  8. 10. 10. 10.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 8.  0.  3.  4.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[106.778564]
 [110.06354 ]
 [110.06354 ]
 [110.06354 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3. 29.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.28916931152344



action possibilites: [-1. 29. 29.] 
expected returns: [[103.27865]
 [106.94104]
 [106.94104]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 110.56056213378906



action possibilites: [-1. 29.] 
expected returns: [[132.50658]
 [135.86836]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 106.9410400390625



action possibilites: [-1.] 
expected returns: [[141.6274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 135.8683624267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[138.40059]
 [141.52878]
 [136.67838]
 [139.80655]
 [137.6254 ]
 [135.90315]
 [141.9056 ]
 [142.07681]
 [140.67087]
 [147.30406]
 [146.52885]
 [138.17343]
 [142.53638]
 [138.94864]
 [139.40817]
 [141.30164]
 [143.38991]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  9.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 141.6273956298828



buy possibilites: [-1] 
expected returns: [[164.97789]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -150.     0.     0.    60.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -32.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 147.30406188964844






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  8.  5. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[156.49138]
 [160.8881 ]
 [160.01656]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25. 29.] 
cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8. 10. 10.  9.  9.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 8.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10] -> size -> 17 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1
Learning step: 0
desired expected reward: 164.97789001464844



action possibilites: [-1] 
expected returns: [[149.82005]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 8.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 160.34564208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[150.03873]
 [153.54723]
 [151.61395]
 [147.23393]
 [153.97586]
 [154.16019]
 [152.58496]
 [159.15901]
 [149.78018]
 [150.65172]
 [153.28862]
 [155.62369]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  5. 10. 10.  9. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 8.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 149.82005310058594



buy possibilites: [-1] 
expected returns: [[174.4469]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 29.  0.  3.] 
cards in discard: [25. 29. 29. 29.  0.  3.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [4. 3. 3. 0. 8.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
  128    0] 
sum of rewards: -7 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 159.1590118408203






Player: 1 
cards in hand: [4. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 3. 3. 0. 8.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 3. 3. 0. 8.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[119.98359]
 [123.12253]
 [123.12253]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 174.4468994140625



action possibilites: [-1. 29. 29.] 
expected returns: [[128.52994]
 [131.66887]
 [131.66887]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 123.29153442382812



action possibilites: [-1. 29.] 
expected returns: [[127.39929]
 [130.53822]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 131.66888427734375



action possibilites: [-1.] 
expected returns: [[159.0085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 130.53822326660156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[155.40584]
 [158.60469]
 [153.644  ]
 [156.84288]
 [154.61217]
 [152.85033]
 [158.99278]
 [159.16475]
 [157.72769]
 [164.51352]
 [163.71985]
 [155.1722 ]
 [159.63614]
 [155.96587]
 [156.43729]
 [158.37108]
 [160.50356]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  8.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 159.0084991455078



buy possibilites: [-1] 
expected returns: [[175.86736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5.     0.     0.  -120.     0.     0.    60.     0.     0.     0.
    0.     0.     0.     0.    62.5    0. ] 
sum of rewards: -2.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 164.51353454589844






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10.  0.  0.  3.  3.  0.  6.  4.  3.  3.  0.  8. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  3.  0. 29.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[172.98776]
 [177.39467]
 [176.52309]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29.  0.] 
cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  9. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  4. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10] -> size -> 19 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 175.8673553466797



action possibilites: [-1] 
expected returns: [[204.60872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  0. 29.  0.] 
cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  4. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 175.74441528320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[201.84903]
 [205.35748]
 [203.42424]
 [199.04419]
 [205.97049]
 [204.39525]
 [202.46198]
 [207.43398]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  0. 29.  0.] 
cards in discard: [25. 29. 29. 29.  0.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  4. 10.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6] -> size -> 20 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 204.6087188720703






Player: 1 
cards in hand: [ 0.  3.  6.  4. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  4. 10.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 4. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 4. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  9.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 4. 0.] 
cards in discard: [6. 8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[120.55456 ]
 [123.693504]
 [123.693504]
 [124.46869 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  8. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  8.  3.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8] -> size -> 21 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 207.43397521972656



action possibilites: [-1] 
expected returns: [[144.61014]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  8.  3.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8  6] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.26244354248047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[141.83388]
 [145.03275]
 [143.27092]
 [139.27838]
 [145.59279]
 [144.15575]
 [142.39394]
 [146.93164]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0.  3.  8.  3.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8  6] -> size -> 22 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.61013793945312






Player: 1 
cards in hand: [29.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  8.  3.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 11.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  3  4  3  8 11 10  6 10  6  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[152.20677]
 [156.44048]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  3.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 29.  8.  7. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.93161010742188



action possibilites: [-1] 
expected returns: [[171.71667]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.80821228027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[170.0745 ]
 [173.51598]
 [171.61961]
 [167.32321]
 [174.11719]
 [172.57207]
 [170.6757 ]
 [175.55272]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 10.] 
adversary cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.7166748046875






Player: 1 
cards in hand: [ 0.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 10.] 
cards in discard: [ 6.  8. 10.  0.  3.  6.  4.  0.  6.  3. 29.  8.  0.  3.  6.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[110.08197 ]
 [113.081245]
 [113.081245]
 [113.081245]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 175.55270385742188



action possibilites: [-1. 29. 29.] 
expected returns: [[122.38582]
 [125.48607]
 [125.48607]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 112.68705749511719



action possibilites: [-1. 29.] 
expected returns: [[129.62718]
 [132.84346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 125.48605346679688



action possibilites: [-1.] 
expected returns: [[158.4872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 132.8434600830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[157.53194]
 [160.7308 ]
 [155.77011]
 [158.96896]
 [156.73825]
 [154.97641]
 [161.11887]
 [161.29083]
 [159.85379]
 [166.6396 ]
 [165.84592]
 [157.29831]
 [161.76225]
 [158.09195]
 [158.56335]
 [160.49715]
 [162.62967]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 7 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  7.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 158.48719787597656



buy possibilites: [-1] 
expected returns: [[174.0038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   60.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 87.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 166.6396026611328






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[176.26497]
 [179.80028]
 [179.80028]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3. 29.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 174.00379943847656



action possibilites: [-1. 29.] 
expected returns: [[195.01263]
 [198.54797]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 178.12342834472656



action possibilites: [-1. 25.] 
expected returns: [[229.16963]
 [233.5765 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 25.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 29.  8.  6. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 198.54798889160156



action possibilites: [-1] 
expected returns: [[212.13634]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 29.  8.  5. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 233.57650756835938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[204.98958]
 [208.49803]
 [206.56479]
 [204.11801]
 [202.18475]
 [208.92668]
 [209.11101]
 [207.53578]
 [214.98138]
 [214.10983]
 [204.73099]
 [209.63036]
 [205.60254]
 [206.12189]
 [208.23946]
 [210.57452]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 29.  8.  5. 10.  9.  8.  6.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 212.13633728027344



buy possibilites: [-1] 
expected returns: [[189.83574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 25.  0.] 
cards in discard: [25. 29. 29. 29.  3.  0.  0.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 29.  8.  5. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [4. 6. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 214.9813995361328






Player: 1 
cards in hand: [4. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 29.  8.  5. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 29.  8.  5. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  5. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29.  3.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[129.98967]
 [133.1286 ]
 [133.9038 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  5. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  6. 10.  3.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6. 3. 4. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3] -> size -> 26 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 189.8357391357422



action possibilites: [-1] 
expected returns: [[139.87314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  4. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  6. 10.  3.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6. 3. 4. 6. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.6500701904297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[137.6492 ]
 [139.05518]
 [135.1518 ]
 [139.91948]
 [142.63855]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 26. 29.  8.  4. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  6. 10.  3.  3.] 
adversary cards in discard: [0. 3. 0. 0. 3. 0. 6. 3. 4. 6. 3. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6] -> size -> 27 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.87313842773438






Player: 1 
cards in hand: [29.  6. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 10.  3.  3.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6. 3. 4. 6. 3. 0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  4. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 10.  3.  3.] 
cards in discard: [0. 3. 0. 0. 3. 0. 6. 3. 4. 6. 3. 0. 0. 6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6] -> size -> 27 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  4. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [25. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[173.98451]
 [178.30731]
 [178.30731]
 [177.45242]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  0.  0.] 
cards in discard: [25. 29.  3.  0.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  4. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.6385498046875



action possibilites: [-1] 
expected returns: [[158.4011]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  0.  0.  0.] 
cards in discard: [25. 29.  3.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 176.93373107910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[152.48523]
 [155.92671]
 [154.03033]
 [149.73396]
 [156.3472 ]
 [156.52794]
 [154.9828 ]
 [161.43138]
 [152.23155]
 [153.08644]
 [155.67303]
 [157.96346]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  0.  0.  0.] 
cards in discard: [25. 29.  3.  0.  0. 29.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  4. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.40109252929688



buy possibilites: [-1] 
expected returns: [[181.50638]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  0.  0.  0.] 
cards in discard: [25. 29.  3.  0.  0. 29.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  8.  8.  6.  0.] 
adversary cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6  6] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 161.43136596679688






Player: 1 
cards in hand: [10.  8.  8.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.  6.  0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  3.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3. 29. 25. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 0. 1.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  1  0
  6  3  6  6] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  3.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3. 29. 25. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  3.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3. 29. 25. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0.] 
cards in discard: [ 0.  3.  0.  0.  3.  0.  6.  3.  4.  6.  3.  0.  0.  6. 29.  6. 10.  3.
  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 25.  0.  3.] 
adversary cards in discard: [25. 29.  3.  0.  0. 29.  3. 29. 25. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [29. 25. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[145.18819]
 [148.87477]
 [149.78404]
 [149.78404]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0.  3.] 
cards in discard: [25. 29.  3.  0.  0. 29.  3. 29. 25. 25. 29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  3. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6] -> size -> 27 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 181.50637817382812



action possibilites: [-1] 
expected returns: [[135.62085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  3. 25. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 149.78407287597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[133.56926]
 [131.07184]
 [138.55858]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  3. 25. 29.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6] -> size -> 28 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.620849609375






Player: 1 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [6. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[152.54189]
 [156.0098 ]
 [156.0098 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  3.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.55857849121094



action possibilites: [-1. 29.] 
expected returns: [[171.45853]
 [174.92644]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  0.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 155.41941833496094



action possibilites: [-1.] 
expected returns: [[202.39015]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 174.92642211914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[198.16142]
 [201.60292]
 [199.70654]
 [197.30653]
 [195.41017]
 [202.02339]
 [202.20413]
 [200.65901]
 [207.96245]
 [207.10756]
 [197.90775]
 [202.7136 ]
 [198.76263]
 [199.27213]
 [201.34921]
 [203.63968]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  5.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 202.39015197753906



buy possibilites: [-1] 
expected returns: [[180.46504]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29. 25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 6. 3.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 345 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 207.96246337890625






Player: 1 
cards in hand: [6. 3. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 3.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3. 25. 29. 25. 29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 3.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25. 29.  0.  0.] 
adversary cards in discard: [25. 29. 25.  0.  3. 25. 29. 25. 29. 29.  0.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[142.93768]
 [147.25548]
 [147.25548]
 [146.4014 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.  0.  0.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29. 25. 29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  2. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  4.  8.  0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0] -> size -> 29 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 180.4650421142578



action possibilites: [-1] 
expected returns: [[135.20021]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  0. 29.  0.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29. 25. 29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  4.  8.  0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 147.25547790527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[130.95251]
 [134.33002]
 [132.46925]
 [128.25314]
 [134.92052]
 [133.4038 ]
 [131.54303]
 [136.3312 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  0. 29.  0.] 
cards in discard: [25. 29. 25.  0.  3. 25. 29. 25. 29. 29.  0.  0.  3.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  6.  4.  8.  0.] 
adversary cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6] -> size -> 30 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 135.20021057128906






Player: 1 
cards in hand: [10.  6.  4.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  4.  8.  0.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 8. 0. 8.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 8. 0. 8.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 8. 0. 8.] 
cards in discard: [6. 0. 0. 0. 3. 6. 0. 6. 3. 3. 6. 3. 6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 25. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[109.18841]
 [113.10253]
 [112.32733]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 25. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  1. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0] -> size -> 31 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 136.3312225341797



action possibilites: [-1] 
expected returns: [[136.97466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 111.77528381347656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[129.55342]
 [130.99046]
 [131.87529]
 [134.65117]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6] -> size -> 32 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.9746551513672






Player: 1 
cards in hand: [ 3. 10.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 26. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 26. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  3. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [25. 25.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[141.865  ]
 [146.18782]
 [146.18782]
 [145.3329 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  3. 29.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 134.6511688232422



action possibilites: [-1] 
expected returns: [[160.62778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 29. 29.  0.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 146.18780517578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[156.51491]
 [158.02884]
 [158.96184]
 [161.88298]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3. 29. 29.  0.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.62777709960938






Player: 1 
cards in hand: [ 0.  6. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 25. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  8.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 25. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 29.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  3.  6.  0.  6.  3.  3.  6.  3.  6.  0. 10.  6.  4.  8.
  0.  8.  6.  3. 10.  3.  0.  0.  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  0. 25. 29.] 
adversary cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [25.  0.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[114.73884 ]
 [118.499916]
 [118.499916]
 [117.75464 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 25. 29.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.8829803466797



action possibilites: [-1] 
expected returns: [[146.75847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 29. 29.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 118.49992370605469





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[141.77954]
 [143.29976]
 [144.23627]
 [147.17041]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25. 29. 29. 29.] 
cards in discard: [25.  0.  3.  3. 29. 25.  0. 25. 25.  0.  3. 29. 29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 146.7584686279297






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [29.  3. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[111.839134]
 [114.97806 ]
 [115.753265]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6. 29.  6. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 147.17042541503906



action possibilites: [-1] 
expected returns: [[141.20874]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6. 29.  6. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 114.9874267578125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[137.21371]
 [142.07167]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  6. 29.  6. 10.] 
adversary cards in discard: [8. 0. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 141.208740234375






Player: 1 
cards in hand: [ 6.  6. 29.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 29.  6. 10.] 
cards in discard: [8. 0. 3. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 10.  3.] 
cards in discard: [8. 0. 3. 0. 0. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [8. 0. 3. 0. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 2 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 3. 3.] 
cards in discard: [8. 0. 3. 0. 0. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 2 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[150.75974]
 [154.15604]
 [154.99344]
 [154.15604]
 [154.99344]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 29. 25.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 142.07167053222656



action possibilites: [-1] 
expected returns: [[145.04764]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25.  0.  0.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.99343872070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[141.43774]
 [144.72574]
 [142.91437]
 [145.30066]
 [143.82405]
 [142.01268]
 [146.67448]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25.  0.  0.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 3. 0. 6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 145.04763793945312






Player: 1 
cards in hand: [6. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 0. 6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25. 29.  0. 25.] 
adversary cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[126.66088]
 [131.01555]
 [130.15337]
 [131.01555]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0. 25.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 4. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.67446899414062



action possibilites: [-1] 
expected returns: [[121.27158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  3. 29.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 4. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 131.0155487060547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[116.59157 ]
 [118.01342 ]
 [118.888245]
 [121.63564 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 25.  3. 29.] 
cards in discard: [25. 29.  3.  3.  0. 29. 25. 25. 29.  0. 29. 25.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 4. 6. 0.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.2715835571289






Player: 1 
cards in hand: [6. 3. 4. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 4. 6. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 4. 6. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 4. 6. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 25. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[101.62227]
 [105.5364 ]
 [104.7612 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0  0] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.63565063476562



action possibilites: [-1] 
expected returns: [[136.73315]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0  0] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 105.22694396972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[133.05731]
 [136.17249]
 [134.45705]
 [136.71826]
 [135.31853]
 [133.6031 ]
 [138.02368]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8. 10.  6.  0.  6.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0  0] -> size -> 36 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 136.733154296875






Player: 1 
cards in hand: [ 8. 10.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  6.  0.  6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8 10  6 10  6  8  6  3  6  0  6
  3  6  6  6  0  6  0  6  3  8  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 29.  3.  3.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[154.63261]
 [158.10052]
 [158.10052]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3.  3.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 138.023681640625



action possibilites: [-1. 25.] 
expected returns: [[163.63245]
 [167.86617]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 25.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 152.5958709716797



action possibilites: [-1] 
expected returns: [[161.45862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 25.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 167.86614990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[157.3066 ]
 [160.81506]
 [158.8818 ]
 [161.42804]
 [159.85281]
 [157.91957]
 [162.89154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3.  0. 25.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 8.] 
adversary cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.4586181640625






Player: 1 
cards in hand: [6. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 8.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3
  6  6  6  0  6  0  6  3  8  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 25. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 8.  0.  3.  0.  0.  6. 29. 10.  6.  6.  3.  3.  0.  6.  3.  3.  0.  6.
  0.  6.  3.  4.  6.  0.  8.  6.  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25. 25.  0.  0. 29.] 
adversary cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [25. 25.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[148.31664]
 [152.72354]
 [152.72354]
 [151.85197]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0. 29.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 162.8915252685547



action possibilites: [-1] 
expected returns: [[117.98186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0. 29. 25. 29.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.72352600097656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[113.67409 ]
 [115.159744]
 [116.07376 ]
 [118.94439 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  0. 29. 25. 29.] 
cards in discard: [25.  0.  0. 29.  0.  3. 29. 29. 29. 25.  0.  3.  3.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 117.98185729980469






Player: 1 
cards in hand: [6. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6
  6  6  0  6  0  6  3  8  0  0  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 25. 29. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [29. 25. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[129.70488]
 [132.84381]
 [133.61902]
 [132.84381]
 [133.61902]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 25.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.94439697265625



action possibilites: [-1] 
expected returns: [[155.70662]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.85317993164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[151.41063]
 [156.39995]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25.  3. 29. 25.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [0. 8. 6. 3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.7066192626953






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [0. 8. 6. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 0.  8.  6.  3. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  3.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[174.51953]
 [178.77019]
 [177.91583]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0. 29.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.3999481201172



action possibilites: [-1] 
expected returns: [[147.89813]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0. 29.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 178.77017211914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[144.09077]
 [147.53227]
 [145.6359 ]
 [148.1335 ]
 [146.58838]
 [144.69199]
 [149.56902]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0. 29.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 4. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 147.89813232421875






Player: 1 
cards in hand: [6. 4. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 4. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25. 29.] 
adversary cards in discard: [25. 29. 29. 25.  3. 29. 25. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 4. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 25. 29.] 
adversary cards in discard: [25. 29. 29. 25.  3. 29. 25. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[129.62758]
 [133.68385]
 [132.88115]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 25. 29.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25. 25.  0.  3.  0. 29.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.5690155029297



action possibilites: [-1] 
expected returns: [[129.1144]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 25.  0.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25. 25.  0.  3.  0. 29.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.683837890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[124.351906]
 [127.79059 ]
 [125.895966]
 [128.39156 ]
 [126.8475  ]
 [124.95287 ]
 [129.82672 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 29. 25.  0.] 
cards in discard: [25. 29. 29. 25.  3. 29. 25. 25.  0.  3.  0. 29.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 3. 8. 6.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 129.11439514160156






Player: 1 
cards in hand: [3. 6. 3. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 8. 6.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 8. 6.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[118.52666]
 [121.66559]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 129.8267364501953



action possibilites: [-1.] 
expected returns: [[124.77072]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 116.10344696044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[121.532875]
 [124.661064]
 [122.93885 ]
 [125.037895]
 [125.20911 ]
 [123.80315 ]
 [129.66113 ]
 [121.30573 ]
 [122.080925]
 [124.433914]
 [126.52221 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  3. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 124.77072143554688



buy possibilites: [-1] 
expected returns: [[167.5226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [ 3. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 3. 3. 6. 0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 233 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 129.66114807128906






Player: 1 
cards in hand: [8. 3. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 6. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8  6 10  6  8  6  3  6  0  6  3  6  6  6
  0  6  0  6  3  8  0  0  3  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 25. 25.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 25. 25.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 25. 25.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 29. 25. 25.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[171.27113]
 [174.66743]
 [175.50484]
 [175.50484]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 25. 25.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 167.52259826660156



action possibilites: [-1] 
expected returns: [[158.5903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29. 25.  0. 29.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 175.50485229492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[154.54317]
 [156.0571 ]
 [156.99011]
 [159.91124]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29. 25.  0. 29.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  6. 29.  0.  0.] 
adversary cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.59030151367188






Player: 1 
cards in hand: [ 0.  6. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 29.  0.  0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10. 10.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  6.  3. 10.  0.  0.  0.  0.  6.  6.  4.  0.  6.  6.  3.  6.  3.
  8.  6.  0.  8.  3.  3.  0.  0. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 25.  0. 25. 29.] 
adversary cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25. 29.] 
expected returns: [[141.06587]
 [144.31946]
 [145.12213]
 [145.12213]
 [144.31946]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25. 29.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 159.9112548828125



action possibilites: [-1] 
expected returns: [[163.70671]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25. 29.  0. 25.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.12213134765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[159.24385]
 [160.76407]
 [161.70058]
 [164.63472]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 25. 29.  0. 25.] 
cards in discard: [ 3. 29. 29.  0.  3.  0.  0. 25.  0.  3. 29. 25.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.7067108154297






Player: 1 
cards in hand: [ 6. 10.  3.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  3.  6.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 6. 0.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29.  3. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29.  3. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[120.23895 ]
 [123.29114 ]
 [123.29114 ]
 [123.29114 ]
 [124.045204]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.6347198486328



action possibilites: [-1] 
expected returns: [[142.91075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 29.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 124.04521179199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[139.15923]
 [143.9026 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 29.  0. 25.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  3.  0.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.91075134277344






Player: 1 
cards in hand: [ 6. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  3.  0.  0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  7.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 3.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0. 29.  3.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[190.75435]
 [194.22224]
 [194.22224]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29.  3.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 4. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 143.90260314941406



action possibilites: [-1.] 
expected returns: [[194.52081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 4. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 188.7176055908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[190.30531]
 [193.677  ]
 [191.81924]
 [194.08847]
 [194.26619]
 [192.75226]
 [199.0697 ]
 [190.05708]
 [190.89449]
 [193.42879]
 [195.67339]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  2. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 4. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 194.52081298828125



buy possibilites: [-1] 
expected returns: [[179.72754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 4. 0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 203 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 199.06968688964844






Player: 1 
cards in hand: [0. 0. 3. 4. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 4. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 25.  0.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 4. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  6.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 25.  0.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 4. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  0. 25.  0.] 
adversary cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[156.97165]
 [160.50697]
 [161.37854]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 25.  0.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 179.7275390625



action possibilites: [-1] 
expected returns: [[148.68173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0. 25.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 161.3785400390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[143.30602]
 [146.74469]
 [144.85004]
 [147.34564]
 [145.8016 ]
 [143.90697]
 [148.7808 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  0.  0. 25.] 
cards in discard: [25. 29.  3. 29. 29.  0. 25. 29. 29. 29.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [8. 0. 6. 0. 6.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 39 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 148.68173217773438






Player: 1 
cards in hand: [8. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 0. 6.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  6  8  6  3  6  0  6  3  6  6  6  0
  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 25. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[134.08049]
 [137.12605]
 [137.87846]
 [137.87846]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 148.7808074951172



action possibilites: [-1] 
expected returns: [[162.53325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 137.8784637451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[159.89757]
 [161.21893]
 [162.03001]
 [164.60997]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6.  3. 10.  3.  0.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 162.5332489013672






Player: 1 
cards in hand: [ 6.  3. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 25.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  3.  0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 25.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [29. 29. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[201.77621]
 [205.18839]
 [205.18839]
 [206.04245]
 [206.04245]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0. 25.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.60997009277344



action possibilites: [-1] 
expected returns: [[182.95854]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0. 25.  0. 29.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 206.04246520996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[179.16798]
 [180.68192]
 [181.61491]
 [184.53607]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  0. 25.  0. 29.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 8. 0. 6. 8.] 
adversary cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.9585418701172






Player: 1 
cards in hand: [6. 8. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 8.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3  8 10  8  3  6  0  6  3  6  6  6  0  6  0
  6  3  8  0  0  3  0 10  0 15  0  8  8  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  6.  3.  3.  6.  0.  0.  8. 29.  6.  3.  0.  3.  8.  0.  0.  3.
  4.  0.  0.  8.  0.  0.  6.  3. 10.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  0. 25.] 
adversary cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[186.56993]
 [190.88773]
 [190.88773]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  0. 25.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 184.5360870361328



action possibilites: [-1] 
expected returns: [[161.523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 25. 29.  0.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 190.88772583007812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[156.21094]
 [159.59596]
 [157.73117]
 [160.18787]
 [158.66765]
 [156.80286]
 [161.60182]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 25. 29.  0.] 
cards in discard: [25.  3.  0. 29. 25.  0.  3. 25. 29. 29.  0. 25.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 15.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 161.5229949951172






Player: 1 
cards in hand: [ 3.  0.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  6.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 24. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 15.  6.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 29. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25. 29. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 29. 29.] 
expected returns: [[142.16386]
 [145.85396]
 [145.12267]
 [145.12267]
 [145.12267]
 [145.12267]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0  3] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 161.601806640625



action possibilites: [-1] 
expected returns: [[157.8214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0  3] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.8539581298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[154.58095]
 [159.2967 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 6. 3. 8. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0  3] -> size -> 36 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 157.82139587402344






Player: 1 
cards in hand: [0. 6. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 8. 0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 29  3  4  3 10  8  3  0  3  6  6  6  0  6  0  6  3  8
  0  0  3  0 10  0 15  0  8  8  0  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  0. 15.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  0. 15.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[185.3303 ]
 [189.56401]
 [188.72661]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 25. 29.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 159.2967071533203



action possibilites: [-1] 
expected returns: [[185.77184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29.  0. 29.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 189.5640106201172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[182.54327]
 [185.91498]
 [184.05722]
 [186.50415]
 [184.99023]
 [183.13248]
 [187.91138]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29.  0. 29.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 8. 6. 6. 3.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3  0] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 185.77183532714844






Player: 1 
cards in hand: [3. 8. 6. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 6. 6. 3.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  6  0  6  0  6  3  8  0  0  3  0
 10  0 15  0  8  8  0  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  3.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  3.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  3.  3.] 
adversary cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[181.12518]
 [185.53207]
 [184.66052]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  3.  3.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 187.911376953125



action possibilites: [-1] 
expected returns: [[178.87311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 185.53208923339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[173.45293]
 [175.02814]
 [175.99916]
 [179.03787]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  3.  0. 25.] 
cards in discard: [25. 29. 29. 29. 29. 25.  0. 25.  3.  0.  0. 29.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 4. 0. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 178.87310791015625






Player: 1 
cards in hand: [0. 4. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 23. 29.  8.  0. 10.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[137.74112]
 [140.7331 ]
 [140.7331 ]
 [141.47237]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 179.03785705566406



action possibilites: [-1] 
expected returns: [[158.65463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.9060821533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[156.01088]
 [157.37953]
 [158.22047]
 [160.86885]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0. 25.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10.  3.  0. 29.  8.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
adversary owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 158.65463256835938






Player: 1 
cards in hand: [10.  3.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 29.  8.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 29  3  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10
  0 15  0  8  8  0  3  0 16] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[213.02312]
 [216.41942]
 [216.41942]
 [216.41942]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.8688507080078



action possibilites: [-1. 29. 29.] 
expected returns: [[158.7942]
 [162.1905]
 [162.1905]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 211.0267333984375



action possibilites: [-1.] 
expected returns: [[220.7324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 156.7978057861328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[215.966  ]
 [219.33768]
 [217.47992]
 [219.92688]
 [218.41295]
 [216.55518]
 [221.33409]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 10.  8.  0.] 
adversary cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
adversary owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 220.73240661621094






Player: 1 
cards in hand: [ 0.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.  0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 29  4  3 10  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15
  0  8  8  0  3  0 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3.  3.  0.  0. 15.  6.  0.  8.  8.  3.  6.  3. 16.  0.  4.  0.  0.  0.
  0. 10.  8. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25. 25.  0.  0.] 
adversary cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [25. 25. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[202.227  ]
 [206.47829]
 [206.47829]
 [206.47829]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  0.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 221.33407592773438



action possibilites: [-1] 
expected returns: [[184.20363]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  0.  0. 25.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 206.47828674316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[178.69992]
 [182.20839]
 [180.27515]
 [182.82138]
 [181.24615]
 [179.3129 ]
 [184.28487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  0.  0. 25.] 
cards in discard: [25.  0. 29. 29.  0. 25.  3. 29. 29. 29. 29.  3.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 184.20362854003906






Player: 1 
cards in hand: [3. 0. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 23. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 6.] 
cards in discard: [3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 25. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [29. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29.] 
expected returns: [[153.25218]
 [156.29774]
 [157.05016]
 [156.29774]
 [156.29774]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 184.2848663330078



action possibilites: [-1] 
expected returns: [[188.36024]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 155.87648010253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[185.6934 ]
 [187.0514 ]
 [187.89235]
 [190.5407 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 8.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 188.36024475097656






Player: 1 
cards in hand: [0. 0. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 8.] 
cards in discard: [3. 3. 0. 0. 3. 6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25.  3.  0. 29. 29.] 
adversary cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [25.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[199.93944]
 [204.17317]
 [203.33575]
 [203.33575]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29. 29.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  4.  3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6. 0. 0. 0. 8. 0. 8.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 190.5406951904297



action possibilites: [-1] 
expected returns: [[180.43721]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 25.  0.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  4.  3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6. 0. 0. 0. 8. 0. 8.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 204.1731719970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[176.64665]
 [178.1606 ]
 [179.09361]
 [182.01474]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29. 25.  0.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 10.  3.  4.  3.] 
adversary cards in discard: [3. 3. 0. 0. 3. 6. 0. 0. 0. 8. 0. 8.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.4372100830078






Player: 1 
cards in hand: [ 6. 10.  3.  4.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  3.  4.  3.] 
cards in discard: [3. 3. 0. 0. 3. 6. 0. 0. 0. 8. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0. 25.  0. 25.  3.  0. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  3.  4.  3.] 
cards in discard: [3. 3. 0. 0. 3. 6. 0. 0. 0. 8. 0. 8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29. 29. 25.  0.] 
adversary cards in discard: [25. 29. 29. 29.  0. 25.  0. 25.  3.  0. 29. 29. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 25.] 
expected returns: [[184.80278]
 [188.03624]
 [188.03624]
 [188.03624]
 [188.83427]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25.  0.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0. 25.  3.  0. 29. 29. 25.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 182.01473999023438



action possibilites: [-1] 
expected returns: [[182.09364]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  0.  3. 25.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0. 25.  3.  0. 29. 29. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 188.83425903320312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[176.75699]
 [182.34193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29.  0.  3. 25.] 
cards in discard: [25. 29. 29. 29.  0. 25.  0. 25.  3.  0. 29. 29. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.09364318847656






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  1. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [25. 25.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[129.47466]
 [133.34216]
 [133.34216]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  0. 15.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 182.34193420410156



action possibilites: [-1] 
expected returns: [[168.89284]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  0. 15.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.5767364501953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[166.3248 ]
 [167.68922]
 [168.53017]
 [171.17854]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0.  0. 25. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 6. 29.  0. 15.  0.] 
adversary cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 168.89283752441406






Player: 1 
cards in hand: [ 6. 29.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0. 15.  0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.  6. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.  6. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  9.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  3.  6.  0.  0.  0.  8.  0.  8.  6. 10.  3.  4.  3. 29.
  0.  0.  3.  0.  0.  6. 15. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0.  3.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[182.16365]
 [185.55995]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 171.17852783203125



action possibilites: [-1.] 
expected returns: [[190.89995]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 180.1672821044922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[186.87886]
 [190.25058]
 [188.39282]
 [190.66203]
 [190.83974]
 [189.32584]
 [186.63066]
 [187.46806]
 [190.00235]
 [192.24696]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 16.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29 11] -> size -> 33 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 190.8999481201172






Player: 1 
cards in hand: [ 0.  0. 16.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  8.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  8  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8
  0  3  0 16  0  3  0 29 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 22. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25. 29.] 
adversary cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[165.75365]
 [169.16382]
 [170.00475]
 [169.16382]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25. 29.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 192.24696350097656



action possibilites: [-1] 
expected returns: [[156.45734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29. 25. 29.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 170.00474548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[151.99449]
 [153.5147 ]
 [154.45122]
 [157.38536]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 29. 25. 29.] 
cards in discard: [25. 25.  3.  0.  0. 25. 25.  3. 29. 29.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [6. 3. 3. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 156.45733642578125






Player: 1 
cards in hand: [6. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[133.82018]
 [136.78201]
 [136.78201]
 [136.78201]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 15.  4.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 157.38536071777344



action possibilites: [-1.] 
expected returns: [[121.583046]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 15.  4.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 131.7968292236328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[117.25714]
 [118.58639]
 [119.40249]
 [121.97556]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [29. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [10. 15.  4.  0. 29.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
adversary owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3  0] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 121.58304595947266






Player: 1 
cards in hand: [10. 15.  4.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  4.  0. 29.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0
  3  0 16  0  3  0 29 11  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4. 29.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4. 29.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4. 29.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[170.59792]
 [173.9942 ]
 [174.83162]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 25.] 
cards in discard: [29. 29. 29.  3.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 121.97557067871094



action possibilites: [-1] 
expected returns: [[199.40952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 25. 29.] 
cards in discard: [29. 29. 29.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.8316192626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[195.36238]
 [196.8763 ]
 [197.80934]
 [200.73045]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29. 25. 29.] 
cards in discard: [29. 29. 29.  3.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 199.40951538085938






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 21. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 25. 29. 25.] 
adversary cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[168.45914]
 [172.66061]
 [171.82118]
 [172.66061]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25. 29. 25.] 
cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 200.73045349121094



action possibilites: [-1] 
expected returns: [[177.15501]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.  0. 25.] 
cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 172.66061401367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[173.03809]
 [176.37242]
 [174.53569]
 [176.95569]
 [175.45807]
 [173.62132]
 [178.34947]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.  0. 25.] 
cards in discard: [29. 29. 29.  3.  3.  0. 25.  0.  3.  0. 29. 25. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 177.15501403808594






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 29. 30. 20. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [25. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[123.01475]
 [126.66735]
 [125.9434 ]
 [125.9434 ]
 [126.66735]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 178.34947204589844



action possibilites: [-1] 
expected returns: [[144.75099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 126.66734313964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[141.5207]
 [146.1533]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [11.  6.  0.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3] -> size -> 36 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 144.75099182128906






Player: 1 
cards in hand: [11.  6.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  0.  0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  5.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  8.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 3.  8.  0.  0. 16.  0.  6.  3.  3.  3.  8. 10. 15. 10.  4. 29.  3.  3.
  0.  0.  3.  8.  3.  0.  0.  6.  0.  0.  8. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 25.  0.  3. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[178.76044]
 [182.09355]
 [182.91548]
 [182.09355]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  3. 29.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 146.15330505371094



action possibilites: [-1] 
expected returns: [[153.74013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29.  0. 25.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 182.9154815673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[149.96426]
 [151.45973]
 [152.3812 ]
 [155.2674 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3. 29.  0. 25.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 153.74012756347656






Player: 1 
cards in hand: [ 3.  3.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3.  0. 29.] 
cards in discard: [0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  3.  0. 25. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[149.05656]
 [152.3834 ]
 [153.20421]
 [152.3834 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 25. 29.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  3.  0. 16.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 155.26739501953125



action possibilites: [-1] 
expected returns: [[155.91064]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 29. 25.  0.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  3.  0. 16.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 153.20420837402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[150.7969 ]
 [152.27333]
 [153.1826 ]
 [156.07326]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0. 29. 25.  0.] 
cards in discard: [25. 29. 29. 25.  0.  3. 29. 25. 29.  0.  3. 29.  0. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  6.  3.  0. 16.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 155.91064453125






Player: 1 
cards in hand: [ 0.  6.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3.  0. 16.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0. 16.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 29. 30. 19. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  3.  0. 16.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29.  0. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 10 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[134.14589]
 [137.16975]
 [137.16975]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 4. 8. 3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 40 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 156.07325744628906



action possibilites: [-1.] 
expected returns: [[147.45485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 4. 8. 3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 40 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 132.3626708984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[144.74228]
 [147.70424]
 [146.0715 ]
 [148.06233]
 [148.22746]
 [146.8876 ]
 [144.52858]
 [145.26053]
 [147.48817]
 [149.48285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [8. 0. 4. 8. 3.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
adversary owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 40 
adversary victory points: 10
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 147.45484924316406






Player: 1 
cards in hand: [8. 0. 4. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 4. 8. 3.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [29  4  3  0  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3
  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 29. 25.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[170.45024]
 [173.69551]
 [174.49664]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29. 25.] 
cards in discard: [29.  0. 29.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 149.48284912109375



action possibilites: [-1] 
expected returns: [[180.06215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 29. 29. 25.] 
cards in discard: [29.  0. 29.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.4966278076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[175.56145]
 [180.92955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 29. 29. 25.] 
cards in discard: [29.  0. 29.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 180.06214904785156






Player: 1 
cards in hand: [ 0.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29. 29.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29. 29.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 18. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29. 29.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25. 29. 29.] 
adversary cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [25. 29. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 29. 29.] 
expected returns: [[166.64131]
 [170.75082]
 [169.93654]
 [170.75082]
 [169.93654]
 [169.93654]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 29. 29.] 
cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 180.92955017089844



action possibilites: [-1] 
expected returns: [[171.63571]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 29.  3. 25.] 
cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 170.7508087158203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[166.6244 ]
 [171.89793]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 29. 29.  3. 25.] 
cards in discard: [29.  0. 29.  0.  0.  0. 25.  3.  0.  3. 29. 29. 25.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  8.  6.  3. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 171.63571166992188






Player: 1 
cards in hand: [ 0.  8.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  6.  3. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  6.  3. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [25. 29. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[142.03026]
 [145.87483]
 [145.11324]
 [145.87483]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 171.89793395996094



action possibilites: [-1] 
expected returns: [[165.34479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 145.8748321533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[163.43549]
 [166.47995]
 [164.80415]
 [167.01373]
 [165.64508]
 [163.96927]
 [168.29343]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 8.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
adversary owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 165.34478759765625






Player: 1 
cards in hand: [ 8.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  3.  6. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0
  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [29. 29. 29. 29. 25.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29. 25.] 
expected returns: [[164.09682]
 [167.27182]
 [167.27182]
 [167.27182]
 [167.27182]
 [168.06963]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 15.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 168.29342651367188



action possibilites: [-1] 
expected returns: [[163.73259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 29. 25.  3.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 15.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 168.0696258544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[158.87877]
 [164.15076]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 29. 25.  3.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 15.  0.] 
adversary cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.7325897216797






Player: 1 
cards in hand: [ 0. 11.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 15.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 15.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 15.  0.] 
cards in discard: [ 0.  3.  3.  3.  0. 29.  3.  0.  6.  3.  0. 16.  8.  8.  0.  3. 11.  0.
  0.  3.  0.  0.  8.  6.  3. 10.  0.  8.  0.  6. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[172.1944 ]
 [175.36858]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.1507568359375



action possibilites: [-1.] 
expected returns: [[164.6071]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 170.32266235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[160.57556]
 [163.99422]
 [162.09956]
 [164.41383]
 [164.59515]
 [163.05115]
 [160.32857]
 [161.16483]
 [163.74109]
 [166.03035]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 29. 25.  0.  0.  0. 25. 25. 29. 29. 29. 29. 25.  3.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 164.6071014404297






Player: 1 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 15.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 4 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  6. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 15. 10.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [25. 29. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29. 25.] 
expected returns: [[134.47287]
 [138.12547]
 [137.40154]
 [137.40154]
 [138.12547]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.03033447265625



action possibilites: [-1] 
expected returns: [[151.79553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 138.12547302246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[149.14742]
 [150.49261]
 [151.31874]
 [153.92223]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3.  0.  3.  8.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
adversary owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 41 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 151.7955322265625






Player: 1 
cards in hand: [16.  3.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  3.  8.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  3  8  0  0  3  0 10  0 15  0  8  8  0  3  0 16  0  3
  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 25.  0. 29. 25.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [29. 25.  0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[170.38496]
 [173.78125]
 [174.61867]
 [173.78125]
 [174.61867]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 29. 25.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 153.92222595214844



action possibilites: [-1] 
expected returns: [[163.46661]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 25. 29.  3.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 174.61866760253906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[159.35326]
 [164.21123]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29. 25. 29.  3.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [8. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
adversary owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.46661376953125






Player: 1 
cards in hand: [8. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 3. 0. 0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  0  6  0  6  8  0  0  0 10  0 15  0  8  8  0  3  0 16  0  3  0 29
 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3. 25.  0. 29.] 
adversary cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[136.31639]
 [140.11964]
 [139.36638]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  0. 29.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 164.2112274169922



action possibilites: [-1] 
expected returns: [[160.62602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 29.  0.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 140.1196746826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[155.41801]
 [158.76086]
 [156.91907]
 [159.34576]
 [157.84404]
 [156.00223]
 [160.74324]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29. 29.  0.] 
cards in discard: [25. 29. 29. 25.  0.  0. 25. 25. 29.  0. 29. 25. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 10.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 160.6260223388672






Player: 1 
cards in hand: [ 3.  0.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 17. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 10.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [29. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[148.14703]
 [151.28596]
 [151.28596]
 [151.28596]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 160.7432403564453



action possibilites: [-1. 29. 29.] 
expected returns: [[168.2289 ]
 [171.12175]
 [171.12175]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.] 
cards in discard: [29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 146.28590393066406



action possibilites: [-1.] 
expected returns: [[171.73991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 166.51446533203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[167.82812]
 [169.15736]
 [169.97348]
 [172.54655]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0. 29.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 1 
player value: 2 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  3.  6.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 171.7399139404297






Player: 1 
cards in hand: [ 6. 11.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  3.  6.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  3.  6.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  3.  6.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 69 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[158.66762]
 [162.79344]
 [161.97719]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0.  0.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 172.5465545654297



action possibilites: [-1] 
expected returns: [[174.98344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  3. 25.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 162.79344177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[171.7549 ]
 [175.1266 ]
 [173.26886]
 [175.71579]
 [174.20186]
 [172.3441 ]
 [177.12299]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  3. 25.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 3.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 174.9834442138672






Player: 1 
cards in hand: [6. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 3.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 29. 25. 25.  0.] 
adversary cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 70 -------------------- 
Player: 0 
cards in hand: [29. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25. 25.] 
expected returns: [[119.213875]
 [122.470856]
 [122.470856]
 [123.29423 ]
 [123.29423 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 25.  0.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 177.1230010986328



action possibilites: [-1] 
expected returns: [[173.69202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25.  0. 25. 29.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 123.29421997070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[168.35536]
 [173.9403 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25.  0. 25. 29.] 
cards in discard: [29.  0. 29.  0. 29. 29.  3. 25.  0. 29.  0.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  8.  0.] 
adversary cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.  6.  0.  3.  0.  3.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 173.6920166015625






Player: 1 
cards in hand: [ 8.  0. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  8.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.  6.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  8.  0.] 
cards in discard: [ 0. 15. 10. 29.  0.  0.  0.  0.  8. 16.  0.  8.  3.  0.  3.  3.  0.  3.
 10.  0.  0.  6. 11.  0.  3.  6.  0.  6.  0.  3.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[150.98903]
 [154.90317]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 173.94032287597656



action possibilites: [-1] 
expected returns: [[163.90103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 154.90316772460938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[162.00023]
 [165.19911]
 [163.43727]
 [165.75914]
 [164.3221 ]
 [162.56026]
 [167.09796]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0.  3. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.90103149414062






Player: 1 
cards in hand: [ 0.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  4.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 25.  0.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 72 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[155.56447]
 [158.72298]
 [159.503  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 25.  0.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 167.09796142578125



action possibilites: [-1] 
expected returns: [[142.84154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  0. 29.  0.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.50299072265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[139.68066]
 [142.99118]
 [141.16731]
 [143.56993]
 [142.08328]
 [140.25941]
 [144.95265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  3.  0. 29.  0.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  3.  3.  0. 15.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29.] 
adversary owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 142.84153747558594






Player: 1 
cards in hand: [ 0.  3.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  0. 15.] 
cards in discard: [ 8.  0.  0.  0. 10. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3
  0 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0. 25.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0. 25.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 29. 30. 16. 29.  8.  0.  9.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0. 25.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16.] 
cards in deck: 31 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  0. 25.] 
adversary cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 73 -------------------- 
Player: 0 
cards in hand: [25. 29. 25.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[131.56429]
 [136.01239]
 [135.13202]
 [136.01239]
 [136.01239]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  0. 25.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3. 29.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.] 
adversary owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 144.95265197753906



action possibilites: [-1] 
expected returns: [[152.0621]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0. 25. 29. 25.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3. 29.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.] 
adversary owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 136.01239013671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[146.85057]
 [152.32538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  0. 25. 29. 25.] 
cards in discard: [25.  0.  0.  3.  0.  3. 29. 25. 29.  0.  3.  0. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16.  3. 29.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.] 
adversary owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 152.06210327148438






Player: 1 
cards in hand: [16.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3. 29.  0.  3.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  6  6  8  0  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0
 10  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16] -> size -> 42 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 16.] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 74 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[165.9898 ]
 [169.11272]
 [169.11272]
 [169.11272]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 152.3253631591797



action possibilites: [-1. 29.] 
expected returns: [[155.21617]
 [158.28606]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.] 
cards in discard: [ 0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 164.14273071289062



action possibilites: [-1.] 
expected returns: [[173.71103]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 29.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 153.4067840576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[169.89418]
 [173.09305]
 [171.33124]
 [173.65309]
 [172.21606]
 [170.45421]
 [174.99193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  3. 25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 11.  0. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 173.71102905273438






Player: 1 
cards in hand: [ 0. 11.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 10.  3.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  3. 29.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 75 -------------------- 
Player: 0 
cards in hand: [29.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[178.57234]
 [181.96864]
 [181.96864]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3. 29.  0.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 174.99192810058594



action possibilites: [-1. 25.] 
expected returns: [[189.88008]
 [194.11377]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 25.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 176.57594299316406



action possibilites: [-1] 
expected returns: [[176.25517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 29.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 194.11378479003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[172.099  ]
 [173.52605]
 [174.40454]
 [177.16147]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29. 29.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11. 10.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 176.2551727294922






Player: 1 
cards in hand: [11. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 25.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 25.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0. 25.  0.] 
adversary cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 76 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[189.89091]
 [194.20872]
 [194.20872]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 25.  0.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 177.1614532470703



action possibilites: [-1] 
expected returns: [[182.42712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  0. 25. 29.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 194.20872497558594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[176.99673]
 [180.43542]
 [178.54077]
 [181.03638]
 [179.49234]
 [177.59769]
 [182.47156]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  0. 25. 29.] 
cards in discard: [ 0. 29.  3. 25. 29. 29.  0.  0. 29. 29. 25.  3.  0. 29. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 6. 0. 8. 8.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 182.4271240234375






Player: 1 
cards in hand: [0. 6. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 8. 8.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 25. 25.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 77 -------------------- 
Player: 0 
cards in hand: [25.  0. 25. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[167.52318]
 [171.41696]
 [171.41696]
 [171.41696]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25. 25.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 182.4715576171875



action possibilites: [-1] 
expected returns: [[177.78322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 171.41696166992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[175.15361]
 [176.55194]
 [177.41623]
 [180.1353 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 25.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 8. 0.] 
adversary cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
adversary owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 177.78321838378906






Player: 1 
cards in hand: [0. 8. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 8. 0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  6  8  0  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10
  3  3  8 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29. 29.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29. 29.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0.  0. 10. 29. 16. 15.  3.  3.  0.  3.  3.  0.  0. 29. 16.  0.
  0.  0. 11.  0. 10.  3. 10. 11.  0.  0.  0.  0.  0.  0.  6.  0.  8.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0.  0. 29. 29.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 78 -------------------- 
Player: 0 
cards in hand: [29.  0.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[173.81827]
 [177.14088]
 [177.14088]
 [177.14088]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 29. 29.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 180.1352996826172



action possibilites: [-1. 29.] 
expected returns: [[205.59697]
 [208.99327]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 171.87831115722656



action possibilites: [-1.] 
expected returns: [[201.28835]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 203.60057067871094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[196.3738 ]
 [197.88771]
 [198.82076]
 [201.74187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 201.28834533691406






Player: 1 
cards in hand: [0. 0. 3. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  3.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 6.] 
cards in discard: [8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  0.] 
adversary cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 79 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[140.025  ]
 [143.73247]
 [142.99765]
 [142.99765]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 29.  0.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 201.7418670654297



action possibilites: [-1] 
expected returns: [[118.3407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  0. 25. 25.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 143.7324676513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[113.396034]
 [114.82092 ]
 [115.69677 ]
 [118.45181 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  0. 25. 25.] 
cards in discard: [25.  0. 25. 25.  3.  0. 29. 29.  0.  0.  0. 29. 29.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 118.3406982421875






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 6.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 29. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25.  0. 29. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 80 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[171.4453 ]
 [175.24327]
 [174.49086]
 [174.49086]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 29.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 118.4518051147461



action possibilites: [-1] 
expected returns: [[173.93779]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 175.24327087402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[171.26448]
 [172.70152]
 [173.58635]
 [176.3622 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 29.  3.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10. 29. 11.  0.] 
adversary cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0.] 
adversary owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 173.9377899169922






Player: 1 
cards in hand: [ 0. 10. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 11.  0.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 29. 11. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  0. 16.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [29  6  6  0 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8
 11  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1] -> size -> 44 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 16. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0. 0. 0. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 16.] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.] 
cards in discard: [8. 0. 0. 3. 3. 6. 1. 0. 0. 3. 0. 0. 0. 0. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 29. 16.] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25.  3.  0.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 81 -------------------- 
Player: 0 
cards in hand: [25. 29. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[195.88977]
 [200.12347]
 [199.28607]
 [200.12347]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25.  3.  0.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 176.36221313476562



action possibilites: [-1] 
expected returns: [[175.74712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  0.  0. 29.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 200.1234893798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[171.96468]
 [173.48141]
 [174.41597]
 [177.36494]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25.  3.  0.  0. 29.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 175.7471160888672






Player: 1 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3. 25.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3. 25.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29.  3. 25.] 
adversary cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 82 -------------------- 
Player: 0 
cards in hand: [29.  0. 29.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 25.] 
expected returns: [[162.69057]
 [166.0806 ]
 [166.0806 ]
 [166.91685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3. 25.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 177.3649444580078



action possibilites: [-1] 
expected returns: [[163.1868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  3. 29. 25.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 166.9168701171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[157.97528]
 [163.45009]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 29.  3. 29. 25.] 
cards in discard: [25.  0. 29. 29.  3.  0. 25. 25. 29. 25.  3.  0.  0. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8. 15.  6. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 163.18679809570312






Player: 1 
cards in hand: [ 0.  8. 15.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  6. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10  0 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11
  0  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 28. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 83 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[148.93146]
 [152.94142]
 [152.14775]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
adversary owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 163.45008850097656



action possibilites: [-1] 
expected returns: [[197.80516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
adversary owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 152.94142150878906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
expected returns: [[196.67686]
 [199.87572]
 [198.1139 ]
 [200.26378]
 [200.43576]
 [198.99875]
 [196.44322]
 [197.23688]
 [199.64209]
 [201.7746 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  3.  8.  3.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
adversary owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.80516052246094






Player: 1 
cards in hand: [11.  0.  3.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  8.  3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  0  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0
  3  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  3.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25. 29. 25.  0.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 84 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 29. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[179.3309 ]
 [183.56462]
 [182.7272 ]
 [183.56462]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 29. 25.  0.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 201.77459716796875



action possibilites: [-1] 
expected returns: [[197.77754]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0.  3.  3.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 183.5646209716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[193.92975]
 [195.47379]
 [196.42535]
 [199.40456]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 25.  0.  3.  3.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  8.  0.  0. 29.] 
adversary cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 197.7775421142578






Player: 1 
cards in hand: [ 0.  8.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  0. 29.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0. 29.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0. 29.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.  0.
  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  7.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0. 29.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0.] 
cards in discard: [ 8.  0.  0.  3.  3.  6.  1.  0.  0.  3.  0.  0.  0.  0.  3. 10. 29. 16.
 11. 10.  0.  0.  0.  3.  3.  1. 15.  8.  6. 10.  0.  8. 11.  3.  3.  0.
  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25.  3.  0. 29.] 
adversary cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 





         -------------------- Turn: 85 -------------------- 
Player: 0 
cards in hand: [25. 25.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[145.67299]
 [150.05519]
 [150.05519]
 [149.1792 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3.  0. 29.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11] -> size -> 45 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 199.40455627441406



action possibilites: [-1] 
expected returns: [[122.02756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0. 29. 29. 29.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11] -> size -> 45 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 150.05519104003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[117.22743]
 [122.25708]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  0. 29. 29. 29.] 
cards in discard: [25.  0. 29.  0.  0.  0. 25. 25.  0. 29. 25.  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11] -> size -> 45 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 122.02755737304688






Player: 1 
cards in hand: [ 0.  0.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3
  0  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 15. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [3. 0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [16.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 86 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 29.] 
expected returns: [[178.34615]
 [181.42911]
 [181.42911]
 [181.42911]
 [181.42911]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 122.25708770751953



action possibilites: [-1. 29. 29. 29.] 
expected returns: [[163.14314]
 [166.1887 ]
 [166.1887 ]
 [166.1887 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29.] 
cards in discard: [ 0. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 176.51524353027344



action possibilites: [-1.] 
expected returns: [[165.75575]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 25. 29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 161.3337860107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[161.62108]
 [163.03429]
 [163.90407]
 [166.63487]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 25. 29. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 165.75575256347656






Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 25.  3.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 87 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[205.81636]
 [209.21266]
 [210.05006]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.  3.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3.  1. 11.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 166.6348876953125



action possibilites: [-1] 
expected returns: [[191.608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 25.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3.  1. 11.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 210.050048828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[188.37946]
 [191.75114]
 [189.89337]
 [192.34035]
 [190.8264 ]
 [188.96863]
 [193.74754]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 25.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  3.  1. 11.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 191.60800170898438






Player: 1 
cards in hand: [ 6.  3.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  1. 11.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1. 11.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  2.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  1. 11.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 29. 25. 25.  0.] 
adversary cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 





         -------------------- Turn: 88 -------------------- 
Player: 0 
cards in hand: [25. 29. 25. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25. 25.] 
expected returns: [[144.24403]
 [148.46806]
 [147.6324 ]
 [148.46806]
 [148.46806]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 25.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 193.74752807617188



action possibilites: [-1] 
expected returns: [[139.75249]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 25.  0.  3.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 148.4680633544922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[134.62807]
 [136.10371]
 [137.0114 ]
 [139.8631 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 25. 25.  0.  3.  0.] 
cards in discard: [ 0. 25. 29. 29. 29. 29.  3. 25.  0.  0. 29.  3. 25.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  0.  0. 10.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 139.7524871826172






Player: 1 
cards in hand: [ 8.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 10.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 14. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [10.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 29. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 89 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[173.64058]
 [176.8009 ]
 [176.8009 ]
 [176.8009 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 139.86309814453125



action possibilites: [-1. 29.] 
expected returns: [[168.94626]
 [172.02924]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 171.77198791503906



action possibilites: [-1. 25.] 
expected returns: [[182.36317]
 [186.27728]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.] 
cards in discard: [29.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -115 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 167.11537170410156



action possibilites: [-1] 
expected returns: [[217.03926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.] 
cards in discard: [29.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 186.2772979736328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[213.01187]
 [216.27194]
 [214.47621]
 [216.84239]
 [215.37807]
 [213.58234]
 [218.20572]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.] 
cards in discard: [29.  0.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 8.  8. 29.  6.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
adversary owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 217.0392608642578






Player: 1 
cards in hand: [ 8.  8. 29.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.  6.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  6  6 10 15  8  8  0 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0
  3  0  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 90 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[195.74196]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  3.  1.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 218.20570373535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[192.03926]
 [195.45132]
 [193.55319]
 [196.0643 ]
 [194.50066]
 [192.62845]
 [197.52779]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [10. 11.  3.  1.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 195.74195861816406



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10. 11.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25. 29. 25. 29.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 13. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25. 29. 25. 29.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  1.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [25. 25. 29. 25. 29.] 
adversary cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 91 -------------------- 
Player: 0 
cards in hand: [25. 25. 29. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29. 25. 29.] 
expected returns: [[129.31201]
 [133.86072]
 [133.86072]
 [132.96068]
 [133.86072]
 [132.96068]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29. 25. 29.] 
cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 197.5277862548828



action possibilites: [-1] 
expected returns: [[154.44017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 25. 29.  3. 25.] 
cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 133.8607177734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[149.18703]
 [154.77199]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29. 25. 29.  3. 25.] 
cards in discard: [29.  0.  0.  0. 29. 29. 25.  0. 25.  0.  0.  3.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29.  3.  0.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 154.44017028808594






Player: 1 
cards in hand: [ 0.  0. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  0.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 29. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 92 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29.] 
expected returns: [[155.56718]
 [158.69008]
 [158.69008]
 [158.69008]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 29. 29.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16. 15. 11.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 154.77198791503906



action possibilites: [-1. 29.] 
expected returns: [[176.06154]
 [179.22188]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.] 
cards in discard: [ 0. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16. 15. 11.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 153.72007751464844



action possibilites: [-1.] 
expected returns: [[192.35173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 29.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16. 15. 11.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 174.20896911621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[188.59677]
 [191.74199]
 [190.01   ]
 [192.29297]
 [190.87976]
 [189.14777]
 [193.61057]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 29.  3. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [16. 15. 11.  0.  3.] 
adversary cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -145 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 192.3517303466797






Player: 1 
cards in hand: [16. 15. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15. 11.  0.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  0.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  3.] 
cards in discard: [ 3.  0. 16.  0.  0.  8.  0.  8.  3.  0.  0.  8.  6.  3.  1. 11.  3.  3.
 10.  8.  0.  0.  0. 10.  6.  0. 29.  8.  3. 10. 11.  3.  1.  3.  0.  0.
 29.  3.  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29.  3. 25. 29. 25.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 93 -------------------- 
Player: 0 
cards in hand: [29.  3. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 25.] 
expected returns: [[193.42963]
 [196.82591]
 [197.66331]
 [196.82591]
 [197.66331]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 25. 29. 25.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10
  0] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 193.61058044433594



action possibilites: [-1] 
expected returns: [[185.59547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29. 25.  0.  0.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10
  0] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 197.66334533691406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[181.80492]
 [183.31886]
 [184.25188]
 [187.17302]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3. 29. 25.  0.  0.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8. 15.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10
  0] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 185.59547424316406






Player: 1 
cards in hand: [ 8. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  0  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0
  0 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 25. 25. 29.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 25. 25. 29.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  6.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 25. 25. 29.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0.] 
cards in discard: [11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [15.] 
owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0
 11] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 25. 25. 29.] 
adversary cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 





         -------------------- Turn: 94 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[147.00047]
 [151.05672]
 [151.05672]
 [150.25404]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 25. 29.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 1.] 
adversary cards in discard: [11. 15.  8.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0
 11] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -185 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 187.17300415039062



action possibilites: [-1] 
expected returns: [[128.69043]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 29.  0. 25.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 1.] 
adversary cards in discard: [11. 15.  8.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0
 11] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 151.05673217773438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[123.71533 ]
 [125.158295]
 [126.0464  ]
 [128.83342 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 25. 29.  0. 25.] 
cards in discard: [ 0. 29.  3. 29. 29. 29.  0. 25. 29.  3. 29. 25.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 3. 3. 8. 1.] 
adversary cards in discard: [11. 15.  8.  3.  0.] 
adversary owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0
 11] -> size -> 49 
adversary victory points: 9
player victory points: 3 

Reward from previous game state: 
[  -5    0    0 -180    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.6904296875






Player: 1 
cards in hand: [0. 3. 3. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 1.] 
cards in discard: [11. 15.  8.  3.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [29  6  6 10 15  8 16  3  0 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0
 10  0  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0
 11] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1.] 
cards in discard: [11. 15.  8.  3.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6 10 15  8 16 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0
  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1.] 
cards in discard: [11. 15.  8.  3.  0.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  6  6 10 15  8 16 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0
  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  1.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [25.  0. 29. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
adversary victory points: 3
player victory points: 8 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 6 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [25.  0. 29. 25.  0.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 29 29 29 25 25 29 25 25 25 29 25 29 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 12. 29.  8.  0.  8.  5.  0.  4.  0. 10. 10.  4. 10.  9.] 
adversary cards in hand: [3. 1.] 
adversary cards in discard: [11. 15.  8.  3.  0.  8.] 
adversary owned cards: [29  6  6 10 15  8 16 29 11  3  0 10  3  3  8 11  0  3  0  3  0  0 10  0
  3  0  0  8 16  0  0  0  0  8  1  3  1  0 11  3  0  8  3  3 10  0 11  8] -> size -> 48 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000155 

action type: buy - action -1.0
Learning step: -120011.34375
desired expected reward: -119882.5078125



