 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[71.29506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -180        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000185 

action type: buy - action -1
Learning step: -119999.0390625
desired expected reward: -120208.109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 57.78337  ]
 [ 93.59392  ]
 [ 70.202866 ]
 [ -5.6459203]
 [ 83.709564 ]
 [ 94.41523  ]
 [ 81.83606  ]
 [107.41198  ]
 [ 20.973198 ]
 [ 58.609238 ]
 [ 58.00827  ]
 [ 70.627914 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 71.65655517578125



buy possibilites: [-1] 
expected returns: [[76.49925]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 107.41197204589844






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[79.96523]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.49925231933594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 68.19739 ]
 [100.3993  ]
 [ 79.41543 ]
 [ 15.055792]
 [101.136795]
 [ 89.89762 ]
 [ 68.928375]
 [ 79.719475]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 79.29655456542969



buy possibilites: [-1] 
expected returns: [[84.324265]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 101.13682556152344






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[109.3559]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.32426452636719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 98.447235]
 [135.30463 ]
 [111.25446 ]
 [ 38.082317]
 [136.0903  ]
 [123.28195 ]
 [ 99.23345 ]
 [111.30328 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 110.1934585571289



buy possibilites: [-1] 
expected returns: [[82.809044]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 136.09030151367188






Player: 1 
cards in hand: [ 3.  0. 15.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 15.  0.  3.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  0. 11.  0.  0.] 
adversary cards in discard: [11.  0.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[ 94.58742]
 [117.59645]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  0.] 
cards in discard: [11.  0.  0.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 82.80904388427734



action possibilites: [-1] 
expected returns: [[74.24491]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 136.72665405273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 61.18364  ]
 [ 98.83305  ]
 [ 74.200195 ]
 [  6.9339805]
 [ 88.49734  ]
 [ 99.811295 ]
 [ 86.49418  ]
 [113.55926  ]
 [ 27.742067 ]
 [ 62.102455 ]
 [ 61.574234 ]
 [ 75.26739  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 74.24491119384766



buy possibilites: [-1] 
expected returns: [[76.87512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [11.  0.  0.  3.  3.  0. 10. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3.  0. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 113.55926513671875






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  7. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  3.  0. 15.  0.  3. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 10.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[ 85.81629]
 [ 74.27911]
 [120.36478]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 76.8751220703125



action possibilites: [-1. 10.] 
expected returns: [[52.28795 ]
 [40.518017]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 119.29020690917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 42.173218]
 [ 75.02469 ]
 [ 53.533714]
 [-11.110754]
 [ 65.99642 ]
 [ 75.892624]
 [ 64.264046]
 [ 87.8873  ]
 [ 10.535151]
 [ 43.030155]
 [ 42.592316]
 [ 54.543003]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  8. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 52.2879524230957



buy possibilites: [-1] 
expected returns: [[72.324875]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 87.88726806640625






Player: 1 
cards in hand: [ 0. 11.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 11.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6. 10. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  3.] 
cards in discard: [8. 0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 11. 29.  3.] 
adversary cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 68.10056]
 [ 89.93021]
 [102.21546]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  3.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.32487487792969



action possibilites: [-1. 11. 11.] 
expected returns: [[ 94.1782 ]
 [115.92795]
 [115.92795]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3. 11.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 100.65806579589844



action possibilites: [-1] 
expected returns: [[113.77109]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 137.89801025390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[109.7022  ]
 [137.34535 ]
 [118.36087 ]
 [ 69.28695 ]
 [138.23767 ]
 [126.735596]
 [110.37636 ]
 [119.266975]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 113.77108764648438



buy possibilites: [-1] 
expected returns: [[100.18058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 11.] 
cards in discard: [29. 29.  0. 10.  0.  3.  0. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 89 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 138.2376708984375






Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 8.  0. 11.  0.  3. 11.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 8.  0. 11.  0.  3. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[46.548855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 100.18058013916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 34.298607]
 [ 67.63108 ]
 [ 45.927162]
 [-18.386862]
 [ 68.46075 ]
 [ 56.657528]
 [ 35.166542]
 [ 46.936478]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  5.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 45.04549026489258



buy possibilites: [-1] 
expected returns: [[63.299988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 19 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 68.46076965332031






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10. 29.  3. 10.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  7. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10. 29.  3. 10.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [11. 10. 29.  3. 10.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29. 10.] 
expected returns: [[59.22856]
 [79.08297]
 [48.88725]
 [91.31466]
 [48.88725]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  3. 10.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 63.29998779296875



action possibilites: [-1. 11. 10. 10.] 
expected returns: [[115.0876 ]
 [130.55513]
 [105.78673]
 [105.78673]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  3. 10.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  6. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 88.70289611816406



action possibilites: [-1] 
expected returns: [[110.104095]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 147.09422302246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[105.378334]
 [113.38208 ]
 [ 68.169136]
 [120.637794]
 [114.68522 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  9. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 110.10409545898438



buy possibilites: [-1] 
expected returns: [[110.15529]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3. 10.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  16   0] 
sum of rewards: 21 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 120.6378173828125






Player: 1 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0. 11. 29. 11.  0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
expected returns: [[56.489487]
 [79.999466]
 [92.80589 ]
 [79.999466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29. 11.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.15528869628906



action possibilites: [-1. 11. 11. 29.] 
expected returns: [[104.765656]
 [127.08531 ]
 [127.08531 ]
 [138.95396 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0. 29.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 89.60562133789062



action possibilites: [-1. 11. 11.] 
expected returns: [[141.09389]
 [164.43625]
 [164.43625]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 138.95394897460938



action possibilites: [-1] 
expected returns: [[82.29439]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 187.1305389404297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 72.217255]
 [101.23996 ]
 [ 82.40874 ]
 [ 42.585636]
 [ 23.615242]
 [ 93.32729 ]
 [101.93663 ]
 [ 91.81928 ]
 [143.26108 ]
 [112.38754 ]
 [ 43.28563 ]
 [ 73.96575 ]
 [ 72.91725 ]
 [ 44.803864]
 [ 72.44753 ]
 [ 82.902   ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8. 10.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 82.29438781738281



buy possibilites: [-1] 
expected returns: [[124.02667]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 10.  8. 29. 11. 10.  3. 10.  0. 10. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 11.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 143.26109313964844






Player: 1 
cards in hand: [ 0.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  8. 11.] 
cards in discard: [29.  0.  3.  0.  0.  0.  0.  3. 15.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[75.884926]
 [92.563385]
 [65.28458 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  6. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.02667236328125



action possibilites: [-1] 
expected returns: [[65.27038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 12 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 107.52496337890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[59.292442]
 [68.216156]
 [18.220627]
 [76.39337 ]
 [69.812386]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  8.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.27037811279297



buy possibilites: [-1] 
expected returns: [[123.68013]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  3. 15.  0. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 76.39334106445312






Player: 1 
cards in hand: [ 3.  3. 15.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 11.  0. 10. 29.] 
adversary cards in discard: [10.  8. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 15.  0. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [29. 11.  0. 10. 29.] 
adversary cards in discard: [10.  8. 11.  3.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[109.02348 ]
 [134.48192 ]
 [125.1503  ]
 [ 99.523964]
 [134.48192 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 10. 29.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 123.68013000488281



action possibilites: [-1. 11. 10. 29. 11.] 
expected returns: [[123.522705]
 [140.54579 ]
 [113.611824]
 [150.60677 ]
 [140.54579 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 29. 11.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 129.50155639648438



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[148.41249]
 [166.79   ]
 [137.86159]
 [166.79   ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 11.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  5. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 150.6068115234375



action possibilites: [-1] 
expected returns: [[92.50676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  27   0] 
sum of rewards: 52 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 185.54739379882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 82.52667 ]
 [110.08697 ]
 [ 92.22234 ]
 [ 38.629646]
 [102.59234 ]
 [110.83572 ]
 [101.14002 ]
 [120.8993  ]
 [ 56.345417]
 [ 83.27541 ]
 [ 82.91031 ]
 [ 93.19627 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 92.50675964355469



buy possibilites: [-1] 
expected returns: [[110.59023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 11.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 128   0] 
sum of rewards: 153 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 120.89930725097656






Player: 1 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  3. 15.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 10.] 
adversary cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  3. 15.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  4.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 10.] 
adversary cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 3.  3. 15.  0. 11. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0. 25. 11.  3. 10.] 
adversary cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 25. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[ 79.000305]
 [134.45166 ]
 [ 95.63266 ]
 [ 70.59755 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  3. 10.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8. 10. 10.  3.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11] -> size -> 19 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 110.5902328491211



action possibilites: [-1] 
expected returns: [[64.985504]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  3.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.45162963867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.138092]
 [76.67392 ]
 [65.30299 ]
 [30.198572]
 [77.145996]
 [70.9811  ]
 [59.610153]
 [65.91554 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  3.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 64.98550415039062



buy possibilites: [-1] 
expected returns: [[52.307236]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3. 10.  0.  0.] 
cards in discard: [10.  8. 11.  3.  0.  0. 10. 10. 29. 29. 29. 11.  0. 10. 11.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 77.14600372314453






Player: 1 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 3.  3. 15.  0. 11. 11. 11.  0.  0.  0.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 29. 10.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10. 29. 10.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.  8.] 
expected returns: [[ 99.397575]
 [ 90.37966 ]
 [123.39813 ]
 [ 90.37966 ]
 [105.66752 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 10.  8.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.30723571777344



action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[ 99.21885 ]
 [ 91.183495]
 [ 91.183495]
 [104.902   ]
 [112.59651 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 118.21969604492188



action possibilites: [-1] 
expected returns: [[100.4438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 126.80126953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 93.24455 ]
 [ 54.334362]
 [103.64309 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  8.  3.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 100.44380187988281






Player: 1 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 25.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 25.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0. 10. 11. 25.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25.] 
expected returns: [[ 85.03099]
 [ 75.84013]
 [100.94173]
 [135.81294]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11. 25.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  6. 15.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 103.64305877685547



action possibilites: [-1] 
expected returns: [[37.981888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 11.  0. 11.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  6. 15.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 134.28468322753906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.880001]
 [44.664978]
 [31.208925]
 [-8.897554]
 [45.25338 ]
 [37.92444 ]
 [24.468395]
 [32.068287]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  0. 11.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  2.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  6. 15.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.98188781738281



buy possibilites: [-1] 
expected returns: [[41.004498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 11.  0. 11.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [11. 11.  6. 15.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 45.25335693359375






Player: 1 
cards in hand: [11. 11.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  6. 15.  0.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5. 10. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 15.  0.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 15.  0.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6. 15.  0.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [29. 10. 11.  3.  0.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [29. 10. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[56.337036]
 [75.738495]
 [49.92847 ]
 [68.701744]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10. 11.  3.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.00449752807617



action possibilites: [-1. 10. 11.] 
expected returns: [[35.287323]
 [27.223566]
 [50.262123]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  0.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  3. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 75.73849487304688



action possibilites: [-1] 
expected returns: [[23.320246]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 65.18074035644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 16.618305 ]
 [ 36.723248 ]
 [ 23.586594 ]
 [-14.9430065]
 [ 37.260067 ]
 [ 30.092218 ]
 [ 17.079266 ]
 [ 23.832985 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  1.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.32024574279785



buy possibilites: [-1] 
expected returns: [[38.401787]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 119 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 37.26007080078125






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29.  0.  0.  0.  3. 11.  6. 14.  0. 11. 11.  6. 15.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [11.  3. 29.  0. 29.] 
adversary cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [11.  3. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
expected returns: [[14.225382]
 [27.578512]
 [35.50562 ]
 [35.50562 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0. 29.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.40178680419922



action possibilites: [-1. 11. 29.] 
expected returns: [[25.265875]
 [39.705376]
 [48.17518 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 29.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.999849319458008



action possibilites: [-1. 11.] 
expected returns: [[ 5.0645127]
 [17.077362 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 39.09941101074219



action possibilites: [-1] 
expected returns: [[39.789333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.  8.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 64  0] 
sum of rewards: 149 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 29.39164161682129





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[33.755993]
 [50.206524]
 [39.51149 ]
 [ 6.353173]
 [44.855766]
 [34.160717]
 [39.838463]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.  8.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.78933334350586



buy possibilites: [-1] 
expected returns: [[17.645584]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [10. 29. 11. 10. 10.  8.  3. 11. 25.  0.  0. 10. 11.  0. 11. 10. 11. 29.
 11. 10.  3.  0.  0.  8.  0. 15.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 60  0  0  0  0  0  0  0 54  0] 
sum of rewards: 139 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 50.20652770996094






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 10. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[60.64582 ]
 [83.39371 ]
 [52.112595]
 [52.112595]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 10. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 29.  6. 14. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.645584106445312



action possibilites: [-1. 10. 10.] 
expected returns: [[63.85589]
 [55.6336 ]
 [55.6336 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 29.  6. 14. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 73.30816650390625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[55.761353]
 [78.11918 ]
 [63.619385]
 [15.216183]
 [70.807594]
 [56.401367]
 [64.62364 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 29. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 29.  6. 14. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 63.855865478515625



buy possibilites: [-1] 
expected returns: [[78.70697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.] 
cards in discard: [11.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [11. 29.  6. 14. 15.] 
adversary cards in discard: [0. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 78.1191635131836






Player: 1 
cards in hand: [11. 29.  6. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  6. 14. 15.] 
cards in discard: [0. 0. 0. 0. 3. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  5.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  0. 11.  0. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6. 14. 15.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  0. 11.  0. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  6. 14. 15.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [29.  0. 11.  0. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[50.36744 ]
 [69.41542 ]
 [62.381226]
 [43.1966  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.70697021484375



action possibilites: [-1. 11. 10.] 
expected returns: [[43.89372 ]
 [59.282364]
 [35.90029 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  8.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 61.801910400390625



action possibilites: [-1] 
expected returns: [[65.46337]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 75.21139526367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
expected returns: [[58.960716]
 [79.458275]
 [66.0021  ]
 [28.509478]
 [72.54933 ]
 [59.448868]
 [66.3915  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 28. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 65.46337127685547



buy possibilites: [-1] 
expected returns: [[28.72785]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0 -20   0   0  54   0] 
sum of rewards: 99 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 79.45824432373047






Player: 1 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0. 11.  3.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  7.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0. 11.  3.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [15. 10.  0. 11.  3.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1] -> size -> 37 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [15. 10.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10. 11.] 
expected returns: [[20.65457 ]
 [13.169298]
 [13.505182]
 [34.872787]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0. 11.  3.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  7.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.72784996032715



action possibilites: [-1] 
expected returns: [[59.6158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 79 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 48.89609909057617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.94304 ]
 [15.392027]
 [59.711525]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  0.  3.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [11.  0. 11.  3.  0.] 
adversary cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.61579895019531






Player: 1 
cards in hand: [11.  0. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [10.  8. 11.  3. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [10.  8. 11.  3. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 11.  3.  0.] 
cards in discard: [ 0.  0.  0.  0.  3.  3. 29. 11. 29.  6. 14. 15.  8.  6.  0.  3.  0.  0.
  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [10.  8. 11.  3. 10.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10.  8. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 10.] 
expected returns: [[16.717857]
 [ 9.182474]
 [22.064438]
 [28.464907]
 [ 9.182474]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 11.  3. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  6.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.71155548095703



action possibilites: [-1] 
expected returns: [[41.78589]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 69 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 40.394859313964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.288567 ]
 [ 7.8210063]
 [42.10888  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  3. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [3. 3. 0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8
  0] -> size -> 25 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.785888671875






Player: 1 
cards in hand: [3. 3. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3 15 11  0 11  8  0  3 29 11  6  0  6 14  0  0  0 29  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11.  1.  3.  8.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11.  1.  3.  8.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11.  1.  3.  8.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [11. 11.  1.  3.  8.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [11. 11.  1.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
expected returns: [[-26.659895]
 [-17.391142]
 [-17.391142]
 [-22.44827 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  1.  3.  8.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 42.108882904052734



action possibilites: [-1] 
expected returns: [[-3.9876308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  8.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 119 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -6.763155937194824





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-12.451233  ]
 [ -5.4141765 ]
 [-43.84229   ]
 [  0.91466045]
 [ -3.9876552 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  8.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  6.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.987630844116211



buy possibilites: [-1] 
expected returns: [[-44.9726]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  8.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [29.  3.  0.  3.  0.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 61 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 0.9146771430969238






Player: 1 
cards in hand: [29.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  3.  0.] 
cards in discard: [0. 8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [10.  0.  0. 10. 11.] 
adversary cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8] -> size -> 41 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  0.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[-13.797848 ]
 [-19.796846 ]
 [-19.796846 ]
 [ -3.3176322]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10. 11.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 0. 15.  6. 11. 29.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: -44.972599029541016



action possibilites: [-1] 
expected returns: [[4.549895]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 15.  6. 11. 29.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -70   0   0  64   0] 
sum of rewards: 99 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 7.256144046783447





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ -1.1440587]
 [  3.9793096]
 [-24.598986 ]
 [  9.155632 ]
 [  4.5498967]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  5.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 15.  6. 11. 29.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.5498948097229



buy possibilites: [-1] 
expected returns: [[20.772772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [11.  1. 29.  0.  0. 10. 10. 29. 15.  1. 29. 11.  0.  0. 10. 15. 11. 15.
 10.  0.  3. 15. 11. 10.  8.  3. 10. 15.  8. 11. 11.  1.  3.  8. 15.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 0. 15.  6. 11. 29.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0 -80   0   0  16   0] 
sum of rewards: 41 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 9.155628204345703






Player: 1 
cards in hand: [ 0. 15.  6. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 11. 29.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 29.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 29.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6. 29.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10.  8. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29. 29. 25.] 
expected returns: [[36.358845]
 [29.521498]
 [41.319042]
 [54.570232]
 [54.570232]
 [73.23356 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29. 25.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  8. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0] -> size -> 24 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.77277183532715



action possibilites: [-1] 
expected returns: [[87.33247]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.23355102539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.091934]
 [51.051113]
 [87.346664]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 29. 29. 29. 10.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 6. 11.  0.  0.  0.] 
adversary cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6] -> size -> 25 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 87.33247375488281






Player: 1 
cards in hand: [ 6. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  0.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  1. 10.  3.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0.] 
cards in discard: [ 0.  8.  0. 29.  3.  3.  0.  0.  0.  0. 11.  0. 15.  6. 29.  6. 10. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [0. 0. 1. 0. 3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[60.59877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 87.34664154052734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
expected returns: [[ 53.206608]
 [ 73.102325]
 [ 60.16188 ]
 [ 32.993923]
 [ 20.053488]
 [ 67.66525 ]
 [ 66.62923 ]
 [105.144226]
 [ 81.25049 ]
 [ 33.476105]
 [ 54.407814]
 [ 34.512104]
 [ 53.3718  ]
 [ 60.518913]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  9.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.59877014160156



buy possibilites: [-1] 
expected returns: [[81.06333]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8 25] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0.  0. 14. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0 -90   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 105.14424133300781






Player: 1 
cards in hand: [ 0.  0.  0. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  8. 10.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14. 11.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 27. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  8. 10.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 14. 11.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [10. 15.  8. 10.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8 25] -> size -> 44 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 15.  8. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8. 10.  8.] 
expected returns: [[91.945435]
 [85.314285]
 [85.053925]
 [97.51564 ]
 [85.314285]
 [97.51564 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  8. 10.  8.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 10 29 29 10 11 11 10  8 10 25 10
  8 10 29 11 10 11 10 11 15  1  1 15  1 15 15 15  8 15  8 25] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 81.0633316040039



action possibilites: [-1] 
expected returns: [[73.227745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 115.38633728027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.6258 ]
 [36.46117]
 [73.79372]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1] -> size -> 28 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.22774505615234






Player: 1 
cards in hand: [11.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 29. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  4.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  3.  0. 15.  8.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[85.23784 ]
 [77.58769 ]
 [91.550125]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 15.  8.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10
 29 11 10 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  6.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.79367065429688



action possibilites: [-1] 
expected returns: [[24.440096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  6.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 113.26185607910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.498161]
 [-8.980125]
 [23.433905]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  6.  6.  0.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.440095901489258






Player: 1 
cards in hand: [29.  6.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  6.  6.  0.  0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1. 11. 10. 10.  0.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1. 11. 10. 10.  0.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 26. 30. 28. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1. 11. 10. 10.  0.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 26. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [ 1. 11. 10. 10.  0.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 1. 11. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[84.104614]
 [96.749756]
 [77.26181 ]
 [77.26181 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11. 10. 10.  0.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 26. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.433910369873047



action possibilites: [-1] 
expected returns: [[46.85962]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -40   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 96.250732421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[39.89588 ]
 [60.64762 ]
 [46.837234]
 [10.876066]
 [53.520363]
 [47.54773 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 46.859619140625



buy possibilites: [-1] 
expected returns: [[73.20263]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 10.  0.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [15.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
adversary owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -50   0   0  54   0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 60.647613525390625






Player: 1 
cards in hand: [15.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  0.  3.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0
  6 10 10  1  3  8  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 15. 15. 15.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 15. 15. 15.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16.  8. 25. 29. 14. 23. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  9. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 15. 15. 15.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [29.  1. 15. 15. 15.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  1. 15. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 15. 15. 15.] 
expected returns: [[65.71625 ]
 [85.12158 ]
 [59.294373]
 [59.294373]
 [59.294373]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 15. 15. 15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 73.20262908935547



action possibilites: [-1. 15. 15.] 
expected returns: [[32.00753 ]
 [25.891256]
 [25.891256]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 15. 15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 77.94324493408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[25.23602 ]
 [42.84441 ]
 [30.902712]
 [ 1.9968  ]
 [36.86964 ]
 [31.339785]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 32.00753402709961



buy possibilites: [-1] 
expected returns: [[37.379646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 15. 15.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [10.  3. 10. 29.  0.] 
adversary cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 39 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 42.84440612792969






Player: 1 
cards in hand: [10.  3. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 29.  0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.] 
cards in discard: [ 1.  0.  0.  0. 14. 11.  3.  8. 11.  0.  6.  0.  0.  6.  6.  3. 29.  0.
  0.  8. 14. 15.  0.  0.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 10.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14] -> size -> 31 
action values: 3 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  3.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8] -> size -> 32 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 30. 27. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [8. 3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29. 10. 10. 11.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [11. 11. 10. 10.  3.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 11. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[16.728926]
 [27.73137 ]
 [27.73137 ]
 [11.591246]
 [11.591246]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10. 10.  3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  0.  1.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 37.37964630126953



action possibilites: [-1] 
expected returns: [[-24.868212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 10.  3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  0.  1.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: -28 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 27.32273292541504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-30.56763 ]
 [-55.423294]
 [-24.868196]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 10.  3.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 22. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 3.  0. 11.  0.  1.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: -24.86821174621582






Player: 1 
cards in hand: [ 3.  0. 11.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  1.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 11. 11. 15. 11.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  1.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 22. 30. 26. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 11. 11. 15. 11.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11.  0.  1.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 22. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 11. 11. 15. 11.] 
adversary cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 11.] 
expected returns: [[67.39766 ]
 [80.57462 ]
 [80.57462 ]
 [60.205185]
 [80.57462 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 15. 11.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -24.86821174621582



action possibilites: [-1] 
expected returns: [[2.2105613]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 15. 11.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: -68 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 80.09341430664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ -4.026885]
 [-28.767683]
 [  2.210567]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 15. 11.] 
cards in discard: [25. 10.  8. 29. 29. 29. 10. 25.  0.  0.  1.  0.  3.  8. 10.  8. 15.  1.
  1. 11.  1. 10. 10.  0. 15. 11.  1. 29.  1. 15. 15.  1. 11. 11. 10. 10.
  3.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0.  0. 11.  3.  6.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.2105612754821777






Player: 1 
cards in hand: [ 0.  0. 11.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  6.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 3. 10. 10. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10.] 
expected returns: [[9.645857 ]
 [3.3082767]
 [3.3082767]
 [3.3082767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 15.  0. 14. 29.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.2105612754821777





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  2.4271636]
 [-24.649416 ]
 [  9.518541 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 10.  0.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 15.  0. 14. 29.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 9.645845413208008



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 15.  0. 14. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0. 14. 29.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 11.  8.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 14.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10. 11.  8.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  8. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 10.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.] 
expected returns: [[24.921541]
 [17.605507]
 [17.703602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  1.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3 14] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0    0    0    0    0    0  -80    0    0
 1066    0] 
sum of rewards: 951 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -31.994911193847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 16.14424 ]
 [ 22.50073 ]
 [-12.606349]
 [ 28.168413]
 [ 23.998737]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  2.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3 14] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.921524047851562



buy possibilites: [-1] 
expected returns: [[43.720207]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10.  1.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [6. 3. 8. 6. 0.] 
adversary cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
adversary owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3 14] -> size -> 35 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0 -90   0   0  16   0] 
sum of rewards: -109 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.168405532836914






Player: 1 
cards in hand: [6. 3. 8. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 6. 0.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15 11  0 11  0  3 29 11  6  0  6 14  0  0  0 29  8  0  0  0  0  6
 10 10  1  3  8  3 14  8  3  3 14] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 29. 29. 15.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 29. 29. 15.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 8.  3. 29. 10. 10. 11.  0.  8.  3.  3.  0. 11.  0.  1.  0.  0. 11.  3.
  6. 15.  0. 14. 29. 14.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 29. 29. 15.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 29. 15.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29. 15.] 
expected returns: [[14.356781]
 [18.680704]
 [30.649992]
 [30.649992]
 [ 8.113396]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29. 15.  1.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.72020721435547



action possibilites: [-1.  8. 29. 15.] 
expected returns: [[ 0.53722763]
 [ 5.8610578 ]
 [18.036669  ]
 [-5.594506  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 15.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 35.318199157714844



action possibilites: [-1.] 
expected returns: [[26.651396]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.448537826538086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[ 19.648531]
 [ 39.943306]
 [ 26.780054]
 [-14.294558]
 [ 33.39202 ]
 [ 27.241957]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 21. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.651395797729492



buy possibilites: [-1] 
expected returns: [[55.361626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [8. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -100    0    0
   54    0] 
sum of rewards: -41 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 39.94328308105469






Player: 1 
cards in hand: [8. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 29. 29. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 20. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 29. 29. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [15. 29. 29. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [15. 29. 29. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 29. 15. 11.] 
expected returns: [[30.48939 ]
 [23.744097]
 [50.23097 ]
 [50.23097 ]
 [23.744097]
 [43.241013]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 29. 15. 11.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 19. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  3.  0. 15. 11.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.36162567138672



action possibilites: [-1. 15. 11. 11.] 
expected returns: [[26.509611]
 [19.645487]
 [37.74901 ]
 [37.74901 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 19. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  3.  0. 15. 11.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 42.82740783691406



action possibilites: [-1] 
expected returns: [[15.859587]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 18. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  3.  0. 15. 11.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   40    0    0    0    0 -110    0    0
   27    0] 
sum of rewards: -78 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 37.145931243896484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[  9.715097]
 [-18.170351]
 [ 15.859627]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 18. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 6.  3.  0. 15. 11.] 
adversary cards in discard: [1. 8. 3. 0. 0. 0.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.859586715698242






Player: 1 
cards in hand: [ 6.  3.  0. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 15. 11.] 
cards in discard: [1. 8. 3. 0. 0. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 18. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [11.  1. 10. 11.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 15.] 
cards in discard: [1. 8. 3. 0. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [11.  1. 10. 11.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 15.] 
cards in discard: [1. 8. 3. 0. 0. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [11.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 17. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [11.  1. 10. 11.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [11.  1. 10. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[35.962116]
 [47.708694]
 [29.453135]
 [47.708694]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 10. 11.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 17. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  6.  0. 14.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.859586715698242



action possibilites: [-1] 
expected returns: [[36.33858]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10. 11.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 16. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  6.  0. 14.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -120    0    0
   27    0] 
sum of rewards: -108 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 47.21074676513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[28.773664  ]
 [47.09364   ]
 [35.26963   ]
 [ 0.98694277]
 [41.164623  ]
 [36.338593  ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 16. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  6.  0. 14.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.33858108520508



buy possibilites: [-1] 
expected returns: [[19.046339]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10. 11.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  6.  0. 14.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: -91 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 47.09366226196289






Player: 1 
cards in hand: [10.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0. 14.  0.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 10.  3. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 14.  0. 14.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 10.  3. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  0. 14.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 15. 30. 25. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 10.  3. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 14.  0. 14.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8. 10.  3. 15. 11.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  3. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 15. 11.] 
expected returns: [[ -7.337251 ]
 [ -1.7495451]
 [-13.067158 ]
 [-13.3818035]
 [  4.287642 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 15. 11.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 15. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8.  1. 14.  8.  3.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.04633903503418



action possibilites: [-1] 
expected returns: [[24.43947]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  3. 15.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8.  1. 14.  8.  3.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0   20    0    0    0    0 -140    0    0
   27    0] 
sum of rewards: -158 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 3.912905216217041





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[18.729097 ]
 [-5.0906315]
 [24.439497 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  3. 15.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 14. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 8.  1. 14.  8.  3.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.439470291137695






Player: 1 
cards in hand: [ 8.  1. 14.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 14.  8.  3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 0. 11. 10.  1.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 8. 3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 14. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16.  8. 29. 14. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 14. 30. 24. 30.  8.  7. 10.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 8. 3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [10.  1.  0.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-23.768799]
 [-30.57311 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 14. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [29. 11.  3. 11.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -140    0    0
 1155    0] 
sum of rewards: 950 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -68.4479751586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6.  8. -1.] 
expected returns: [[-31.12131 ]
 [-13.107027]
 [-24.625303]
 [-58.224144]
 [-18.764032]
 [-23.768799]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 14. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [29. 11.  3. 11.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -23.768800735473633



buy possibilites: [-1] 
expected returns: [[-28.891973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [29. 11.  3. 11.  0.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    0  -60    0    0    0    0    0    0    0 -150    0    0
   54    0] 
sum of rewards: -161 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -13.107023239135742






Player: 1 
cards in hand: [29. 11.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 11.  0.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  1. 25.  1.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1  1] -> size -> 50 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 13. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  1. 25.  1.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1  1] -> size -> 50 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.] 
cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3. 11.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 13. 30. 24. 30.  8.  7.  9.  0.  1.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [ 1.  1. 25.  1.  1.] 
adversary cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.  1. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1  1] -> size -> 50 
adversary victory points: 2
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 8 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 5 
Witch: 2 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  1. 25.  1.  1.] 
cards in discard: [ 3. 10. 10. 10.  0. 11.  8.  8. 15. 10.  1.  1. 25.  8. 15.  1. 29. 29.
  0. 15. 29.  1. 29. 11. 15. 11.  1.  1. 11.  1. 10. 11.  0.  1. 11.  8.
 10.  3. 15.  0. 11.  1. 10.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 29 11 11 29 29 10 11 11 10 10 25 10  8 10 29 11 10
 11 10 11  1  1 15  1 15 15 15  8 15  8 25  1  1  1  1  1  8  1  1  1  1
  1  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 13. 30. 24. 30.  8.  7.  9.  0.  0.  8.  4.  7. 10.  0. 10.  3.] 
adversary cards in hand: [11.  0.  3.] 
adversary cards in discard: [ 1.  8.  3.  0.  0.  0.  1. 11.  6.  3.  0. 15.  3. 10.  6.  0. 14.  0.
 14. 16. 14.  8.  1.  8.  3. 11.  3.  8.] 
adversary owned cards: [15 11  0 11  0  3 29 11  0  6 14  0  0  0 29  8  0  0  0  0  6 10 10  1
  3  8  3 14  8  3  3 14  1  1  3 16  8] -> size -> 37 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000065 

action type: buy - action -1
Learning step: -120001.4375
desired expected reward: -120030.328125



