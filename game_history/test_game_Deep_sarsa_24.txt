 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.78981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -510        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000515 

action type: buy - action -1.0
Learning step: -300014.78125
desired expected reward: -300381.96875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[83.097015]
 [89.12536 ]
 [85.4744  ]
 [83.62951 ]
 [80.82303 ]
 [82.347595]
 [89.20313 ]
 [86.81977 ]
 [91.69216 ]
 [92.23063 ]
 [83.70728 ]
 [84.85095 ]
 [83.173485]
 [80.82303 ]
 [89.7416  ]
 [80.82303 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.26554107666016



buy possibilites: [-1] 
expected returns: [[46.45153]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. 32.  0.] 
sum of rewards: 27.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 92.23062133789062






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 16.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[76.80921]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 46.45153045654297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[78.39761 ]
 [80.50036 ]
 [76.3792  ]
 [81.674545]
 [76.3792  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 76.30685424804688



buy possibilites: [-1] 
expected returns: [[75.827156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 81.6745376586914






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[60.18077]
 [70.39456]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 75.82715606689453



action possibilites: [-1.] 
expected returns: [[51.32643]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 69.70645141601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[53.804333]
 [58.782368]
 [55.780426]
 [51.91183 ]
 [53.150776]
 [58.841835]
 [56.865753]
 [61.27253 ]
 [54.286766]
 [53.863808]
 [59.264782]
 [51.91183 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 51.32643127441406



buy possibilites: [-1] 
expected returns: [[41.057636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 61.27253723144531






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 8.] 
adversary cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[72.45451]
 [77.59184]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 8.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.05763626098633



action possibilites: [-1] 
expected returns: [[30.929842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  8 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: 70.10589599609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[33.281433]
 [31.772787]
 [31.772787]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  8 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.929841995239258



buy possibilites: [-1] 
expected returns: [[32.0486]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [29. 29.  0.  0.  0.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3 29  8 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 33.281436920166016






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  8 29  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0. 16.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3 29  8 29  0] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[31.56779]
 [36.16443]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3 29  8 29  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.04859924316406



action possibilites: [-1] 
expected returns: [[45.20384]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  8 29  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 37.42055892944336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[43.964134]
 [42.061813]
 [42.061813]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  8 29  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 45.20383834838867



buy possibilites: [-1] 
expected returns: [[52.2855]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -45.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 43.964134216308594






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 16.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 16.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [ 0. 16.  0.  0. 16.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29. 29.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[33.80639 ]
 [41.624805]
 [41.624805]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29. 29.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 52.285499572753906



action possibilites: [-1. 29.] 
expected returns: [[26.29451 ]
 [33.670403]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 41.30668258666992



action possibilites: [-1.  8.] 
expected returns: [[ 7.607719]
 [11.320986]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3 29  8 29  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.6703987121582



action possibilites: [-1] 
expected returns: [[10.7182045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29  8 29  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: 10.30561637878418





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[11.978794]
 [13.30929 ]
 [10.71563 ]
 [14.014166]
 [10.71563 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29  8 29  0  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  9. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.718204498291016



buy possibilites: [-1] 
expected returns: [[-4.851527]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 14.014167785644531






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [29. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[33.299263]
 [41.194946]
 [41.194946]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.851527214050293



action possibilites: [-1. 29.  8.] 
expected returns: [[25.06082 ]
 [33.816605]
 [29.5944  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.784751892089844



action possibilites: [-1.  8.  8.] 
expected returns: [[28.6392 ]
 [33.20561]
 [33.20561]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 29  8 29  0  0  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.81659698486328



action possibilites: [-1] 
expected returns: [[32.589714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29 29  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 34.59248352050781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.99388 ]
 [35.518005]
 [32.535194]
 [36.36714 ]
 [32.535194]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29 29  8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  8. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.58971405029297



buy possibilites: [-1] 
expected returns: [[16.15368]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 3 29 29  8  8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [14.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.36713409423828






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 29  8  8] -> size -> 5 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 29  8  8] -> size -> 5 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [14.  0.  0.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 29 29  8  8] -> size -> 5 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3. 29.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 29.] 
expected returns: [[20.862465]
 [27.220455]
 [24.217083]
 [24.217083]
 [27.220455]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 29 29  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.1536808013916



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[ 8.824726]
 [11.871531]
 [11.871531]
 [14.514387]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 3 29 29  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 25.26309585571289



action possibilites: [-1.  8.  8.] 
expected returns: [[-3.0589645 ]
 [ 0.12975168]
 [ 0.12975168]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 3 29 29  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 14.514383316040039



action possibilites: [-1] 
expected returns: [[30.467463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 1.24965238571167





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.60638 ]
 [34.238285]
 [30.999567]
 [35.14618 ]
 [30.999567]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  7. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.46746253967285



buy possibilites: [-1] 
expected returns: [[19.01138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8  8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  6. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  0. 16. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 35.14617156982422






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [14.  0.  0. 16. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 16. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  6. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29. 29.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8  8] -> size -> 5 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 16. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  6. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29. 29.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8  8] -> size -> 5 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0. 16. 16.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29. 29.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8  8] -> size -> 5 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 8. 29. 29.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.  8.  8.] 
expected returns: [[14.166254]
 [17.616089]
 [20.871243]
 [20.871243]
 [17.616089]
 [17.616089]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 29.  8.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 19.01137924194336



action possibilites: [-1.  8. 29.  8.  8.] 
expected returns: [[-6.388815 ]
 [-3.7290716]
 [-1.4283042]
 [-3.7290716]
 [-3.7290716]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 18.579593658447266



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-5.8777924]
 [-2.8711133]
 [-2.8711133]
 [-2.8711133]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8  8] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -1.4283075332641602



action possibilites: [-1] 
expected returns: [[27.420252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -1.8333230018615723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.512201]
 [29.88693 ]
 [27.200909]
 [30.619741]
 [27.200909]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  5. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.420251846313477



buy possibilites: [-1] 
expected returns: [[28.941114]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 30.619733810424805






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 30. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [ 8.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 29.] 
expected returns: [[19.111696]
 [22.88261 ]
 [22.88261 ]
 [26.564533]
 [26.564533]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.94111442565918



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[25.536135]
 [29.465044]
 [29.465044]
 [32.977287]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 24.305295944213867



action possibilites: [-1.  8.  8.] 
expected returns: [[38.262062]
 [42.955902]
 [42.955902]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 32.97728729248047



action possibilites: [-1] 
expected returns: [[27.218908]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 40.55385971069336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[28.063799]
 [29.533915]
 [26.67385 ]
 [30.321215]
 [26.67385 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  4. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.218908309936523



buy possibilites: [-1] 
expected returns: [[30.68455]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 30.321210861206055






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 8. 14.  0.  0. 16. 16.  3.  3.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 4 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 4 





Player: 0 
cards in hand: [29.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.  8.] 
expected returns: [[27.987028]
 [35.99071 ]
 [32.2025  ]
 [35.99071 ]
 [32.2025  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.68454933166504



action possibilites: [-1.  8. 29.  8.] 
expected returns: [[30.970533]
 [35.01844 ]
 [38.58514 ]
 [35.01844 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.25891876220703



action possibilites: [-1.  8.  8.] 
expected returns: [[36.917007]
 [41.99832 ]
 [41.99832 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.58513641357422



action possibilites: [-1] 
expected returns: [[28.170473]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 39.51329803466797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.236116]
 [30.605032]
 [27.952303]
 [31.383268]
 [27.952303]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  3. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.170473098754883



buy possibilites: [-1] 
expected returns: [[26.537031]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16.  3.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 31.383264541625977






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [16.  3.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 16  0 14  0  8  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [ 8.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 29.] 
expected returns: [[17.394638]
 [21.290644]
 [21.290644]
 [24.870834]
 [24.870834]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.537031173706055



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[27.682337]
 [31.61777 ]
 [31.61777 ]
 [35.12978 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 23.94495964050293



action possibilites: [-1.  8.  8.] 
expected returns: [[32.489784]
 [37.158615]
 [37.158615]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 35.12977981567383



action possibilites: [-1] 
expected returns: [[31.23113]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 32.85933303833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[31.993673]
 [33.513412]
 [30.61722 ]
 [34.411945]
 [30.61722 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  2. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.231130599975586



buy possibilites: [-1] 
expected returns: [[40.297607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 34.41194534301758






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 30. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 0.  8. 16.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [29.  8.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 29.] 
expected returns: [[25.103064]
 [32.85361 ]
 [29.212286]
 [29.212286]
 [32.85361 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.297607421875



action possibilites: [-1.  8.  8. 29.] 
expected returns: [[28.463793]
 [32.545734]
 [32.545734]
 [36.130363]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.79258918762207



action possibilites: [-1.  8.  8.] 
expected returns: [[35.078365]
 [39.51528 ]
 [39.51528 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.13036346435547



action possibilites: [-1] 
expected returns: [[32.465027]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 35.38535690307617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[33.62011 ]
 [35.383774]
 [32.021286]
 [36.34967 ]
 [32.021286]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  1. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.46502685546875



buy possibilites: [-1] 
expected returns: [[42.731697]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0. 16.] 
adversary cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 36.349666595458984






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0. 16.] 
cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 29. 30.  8. 10.  8. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.] 
cards in discard: [ 0.  8. 16.  1.  0.  0.  0.  0.  0. 16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.] 
adversary cards in discard: [8.] 
adversary owned cards: [29 29  8  8] -> size -> 4 
adversary victory points: 0
player victory points: 3 





Player: 0 
cards in hand: [29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[32.487576]
 [39.485657]
 [39.485657]
 [36.20481 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 90.17487335205078



action possibilites: [-1. 29.  8.] 
expected returns: [[40.995117]
 [48.613922]
 [45.02797 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 35.91071701049805



action possibilites: [-1.  8.] 
expected returns: [[40.122025]
 [45.56157 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 0
Learning step: 0
desired expected reward: 42.568939208984375



action possibilites: [-1] 
expected returns: [[29.506155]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 45.56156921386719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[31.698793]
 [33.282455]
 [30.158243]
 [30.158243]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.506155014038086



buy possibilites: [-1] 
expected returns: [[30.52445]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [8. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  8  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 33.28245162963867






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8  3] -> size -> 5 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  8. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  8  3] -> size -> 5 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 29.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.  8.] 
expected returns: [[24.24879 ]
 [30.828844]
 [27.759527]
 [30.828844]
 [27.759527]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8. 29.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  8  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.524450302124023



action possibilites: [-1. 29.  8.] 
expected returns: [[0.30815172]
 [5.257154  ]
 [2.958325  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  8  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.279296875



action possibilites: [-1.  8.  8.] 
expected returns: [[2.8798223]
 [6.485725 ]
 [6.485725 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  8  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 4.1938862800598145



action possibilites: [-1] 
expected returns: [[33.95037]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: 2.4022841453552246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[36.335976]
 [38.05744 ]
 [34.68099 ]
 [34.68099 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 28. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.95037078857422



buy possibilites: [-1] 
expected returns: [[33.175957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  8. 16.] 
adversary cards in discard: [0. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 38.057437896728516






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  8. 16.] 
cards in discard: [0. 0. 3. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16 16  0 14  0  8  3  0  0  1 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 27. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 0. 3. 3. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 0. 3. 3. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 26. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0. 0. 3. 3. 3. 3. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [29.  8. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[44.44689 ]
 [52.019352]
 [48.445236]
 [52.019352]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.17595672607422



action possibilites: [-1. 29.] 
expected returns: [[ 5.693355]
 [12.182137]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 47.75154113769531



action possibilites: [-1.  8.] 
expected returns: [[-1.532731 ]
 [ 2.3003416]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.274038314819336



action possibilites: [-1] 
expected returns: [[34.08642]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -1.6067118644714355





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[35.517868]
 [37.296616]
 [33.810307]
 [33.810307]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 25. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 34.08641815185547



buy possibilites: [-1] 
expected returns: [[27.286978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 14. 16.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 37.29661560058594






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 14. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14. 16.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 29. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.  0.] 
cards in discard: [ 0.  0.  3.  3.  3.  3.  3. 16.  0.  0.  8.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[34.127888]
 [41.378807]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 38.06966018676758



action possibilites: [-1. 29.] 
expected returns: [[16.943747]
 [24.133602]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 37.48114776611328



action possibilites: [-1.  8.] 
expected returns: [[-0.21200943]
 [ 3.4467025 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.921091079711914



action possibilites: [-1] 
expected returns: [[21.717743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 3.4467015266418457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[22.97808 ]
 [24.722609]
 [21.304827]
 [21.304827]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.717742919921875



buy possibilites: [-1] 
expected returns: [[-8.562326]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: 11 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 24.722604751586914






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [0. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3  3] -> size -> 6 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  8.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3  3] -> size -> 6 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 0. 0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3  3] -> size -> 6 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  3.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[ 6.7391286]
 [13.603052 ]
 [13.603052 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: -8.562326431274414



action possibilites: [-1. 29.] 
expected returns: [[-0.7479565]
 [ 6.263907 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.477806091308594



action possibilites: [-1.  8.] 
expected returns: [[-6.8704605]
 [-3.3013844]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.691955089569092



action possibilites: [-1] 
expected returns: [[28.80824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -4.097379207611084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[29.974817]
 [31.845415]
 [28.181421]
 [28.181421]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 23. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.80824089050293



buy possibilites: [-1] 
expected returns: [[0.09851933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 31.845407485961914






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [24. 28. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 0.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  8.  3. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3.  8.  3. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[17.720661]
 [20.993124]
 [24.057165]
 [24.057165]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.09851932525634766



action possibilites: [-1. 29.] 
expected returns: [[-9.638872]
 [-2.059773]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.0396785736084



action possibilites: [-1.  8.] 
expected returns: [[-10.625877]
 [ -7.580592]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -4.3573198318481445



action possibilites: [-1] 
expected returns: [[26.691565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -11.10251235961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[27.711496]
 [29.58209 ]
 [25.918104]
 [25.918104]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 22. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.691564559936523



buy possibilites: [-1] 
expected returns: [[-1.4015079]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [16. 16.  3.  0.  8.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 29.58208656311035






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [16. 16.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  3.  0.  8.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  8  3  0  0  1 16  3  3  1 29  1] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  7.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  3. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 8. 29.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-3.2209702]
 [ 0.6022067]
 [ 3.989698 ]
 [ 3.989698 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3. 29.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.40150785446167



action possibilites: [-1. 29.] 
expected returns: [[-25.174997]
 [-19.707378]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 0.5352416038513184



action possibilites: [-1.  8.] 
expected returns: [[-22.951248]
 [-19.845592]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.212570190429688



action possibilites: [-1] 
expected returns: [[9.364767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -22.873489379882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[10.56142 ]
 [12.36743 ]
 [ 8.835798]
 [ 8.835798]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 21. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 9.364767074584961



buy possibilites: [-1] 
expected returns: [[18.256767]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3. 14.  0.] 
adversary cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 12.367429733276367






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 14.  0.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 14.  0.] 
cards in discard: [29.  0.  3.  1.  0.  0.  1.  3.  0.  1.  0.  0. 29. 16. 16.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  3.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-0.4562769]
 [ 6.793916 ]
 [ 3.2344275]
 [ 6.793916 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.25676727294922



action possibilites: [-1. 29.] 
expected returns: [[-23.740522]
 [-17.677004]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.736809253692627



action possibilites: [-1.  8.] 
expected returns: [[-24.419634]
 [-21.685524]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -19.10886001586914



action possibilites: [-1] 
expected returns: [[7.677135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -24.107881546020508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 8.981323 ]
 [10.677057 ]
 [ 7.3594737]
 [ 7.3594737]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 20. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.677134990692139



buy possibilites: [-1] 
expected returns: [[13.735487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 10.677055358886719






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  6.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [ 3.  3.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-9.595928 ]
 [-5.734948 ]
 [-2.1564276]
 [-2.1564276]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -95 

action type: buy - action -1
Learning step: 0
desired expected reward: 13.73548698425293



action possibilites: [-1. 29.] 
expected returns: [[-24.100342]
 [-18.666655]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -5.109743118286133



action possibilites: [-1.  8.] 
expected returns: [[-24.382702]
 [-21.831327]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.180484771728516



action possibilites: [-1] 
expected returns: [[-4.719417]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -24.186458587646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-3.5968409]
 [-2.0324934]
 [-5.0918155]
 [-5.0918155]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 19. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -65 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.719417095184326



buy possibilites: [-1] 
expected returns: [[2.8616233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 18. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  1.  0. 16.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[ -5   0   0 -90   0   0  60   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -2.032503128051758






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 0.  1.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 16.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 18. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 18. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 18. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29. 29.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 3. 29. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[1.4689736]
 [7.814057 ]
 [7.814057 ]
 [4.699021 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  8.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.8616232872009277



action possibilites: [-1. 29.] 
expected returns: [[-15.01177 ]
 [ -9.119421]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 5.323995113372803



action possibilites: [-1.  8.] 
expected returns: [[-9.9274645]
 [-6.7087727]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.662938117980957



action possibilites: [-1] 
expected returns: [[-2.9595711]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -10.306928634643555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-2.4135637]
 [-0.4770236]
 [-4.244579 ]
 [-4.244579 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 17. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.959571123123169



buy possibilites: [-1] 
expected returns: [[-10.065397]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1. 16.  3.  3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -0.47702789306640625






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  1. 16.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 16.  3.  3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0  1 16  3  3  1 29  1 29 29  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  9. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  3.  8.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [29.  3.  8.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-14.475931]
 [ -8.269513]
 [-11.300838]
 [ -8.269513]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  3. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -125 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.065397262573242



action possibilites: [-1. 29.] 
expected returns: [[-25.50031 ]
 [-20.038511]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -105 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -10.497021675109863



action possibilites: [-1.  8.] 
expected returns: [[-24.681078]
 [-21.761158]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -85 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.94685935974121



action possibilites: [-1] 
expected returns: [[11.145811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -23.251359939575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[11.691872]
 [13.516773]
 [ 9.944515]
 [ 9.944515]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 16. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -150    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.145811080932617



buy possibilites: [-1] 
expected returns: [[-13.287878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 15. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 14.  1.  0.  0.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -120    0    0   60    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -49 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 13.516765594482422






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [29. 14.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  1.  0.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 15. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 27. 30. 15. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 27. 30. 15. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.] 
cards in discard: [29.  0.  0.  0.  3.  0.  0.  3. 16.  1.  0.  0. 14. 16.  3.  3.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 8.] 
adversary cards in discard: [29. 29.] 
adversary owned cards: [29 29  8  3  3] -> size -> 5 
adversary victory points: 2
player victory points: 7 





Player: 0 
cards in hand: [3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-20.25974 ]
 [-17.102116]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8.] 
cards in discard: [29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -155 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 2.2675890922546387



action possibilites: [-1] 
expected returns: [[-1.4475751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -17.4237060546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-0.3701849]
 [-1.8629947]
 [-1.8629947]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -150    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -135 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.4475750923156738



buy possibilites: [-1] 
expected returns: [[-9.7949295]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [14.  0.  1.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -0.37018728256225586






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [14.  0.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.  3. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1. 29.] 
cards in discard: [3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  1.] 
cards in discard: [ 3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0. 10.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3. 29. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 





Player: 0 
cards in hand: [ 8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-7.0986276]
 [-3.7337632]
 [-0.7145791]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -215 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 11.793920516967773



action possibilites: [-1.  8.] 
expected returns: [[-0.87984705]
 [ 3.7574525 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -2.3371853828430176



action possibilites: [-1] 
expected returns: [[-15.405924]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -2.1967976093292236





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-14.672245]
 [-15.847046]
 [-15.847046]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -210    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -175 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.405923843383789



buy possibilites: [-1] 
expected returns: [[4.6185555]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -210.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -175.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -14.672248840332031






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 30. 14. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 16.  0.  0.  3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  8. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [ 0.  8. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-19.301733]
 [-15.763248]
 [-12.701622]
 [-12.701622]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.618555545806885



action possibilites: [-1.  8.] 
expected returns: [[-2.0496216]
 [ 2.2466984]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -14.949214935302734



action possibilites: [-1] 
expected returns: [[-21.978647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -4.146351337432861





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-21.709314]
 [-22.745043]
 [-22.745043]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: take_action - action -1
Learning step: 0
desired expected reward: -21.978647232055664



buy possibilites: [-1] 
expected returns: [[3.497971]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  1.  3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -205.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -21.709320068359375






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  1.  3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3  1 29  1 29 29  0  3 14
  3 25  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 13. 30.  8. 10.  7. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 





Player: 0 
cards in hand: [29.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[ 3.273099 ]
 [10.874598 ]
 [ 7.3261228]
 [10.874598 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.4979710578918457



action possibilites: [-1.  8.] 
expected returns: [[-2.5838013 ]
 [ 0.90037966]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.940420627593994



action possibilites: [-1] 
expected returns: [[0.22508717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -5.668427467346191





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.30612516]
 [-1.1149375 ]
 [-1.1149375 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.22508716583251953



buy possibilites: [-1] 
expected returns: [[-22.459545]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
adversary victory points: 8
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -240.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -205.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: 0.30612850189208984






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 13. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 3. 29. 25. 29. 29. 14.  0.  1.  3.  3. 16.  0.  0.  3. 16.  0. 16.  0.
  0.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[ 8.274864]
 [15.686356]
 [15.686356]
 [12.228689]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -22.459545135498047



action possibilites: [-1.  8.] 
expected returns: [[0.13134527]
 [3.6670775 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 11.386404037475586



action possibilites: [-1] 
expected returns: [[-4.9593134]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -4.13412618637085





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-4.629841]
 [-6.000272]
 [-6.000272]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -4.95931339263916



buy possibilites: [-1] 
expected returns: [[-31.827791]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  0. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -4.62983512878418






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [17. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 5 
card supply: [16. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[ 7.207641]
 [14.830545]
 [11.268482]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -14.734647750854492



action possibilites: [-1.  8.] 
expected returns: [[-0.2555151]
 [ 3.2417798]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 10.365432739257812



action possibilites: [-1] 
expected returns: [[-10.915085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -5.25017786026001





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-10.67166 ]
 [-12.028679]
 [-12.028679]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -10.915084838867188



buy possibilites: [-1] 
expected returns: [[-28.18115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -10.671655654907227






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29.  0. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[-1.0778127]
 [ 6.7582097]
 [ 6.7582097]
 [ 3.080717 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3. 29.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -28.181150436401367



action possibilites: [-1.  8.] 
expected returns: [[-1.1959434]
 [ 2.2082705]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3. 29.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.023613452911377



action possibilites: [-1] 
expected returns: [[-11.80743]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3. 29.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -6.365360260009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-11.635021]
 [-13.063644]
 [-13.063644]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3. 29.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.807430267333984



buy possibilites: [-1] 
expected returns: [[-27.781155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3. 29.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -11.635015487670898






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3. 29.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 27. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-1.2681708]
 [ 6.0949616]
 [ 2.65101  ]
 [ 6.0949616]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3. 29.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -27.78115463256836



action possibilites: [-1.  8.] 
expected returns: [[-3.0160375 ]
 [ 0.33331585]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3. 29.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 2.355372905731201



action possibilites: [-1] 
expected returns: [[-6.810175]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3. 29.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -8.060785293579102





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.6875067]
 [-8.202616 ]
 [-8.202616 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3. 29.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.810174942016602



buy possibilites: [-1] 
expected returns: [[-25.631136]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  3. 29.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -6.687512397766113






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  3. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3. 29.  3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [29.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-3.6074295 ]
 [ 3.7349916 ]
 [ 0.24301195]
 [ 3.7349916 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16. 25. 16.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.631135940551758



action possibilites: [-1.  8.] 
expected returns: [[-4.5781784]
 [-1.2935658]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16. 25. 16.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -0.373812198638916



action possibilites: [-1] 
expected returns: [[-6.422244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16. 25. 16.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -9.548704147338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.303391 ]
 [-7.8076754]
 [-7.8076754]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16. 25. 16.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -6.422244071960449



buy possibilites: [-1] 
expected returns: [[-24.568375]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16. 25. 16.  3.] 
adversary cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -270.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -235.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -6.303390979766846






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0. 16. 25. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25. 16.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 25. 16.  3.] 
cards in discard: [ 0. 14.  0.  0. 14.  0.  3.  0.  3.  0.  0.  3.  1.  1. 29. 29.  0.  3.
  3. 16. 29.  0.  3.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8. 10.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 9 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 29  8  0  6] -> size -> 5 
adversary victory points: 0
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 29  8  0  6] -> size -> 5 
adversary victory points: 0
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 16.  3.  0.  0.] 
cards in discard: [0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8.  0. 29. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 29  8  0  6] -> size -> 5 
adversary victory points: 0
player victory points: 9 





Player: 0 
cards in hand: [ 8.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-26.462065]
 [-23.767992]
 [-21.247042]
 [-21.247042]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29. 29.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  6] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -605 

action type: buy - action -1
Learning step: 0
desired expected reward: -24.568374633789062



action possibilites: [-1.  8.] 
expected returns: [[-31.453459]
 [-28.795773]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  6] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -24.434179306030273



action possibilites: [-1] 
expected returns: [[-18.218807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
adversary victory points: 9
player victory points: -1 

Reward from previous game state: 
[  -5    0    0 -300    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -265 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -28.85514259338379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-17.51616 ]
 [-15.999861]
 [-18.94559 ]
 [-18.94559 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 12. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.218807220458984



buy possibilites: [-1] 
expected returns: [[-55.721626]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -189 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -15.999868392944336






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [1. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 8. 29.  3.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [ 8. 29.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-27.328968]
 [-24.789383]
 [-22.424915]
 [-22.424915]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -55.72162628173828



action possibilites: [-1.  8.] 
expected returns: [[-30.777067]
 [-28.14194 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -25.950605392456055



action possibilites: [-1] 
expected returns: [[-19.879267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -27.925472259521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-18.06862 ]
 [-16.531084]
 [-19.516098]
 [-19.516098]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 11. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.8792667388916



buy possibilites: [-1] 
expected returns: [[-32.170628]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  1.  3. 29.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -189 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.531095504760742






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  3. 29.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 3.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 





Player: 0 
cards in hand: [ 0.  8. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-23.992796]
 [-20.88732 ]
 [-18.14158 ]
 [-18.14158 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  3. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 16.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -32.17062759399414



action possibilites: [-1.  8.] 
expected returns: [[-33.351406]
 [-30.398275]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 16.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.97184181213379



action possibilites: [-1] 
expected returns: [[-17.608164]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 16.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -30.11824607849121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-16.255476 ]
 [-14.8266735]
 [-17.58664  ]
 [-17.58664  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 10. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 16.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -17.608163833618164



buy possibilites: [-1] 
expected returns: [[-21.334917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29. 16.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -189 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -14.826675415039062






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [29. 29. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 16.  0.  0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 16.  0.  0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8.  3.  0. 29. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8.  3.  0. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-24.151285]
 [-21.02854 ]
 [-18.199081]
 [-18.199081]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 29. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -245 

action type: buy - action -1
Learning step: 0
desired expected reward: -21.334917068481445



action possibilites: [-1.  8.] 
expected returns: [[-33.806396]
 [-30.323637]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -22.24593162536621



action possibilites: [-1] 
expected returns: [[-18.199888]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -205 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -29.555208206176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-16.852915]
 [-15.456362]
 [-18.132072]
 [-18.132072]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30.  9. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.199888229370117



buy possibilites: [-1] 
expected returns: [[-20.728523]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  8. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [14.  3. 14.  0.  0.] 
adversary cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
adversary victory points: 9
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -240    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -189 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -15.456363677978516






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [14.  3. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 14.  0.  0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  8. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 14.  0.  0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30.  8. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 9 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 14.  0.  0.] 
cards in discard: [ 0. 25.  0. 16. 16.  3.  0.  0. 15.  1.  0.  3.  3.  0.  3. 10. 29.  3.
  1.  3.  3. 29. 29. 16.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  7. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 





Player: 0 
cards in hand: [29.  0.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-21.210827]
 [-15.261797]
 [-18.122572]
 [-15.261797]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  7. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -20.72852325439453



action possibilites: [-1.  8.] 
expected returns: [[-38.010773]
 [-32.310574]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30.  7. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -21.15421485900879



action possibilites: [-1] 
expected returns: [[-19.821966]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30.  7. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -33.425079345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-17.859987]
 [-16.27825 ]
 [-19.3443  ]
 [-19.3443  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30.  7. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -300    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -265 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.82196617126465



buy possibilites: [-1] 
expected returns: [[-54.487923]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -219 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -16.27825355529785






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29. 29.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 





Player: 0 
cards in hand: [29. 29.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[-20.030813]
 [-15.116631]
 [-15.116631]
 [-17.402956]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -54.48792266845703



action possibilites: [-1.  8.] 
expected returns: [[-34.15413 ]
 [-29.233294]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -20.321983337402344



action possibilites: [-1] 
expected returns: [[-45.308197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -30.81989097595215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-32.584854]
 [-28.580233]
 [-36.278435]
 [-36.278435]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30.  6. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
adversary victory points: 10
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -300    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -265 

action type: take_action - action -1
Learning step: 0
desired expected reward: -45.308197021484375



buy possibilites: [-1] 
expected returns: [[-60.531128]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30.  5. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  0. 14.  0.  0.] 
adversary cards in discard: [0. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
adversary victory points: 10
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -219 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -28.58025360107422






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [29.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 14.  0.  0.] 
cards in discard: [0. 0. 3. 3. 0. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30.  5. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30.  5. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29. 29.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30.  5. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.  3.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30.  5. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.  3.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 10 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [0. 0. 3. 3. 0. 0. 0. 3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.] 
adversary cards in discard: [29.  3.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 11 





Player: 0 
cards in hand: [ 8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-27.235859]
 [-25.17827 ]
 [-23.392466]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 16.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -300    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -305 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -5.8699116706848145



action possibilites: [-1.  8.] 
expected returns: [[-14.808222]
 [-11.779142]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 16.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -26.012495040893555



action possibilites: [-1] 
expected returns: [[-153.57123]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 16.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -300    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -265 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -21.093523025512695





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-138.95735]
 [-145.87315]
 [-145.87315]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  3] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 16.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -300    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -265 

action type: take_action - action -1
Learning step: 0
desired expected reward: -153.57122802734375



buy possibilites: [-1] 
expected returns: [[-13.940542]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  3  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3.  0. 29. 16.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
adversary victory points: 11
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0. -300.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -138.95741271972656






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0. 29. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29. 16.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 11 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30.  4. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30.  3. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0. 29.  8. 29.  3.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  3  0] -> size -> 5 
adversary victory points: 1
player victory points: 12 





Player: 0 
cards in hand: [ 0. 29.  8. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-98.82581]
 [-61.21087]
 [-78.95794]
 [-61.21087]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  8. 29.  3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30.  3. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  1. 29. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.940542221069336



action possibilites: [-1.  8.] 
expected returns: [[-105.99091]
 [ -91.92421]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  3  0] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30.  3. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  1. 29. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -98.74360656738281



action possibilites: [-1] 
expected returns: [[-41.621403]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 26. 30.  3. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  1. 29. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -89.5417709350586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-25.428377]
 [-21.334684]
 [-29.425722]
 [-29.425722]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 26. 30.  3. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  1. 29. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
adversary victory points: 12
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -360    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -325 

action type: take_action - action -1
Learning step: 0
desired expected reward: -41.621402740478516



buy possibilites: [-1] 
expected returns: [[-48.45589]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  3.  1. 29. 14.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -279 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -21.33469009399414






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  1. 29. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29. 14.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 26. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  8.  0.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 12 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 26. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 12 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 29.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 26. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 12 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 29.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 29.] 
adversary cards in discard: [29.  8.] 
adversary owned cards: [29 29  8  0  3] -> size -> 5 
adversary victory points: 1
player victory points: 12 





Player: 0 
cards in hand: [ 0.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-34.66832 ]
 [-21.985388]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.] 
cards in discard: [29.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: 8.73997688293457



action possibilites: [-1.] 
expected returns: [[-43.37584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -31.790441513061523





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-25.2665  ]
 [-22.933062]
 [-27.418741]
 [-27.418741]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3] -> size -> 5 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 30.  2. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
adversary victory points: 12
player victory points: 1 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -43.37583923339844



buy possibilites: [-1] 
expected returns: [[-131.2286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3  3] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [16. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
adversary victory points: 12
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -300    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -269 

action type: buy - action 3.0
Learning step: 0
desired expected reward: -22.93307876586914






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [16. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3  3] -> size -> 6 
adversary victory points: 2
player victory points: 12 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.  3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3
 25  3 16  0  3  0  1  0 15 10  3  0  3  3  1] -> size -> 39 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3  3] -> size -> 6 
adversary victory points: 2
player victory points: 12 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3  3] -> size -> 6 
adversary victory points: 2
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  9. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3  3] -> size -> 6 
adversary victory points: 2
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  3. 29.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0  3  3] -> size -> 6 
adversary victory points: 2
player victory points: 11 





Player: 0 
cards in hand: [29.  3. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[-61.636257]
 [-35.800426]
 [-35.800426]
 [-47.626053]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 29.  0.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  3  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  1.  0. 25.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -270    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -275 

action type: buy - action -1
Learning step: 0
desired expected reward: -131.22860717773438



action possibilites: [-1.  8.] 
expected returns: [[-115.871506]
 [-103.84457 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0  3  3] -> size -> 6 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  1.  0. 25.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -54.77147674560547



action possibilites: [-1] 
expected returns: [[-110.8226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  1.  0. 25.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: trash_cards_n_from_hand - action 5
Learning step: 0
desired expected reward: -98.60088348388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-80.81951]
 [-85.44235]
 [-85.44235]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  1.  0. 25.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
adversary victory points: 11
player victory points: 2 

Reward from previous game state: 
[  -5    0    0 -270    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -235 

action type: take_action - action -1
Learning step: 0
desired expected reward: -110.82260131835938



buy possibilites: [-1] 
expected returns: [[3.3686228]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [15. 16.  1.  0. 25.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -80.8195571899414






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [15. 16.  1.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  1.  0. 25.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  1.  0. 25.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  8. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 16.  1.  0. 25.] 
cards in discard: [ 0.  0.  3.  3.  0.  0.  0.  3. 29. 14.  0.  0.  3.  0.  3. 29.  3.  0.
 16.  3.  1. 14.  3.  3.  1. 29.  1. 10. 10. 16.  0.  0.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [29.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-33.97734 ]
 [-23.657833]
 [-28.418959]
 [-23.657833]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  8. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.3686227798461914



action possibilites: [-1.  8.] 
expected returns: [[-163.90234]
 [-149.26283]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -54.91973114013672



action possibilites: [-1] 
expected returns: [[-73.3685]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -165.74705505371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-45.154675]
 [-48.9569  ]
 [-48.9569  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -73.36849975585938



buy possibilites: [-1] 
expected returns: [[-7.106364]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [16.  0.  3.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -45.15467834472656






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [16.  0.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  3.  3.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  3.  3.] 
cards in discard: [0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [29.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-106.631546]
 [ -79.21352 ]
 [ -89.2932  ]
 [ -79.21352 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.106363773345947



action possibilites: [-1.  8.] 
expected returns: [[-213.11256]
 [-201.7653 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -152.8400115966797



action possibilites: [-1] 
expected returns: [[-104.52408]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -208.43313598632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-64.07294]
 [-68.57028]
 [-68.57028]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 6. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -104.52407836914062



buy possibilites: [-1] 
expected returns: [[-2.5829196]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  1.  3. 14.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -64.07295989990234






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  1.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  3. 14.] 
cards in discard: [ 0. 16.  0.  3.  3.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29. 29.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  9.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29.  8.  0.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
expected returns: [[-104.29936 ]
 [ -81.314255]
 [ -94.01393 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 16. 10. 29.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -218.8032684326172



action possibilites: [-1.  8.] 
expected returns: [[-263.81458]
 [-254.81776]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 16. 10. 29.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -119.94929504394531



action possibilites: [-1] 
expected returns: [[-105.95847]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 16. 10. 29.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -253.8295135498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-66.93435]
 [-70.2911 ]
 [-70.2911 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 16. 10. 29.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -105.9584732055664



buy possibilites: [-1] 
expected returns: [[-10.193711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 1. 16. 10. 29.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -66.9343490600586






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 1. 16. 10. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 10. 29.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16. 10.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 0. 29. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 0. 29. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.  8.] 
expected returns: [[-261.37576]
 [-235.54573]
 [-235.54573]
 [-251.28499]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29.  8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29. 10.  1. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -10.193711280822754



action possibilites: [-1.  8.] 
expected returns: [[-258.90344]
 [-250.51582]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29. 10.  1. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -250.3965606689453



action possibilites: [-1] 
expected returns: [[-164.34221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29. 10.  1. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -248.66383361816406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-122.15965 ]
 [-126.864876]
 [-126.864876]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29. 10.  1. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -164.3422088623047



buy possibilites: [-1] 
expected returns: [[-48.56254]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29. 10.  1. 10.  0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -122.1597671508789






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [29. 10.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  1. 10.  0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [29.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 29.] 
expected returns: [[-165.74896]
 [-149.01071]
 [-156.33043]
 [-149.01071]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 14.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -48.562538146972656



action possibilites: [-1.  8.] 
expected returns: [[-253.02629]
 [-245.03787]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 14.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -168.40211486816406



action possibilites: [-1] 
expected returns: [[-166.26903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 14.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -243.11097717285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-126.09543]
 [-130.46909]
 [-130.46909]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 14.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -166.26902770996094



buy possibilites: [-1] 
expected returns: [[-55.219772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  0.  3. 14.  3.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -126.09550476074219






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  3. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 14.  3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6. 10.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8.  0. 29.] 
adversary cards in discard: [29.] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[-213.86311]
 [-192.53723]
 [-174.829  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 29.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -108.26490783691406



action possibilites: [-1.  8.] 
expected returns: [[-242.083  ]
 [-228.75612]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -190.7496795654297



action possibilites: [-1] 
expected returns: [[-211.45998]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -232.24961853027344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-184.66624]
 [-188.85753]
 [-188.85753]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -211.45997619628906



buy possibilites: [-1] 
expected returns: [[-179.59744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -184.66629028320312






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 24. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 8. 29.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 





Player: 0 
cards in hand: [ 8. 29.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
expected returns: [[-230.62506]
 [-220.06435]
 [-205.97588]
 [-205.97588]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0. 29.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15. 25.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -335 

action type: buy - action -1
Learning step: 0
desired expected reward: -179.59744262695312



action possibilites: [-1.  8.] 
expected returns: [[-276.84854]
 [-268.58542]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15. 25.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -219.9666290283203



action possibilites: [-1] 
expected returns: [[-227.19728]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15. 25.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: trash_cards_n_from_hand - action 0
Learning step: 0
desired expected reward: -268.5730895996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-200.04478]
 [-204.36923]
 [-204.36923]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15. 25.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5    0    0 -330    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -295 

action type: take_action - action -1
Learning step: 0
desired expected reward: -227.19728088378906



buy possibilites: [-1] 
expected returns: [[-163.79878]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29 29  8  0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15. 25.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
adversary victory points: 11
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0. -330.    0.    0.   40.    0.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -295.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -200.0448455810547






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 16. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 15. 25.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30.  1. 30.  8.  9.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [29 29  8  0] -> size -> 4 
adversary victory points: 0
player victory points: 11 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16. 15.  0.  1.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30.  1. 30.  8.  8.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 29  8  0  6] -> size -> 5 
adversary victory points: 0
player victory points: 11 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16. 15.  0.  1.] 
cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 23. 30.  1. 30.  8.  8.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [29.  8.  0. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [29 29  8  0  6] -> size -> 5 
adversary victory points: 0
player victory points: 11 


Player 1 won the game! 



Player 0 bought cards:
Copper: 20 
Silver: 0 
Gold: 0 
Estate: 19 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 9 
Witch: 0 
Poacher: 2 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [29.  8.  0. 29.] 
cards in discard: [6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29 29  8  0  6] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30.  0. 30.  8.  8.  6.  9.  0.  9.  5.  8. 10.  7. 10.  7.] 
adversary cards in hand: [ 3.  3. 16. 15.  0.  1.] 
adversary cards in discard: [ 0. 16.  0.  3.  3.  3. 15. 14.  0.  0.  1.  3. 29. 15. 29. 10.  1. 16.
  0.  0. 10. 29. 10.  1.  0.  3.  0. 11. 14.  3.  0.  3.  3.  1.  0.  3.
  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3 16  0 14  0  3  0  0 16  3  3 29  1 29 29  0  3 14  3 25
  3 16  0  3  0  1  0 15 10  3  0  3  3  1  1 10 10  0 15 15 11  1  3] -> size -> 47 
adversary victory points: 12
player victory points: -1 

Reward from previous game state: 
[      -5 -3000000        0     -390        0        0        0        0
        0        0        0        0        0     -300        0        0] 
sum of rewards: -3000695 

action type: buy - action -1
Learning step: -300053.125
desired expected reward: -300216.9375



