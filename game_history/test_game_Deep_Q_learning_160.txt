 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.378075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -210        0        0        0        0
        0        0        0        0        0        0        0        0] 
sum of rewards: -3000215 

action type: buy - action -1.0
Learning step: -120003.0546875
desired expected reward: -120141.515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 23.473097]
 [ 42.482944]
 [ 34.946236]
 [-27.410645]
 [ 43.430832]
 [ 31.981094]
 [ 37.772808]
 [ 29.494038]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 30.26348114013672



buy possibilites: [-1] 
expected returns: [[27.730652]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 43.43082046508789






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [11.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[28.212486]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.73065185546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 20.424269 ]
 [ 39.72086  ]
 [ 32.81989  ]
 [-41.632835 ]
 [ 43.423355 ]
 [ 41.473175 ]
 [ 28.993095 ]
 [ 47.391354 ]
 [ -4.3908567]
 [ 35.887825 ]
 [ 24.735188 ]
 [ 26.147385 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.654094696044922



buy possibilites: [-1] 
expected returns: [[30.790596]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [11.  3.  0.  3.  0.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.391357421875






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [ 8.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.45597 ]
 [31.306946]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.79059600830078



action possibilites: [-1] 
expected returns: [[17.261204]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.89590835571289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 12.25338 ]
 [ 31.182686]
 [ 22.655281]
 [-47.51735 ]
 [ 30.276314]
 [ 20.189548]
 [ 24.824137]
 [ 17.396927]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.26120376586914



buy possibilites: [-1] 
expected returns: [[20.504963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [10.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 31.182659149169922






Player: 1 
cards in hand: [ 8. 11.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [10.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [10.  1. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[11.454384]
 [28.614796]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [10.  1. 11.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.504962921142578



action possibilites: [-1.] 
expected returns: [[26.770988]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 28.19593048095703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 23.263626  ]
 [ 40.486206  ]
 [ 32.89583   ]
 [  7.455051  ]
 [-23.788097  ]
 [ 42.861813  ]
 [ 40.188354  ]
 [ 30.80421   ]
 [ 50.965378  ]
 [ 46.382072  ]
 [ -0.14205074]
 [ 35.257687  ]
 [ 35.41933   ]
 [ 14.270119  ]
 [ 25.787344  ]
 [ 27.638748  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 26.77098846435547



buy possibilites: [-1] 
expected returns: [[17.291193]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  1. 11.  0.  3.  0.  0. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 8. 11.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 265 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 50.96537780761719






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 8. 11.  3.  0.  3. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[13.58893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.29119300842285





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[  8.401638]
 [ 27.411404]
 [ 18.974348]
 [-53.48684 ]
 [ 26.1929  ]
 [ 15.926819]
 [ 20.46474 ]
 [ 13.375626]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.387046813964844



buy possibilites: [-1] 
expected returns: [[21.169643]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 27.41138458251953






Player: 1 
cards in hand: [ 0.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [29.  0. 11.  0.  3.] 
adversary cards in discard: [1. 3. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 6 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [23.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.707106]
 [36.52176 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 270   0] 
sum of rewards: 265 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: 21.185302734375



action possibilites: [-1] 
expected returns: [[17.009325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 38.03936004638672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 14.236298]
 [ 24.204792]
 [-51.222355]
 [ 22.264324]
 [ 18.44501 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 30. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 17.00932502746582



buy possibilites: [-1] 
expected returns: [[12.2868805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  8. 11.  0.] 
adversary cards in discard: [23. 14.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 61 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 24.204790115356445






Player: 1 
cards in hand: [ 3.  3.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 11.  0.] 
cards in discard: [23. 14.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  8.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [23. 14.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0.] 
cards in discard: [23. 14.  0.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 25.  1.] 
adversary cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10. 25.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[63.708076]
 [68.77055 ]
 [84.43429 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 25.  1.] 
cards in discard: [ 1.  3.  0.  0.  0.  3. 29.  3. 10.  3. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8. 10. 10.  7.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11] -> size -> 15 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 12.286880493164062



action possibilites: [-1] 
expected returns: [[6.553452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 84.53170776367188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[  1.6637688]
 [ 17.996492 ]
 [ 12.548378 ]
 [-12.519816 ]
 [-50.686256 ]
 [ 21.23789  ]
 [ 19.352451 ]
 [  9.127192 ]
 [ 27.940212 ]
 [ 26.643541 ]
 [-20.049208 ]
 [ 15.470942 ]
 [ 15.482176 ]
 [ -5.70739  ]
 [  5.832854 ]
 [  8.32696  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  0.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  9.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.553452014923096



buy possibilites: [-1] 
expected returns: [[3.3551574]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  0.  3.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [14.  3.  3.  0.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 295 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 27.940208435058594






Player: 1 
cards in hand: [14.  3.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [25. 25.  0.  0. 10.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  3.  0.  0.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [3. 1. 0. 3. 0.] 
adversary cards in discard: [25. 25.  0.  0. 10.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25] -> size -> 19 
adversary victory points: 4
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[45.002804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.3551573753356934





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[40.586334 ]
 [58.39508  ]
 [51.38886  ]
 [ 0.9987564]
 [61.96884  ]
 [59.63121  ]
 [47.781242 ]
 [65.48621  ]
 [17.828377 ]
 [54.27676  ]
 [43.436283 ]
 [45.576904 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  9.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.499183654785156



buy possibilites: [-1] 
expected returns: [[29.243225]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 3. 0.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0. 11.  3.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 65.48625946044922






Player: 1 
cards in hand: [ 0. 11.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [ 6. 14.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3. 29.  0.  0.] 
adversary cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [ 6. 14.  3.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  9.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3. 29.  0.  0.] 
adversary cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 11.  3.] 
cards in discard: [ 6. 14.  3.  3.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  8.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [11.  3. 29.  0.  0.] 
adversary cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  3. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[71.55175 ]
 [84.601295]
 [88.68263 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  0.  0.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  8.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.24322509765625



action possibilites: [-1. 11. 10.] 
expected returns: [[45.588974]
 [56.697613]
 [52.16244 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 10.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  8.  8.  8.  9.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.6687240600586



action possibilites: [-1] 
expected returns: [[42.961464]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 122 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 58.13215637207031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 34.799824]
 [ 52.0363  ]
 [ 44.387913]
 [-26.828108]
 [ 52.892513]
 [ 42.893593]
 [ 48.456196]
 [ 45.17612 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  7.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 42.961463928222656



buy possibilites: [-1] 
expected returns: [[78.580956]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [25. 25.  0.  0. 10.  1.  0.  3. 29.  3.  1.  0.  3.  0. 10. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  0.  0.  0. 23.] 
adversary cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0 54  0] 
sum of rewards: 149 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 52.89251708984375






Player: 1 
cards in hand: [ 8.  0.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 23.] 
cards in discard: [ 6. 14.  3.  3.  0.  0.  8.  0. 11.  0. 11.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8] -> size -> 17 
action values: 0 
buys: 2 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  8.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[15.430618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14. 11.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 78.5809555053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[  9.177023]
 [ 27.437748]
 [ 20.18222 ]
 [-37.43858 ]
 [ 28.919533]
 [ 27.67965 ]
 [ 17.167505]
 [ 31.617035]
 [-18.663935]
 [ 21.844563]
 [ 10.231178]
 [ 17.53801 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  7.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14. 11.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 13.807308197021484



buy possibilites: [-1] 
expected returns: [[35.35738]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 14. 11.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29] -> size -> 18 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 183 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 31.61703109741211






Player: 1 
cards in hand: [ 0.  0.  6. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14. 11.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 29. 30.  8.  9. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 25.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 14.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 25.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 14.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 11.  0. 25.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11. 10. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11. 25.] 
expected returns: [[51.67861 ]
 [60.61705 ]
 [55.730225]
 [60.61705 ]
 [70.75502 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0. 25.] 
cards in discard: [29.  3.  0.  1.  0.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  9. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3] -> size -> 19 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.35737991333008



action possibilites: [-1] 
expected returns: [[56.352882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  0.  3.  3.] 
cards in discard: [29.  3.  0.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.33833312988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[49.680283]
 [15.646484]
 [55.721645]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  0.  3.  3.] 
cards in discard: [29.  3.  0.  1.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3  6] -> size -> 20 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.352882385253906






Player: 1 
cards in hand: [ 0. 11.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  3.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 11 14 23 11  6  8 29  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [29. 23.  8.  0.  0.  0.  3.  3. 11.  0.  0.  6. 14.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  1.  0.] 
adversary cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[79.88899]
 [86.07345]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  1.  0.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 55.721649169921875



action possibilites: [-1. 25.] 
expected returns: [[62.109146]
 [82.83645 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 25.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  8. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0] -> size -> 19 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 85.58963012695312



action possibilites: [-1. 29. 10.] 
expected returns: [[ 95.87256 ]
 [104.957115]
 [ 93.827415]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 29. 10.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 82.83643341064453



action possibilites: [-1. 10. 29.] 
expected returns: [[66.16857]
 [66.78365]
 [77.99429]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 10. 29.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 25. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 115 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 104.95709991455078



action possibilites: [-1. 10.] 
expected returns: [[102.71685]
 [102.60325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1.  0. 10.  0.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 25. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 77.99430847167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 93.9056  ]
 [108.39062 ]
 [ 91.96884 ]
 [101.74272 ]
 [ 79.62892 ]
 [108.39991 ]
 [ 57.53047 ]
 [111.08423 ]
 [108.04031 ]
 [100.72486 ]
 [117.53526 ]
 [114.21627 ]
 [ 73.54228 ]
 [104.04276 ]
 [103.73852 ]
 [ 85.616035]
 [ 95.63749 ]
 [104.58214 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.  0.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 25. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  0 60  0  0 80  0  0  0  0  0  0  0  0  0] 
sum of rewards: 135 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 102.71685791015625



buy possibilites: [-1] 
expected returns: [[124.85343]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1.  0. 10.  0.] 
cards in discard: [29.  3.  0.  1.  0.  3. 25. 11. 10. 11.  0.  3.  3. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 25. 29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.  80.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 197.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 117.53524017333984






Player: 1 
cards in hand: [ 0.  0. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  6.  8.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  8.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 6. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  8.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [ 6. 11.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [29. 29.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [29. 29.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[34.792152]
 [47.665054]
 [47.665054]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 23.  0. 29.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 124.85343170166016



action possibilites: [-1. 29.] 
expected returns: [[26.55253 ]
 [37.109467]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 23.  0. 29.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 45.81462097167969



action possibilites: [-1.] 
expected returns: [[14.601349]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 23.  0. 29.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 37.109466552734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 12.5880165]
 [ 26.977959 ]
 [ 10.3086815]
 [ 19.799288 ]
 [ -2.4335632]
 [-23.057394 ]
 [ 30.782036 ]
 [ 27.308876 ]
 [ 20.026249 ]
 [ 38.800526 ]
 [ 33.058765 ]
 [ -8.813324 ]
 [ 22.075397 ]
 [ 23.399868 ]
 [  4.1044145]
 [ 13.065195 ]
 [ 16.413273 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  7.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 23.  0. 29.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 125 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 14.601348876953125



buy possibilites: [-1] 
expected returns: [[38.184624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 1.] 
cards in discard: [25.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 8.  6. 23.  0. 29.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  40.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 187.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 38.80052185058594






Player: 1 
cards in hand: [ 8.  6. 23.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23. 29.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 23.  0. 29.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 29.  3.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6.  0. 29.  3.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
action values: 0 
buys: 2 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  3. 25. 11.  0.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[45.58088 ]
 [66.456245]
 [56.600677]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25. 11.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8] -> size -> 22 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.18462371826172



action possibilites: [-1] 
expected returns: [[22.83197]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0. 10.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.29869842529297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 18.733606]
 [ 33.51495 ]
 [ 27.945618]
 [-16.960876]
 [ 35.39624 ]
 [ 25.674397]
 [ 30.966793]
 [ 25.129269]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0. 10.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  5.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.83197021484375



buy possibilites: [-1] 
expected returns: [[66.783264]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0. 10.  0.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6. 14.  8.  0.] 
adversary cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 35.396244049072266






Player: 1 
cards in hand: [ 3.  6. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  8.  0.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  0. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0.] 
cards in discard: [ 6. 11.  8. 11.  0.  0.  0.  3. 23.  8.  6.  0. 29.  3.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [10. 29. 25.] 
adversary cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: 1 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 25.] 
expected returns: [[69.40715 ]
 [71.29284 ]
 [80.08966 ]
 [86.030525]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29. 25.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  6. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3] -> size -> 24 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0   0   0   0   0   0   0   0   0 790   0] 
sum of rewards: 875 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 52.00301742553711



action possibilites: [-1] 
expected returns: [[72.84322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  3. 25.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.03052520751953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.128265 ]
 [-3.7192307]
 [73.220634 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 29.  3. 25.] 
cards in discard: [25. 29. 29.  0.  0.  3.  3.  1. 11. 25.  0.  3. 11.  0. 10.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3
  6] -> size -> 25 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.84322357177734






Player: 1 
cards in hand: [8. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [6. 0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3. 25. 11. 10.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 11. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[18.717014]
 [35.944454]
 [27.302807]
 [21.598381]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 11. 10.  1.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  5. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  3.  6.  8.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0] -> size -> 24 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 73.22062683105469



action possibilites: [-1] 
expected returns: [[1.6650872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 10.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  3.  6.  8.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.88425827026367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -1.0273876]
 [ 12.024136 ]
 [  5.0276275]
 [-36.30247  ]
 [ 14.743629 ]
 [ 11.736212 ]
 [  5.0863004]
 [ 15.93767  ]
 [-22.858788 ]
 [  7.352965 ]
 [ -2.8577225]
 [  4.327926 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  1.  1.  3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  6.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  3.  6.  8.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 1.6650872230529785



buy possibilites: [-1] 
expected returns: [[14.055405]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11. 10.  1.  1.  3.] 
cards in discard: [29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [23.  3.  6.  8.  0.] 
adversary cards in discard: [6. 0. 8. 6. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 15.937688827514648






Player: 1 
cards in hand: [23.  3.  6.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3.  6.  8.  0.] 
cards in discard: [6. 0. 8. 6. 0. 6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  8.  0. 11.] 
cards in discard: [6. 0. 8. 6. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  8.  0. 11.] 
cards in discard: [6. 0. 8. 6. 0. 6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
action values: 0 
buys: 2 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[81.40892]
 [94.35619]
 [90.82275]
 [98.61864]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0.  0.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.055404663085938



action possibilites: [-1. 11. 10.] 
expected returns: [[47.43409 ]
 [56.86158 ]
 [53.919716]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  4.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 98.61863708496094



action possibilites: [-1] 
expected returns: [[33.292805]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 242 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 58.54909133911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.77488  ]
 [43.242138 ]
 [36.439407 ]
 [-7.6170387]
 [46.631084 ]
 [43.805424 ]
 [35.38256  ]
 [47.137653 ]
 [ 5.697682 ]
 [38.80644  ]
 [27.000462 ]
 [32.67422  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  5.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 215 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.29280471801758



buy possibilites: [-1] 
expected returns: [[69.87716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  3.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 343 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.13764190673828






Player: 1 
cards in hand: [ 0. 11.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  0.] 
cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [25. 25.  3. 11. 29.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  3.  0.] 
cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [25. 25.  3. 11. 29.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
adversary victory points: 4
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [25. 25.  3. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11. 29.] 
expected returns: [[ 80.70969 ]
 [102.98008 ]
 [102.98008 ]
 [ 91.91434 ]
 [ 95.896935]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  3. 11. 29.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  4. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.  0. 11.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 69.87715911865234



action possibilites: [-1] 
expected returns: [[88.971855]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 11. 29.  0. 10.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.  0. 11.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 102.98005676269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[81.88659 ]
 [47.062767]
 [89.80197 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3. 11. 29.  0. 10.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 3.  6.  3. 14.  0.] 
adversary cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.  0. 11.  6.  3.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 88.97185516357422






Player: 1 
cards in hand: [ 3.  6.  3. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  3. 14.  0.] 
cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.  0. 11.  6.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0. 25. 25.
  3. 11. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  3. 14.  0.] 
cards in discard: [ 6.  0.  8.  6.  0.  6. 23.  3.  6.  8.  0. 11.  0. 11.  6.  3.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 25.  0. 29.  3.] 
adversary cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0. 25. 25.
  3. 11. 29.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
adversary victory points: 4
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0. 25.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[65.00039]
 [86.63655]
 [78.49697]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.  3.] 
cards in discard: [29. 25.  3. 11. 10.  1.  1.  3. 11. 29. 29. 11. 10.  0.  0.  0. 25. 25.
  3. 11. 29.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  3. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6] -> size -> 26 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 89.80196380615234



action possibilites: [-1] 
expected returns: [[37.384205]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  2. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  8. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6] -> size -> 27 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 86.63656616210938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[37.477436 ]
 [50.294437 ]
 [44.06868  ]
 [ 3.6539512]
 [50.69082  ]
 [43.617302 ]
 [46.72314  ]
 [43.05969  ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  2. 10.  3.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  8. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6] -> size -> 27 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.38420486450195



buy possibilites: [-1] 
expected returns: [[15.694447]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3. 11.  0.] 
cards in discard: [11.] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0.  6.  0.  8. 29.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6] -> size -> 27 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.69081497192383






Player: 1 
cards in hand: [ 0.  6.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  8. 29.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  8. 29.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  8. 29.] 
cards in discard: [6. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 11. 10.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10.] 
expected returns: [[46.081055]
 [61.763527]
 [56.28345 ]
 [53.10663 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 10.  0.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.694446563720703



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[40.519184]
 [46.82019 ]
 [42.91051 ]
 [46.82019 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 11.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  7. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 61.76353454589844



action possibilites: [-1] 
expected returns: [[29.308228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 302 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 49.13825607299805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 24.077461]
 [ 39.415497]
 [ 32.44314 ]
 [-26.433016]
 [ 39.62381 ]
 [ 30.933369]
 [ 35.0781  ]
 [ 29.768597]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  2.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.3082275390625



buy possibilites: [-1] 
expected returns: [[40.13568]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 11.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [14.  6.  8.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 329 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 39.623817443847656






Player: 1 
cards in hand: [14.  6.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  8.  6.  3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1.  0.  3. 25.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 25.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [29.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[35.17884 ]
 [57.515484]
 [67.12768 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  2. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[  -5    0    0  240    0    0    0    0    0    0    0    0    0    0
 1026    0] 
sum of rewards: 1261 

action type: discard_down_to_3_cards - action 9
Learning step: 0
desired expected reward: -32.574440002441406



action possibilites: [-1] 
expected returns: [[21.936905]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11. 10.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 67.12769317626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 10.010445]
 [-31.896336]
 [ 20.926197]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0. 11. 10.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 3. 3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6] -> size -> 30 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.936904907226562






Player: 1 
cards in hand: [0. 8. 6. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 3. 3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  1. 29.  3.  0.] 
adversary cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
adversary victory points: 4
player victory points: -5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [29.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[-23.261154]
 [-15.41885 ]
 [-15.41885 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 29.  3.  0.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.926206588745117



action possibilites: [-1. 29.] 
expected returns: [[-10.396864 ]
 [  3.3255935]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  3.  0.  3.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -15.418859481811523



action possibilites: [-1. 25.] 
expected returns: [[79.94851]
 [93.38912]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  3. 25.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  1. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 3.3255887031555176



action possibilites: [-1] 
expected returns: [[77.43944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  3. 10. 25.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 27. 30.  8.  0. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 93.38912200927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[72.14327 ]
 [86.00531 ]
 [80.243256]
 [58.669975]
 [87.364365]
 [85.91524 ]
 [77.29128 ]
 [93.00222 ]
 [89.92897 ]
 [52.589256]
 [81.07093 ]
 [81.22241 ]
 [64.197815]
 [73.322556]
 [79.63776 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  3. 10. 25.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 28. 30. 27. 30.  8.  0. 10.  1.  7.  6.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1
Learning step: 0
desired expected reward: 77.43943786621094



buy possibilites: [-1] 
expected returns: [[41.13624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  3. 10. 25.] 
cards in discard: [11. 25.  0.  0. 29.  3. 11.  0. 10. 11. 29. 11.  0. 10.  0. 11.  1.  3.
 25. 29.  0. 11. 10. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 0. 0.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6] -> size -> 32 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 575 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 93.0021743774414






Player: 1 
cards in hand: [6. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
adversary victory points: 4
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
adversary victory points: 4
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 0. 0.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 25.  1. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
adversary victory points: 4
player victory points: -6 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 25.  1. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 1.5280399]
 [16.273909 ]
 [10.17655  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 25.  1. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 23.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 41.13623809814453



action possibilites: [-1] 
expected returns: [[40.0801]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 23.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.27389144897461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[33.928654]
 [41.130688]
 [40.87889 ]
 [40.739788]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 29. 25. 25.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 27. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 23.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 40.080101013183594



buy possibilites: [-1] 
expected returns: [[32.258156]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  1. 29. 25. 25.] 
cards in discard: [3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 23.  6.  3.] 
adversary cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 361 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 41.13068389892578






Player: 1 
cards in hand: [ 0. 11. 23.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 23.  6.  3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10. 25. 25.  3.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 23.  6.  3.] 
cards in discard: [ 6.  0.  0.  6.  0.  8. 29.  0. 14.  6.  8.  6.  3.  6.  0.  0.  8.  6.
  3.  3.  6.  1.  6.  6.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [10. 25. 25.  3.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [10. 25. 25.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 25.] 
expected returns: [[65.16589]
 [71.85059]
 [85.9078 ]
 [85.9078 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 25.  3.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 29.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.258155822753906



action possibilites: [-1] 
expected returns: [[39.83574]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  3.  0. 10. 29.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 29.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 85.90777587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[31.886139]
 [40.662083]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 25.  3.  0. 10. 29.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 29.  1.  6. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
adversary victory points: -6
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.83573913574219






Player: 1 
cards in hand: [11. 29.  1.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  1.  6. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  1.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  1. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  6. 11.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  1. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  6. 11.] 
cards in discard: [11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 26. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  1. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  6. 11.] 
cards in discard: [11.  3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  1. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
adversary victory points: 5
player victory points: -5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[88.6889 ]
 [94.18554]
 [94.18554]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  1. 11.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 25. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 40.662078857421875



action possibilites: [-1] 
expected returns: [[23.724243]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 342 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 95.36893463134766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.86202  ]
 [35.62529  ]
 [30.524128 ]
 [41.23526  ]
 [25.697609 ]
 [47.012653 ]
 [-5.5915136]
 [34.738083 ]
 [23.94214  ]
 [29.489868 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  4.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.7242431640625



buy possibilites: [-1] 
expected returns: [[30.630234]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1. 11.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 0. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
adversary victory points: -5
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -10   0   0 128   0] 
sum of rewards: 433 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.01267623901367






Player: 1 
cards in hand: [8. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6. 6. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  8 14 23 11  6  8 29  3  6  0  6 11  8  6  3  6  0
  6  6  6  0  0  6  0  6  1 11  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11.  0.  0. 10. 29.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
adversary victory points: 5
player victory points: -3 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11.  0.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[56.303875]
 [62.836174]
 [57.946053]
 [66.96315 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 10. 29.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.630233764648438



action possibilites: [-1. 11. 11.] 
expected returns: [[69.05446 ]
 [75.744125]
 [75.744125]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 11.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 26. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 62.414329528808594



action possibilites: [-1] 
expected returns: [[6.346684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 25. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0 -20   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 75.75786590576172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-15.312155 ]
 [  6.344091 ]
 [  2.3680673]
 [  5.413014 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 25. 30. 25. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 275 

action type: take_action - action -1
Learning step: 0
desired expected reward: 6.346683979034424



buy possibilites: [-1] 
expected returns: [[18.695427]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 3.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0 -30   0   0  16   0] 
sum of rewards: 291 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 6.344102382659912






Player: 1 
cards in hand: [8. 6. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 6. 3.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8 14 23 11  8 29  3  0  6 11  8  6  3  6  0  6  6  6
  0  0  6  0  6  1 11  3  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  0. 11.  0.] 
adversary cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[117.95495]
 [128.30862]
 [122.57711]
 [122.57711]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0. 11.  0.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 18.69542694091797



action possibilites: [-1. 11. 10.] 
expected returns: [[  1.4944129]
 [-14.997309 ]
 [-18.854881 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 5
Learning step: 0
desired expected reward: 123.41039276123047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-28.179276 ]
 [-29.117323 ]
 [-14.505308 ]
 [  1.4944129]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10.] 
cards in discard: [ 3. 25.  3.  3.  1. 29. 25. 25. 25. 10. 25.  3.  0. 10. 29.  1. 29. 11.
  0.  1. 11.  0.  0. 10.  1.  3. 29. 11.  0. 11.  0. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 6. 0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.4944052696228027






Player: 1 
cards in hand: [0. 8. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [29.  0. 11.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
adversary victory points: 6
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [29.  0. 11.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29.] 
expected returns: [[ 3.1873488]
 [13.846184 ]
 [ 9.59124  ]
 [13.846184 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 11.  3. 29.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  3.  6.  6.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 1.4944052696228027



action possibilites: [-1. 29.] 
expected returns: [[35.335175]
 [45.560722]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.] 
cards in discard: [ 0. 11.] 
cards in deck: 32 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  3.  6.  6.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 12.421867370605469



action possibilites: [-1.] 
expected returns: [[34.105618]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 0. 11.  1. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  3.  6.  6.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.264469146728516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[28.941582]
 [36.408417]
 [35.979355]
 [34.348656]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 11.  1. 29.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 2 
card supply: [23. 25. 30. 24. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  3.  6.  6.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 6 

Reward from previous game state: 
[ -5   0   0 270   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 305 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.10561752319336



buy possibilites: [-1] 
expected returns: [[29.009953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 0. 11.  1. 29.  3.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [23.  0.  3.  6.  6.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 311 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 36.40843200683594






Player: 1 
cards in hand: [23.  0.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  3.  6.  6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 10.  1.  1. 25.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  6.  6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 10.  1.  1. 25.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  3.  6.  6.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [11. 10.  1.  1. 25.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 10.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 25.] 
expected returns: [[22.090668]
 [30.733025]
 [26.347979]
 [40.079216]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.  1. 25.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 29.009952545166016



action possibilites: [-1] 
expected returns: [[32.27691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1.  1.  3.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.0792121887207





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.15738 ]
 [41.173344]
 [34.13308 ]
 [12.222069]
 [42.564392]
 [32.892746]
 [48.265495]
 [44.467102]
 [ 5.596292]
 [33.943714]
 [35.203793]
 [17.080273]
 [26.36757 ]
 [35.52352 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  1.  1.  3.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  5.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 32.27690887451172



buy possibilites: [-1] 
expected returns: [[84.51242]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  1.  1.  3.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25.] 
cards in deck: 24 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  0.  0.] 
adversary cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -50   0   0 250   0] 
sum of rewards: 515 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 48.265499114990234






Player: 1 
cards in hand: [ 3. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.  0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0. 29.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  9.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [11.  3. 11. 29.  1.  6. 11.  0.  8.  0.  0.  8.  6.  0.  8.  6.  6.  0.
  0. 23.  0.  3.  6.  6. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 10.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[37.497673]
 [50.251717]
 [37.80929 ]
 [38.527878]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[  -5    0    0  300    0    0    0    0    0    0    0  -50    0    0
 1364    0] 
sum of rewards: 1609 

action type: discard_down_to_3_cards - action 5
Learning step: 0
desired expected reward: -111.99522399902344



action possibilites: [-1] 
expected returns: [[15.324945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.  3.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 50.25172424316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 3.4818711]
 [15.870594 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 11.  3.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 6. 0. 3. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 15.324945449829102






Player: 1 
cards in hand: [6. 6. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 6.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 0. 3. 6.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3.  0. 10.  3.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
adversary victory points: 7
player victory points: -3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [29.  3.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[47.090996]
 [55.018265]
 [45.59237 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0. 10.  3.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 1. 8. 0. 3.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 15.870620727539062



action possibilites: [-1.] 
expected returns: [[78.34637]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 1. 8. 0. 3.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 52.823974609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[72.14695]
 [85.62643]
 [78.13828]
 [77.96201]
 [79.76967]
 [79.33432]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25] -> size -> 40 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 25. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 1. 8. 0. 3.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 78.34636688232422



buy possibilites: [-1] 
expected returns: [[65.6163]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [6. 1. 8. 0. 3.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6.] 
adversary owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
adversary victory points: -3
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0 -60   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 85.6264419555664






Player: 1 
cards in hand: [6. 1. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 8. 0. 3.] 
cards in discard: [0. 6. 6. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6
  0  6  1 11  3  0  0  0 14  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 11. 25.  0.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
adversary victory points: 7
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [0. 6. 6. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 11. 25.  0.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
adversary victory points: 7
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [0. 6. 6. 0. 3. 6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 11. 25.  0.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
adversary victory points: 7
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [0. 6. 6. 0. 3. 6. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [25. 11. 11. 25.  0.] 
adversary cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
adversary victory points: 7
player victory points: -4 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [25. 11. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 11. 25.] 
expected returns: [[49.219906]
 [56.288223]
 [47.690308]
 [47.690308]
 [56.288223]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 11. 25.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8. 23.  0.  0.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 65.61630249023438



action possibilites: [-1] 
expected returns: [[20.490547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.  0. 29.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8. 23.  0.  0.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 56.28821563720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[17.442589]
 [25.502758]
 [21.64179 ]
 [20.490576]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 25.  0. 29.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 30. 23. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8. 23.  0.  0.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.49054718017578



buy possibilites: [-1] 
expected returns: [[14.14983]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 25.  0. 29.  0.] 
cards in discard: [ 0. 11.  1. 29.  3. 29. 29.  3. 25. 25. 11. 10.  1.  1.  3.  0.  0. 29.
 25. 11. 10. 11.  3.  0. 10.  1. 29.  3.  3.  1.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8. 23.  0.  0.] 
adversary cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
adversary owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0 -70   0   0  16   0] 
sum of rewards: 321 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 25.502735137939453






Player: 1 
cards in hand: [11.  8. 23.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 23.  0.  0.] 
cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  0.  0.] 
cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  8 14 23 11  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0
  6 11  3  0  0  0 14  0  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 6. 6. 0. 3. 6. 0. 8. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.  8.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
action values: 0 
buys: 2 
player value: 1 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 1.  3. 25. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 1.  3. 25. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[12.418768 ]
 [23.368523 ]
 [ 3.8080583]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 25. 10.  0.] 
cards in discard: [] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14. 11.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 14.149829864501953



action possibilites: [-1] 
expected returns: [[35.92153]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  0.  1.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14. 11.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.368473052978516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.492283]
 [46.540394]
 [32.029118]
 [40.721493]
 [19.775532]
 [50.54406 ]
 [39.862877]
 [56.985428]
 [52.37371 ]
 [14.211481]
 [43.065834]
 [43.77835 ]
 [26.541012]
 [34.204384]
 [39.254597]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  1.  1.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 7 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  4.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14. 11.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.921531677246094



buy possibilites: [-1] 
expected returns: [[17.279259]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  0.  1.  1.] 
cards in discard: [25.] 
cards in deck: 35 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 14. 11.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5.    0.    0.  360.    0.    0.   20.    0.    0.    0.    0.  -80.
   0.    0.   62.5   0. ] 
sum of rewards: 357.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 56.98542785644531






Player: 1 
cards in hand: [ 3.  0.  6. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 14. 11.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  3. 11.  3.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 14.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  3. 11.  3.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 14.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29. 11.  3. 11.  3.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [29. 11.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[43.668724]
 [54.278915]
 [50.241535]
 [50.241535]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 11.  3.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.279258728027344



action possibilites: [-1. 11. 29.] 
expected returns: [[59.184753]
 [64.26383 ]
 [69.39648 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 48.73822021484375



action possibilites: [-1.] 
expected returns: [[90.29588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 63.667457580566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[82.75526 ]
 [89.609276]
 [89.324715]
 [90.960175]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 90.29588317871094






Player: 1 
cards in hand: [ 0.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  6. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  0.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  5. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  0.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  5. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  0.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  5. 10. 10.] 
adversary cards in hand: [29.  3. 11. 11.  0.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [29.  3. 11. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[31.96344 ]
 [43.319565]
 [39.283897]
 [39.283897]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 11. 11.  0.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 90.96017456054688



action possibilites: [-1. 11.] 
expected returns: [[79.74811]
 [88.42283]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25] -> size -> 43 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  3.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.69428253173828



action possibilites: [-1] 
expected returns: [[73.35333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0 -90   0   0  64   0] 
sum of rewards: 369 

action type: gain_card_n - action 5
Learning step: 0
desired expected reward: 91.10628509521484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[65.0303  ]
 [72.88722 ]
 [71.779335]
 [74.14864 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  0.] 
adversary cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 395 

action type: take_action - action -1
Learning step: 0
desired expected reward: 73.35333251953125






Player: 1 
cards in hand: [ 0. 14.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.  0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  3.  8.  0.] 
cards in discard: [ 0.  6.  6.  0.  3.  6.  0.  8.  6.  0. 23.  8.  0. 11.  3.  0.  6. 14.
 10.  0. 11.  0.  0.  6.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 10. 10.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
expected returns: [[23.28336 ]
 [35.705196]
 [29.39959 ]
 [29.39959 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 10. 10.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 24. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 74.1486587524414



action possibilites: [-1] 
expected returns: [[59.37171]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 10.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -100    0    0
   27    0] 
sum of rewards: 302 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 34.88621520996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[51.110435]
 [59.371727]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10. 10.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 59.37171173095703






Player: 1 
cards in hand: [ 0.  3.  0.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  6. 29.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25. 29.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25. 29.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
adversary victory points: 8
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  5. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25. 29.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
adversary victory points: 8
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 6. 11. 10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  1. 25. 29.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
adversary victory points: 8
player victory points: -4 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  1. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[38.81933]
 [51.14665]
 [49.15413]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 25. 29.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 355 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 59.37171173095703



action possibilites: [-1] 
expected returns: [[8.817358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  1. 29. 29. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 51.14664077758789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -4.0858326]
 [ 20.165836 ]
 [ 11.595621 ]
 [ 25.255888 ]
 [  6.836041 ]
 [ 28.796574 ]
 [-35.453587 ]
 [ 14.745615 ]
 [  1.2662239]
 [  8.817287 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  2.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 360   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 375 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.817358016967773



buy possibilites: [-1] 
expected returns: [[34.627144]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  1. 29. 29. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 6. 0. 8.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
adversary victory points: -4
player victory points: 8 

Reward from previous game state: 
[  -5    0    0  360    0    0   20    0    0    0    0 -110    0    0
  128    0] 
sum of rewards: 393 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 28.796592712402344






Player: 1 
cards in hand: [0. 6. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 0. 8.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  6  3  6  0  6  6  6  0  0  6  0  6 11  3  0
  0  0 14  0  0  0 10  0  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 25.  3.  1.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
adversary victory points: 8
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 25.  3.  1.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
adversary victory points: 8
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 25.  3.  1.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
adversary victory points: 8
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [16. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 11. 25.  3.  1.] 
adversary cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
adversary victory points: 8
player victory points: -2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 25.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[49.050346]
 [55.943527]
 [65.28774 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 25.  3.  1.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6. 11.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.62714385986328



action possibilites: [-1] 
expected returns: [[57.079437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  3.  1.  3. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6. 11.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 65.2877426147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[49.674576]
 [58.921227]
 [56.04574 ]
 [57.079456]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  1.  3. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 23. 30. 22. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6. 11.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
adversary victory points: -2
player victory points: 8 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.079437255859375



buy possibilites: [-1] 
expected returns: [[32.737118]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  3.  1.  3. 25.] 
cards in discard: [25. 25.  1.  3. 10.  0.  1.  1. 11.  3. 11. 25. 29. 29.  3. 11. 29. 29.
 29. 11.  3.  0.  1. 11.  3.  0. 10. 10. 29. 25.  0.  0.  1. 29. 29. 25.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 21. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  6. 11.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -120    0    0
   16    0] 
sum of rewards: 241 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 58.92121887207031






Player: 1 
cards in hand: [ 0.  0. 10.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6. 11.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 30. 21. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  7.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [25. 11. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
expected returns: [[44.01663 ]
 [57.692924]
 [46.0394  ]
 [41.121452]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 42 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 14.  3.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.737117767333984



action possibilites: [-1] 
expected returns: [[29.321934]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 14.  3.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 57.69292449951172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[25.16698 ]
 [38.2986  ]
 [32.005768]
 [32.93242 ]
 [35.887142]
 [32.319016]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 23. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 14.  3.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.32193374633789



buy possibilites: [-1] 
expected returns: [[34.779007]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0.  0. 10.] 
cards in discard: [1.] 
cards in deck: 40 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  0. 14.  3.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
adversary owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  330    0    0   20    0    0    0    0 -130    0    0
   54    0] 
sum of rewards: 269 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 38.298622131347656






Player: 1 
cards in hand: [ 0.  8.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 14.  3.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  3  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0
 14  0  0  0 10  0  0 10  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 29.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
adversary victory points: 9
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 29.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
adversary victory points: 9
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 22. 30. 21. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 29.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
adversary victory points: 9
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 29.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
adversary victory points: 9
player victory points: -2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[42.18235 ]
 [53.36359 ]
 [46.488605]
 [53.36359 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10. 29.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 22. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 14.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.77900695800781



action possibilites: [-1. 10. 29.] 
expected returns: [[ 93.43894 ]
 [ 97.308495]
 [106.473854]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 29.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 22. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 14.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 49.203269958496094



action possibilites: [-1.] 
expected returns: [[56.0438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
action values: 1 
buys: 0 
player value: 2 
card supply: [15. 22. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 14.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 98.9947509765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
expected returns: [[49.209026]
 [63.078224]
 [57.09146 ]
 [56.82879 ]
 [61.261147]
 [56.531254]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 22. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 14.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 56.043800354003906



buy possibilites: [-1] 
expected returns: [[55.21241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  8.  3.  0. 14.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
adversary victory points: -2
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  330    0    0   40    0    0    0    0 -140    0    0
   54    0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 63.078224182128906






Player: 1 
cards in hand: [ 0.  8.  3.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 20. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3.  0. 14.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 25. 29. 29.  0.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 29. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[18.98167 ]
 [32.996563]
 [30.588783]
 [30.588783]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29. 29.  0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 23.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.21240997314453



action possibilites: [-1] 
expected returns: [[37.209976]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 29.  0. 25. 11.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 23.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.996559143066406





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.815151]
 [37.20993 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29. 29.  0. 25. 11.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  6. 23.  6.  0.] 
adversary cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.20997619628906






Player: 1 
cards in hand: [ 0.  6. 23.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 23.  6.  0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25.  3. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 23.  6.  0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  6.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25.  3. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 23.  6.  0.] 
cards in discard: [ 6. 11. 10. 29.  0.  3.  0.  0.  8.  0.  0.  0.  8. 11.  0.  0. 10.  6.
  3.  8.  0.  0. 14.  3.  0.  8.  3.  0. 14.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [25.  3. 29.  1.  1.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
adversary victory points: 9
player victory points: -1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [25.  3. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[-47.769   ]
 [-29.336067]
 [-39.23102 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3. 29.  1.  1.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.20997619628906



action possibilites: [-1] 
expected returns: [[41.84429]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.  1.  3.  0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -29.336055755615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[33.451717]
 [48.364307]
 [43.21073 ]
 [18.247084]
 [51.142773]
 [39.4655  ]
 [58.458366]
 [53.22642 ]
 [12.532124]
 [44.261242]
 [44.735233]
 [26.246553]
 [34.849564]
 [41.844288]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  1.  3.  0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  3.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 41.84429168701172



buy possibilites: [-1] 
expected returns: [[11.527241]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  1.  1.  3.  0.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25.] 
cards in deck: 19 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
adversary victory points: -1
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  300    0    0   20    0    0    0    0 -150    0    0
  250    0] 
sum of rewards: 415 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 58.45838165283203






Player: 1 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [11. 10.  1. 11.  3.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25] -> size -> 50 
adversary victory points: 9
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 21. 30. 19. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [11. 10.  1. 11.  3.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25] -> size -> 50 
adversary victory points: 9
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 21. 30. 18. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [11. 10.  1. 11.  3.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25] -> size -> 50 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [11. 10.  1. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.] 
expected returns: [[ 3.9217267]
 [12.966911 ]
 [ 8.076563 ]
 [12.966911 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  1. 11.  3.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 30. 18. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 29. 11.] 
adversary cards in discard: [3. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.527240753173828



action possibilites: [-1] 
expected returns: [[2.4076657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 11.  3.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 18. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 29. 11.] 
adversary cards in discard: [3. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[  -5    0    0  270    0    0   20    0    0    0    0 -160    0    0
   27    0] 
sum of rewards: 152 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 11.803144454956055





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-6.5543647]
 [ 0.2629819]
 [-1.5326853]
 [ 2.4076524]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 11.  3.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 20. 30. 18. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0.  6. 29. 11.] 
adversary cards in discard: [3. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3] -> size -> 38 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.407665729522705






Player: 1 
cards in hand: [ 3.  0.  6. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 29. 11.] 
cards in discard: [3. 0. 6. 0. 0. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 18. 30.  8.  0. 10.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 25. 25.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
adversary victory points: 9
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 29.] 
cards in discard: [ 3.  0.  6.  0.  0.  6. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 25. 25.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
adversary victory points: 9
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 29.] 
cards in discard: [ 3.  0.  6.  0.  0.  6. 16.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 25. 25.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
adversary victory points: 9
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  6. 29.] 
cards in discard: [ 3.  0.  6.  0.  0.  6. 16.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3.  3. 25. 25.] 
adversary cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
adversary victory points: 9
player victory points: 0 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  3. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 5.2304654]
 [30.841137 ]
 [30.841137 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 25. 25.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  6.  0.  0.  6. 16.  0. 11.  3.  0.  6. 29.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 2.407665729522705



action possibilites: [-1] 
expected returns: [[22.26125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  3. 25.  3.  1.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  6.  0.  0.  6. 16.  0. 11.  3.  0.  6. 29.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.841156005859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16.  8. 29. 14. 10. 15. -1.] 
expected returns: [[13.984219 ]
 [26.639208 ]
 [20.371422 ]
 [32.71306  ]
 [21.338205 ]
 [34.256092 ]
 [-5.9828176]
 [25.113283 ]
 [13.888336 ]
 [22.261227 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  3. 25.  3.  1.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  1.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  6.  0.  0.  6. 16.  0. 11.  3.  0.  6. 29.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.261249542236328



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 5 
Gold: 0 
Estate: 6 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 0 
Witch: 8 
Poacher: 8 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  3.  3. 25.  3.  1.] 
cards in discard: [ 1. 25. 11. 10.  0.  0.  0. 10.  0. 29.  3. 10.  1. 29. 29.  0. 25.  3.
 29. 29.  0. 25. 11. 25. 25.  3. 29.  1.  1.  3.  0.  1. 11. 10.  1. 11.
  3. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10  1 25  1 10  3 25 29 10 11 29 25
 25 11 29 11 29 11 10 11 25  3  1 29  1  3  3 25  1  3 25 29  1 29  3  1
  1 25  1 29] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 18. 30.  8.  0.  9.  0.  5.  2.  0.  8.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  8.] 
adversary cards in discard: [ 3.  0.  6.  0.  0.  6. 16.  0. 11.  3.  0.  6. 29.] 
adversary owned cards: [ 8 14 23  8 29  0 11  8  3  0  6  6  6  0  0  6  0  6 11  3  0  0  0 14
  0  0  0 10  0  0 10  0  0  8  3  3  8  3 16  0] -> size -> 40 
adversary victory points: 0
player victory points: 9 

Reward from previous game state: 
[     -5 3000000       0     270       0       0      20       0       0
       0       0    -170       0       0      64       0] 
sum of rewards: 3000179 

action type: buy - action 29.0
Learning step: 120005.7890625
desired expected reward: 120040.046875



