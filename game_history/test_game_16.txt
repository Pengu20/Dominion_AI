 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.652023]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0     -90       0       0       0       0] 
sum of rewards: 3000105 

action type: buy - action 0.0
Learning step: 120003.40625
desired expected reward: 120023.2109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 9.304558]
 [11.57941 ]
 [10.283321]
 [ 7.770179]
 [10.577276]
 [ 9.397569]
 [ 8.539356]
 [ 8.644159]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.659673690795898



buy possibilites: [-1] 
expected returns: [[11.68747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [15.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 11.579411506652832






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [15.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [1. 0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[8.967726]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.687470436096191





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[10.849403]
 [13.332812]
 [11.943629]
 [ 9.170621]
 [12.751488]
 [12.312161]
 [11.015061]
 [15.175897]
 [ 9.910337]
 [10.069234]
 [12.070525]
 [10.097038]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1. 0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 7.921477317810059



buy possibilites: [-1] 
expected returns: [[2.138039]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 1.  0.  3.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 15.175898551940918






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 15  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.577599]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.1380391120910645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.445545]
 [23.918812]
 [22.509163]
 [20.6576  ]
 [19.589218]
 [23.34002 ]
 [23.037857]
 [21.7509  ]
 [26.008099]
 [25.750458]
 [20.433102]
 [23.595592]
 [20.818035]
 [21.293636]
 [22.611855]
 [20.692158]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.9002685546875



buy possibilites: [-1] 
expected returns: [[20.45119]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 15.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 250   0] 
sum of rewards: 245 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 26.008102416992188






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 15.  3.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 15.  3.  3.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [25.  0.  1.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[9.962215]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 20.451190948486328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[10.973529 ]
 [13.612035 ]
 [12.115694 ]
 [ 9.1351795]
 [12.553247 ]
 [11.169176 ]
 [10.1796665]
 [10.1896105]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  1.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 8.522947311401367



buy possibilites: [-1] 
expected returns: [[23.052944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [25.  0.  1.  0.  3.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3. 10.  3.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 14] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 13.612034797668457






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 15  8 10 14] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [25.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
adversary victory points: 3
player victory points: 2 





Player: 0 
cards in hand: [25.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[28.2224  ]
 [33.49444 ]
 [33.216484]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  8. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0] -> size -> 12 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.05294418334961



action possibilites: [-1] 
expected returns: [[8.29252]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  8. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 31.872638702392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 9.202474]
 [11.480956]
 [10.204089]
 [ 7.554203]
 [10.945563]
 [10.707662]
 [ 9.460923]
 [13.230746]
 [ 8.308028]
 [ 8.59359 ]
 [10.308381]
 [ 8.507531]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  3.  1.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  8. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.292519569396973



buy possibilites: [-1] 
expected returns: [[-6.293107]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  0.  3.  1.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 15.] 
adversary cards in discard: [ 0.  8. 10.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 173 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 13.230748176574707






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 0.  8. 10.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 25.  0.  3. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 0.  8. 10.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 25.  0.  3. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 15.] 
cards in discard: [ 0.  8. 10.  3.  6. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [29. 25.  0.  3. 29.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-0.46067214]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 25.  0.  3. 29.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: -6.293107032775879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[2.2873192 ]
 [4.805822  ]
 [1.1078317 ]
 [3.36024   ]
 [1.5920758 ]
 [0.59112906]
 [4.201663  ]
 [3.7848344 ]
 [2.4600787 ]
 [6.947809  ]
 [6.70306   ]
 [1.3751016 ]
 [4.5178413 ]
 [1.5052848 ]
 [2.2104535 ]
 [3.484428  ]
 [1.5808587 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 25.  0.  3. 29.  0.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  9.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -1.4717456102371216



buy possibilites: [-1] 
expected returns: [[-4.572745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [29. 25.  0.  3. 29.  0.  3.  1. 25.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 14.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   0.  60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 117.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 6.947807312011719






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [ 3. 15.  0. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 14.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [ 0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[42.512638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0. 14.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0   0   0   0   0   0   0   0   0 440   0] 
sum of rewards: 495 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 15.14953899383545





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[41.395393]
 [42.490032]
 [39.30608 ]
 [41.850998]
 [40.64494 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 30. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0. 14.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 38.96768569946289



buy possibilites: [-1] 
expected returns: [[9.561049]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0. 29.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 8.] 
adversary cards in discard: [ 0. 14.  3. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0 16  0] 
sum of rewards: 101 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 42.490028381347656






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0. 14.  3. 15.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0. 14.  3. 15.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  9. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 8.] 
cards in discard: [ 0. 14.  3. 15.  0.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0.  1.  1.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29.  0.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-1.9117934]
 [ 2.5127077]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.  1.] 
cards in discard: [ 0. 29.  3.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.561049461364746



action possibilites: [-1.] 
expected returns: [[10.839469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 1.906351089477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.3053665]
 [15.490338 ]
 [12.251577 ]
 [14.244817 ]
 [12.73598  ]
 [14.88008  ]
 [11.86384  ]
 [14.966891 ]
 [14.430377 ]
 [13.300725 ]
 [17.282238 ]
 [17.11121  ]
 [12.538851 ]
 [15.267417 ]
 [12.459891 ]
 [13.283943 ]
 [14.373927 ]
 [12.690886 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 8 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  8.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 10.839468955993652



buy possibilites: [-1] 
expected returns: [[21.129856]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 1. 0.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 10.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 167.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.282230377197266






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3.  0.  3. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 25. 29.  0.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  3.  0.  3. 25.] 
adversary cards in discard: [ 0. 29.  3.  0.  3.  0. 25. 29.  0.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25.  3.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[13.403676]
 [17.970741]
 [17.970741]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  3. 25.] 
cards in discard: [ 0. 29.  3.  0.  3.  0. 25. 29.  0.  0.  1.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  9. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10] -> size -> 16 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 21.12985610961914



action possibilites: [-1] 
expected returns: [[23.004684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.54029083251953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.465569]
 [26.104076]
 [24.607735]
 [21.62722 ]
 [25.04395 ]
 [23.661217]
 [22.671711]
 [22.681652]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 29. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.004684448242188



buy possibilites: [-1] 
expected returns: [[17.33548]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25.  0.  0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 6. 15.  0.  3.  0.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6] -> size -> 17 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 159 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 26.10407257080078






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 6. 15.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  3.  0.] 
cards in discard: [ 0. 10.  0. 15.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3.  1.  3.  1.] 
adversary cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  3.  0.] 
cards in discard: [ 0. 10.  0. 15.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3.  1.  3.  1.] 
adversary cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  3.  0.] 
cards in discard: [ 0. 10.  0. 15.  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [29.  3.  1.  3.  1.] 
adversary cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
adversary victory points: 4
player victory points: 1 





Player: 0 
cards in hand: [29.  3.  1.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[0.37706876]
 [4.298652  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3.  1.] 
cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 14.  8.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 17.335479736328125



action possibilites: [-1.] 
expected returns: [[11.480073]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 3. 1. 0.] 
cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 14.  8.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 4.352899551391602





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[13.45608 ]
 [15.641053]
 [12.402288]
 [14.395528]
 [12.886693]
 [12.014551]
 [15.117602]
 [14.581092]
 [13.45144 ]
 [17.432991]
 [17.261967]
 [12.689562]
 [15.418132]
 [12.610601]
 [13.434656]
 [14.524636]
 [12.841599]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 1. 0.] 
cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  7.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 14.  8.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 11.480072975158691



buy possibilites: [-1] 
expected returns: [[5.040411]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 3. 1. 0.] 
cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0.  3. 10. 14.  8.] 
adversary cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5.   0.   0.  90.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
 62.5  0. ] 
sum of rewards: 167.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 17.432987213134766






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 10. 14.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10. 14.  8.] 
cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0. 25. 29.  3.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
adversary victory points: 4
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10. 14.  8.] 
cards in discard: [ 0. 10.  0. 15.  0.  6.  3.  6. 15.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29.  0. 25.  0.] 
adversary cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0. 25. 29.  3.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
adversary victory points: 4
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 29.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-3.5577211 ]
 [-0.01132703]
 [ 0.12301898]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 25.  0.] 
cards in discard: [ 1. 25.  3.  0.  3. 25.  0.  0. 25. 29.  3.  1.  3.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  8. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3] -> size -> 18 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.040410995483398



action possibilites: [-1] 
expected returns: [[-5.8540974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.19455647468566895





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.2446547 ]
 [-2.8157952 ]
 [-4.1978474 ]
 [-5.9398966 ]
 [-6.9408426 ]
 [-3.3924663 ]
 [-3.8438773 ]
 [-5.117552  ]
 [-0.774037  ]
 [-0.99922013]
 [-6.156871  ]
 [-3.0816433 ]
 [-6.0429416 ]
 [-5.321518  ]
 [-4.0722036 ]
 [-5.9511127 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  1.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  6.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.854097366333008



buy possibilites: [-1] 
expected returns: [[-1.8370929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0.  1.  3.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [ 3.  0.  6. 14.  0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0  90   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 355 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -0.7740381956100464






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  6. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 14.  0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25. 25.  3.  0.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  9. 10.  8. 10.  8.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [ 6. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25.  0.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.5581932]
 [7.6955595]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.] 
cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  7. 10. 10.  9.  5.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14] -> size -> 20 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0 842   0] 
sum of rewards: 957 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 1.8582711219787598



action possibilites: [-1] 
expected returns: [[19.348343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  5.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.172734260559082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[21.173775]
 [23.41196 ]
 [22.120396]
 [20.55334 ]
 [19.635204]
 [22.87318 ]
 [22.402813]
 [21.248951]
 [25.266647]
 [25.076305]
 [20.347843]
 [23.150616]
 [20.395939]
 [21.104465]
 [22.240128]
 [20.537529]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  5.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.348342895507812



buy possibilites: [-1] 
expected returns: [[8.008623]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0.] 
cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 3.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 385 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 25.266647338867188






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 29.  3.  3.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 3.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [25. 29.  3.  3.  0.] 
adversary cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
adversary victory points: 4
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [25. 29.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[17.948875]
 [22.519276]
 [22.265938]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  3.  3.  0.] 
cards in discard: [25. 25.  0. 29.  0.  0.  1.  3. 25.  3. 25. 25.  0.  0.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  6. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.008623123168945



action possibilites: [-1] 
expected returns: [[2.718461]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.519271850585938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[4.194059 ]
 [6.0912323]
 [4.9760604]
 [2.9270205]
 [5.63097  ]
 [5.10446  ]
 [4.1478643]
 [7.464258 ]
 [3.5208473]
 [3.4100575]
 [5.0884175]
 [3.6856956]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  8.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.718461036682129



buy possibilites: [-1] 
expected returns: [[4.696289]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  3.  0.  0.  1.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8. 10. 10.  0.  0.] 
adversary cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 293 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 7.464256286621094






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8. 10. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10. 10.  0.  0.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3.  3.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3.  3.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  9.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3.  3.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  3.] 
cards in discard: [ 6. 14. 14.  3.  0.  6.  0.  6.  0.  0.  0.  6.  3.  6.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  8.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 1.  0. 25.  3.  3.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
adversary victory points: 4
player victory points: -2 





Player: 0 
cards in hand: [ 1.  0. 25.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[29.555378]
 [34.12881 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25.  3.  3.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  5. 10. 10.  8.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8] -> size -> 23 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 4.6962890625



action possibilites: [-1] 
expected returns: [[25.35704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0. 1.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 15. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.65573501586914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[26.02671 ]
 [28.251026]
 [24.944275]
 [26.965641]
 [25.41193 ]
 [24.499008]
 [27.716213]
 [27.231781]
 [26.086235]
 [30.088028]
 [29.902622]
 [25.207722]
 [27.98891 ]
 [25.235168]
 [25.957767]
 [27.085972]
 [25.398708]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0. 1.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  4.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 15. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.357040405273438



buy possibilites: [-1] 
expected returns: [[26.313057]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0. 1.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  3.  0. 15. 15.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 24 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    0.  180.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 257.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 30.088027954101562






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 8.  3.  0. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0. 15. 15.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 15.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 15.] 
cards in discard: [6. 1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 25. 25.  0. 29.] 
adversary cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
adversary victory points: 4
player victory points: -3 





Player: 0 
cards in hand: [ 0. 25. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[ 6.2100267]
 [10.380939 ]
 [10.380939 ]
 [10.175004 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25.  0. 29.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  4. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 14. 14.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1] -> size -> 24 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.31305694580078



action possibilites: [-1] 
expected returns: [[2.0309715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0. 29.  0. 25.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 14. 14.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 10.380934715270996





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 0.57709503]
 [ 2.434485  ]
 [ 1.334681  ]
 [-0.8489772 ]
 [ 1.6458101 ]
 [ 0.67941   ]
 [-0.0526247 ]
 [ 0.06624579]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 29.  0. 25.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 14. 14.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 2.0309715270996094



buy possibilites: [-1] 
expected returns: [[3.0844984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0. 29.  0. 25.] 
cards in discard: [29. 25. 29.  3.  3.  0.  0.  1. 25. 25.  1.  0.  3.  3.  0.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 8.  6. 14. 14.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 279 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 2.434481620788574






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 14. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14. 14.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [29.  0.  1. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 14.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 14.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  8. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 14.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [ 0. 29. 25.] 
adversary cards in discard: [29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [ 0. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-7.174705 ]
 [-3.6079981]
 [-3.4748492]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.] 
cards in discard: [29.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  3. 10. 10.  8.  3.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10] -> size -> 26 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -10.085997581481934



action possibilites: [-1] 
expected returns: [[-5.576619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  1.] 
cards in discard: [29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6] -> size -> 27 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -3.6935653686523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-4.6207266]
 [-2.8286836]
 [-3.8902135]
 [-5.82824  ]
 [-3.2647998]
 [-3.763782 ]
 [-4.662548 ]
 [-1.5167043]
 [-5.2631645]
 [-5.360015 ]
 [-3.785571 ]
 [-5.097046 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1.] 
cards in discard: [29.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  7.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6] -> size -> 27 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.5766191482543945



buy possibilites: [-1] 
expected returns: [[-0.01039219]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  1.] 
cards in discard: [29.  1. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [0. 3. 6. 6. 6.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6] -> size -> 27 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 383 

action type: buy - action 29.0
Learning step: 0
desired expected reward: -1.5167030096054077






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 6. 6.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1. 25.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
adversary victory points: 4
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 6.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1. 25.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
adversary victory points: 4
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 6. 6.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1. 25.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
adversary victory points: 4
player victory points: -5 





Player: 0 
cards in hand: [29. 25.  3.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[32.96681 ]
 [37.55206 ]
 [37.795944]
 [37.795944]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  1. 25.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  2. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0] -> size -> 28 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -0.010392189025878906



action possibilites: [-1] 
expected returns: [[24.260986]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1. 25.  0.  0.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6] -> size -> 29 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 37.795936584472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.698452]
 [25.576172]
 [24.454845]
 [22.356285]
 [25.121975]
 [24.684097]
 [23.736164]
 [26.95633 ]
 [22.977222]
 [23.008308]
 [24.551434]
 [23.191196]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 25.  0.  0.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  6.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6] -> size -> 29 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.260986328125



buy possibilites: [-1] 
expected returns: [[11.28902]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1. 25.  0.  0.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6] -> size -> 29 
adversary victory points: -5
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 26.956336975097656






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [10.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 25.  0. 25.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
adversary victory points: 4
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  5.  8. 10.  7. 10.  8.] 
adversary cards in hand: [25. 25.  0. 25.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
adversary victory points: 4
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 6.  1. 15.  8.  3. 15.  6. 10. 14.  8.  6. 14.  0.  6.  0.  0.  3.  6.
  6.  6.  6. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25.  0. 25.  3.] 
adversary cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
adversary victory points: 4
player victory points: -6 





Player: 0 
cards in hand: [25. 25.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[2.2205205]
 [5.7812424]
 [5.7812424]
 [5.7812424]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0. 25.  3.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  1. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10] -> size -> 30 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1
Learning step: 0
desired expected reward: 11.289019584655762



action possibilites: [-1] 
expected returns: [[-14.214414]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 25.  3.  1. 25.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.781241416931152





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-14.476605 ]
 [-12.770405 ]
 [-13.7752905]
 [-13.569141 ]
 [-14.451715 ]
 [-15.128052 ]
 [-14.937091 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25.  3.  1. 25.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 25. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -14.2144136428833



buy possibilites: [-1] 
expected returns: [[-12.832968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 25.  3.  1. 25.] 
cards in discard: [29.  1. 29. 25.  0. 29.  0.  1. 29. 25. 29.  3.  1. 25.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  6. 10.  0.  3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 1.0
Learning step: 0
desired expected reward: -12.770407676696777






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 3.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
adversary victory points: 4
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
adversary victory points: 4
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.  0.  3.] 
cards in discard: [6. 0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
adversary victory points: 4
player victory points: -7 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[1.3725832]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 1. 6. 3. 6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6  0] -> size -> 32 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -12.832967758178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[2.2787585]
 [4.493263 ]
 [3.2090836]
 [3.5039096]
 [2.3605027]
 [1.5110254]
 [1.653336 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 24. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 1. 6. 3. 6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6  0] -> size -> 32 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.3725831508636475



buy possibilites: [-1] 
expected returns: [[-1.4086298]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [8. 1. 6. 3. 6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6  0] -> size -> 32 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0  54   0] 
sum of rewards: 379 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 4.493259429931641






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [8. 1. 6. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 3. 6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 15  8 10 14  0  6 15  0 10  6  3  6 14  6  6  8  6  1
  6 10  6  0  6 10  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 25.  1.  1. 25.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
adversary victory points: 4
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 25.  1.  1. 25.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
adversary victory points: 4
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 25.  1.  1. 25.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
adversary victory points: 4
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 25.  1.  1. 25.] 
adversary cards in discard: [1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
adversary victory points: 4
player victory points: -7 





Player: 0 
cards in hand: [ 3. 25.  1.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[ 8.09291  ]
 [12.4774475]
 [12.4774475]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  1.  1. 25.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 15.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -1.4086297750473022



action possibilites: [-1] 
expected returns: [[38.727135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  1. 25.  0. 25.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 15.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 12.477456092834473





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.79931 ]
 [39.957348]
 [38.707306]
 [37.193745]
 [39.43754 ]
 [38.99254 ]
 [37.881546]
 [41.74644 ]
 [41.5616  ]
 [36.994747]
 [39.696404]
 [37.059185]
 [37.72164 ]
 [38.820644]
 [37.186726]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 25.  0. 25.] 
cards in discard: [1. 0. 3. 3. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  3.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 15.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 38.727134704589844



buy possibilites: [-1] 
expected returns: [[85.69892]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  1. 25.  0. 25.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15. 15.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
adversary victory points: -7
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 595 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 41.7464485168457






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [15. 15.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0. 14.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29. 25. 25. 29.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
adversary victory points: 4
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
adversary victory points: 4
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 28. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
adversary victory points: 4
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 23. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 29.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
adversary victory points: 4
player victory points: -6 





Player: 0 
cards in hand: [25. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 29.] 
expected returns: [[12.834087]
 [17.164558]
 [17.164558]
 [16.930794]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 29.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -15.40580940246582



action possibilites: [-1] 
expected returns: [[12.672269]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 23. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 17.16454315185547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[11.372881]
 [13.371769]
 [12.165599]
 [12.530871]
 [11.501544]
 [10.774821]
 [10.858234]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 23. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: 12.672268867492676



buy possibilites: [-1] 
expected returns: [[5.520603]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  8.  6.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
adversary victory points: -6
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 369 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 13.371771812438965






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [ 0. 10.  8.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  6.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25. 29. 29. 25.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
adversary victory points: 4
player victory points: -6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 6. 0.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3 15  8 10 14  0 15  0 10  6  3  6 14  6  6  8  6  6 10  6
  0  6 10  6  0  0  3] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25. 29. 29. 25.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
adversary victory points: 4
player victory points: -6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25. 29. 29. 25.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25. 29. 29. 25.] 
adversary cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [29. 25. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29. 29. 25.] 
expected returns: [[-2.6887035 ]
 [ 0.53951097]
 [ 0.6436825 ]
 [ 0.53951097]
 [ 0.53951097]
 [ 0.6436825 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29. 29. 25.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 5.520603179931641



action possibilites: [-1] 
expected returns: [[4.6967173]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 25.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 0.6436843872070312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[5.312123 ]
 [6.935071 ]
 [5.9673147]
 [6.069067 ]
 [5.255594 ]
 [4.6154423]
 [4.8897405]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 25.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 22. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 4.696717262268066



buy possibilites: [-1] 
expected returns: [[3.355322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 29. 25.  0.  1.] 
cards in discard: [ 1.  0.  3.  3.  0.  0. 25. 25.  3.  1.  1. 25.  0. 25.  0. 29.  1. 25.
 25. 29.  0.  1.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6. 10.  0. 14.  6.] 
adversary cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 6.9350690841674805






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [ 6. 10.  0. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0. 14.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 14.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0. 14.  6.] 
cards in discard: [ 6.  0.  3.  6. 10.  0.  3.  0.  8.  6.  3. 14. 15. 15.  0.  6. 10.  8.
  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [29. 25.  3.  1.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
adversary victory points: 4
player victory points: -4 





Player: 0 
cards in hand: [29. 25.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-8.383897 ]
 [-4.510618 ]
 [-4.3571453]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  3.  1.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.3553218841552734



action possibilites: [-1] 
expected returns: [[0.6542089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  1.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -4.357145309448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[0.8979926]
 [1.729209 ]
 [0.9137058]
 [0.3463502]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3. 25.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 21. 30. 27. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 0.6542088985443115



buy possibilites: [-1] 
expected returns: [[6.562212]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  1.  3. 25.  3.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 301 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 1.7292118072509766






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 25. 25.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 21. 30. 26. 30.  8.  0. 10. 10.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 25. 25.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  6. 10.] 
cards in discard: [11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 25. 25.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 0.  0. 29. 25. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 25.] 
expected returns: [[68.33762]
 [73.50576]
 [73.80107]
 [73.80107]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25. 25.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  6.  0.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 6.562211990356445



action possibilites: [-1] 
expected returns: [[21.602264]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 25.  0.  0.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  6.  0.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 73.80107116699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[21.081516]
 [23.23074 ]
 [21.95433 ]
 [22.721218]
 [22.309746]
 [21.202843]
 [24.819584]
 [20.207306]
 [20.366562]
 [22.05318 ]
 [20.487728]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.  0.  0.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  5.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  6.  0.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.602264404296875



buy possibilites: [-1] 
expected returns: [[0.7124598]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29. 25.  0.  0.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3. 10. 14.  6.  0.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 24.819576263427734






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  6.  0.] 
cards in discard: [11.  0.  0.  0.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25.  0.  0. 29.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  0.] 
cards in discard: [11.  0.  0.  0.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.] 
cards in discard: [11.  0.  0.  0.  6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  9.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  6.  0.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 29.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[19.060879]
 [23.128178]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  8.  8.  6.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  270    0    0    0    0    0    0    0    0    0    0
 1616    0] 
sum of rewards: 1881 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -16.744503021240234



action possibilites: [-1.] 
expected returns: [[0.6713431]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  8.  8.  6.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.591873168945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[0.95690894]
 [2.6633883 ]
 [1.6583362 ]
 [2.263702  ]
 [1.8644853 ]
 [0.9817977 ]
 [3.9186778 ]
 [0.28586626]
 [0.30486584]
 [1.7460551 ]
 [0.4963336 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  4.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  8.  8.  6.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 0.6713430881500244



buy possibilites: [-1] 
expected returns: [[-17.998138]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [15.  0.  8.  8.  6.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 413 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 3.918679714202881






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [15.  0.  8.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  8.  6.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10
  6  0  0  3  0 11 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 6.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 25. 25.  0.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [25. 25. 25.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 25.] 
expected returns: [[-1.7130315]
 [ 1.6193705]
 [ 1.6193705]
 [ 1.6193705]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25. 25.  0.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -17.998138427734375



action possibilites: [-1] 
expected returns: [[-5.9973536]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 25.  0.  1. 29.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 1.6193699836730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.077761 ]
 [-3.1977215]
 [-4.322425 ]
 [-5.6368656]
 [-3.6452985]
 [-4.1065226]
 [-5.0619965]
 [-1.6780126]
 [-1.8207886]
 [-5.813404 ]
 [-3.4891214]
 [-5.8044586]
 [-5.2061234]
 [-4.2255983]
 [-5.5763946]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  1. 29.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  2.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: -5.997353553771973



buy possibilites: [-1] 
expected returns: [[-7.833911]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 25.  0.  1. 29.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  6.  3.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -10   0   0 250   0] 
sum of rewards: 525 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -1.678017258644104






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1. 25. 25. 25. 25.  0.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  8.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1. 25. 25. 25. 25.  0.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  6.  3.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  1. 29.  1.  1.] 
adversary cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1. 25. 25. 25. 25.  0.  1. 29.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 3.  1. 29.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[1.7708263]
 [4.999111 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  1.  1.] 
cards in discard: [ 3. 25. 29.  3.  1.  3. 25.  3. 29. 25.  0.  0. 29. 25.  0.  0. 25.  0.
  1. 29. 29.  0.  1. 25. 25. 25. 25.  0.  1. 29.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  6. 10.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -7.833910942077637



action possibilites: [-1.] 
expected returns: [[12.200002]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  6. 10.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.8161044120788574





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[11.922678 ]
 [14.015874 ]
 [10.851301 ]
 [12.774146 ]
 [11.286697 ]
 [13.361223 ]
 [13.520005 ]
 [13.05929  ]
 [11.9846525]
 [15.751325 ]
 [15.5585165]
 [11.092682 ]
 [13.701472 ]
 [11.16329  ]
 [11.777431 ]
 [12.877692 ]
 [11.354215 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 9 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  1.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  6. 10.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.20000171661377



buy possibilites: [-1] 
expected returns: [[22.502747]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 1. 1.] 
cards in discard: [ 3. 25.] 
cards in deck: 30 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
action values: 0 
buys: 0 
player value: 4 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  6.  0.  6. 10.] 
adversary cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5.    0.    0.  270.    0.    0.   20.    0.    0.    0.    0.  -20.
   0.    0.   62.5   0. ] 
sum of rewards: 327.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 15.751334190368652






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [ 0.  6.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  6. 10.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0.  6. 15.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  6. 15.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0.  6. 15.] 
cards in discard: [11.  0.  0.  0.  6. 10. 11. 14.  3. 10.  6.  0.  0. 15.  8.  8.  6.  8.
  0.  0. 10.  6.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 3.  3.  1.  0. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
adversary victory points: 5
player victory points: -4 





Player: 0 
cards in hand: [ 3.  3.  1.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.55423 ]
 [34.336346]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  1.  0. 29.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.50274658203125



action possibilites: [-1.] 
expected returns: [[12.904588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 32.582271575927734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[12.989778]
 [14.816102]
 [13.740819]
 [13.90573 ]
 [12.976086]
 [12.260791]
 [12.498863]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 21. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 12.904587745666504



buy possibilites: [-1] 
expected returns: [[32.236862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 14.  3.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0 -30   0   0  54   0] 
sum of rewards: 309 

action type: buy - action 1.0
Learning step: 0
desired expected reward: 14.8161039352417






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 14.  3.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  6. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25.  3. 25. 29. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
adversary victory points: 5
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 20. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 29. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
adversary victory points: 5
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 20. 30. 26. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 29. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
adversary victory points: 5
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6. 14.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [25. 29. 29.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 29.] 
expected returns: [[1.5452166]
 [5.4437294]
 [5.300951 ]
 [5.300951 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29. 29.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 15. 10.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[  -5    0    0  240    0    0    0    0    0    0    0  -30    0    0
 1957    0] 
sum of rewards: 2162 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: -16.744503021240234



action possibilites: [-1] 
expected returns: [[-11.873107]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 25. 29.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 15. 10.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 5.443729877471924





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-11.541506]
 [-12.040141]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25. 29.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 15. 10.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.873106956481934



buy possibilites: [-1] 
expected returns: [[-13.23002]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 25. 29.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0.  3. 15. 15. 10.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.] 
adversary owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -40   0   0   0   0] 
sum of rewards: 215 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -11.541507720947266






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 15. 10.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1. 15. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15. 15.  8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6
  0  0  3  0 11 11  0  8  0  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15.] 
owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 3 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15. 15.] 
owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15. 15.] 
owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 15. 15.] 
owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  0. 25. 29. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
adversary victory points: 5
player victory points: -3 





Player: 0 
cards in hand: [ 1.  0. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 25.] 
expected returns: [[3.5118284]
 [6.8443136]
 [6.740138 ]
 [6.8443136]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 25. 29. 25.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
adversary owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -13.230019569396973



action possibilites: [-1] 
expected returns: [[-0.7887974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 29. 25.  0.  3.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
adversary owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 6.844315528869629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-0.7775556 ]
 [ 0.9112711 ]
 [-0.12236404]
 [ 0.46369386]
 [ 0.00241423]
 [-0.83408415]
 [ 2.2882056 ]
 [-1.3676212 ]
 [-1.4742389 ]
 [-0.02746224]
 [-1.1999366 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 25.  0.  3.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  3.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
adversary owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.7887973785400391



buy possibilites: [-1] 
expected returns: [[2.5436192]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0. 29. 25.  0.  3.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 10.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
adversary owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
adversary victory points: -3
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -50   0   0 128   0] 
sum of rewards: 333 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 2.288207530975342






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  0. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 10.  8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 15  8 10 14  0 15  0 10  3 14  6  6  8  6  6 10  6  0  6 10  6  0
  0  3  0 11 11  0  8  0  3  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  0. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
adversary victory points: 5
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  0. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
adversary victory points: 5
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 25.  0.  0. 25.] 
adversary cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
adversary victory points: 5
player victory points: -2 





Player: 0 
cards in hand: [ 0. 25.  0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25.] 
expected returns: [[1.1370969]
 [4.6985207]
 [4.6985207]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  0. 25.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 11.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
adversary owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1
Learning step: 0
desired expected reward: 2.543619155883789



action possibilites: [-1] 
expected returns: [[-1.7638081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 25.  1. 25.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 11.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
adversary owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 4.698519706726074





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-1.3414247 ]
 [ 0.28141642]
 [-0.6862334 ]
 [-1.7774377 ]
 [-0.11057329]
 [-0.58448064]
 [-1.3979542 ]
 [ 1.4644208 ]
 [-1.9314901 ]
 [ 0.05149269]
 [-2.0381064 ]
 [-1.4079379 ]
 [-0.591331  ]
 [-1.763807  ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  1. 25.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  2.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 11.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
adversary owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: -1.7638081312179565



buy possibilites: [-1] 
expected returns: [[-2.4125051]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 25.  1. 25.] 
cards in discard: [ 3. 25. 29.  1.  1.  1.  1.  0. 29.  1. 29.  3.  3.  1. 25.  3.  0. 25.
 29. 29. 25. 29. 29. 25.  1.  0. 29. 25.  0.  3. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 0. 11. 10. 11.  8.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
adversary owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
adversary victory points: -2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   0. 210.   0.   0.  20.   0.   0.   0.   0. -60.   0.   0.
  32.   0.] 
sum of rewards: 197.0 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 1.464418888092041






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 0. 11. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 11.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10. 11.  8.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1. 11. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  8.  0.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 15  8 10 14  0 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3
  0 11 11  0  8  0  3  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 25. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
adversary victory points: 5
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
adversary victory points: 5
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8. 11.] 
owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [ 1.  1.  0.  1. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
adversary victory points: 5
player victory points: -1 





Player: 0 
cards in hand: [ 1.  1.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[12.806132]
 [16.813385]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  0.  1. 25.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 6.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3. 10.  8.
 11. 11.  0.] 
adversary owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: -2.4125051498413086



action possibilites: [-1] 
expected returns: [[16.505447]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 6.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3. 10.  8.
 11. 11.  0.] 
adversary owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 16.813377380371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[17.035713]
 [19.13786 ]
 [15.984239]
 [17.897415]
 [16.423813]
 [18.504704]
 [18.633541]
 [18.170368]
 [17.096428]
 [20.689468]
 [16.22741 ]
 [18.842888]
 [16.282661]
 [16.91967 ]
 [18.004955]
 [16.457603]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 1. 1. 1.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29] -> size -> 41 
action values: 0 
buys: 1 
player value: 11 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  1.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 6.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3. 10.  8.
 11. 11.  0.] 
adversary owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 16.505447387695312



Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 9 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 0 
Chapel: 0 
Witch: 10 
Poacher: 10 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [1. 1. 0. 1. 1. 1.] 
cards in discard: [29.] 
cards in deck: 34 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 29 25  1 29 25  3 25  1 25 25 25 29 25
  1 29 29  1  1 25  1  1  3 29 29 25 25  1  0 29 29 29] -> size -> 42 
action values: 0 
buys: 0 
player value: 7 
card supply: [20. 20. 30. 24. 30.  8.  0. 10.  8.  7.  0.  0.  8. 10.  6. 10.  8.] 
adversary cards in hand: [6. 6. 6. 6. 6.] 
adversary cards in discard: [ 3. 14.  0.  3.  6. 14.  0. 10. 15. 15.  3.  8.  8.  3. 10.  3. 10.  8.
 11. 11.  0.] 
adversary owned cards: [ 3 15  8 10 14 15  0 10  3 14  6  8  6  6 10  6  0  6 10  6  0  0  3  0
 11 11  0  8  0  3  0  3] -> size -> 32 
adversary victory points: -1
player victory points: 5 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      20       0       0
       0       0     -70       0       0      64       0] 
sum of rewards: 3000189 

action type: buy - action 29.0
Learning step: 120006.7265625
desired expected reward: 120027.4140625



