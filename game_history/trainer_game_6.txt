 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[335.1783]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5 500   3  10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 508 

action type: discard_down_to_3_cards - action 1
Learning step: 18.330657958984375
desired expected reward: 159.71751403808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[323.10776]
 [323.10776]
 [323.1094 ]
 [323.10776]
 [324.85443]
 [323.93817]
 [323.90002]
 [333.35916]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.673046112060547
desired expected reward: 327.9913330078125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[361.26816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.577558517456055
desired expected reward: 324.7816162109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[348.25458]
 [348.25458]
 [348.25616]
 [348.25458]
 [348.64474]
 [350.00122]
 [349.08493]
 [352.3468 ]
 [349.73413]
 [349.04675]
 [350.68854]
 [358.50592]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.421972274780273
desired expected reward: 353.5958251953125



buy possibilites: [-1] 
expected returns: [[342.33206]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  0.  3.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [14.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 11.0
Learning step: -9.672588348388672
desired expected reward: 340.32861328125






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [14.  3.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[314.83676]
 [306.332  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -10.670439720153809
desired expected reward: 331.66162109375



action possibilites: [-1] 
expected returns: [[360.78638]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -303 

action type: gain_card_n - action 3
Learning step: -23.992483139038086
desired expected reward: 315.2110595703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[346.66458]
 [346.66617]
 [346.66458]
 [347.495  ]
 [356.916  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -3 

action type: take_action - action -1
Learning step: -10.337672233581543
desired expected reward: 350.4486999511719



buy possibilites: [-1] 
expected returns: [[366.6595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [6. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 16 

action type: buy - action 3.0
Learning step: -8.283470153808594
desired expected reward: 338.3826904296875






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[345.35678]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -11.143295288085938
desired expected reward: 355.51617431640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[335.02005]
 [335.02005]
 [335.02173]
 [335.02005]
 [335.02005]
 [335.41025]
 [336.76675]
 [335.8505 ]
 [338.425  ]
 [339.11237]
 [336.4997 ]
 [337.01385]
 [335.81235]
 [336.05945]
 [337.45407]
 [345.27145]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.330513000488281
desired expected reward: 335.8774719238281



buy possibilites: [-1] 
expected returns: [[336.5143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 6.  3. 11.  0.  3.  0.  3. 23.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 14.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 38 

action type: buy - action 23.0
Learning step: -7.379122257232666
desired expected reward: 329.634765625






Player: 1 
cards in hand: [ 0.  3.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 14.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 3. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [3. 3. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[357.63138]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.32728099822998
desired expected reward: 327.1870422363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[345.91064]
 [345.91064]
 [356.16202]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -10.735101699829102
desired expected reward: 349.1953430175781



buy possibilites: [-1] 
expected returns: [[354.8922]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6. 0. 3.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -42.0 

action type: buy - action 0.0
Learning step: -11.410457611083984
desired expected reward: 334.50018310546875






Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 28. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 3. 6. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[376.20193]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 6. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -9.860915184020996
desired expected reward: 345.03131103515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[363.13702]
 [363.13702]
 [363.1388 ]
 [363.13702]
 [363.53394]
 [364.905  ]
 [363.9751 ]
 [367.26883]
 [364.63437]
 [363.93967]
 [365.59973]
 [373.47488]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [0. 3. 3. 6. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 14.] 
adversary cards in discard: [3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -11.193011283874512
desired expected reward: 364.951171875



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 14.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 3.  0. 23. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [23. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 8. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 27. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [23. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [3. 8. 0. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [23. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[313.2628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [23. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[  -5    0    3  -20    0    0    0  -60    0    0    0    0    0 -300
   34    0] 
sum of rewards: -348 

action type: discard_down_to_3_cards - action 6
Learning step: -26.569091796875
desired expected reward: 298.6159362792969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[302.5481]
 [302.5499]
 [302.5481]
 [303.3862]
 [312.886 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [23. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  9. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.996447563171387
desired expected reward: 305.121826171875



buy possibilites: [-1] 
expected returns: [[296.98434]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [23. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -14 

action type: buy - action 8.0
Learning step: -9.187162399291992
desired expected reward: 294.19903564453125






Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.39227]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [23. 11.  8.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  0.  3.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1
Learning step: -8.378947257995605
desired expected reward: 288.60540771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[329.0272 ]
 [329.0272 ]
 [329.02893]
 [329.0272 ]
 [330.79517]
 [329.8653 ]
 [329.82983]
 [339.36505]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [23. 11.  8.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [ 0. 14.  8.  0.  3.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -10.479094505310059
desired expected reward: 325.9773864746094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8.  0.  3.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 14  3  8  3  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  8. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14.  0.] 
cards in discard: [3. 0. 3. 3. 0. 8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 0. 0.] 
adversary cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[312.261]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.545687675476074
desired expected reward: 328.8193664550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[305.81833]
 [305.81833]
 [305.82013]
 [305.81833]
 [307.5863 ]
 [306.65643]
 [306.62097]
 [316.1562 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9. 10. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.284170150756836
desired expected reward: 302.829833984375



buy possibilites: [-1] 
expected returns: [[307.3384]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 0.] 
cards in discard: [23. 11.  8.  3.  0.  0.  0.  3.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3  8] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 6 

action type: buy - action 10.0
Learning step: -8.115935325622559
desired expected reward: 298.5050354003906






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 14  3  8  3  3  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  3.  8. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[287.70032]
 [278.20056]
 [278.1651 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 10.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.11034870147705
desired expected reward: 298.2280578613281



action possibilites: [-1.  8.] 
expected returns: [[300.33926]
 [290.83948]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  6  3 23  0  8 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -6.411177158355713
desired expected reward: 272.8490905761719



action possibilites: [-1.] 
expected returns: [[301.12778]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 3
Learning step: -6.923488616943359
desired expected reward: 283.05377197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[289.6926 ]
 [289.6926 ]
 [300.03046]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 16 

action type: take_action - action -1.0
Learning step: -7.6592116355896
desired expected reward: 293.46856689453125



buy possibilites: [-1] 
expected returns: [[243.96867]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3.] 
cards in discard: [0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [1. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -20.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -14.0 

action type: buy - action 0.0
Learning step: -9.180570602416992
desired expected reward: 280.51202392578125






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [1. 8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[263.1909]
 [255.0087]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0. 10.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.557675361633301
desired expected reward: 236.41099548339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[251.27763]
 [251.27763]
 [251.27763]
 [251.27763]
 [251.64728]
 [252.95221]
 [252.06335]
 [255.21242]
 [252.6889 ]
 [252.02667]
 [253.61447]
 [261.1344 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0. 10.  8.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 26. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -8.686785697937012
desired expected reward: 254.9524688720703



buy possibilites: [-1] 
expected returns: [[280.10754]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [ 0. 10.  8.  0.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  8.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -11.0 

action type: buy - action 3.0
Learning step: -6.81146240234375
desired expected reward: 244.46617126464844






Player: 1 
cards in hand: [ 0.  3.  8.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 23.  6.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 25. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8. 3.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[255.02838]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 1.] 
adversary cards in discard: [ 3. 14.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -20    0    0    0  -90    0    0    0    0    0 -300
   43    0] 
sum of rewards: -370 

action type: discard_down_to_3_cards - action 5
Learning step: -26.277679443359375
desired expected reward: 243.39602661132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[244.65707]
 [244.65707]
 [244.65707]
 [245.41565]
 [254.17027]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  9. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 1.] 
adversary cards in discard: [ 3. 14.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -23 

action type: take_action - action -1.0
Learning step: -8.277321815490723
desired expected reward: 245.32301330566406



buy possibilites: [-1] 
expected returns: [[250.76868]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 0. 10.  8.  0.  3.  3.  0.  0.  0.  0. 11. 23.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 1.] 
adversary cards in discard: [ 3. 14.  0.  3.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -334.0 

action type: buy - action 6.0
Learning step: -23.290557861328125
desired expected reward: 221.36648559570312






Player: 1 
cards in hand: [0. 8. 3. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 1.] 
cards in discard: [ 3. 14.  0.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 1.] 
cards in discard: [ 3. 14.  0.  3.  8.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  7. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 1.] 
cards in discard: [ 3. 14.  0.  3.  8.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  6. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[260.88574]
 [251.8147 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  6. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.45460033416748
desired expected reward: 242.31407165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[255.69496]
 [255.69496]
 [255.69496]
 [255.69496]
 [257.36954]
 [256.4807 ]
 [256.44403]
 [265.55176]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  6. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.985713005065918
desired expected reward: 252.5634765625



buy possibilites: [-1] 
expected returns: [[259.53323]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -32.0 

action type: buy - action 8.0
Learning step: -8.584538459777832
desired expected reward: 247.89617919921875






Player: 1 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  6. 10.  0.  3.] 
adversary cards in discard: [8. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  6. 10.  0.  3.] 
adversary cards in discard: [8. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [23.  6. 10.  0.  3.] 
adversary cards in discard: [8. 0. 0. 8. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [23.  6. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10.] 
expected returns: [[271.7251 ]
 [263.7891 ]
 [262.61737]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6. 10.  0.  3.] 
cards in discard: [8. 0. 0. 8. 3. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.713658332824707
desired expected reward: 250.819580078125



action possibilites: [-1. 10.] 
expected returns: [[288.6529 ]
 [279.54517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [8. 0. 0. 8. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -13 

action type: take_action - action 23.0
Learning step: -7.392263889312744
desired expected reward: 255.3181915283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[281.39893]
 [281.39893]
 [281.39893]
 [281.39893]
 [283.07355]
 [282.1847 ]
 [282.148  ]
 [291.25574]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [8. 0. 0. 8. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 0 
buys: 2 
player value: 3 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [0. 3. 8. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.762560844421387
desired expected reward: 279.8903503417969






Player: 1 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [0. 3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [0. 3. 8. 0. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  9.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 0.  3.  8.  0.  0.  0. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0 14] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[222.28342]
 [214.10121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1.0
Learning step: -11.400834083557129
desired expected reward: 279.8548889160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[212.96785]
 [212.96785]
 [212.96785]
 [213.75356]
 [222.82458]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 24. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -7.865420818328857
desired expected reward: 212.27133178710938



buy possibilites: [-1] 
expected returns: [[222.25217]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [ 8.  0.  0.  8.  3.  0. 23.  6. 10.  0.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  8.  8.] 
adversary cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0 14] -> size -> 17 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -20   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -15 

action type: buy - action 3.0
Learning step: -6.202040195465088
desired expected reward: 206.7657928466797






Player: 1 
cards in hand: [ 0. 14.  3.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  8.  8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 14  3  8  3  3  8  1  3  8  0 14] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.] 
cards in discard: [ 0.  3.  8.  0.  0.  0. 14.  3.  0.  1.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[242.8778 ]
 [233.83606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 14. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -6.4386420249938965
desired expected reward: 215.8135223388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[231.39879]
 [231.39879]
 [231.39926]
 [231.39879]
 [233.07497]
 [232.18233]
 [232.15326]
 [241.19502]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 14. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -7.459893226623535
desired expected reward: 233.63626098632812



buy possibilites: [-1] 
expected returns: [[282.31595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 3. 14. 14.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -43.0 

action type: buy - action 0.0
Learning step: -7.3678297996521
desired expected reward: 224.03094482421875






Player: 1 
cards in hand: [ 3. 14. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 6. 11.  0.  3.  8.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [6. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10. 10.  8.  9.  9. 10. 10.] 
adversary cards in hand: [6. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  0.  0.] 
cards in discard: [29.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [6. 3. 8.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[275.508  ]
 [266.49533]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5    0    2  -10    0    0    0  -90    0    0    0    0    0 -600
   47    0] 
sum of rewards: -656 

action type: discard_down_to_3_cards - action 1
Learning step: -37.76240158081055
desired expected reward: 182.84304809570312



action possibilites: [-1] 
expected returns: [[290.14432]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.7587785720825195
desired expected reward: 254.9817352294922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[281.68164]
 [281.68164]
 [291.47787]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  8. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -4 

action type: take_action - action -1
Learning step: -8.294429779052734
desired expected reward: 281.8498840332031



buy possibilites: [-1] 
expected returns: [[260.91525]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 8.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5    0    0  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -315 

action type: buy - action 6.0
Learning step: -23.963489532470703
desired expected reward: 257.7181396484375






Player: 1 
cards in hand: [3. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 8.] 
cards in discard: [29. 14.  3. 14.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 14  8  3  3  8  1  3  8  0 14  0 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 8. 3. 0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[266.35464]
 [257.34195]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -7.916123390197754
desired expected reward: 252.99913024902344



action possibilites: [-1] 
expected returns: [[248.8443]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: trash_cards_n_from_hand - action 0
Learning step: -6.985158443450928
desired expected reward: 249.6979522705078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[242.31857]
 [242.31903]
 [242.31857]
 [243.07504]
 [251.773  ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: -6.692418575286865
desired expected reward: 242.15188598632812



buy possibilites: [-1] 
expected returns: [[300.36334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 8. 0. 1.] 
adversary cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -25.0 

action type: buy - action 0.0
Learning step: -6.607753753662109
desired expected reward: 235.7108154296875






Player: 1 
cards in hand: [8. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 0. 1.] 
cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 14  8  8  1  3  8  0 14  0 29  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 23.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 23.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 23.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [29. 14.  3. 14.  0.  0.  0.  8.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 6.  3.  0. 23.  0.] 
adversary cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[209.7528]
 [201.882 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 23.  0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -11.187540054321289
desired expected reward: 289.1758117675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[203.74278]
 [203.74327]
 [203.74278]
 [204.52634]
 [213.53902]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 23.  0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  5. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -6.490400791168213
desired expected reward: 200.98886108398438



buy possibilites: [-1] 
expected returns: [[288.98996]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  0. 23.  0.] 
cards in discard: [ 0.  0.  3. 10.  0.  0. 11.  0.  6.  8.  6.  0.  8.  0.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  4. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -7 

action type: buy - action 8.0
Learning step: -3.559201955795288
desired expected reward: 190.67030334472656






Player: 1 
cards in hand: [ 0.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  4. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
adversary victory points: 0
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  4. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
adversary victory points: 0
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  4. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
adversary victory points: 0
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.] 
cards in discard: [8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 23.  0.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
adversary victory points: 0
player victory points: 1 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 8. 23.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
expected returns: [[193.21695]
 [184.25287]
 [185.41447]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 23.  0.  0.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  6  3 23  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: buy - action -1
Learning step: -11.00075626373291
desired expected reward: 277.98919677734375



action possibilites: [-1] 
expected returns: [[221.41322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: trash_cards_n_from_hand - action 10
Learning step: -3.341978073120117
desired expected reward: 179.13352966308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[211.52644]
 [211.52644]
 [221.27806]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action -1
Learning step: -5.436707973480225
desired expected reward: 215.9765167236328



buy possibilites: [-1] 
expected returns: [[217.84631]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0. 14.  3.  0.] 
adversary cards in discard: [ 8.  8. 29.  0.  0.] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[ -5   0   1   0   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action 0.0
Learning step: -6.374781131744385
desired expected reward: 205.15167236328125






Player: 1 
cards in hand: [ 0.  0. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8.  8. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8.  8. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.  3.  0.] 
cards in discard: [ 8.  8. 29.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8  0] -> size -> 19 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[253.12431]
 [244.16026]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11  3  0  8 10  0  3  6  8  3  0  6  0  8  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1
Learning step: -5.521005153656006
desired expected reward: 212.32530212402344



action possibilites: [-1] 
expected returns: [[230.38683]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: trash_cards_n_from_hand - action 2
Learning step: -5.477262020111084
desired expected reward: 234.74205017089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[221.30428]
 [221.30774]
 [221.30428]
 [222.09184]
 [231.05592]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1
Learning step: -5.140822887420654
desired expected reward: 225.24600219726562



buy possibilites: [-1] 
expected returns: [[259.32883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -5.380316257476807
desired expected reward: 215.92398071289062






Player: 1 
cards in hand: [ 8. 14.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8. 14.] 
cards in discard: [0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  6. 10.  0.] 
adversary cards in discard: [0. 8. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[280.50806]
 [271.52756]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 10.  0.] 
cards in discard: [0. 8. 0. 8. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0.  8. 14.  8. 14.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -6.420953273773193
desired expected reward: 252.90786743164062



action possibilites: [-1.] 
expected returns: [[277.67654]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [0. 8. 0. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0.  8. 14.  8. 14.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 10.0
Learning step: -5.943258762359619
desired expected reward: 264.8763427734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[267.25894]
 [267.25934]
 [267.2624 ]
 [267.25894]
 [268.9494 ]
 [268.04648]
 [268.03006]
 [277.01056]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 3.] 
cards in discard: [0. 8. 0. 8. 0. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  8. 29.  0.  0.] 
adversary cards in discard: [ 0.  8. 14.  8. 14.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -6.482086181640625
desired expected reward: 271.1944580078125






Player: 1 
cards in hand: [ 0.  8. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [ 0.  8. 14.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [ 0.  8. 14.  8. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 23. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 29.  0.  0.] 
cards in discard: [ 0.  8. 14.  8. 14.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 22. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  3.] 
adversary cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3.] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[234.27083]
 [226.49223]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  3.] 
cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 30.  8.  7. 10.  9.  3. 10.  9.  8.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -8.831233024597168
desired expected reward: 268.1793212890625



action possibilites: [-1] 
expected returns: [[183.25816]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 22. 30.  8.  7. 10.  9.  3. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 33 

action type: gain_card_n - action 8
Learning step: -5.020767688751221
desired expected reward: 210.8607635498047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[177.58624]
 [177.59111]
 [177.58624]
 [178.31793]
 [186.59654]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 29. 30. 22. 30.  8.  7. 10.  9.  3. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -4.271759033203125
desired expected reward: 178.9864044189453



buy possibilites: [-1] 
expected returns: [[278.47183]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3.] 
cards in discard: [ 0.  8.  0.  8.  0.  0. 10.  0.  0.  6.  0.  3. 14.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  3. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 36 

action type: buy - action 3.0
Learning step: -0.8139389157295227
desired expected reward: 176.77716064453125






Player: 1 
cards in hand: [29.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  3. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  3. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  6. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[207.64778]
 [198.76309]
 [198.77182]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6. 10.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  8.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1
Learning step: -9.023602485656738
desired expected reward: 269.4482421875



action possibilites: [-1.  8.] 
expected returns: [[173.98093]
 [165.10498]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0 11  3  0  8 10  0  3  8  3  0  6  0  8  0  0 14  3] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  8.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 10.0
Learning step: -4.633054256439209
desired expected reward: 192.34243774414062



action possibilites: [-1.] 
expected returns: [[228.1983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  8.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: trash_cards_n_from_hand - action 9
Learning step: -0.6181297302246094
desired expected reward: 162.43370056152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[218.43903]
 [218.43903]
 [228.09903]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3] -> size -> 17 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  8.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -4.021130561828613
desired expected reward: 224.1771697998047



buy possibilites: [-1] 
expected returns: [[202.02737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [14.  8.  3.  0.  8.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   3  10   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 18 

action type: buy - action 0.0
Learning step: -5.476335525512695
desired expected reward: 212.9626922607422






Player: 1 
cards in hand: [14.  8.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  8.] 
cards in discard: [ 8. 29.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 14  8  3  8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 29.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 29.  3.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 29.  3.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  3.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[207.04077]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -4.5668439865112305
desired expected reward: 197.4605255126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[199.59673]
 [199.59839]
 [199.60191]
 [199.59673]
 [199.99132]
 [201.28342]
 [200.3808 ]
 [203.47508]
 [201.02658]
 [200.37202]
 [201.93799]
 [209.25671]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 29. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.8669328689575195
desired expected reward: 201.11195373535156



buy possibilites: [-1] 
expected returns: [[201.97054]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 0. 10.  8.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 8. 14.  0.  0.  0.] 
adversary cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 22.5 

action type: buy - action 1.0
Learning step: -4.310582637786865
desired expected reward: 195.28781127929688






Player: 1 
cards in hand: [ 8. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  0.  0.] 
cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0 14  0 29  0  0  8  0  0  3  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [11. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [11. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [11. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8. 29.  3.  0.  0.  0.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [15. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [11. 14.  0.  0.  0.] 
adversary cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [11. 14.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[228.58008]
 [220.60678]
 [220.34991]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 14.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -4.20846700668335
desired expected reward: 197.76206970214844



action possibilites: [-1] 
expected returns: [[260.18576]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action 14.0
Learning step: -3.190676212310791
desired expected reward: 215.70643615722656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[250.73853]
 [250.74023]
 [250.74376]
 [250.73853]
 [250.73853]
 [251.13316]
 [252.42526]
 [251.52258]
 [253.96236]
 [254.61691]
 [252.1684 ]
 [252.69035]
 [251.51384]
 [251.77895]
 [253.07982]
 [260.39856]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 28. 30. 21. 30.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1
Learning step: -5.427656650543213
desired expected reward: 254.7581024169922



buy possibilites: [-1] 
expected returns: [[209.37431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [ 0. 10.  8.  3.  1.  3.  0.  0.  0.  0.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0 50  0] 
sum of rewards: 121 

action type: buy - action 4.0
Learning step: -1.749671220779419
desired expected reward: 248.98887634277344






Player: 1 
cards in hand: [0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  2. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [0. 0. 8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  1. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[172.21619]
 [163.39305]
 [163.39305]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  1. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [0. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -4.16804838180542
desired expected reward: 205.20626831054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[163.11055]
 [163.11725]
 [163.11055]
 [163.87608]
 [172.57913]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  1. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [0. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: take_action - action -1.0
Learning step: -2.357156753540039
desired expected reward: 170.14097595214844



buy possibilites: [-1] 
expected returns: [[189.5412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 8. 8.] 
cards in discard: [8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 8. 8. 8. 0.] 
adversary cards in discard: [0. 0. 8. 0. 3. 0.] 
adversary owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0  8] -> size -> 14 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 59 

action type: buy - action 8.0
Learning step: -0.9791267514228821
desired expected reward: 162.89695739746094






Player: 1 
cards in hand: [0. 8. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 8. 0.] 
cards in discard: [0. 0. 8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  0  0 29  0  0  8  0  0  3  8  0  0  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
adversary victory points: 6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
adversary victory points: 6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 0. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
adversary victory points: 6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 0. 8. 0. 3. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 8. 0.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8.] 
adversary owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
adversary victory points: 6
player victory points: 1 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[197.16078]
 [188.27173]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 0.] 
cards in discard: [8. 0. 0. 3. 8. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11  0  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 51 

action type: buy - action -1
Learning step: -2.6041336059570312
desired expected reward: 186.93707275390625



action possibilites: [-1] 
expected returns: [[164.40184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 3. 8. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: trash_cards_n_from_hand - action 2
Learning step: -1.9256584644317627
desired expected reward: 181.56834411621094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.5484]
 [155.5484]
 [165.2304]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 3. 8. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 28. 30. 21. 29.  8.  7. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 6 

Reward from previous game state: 
[-5  0  6 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 71 

action type: take_action - action -1
Learning step: -1.0961769819259644
desired expected reward: 163.3056640625



buy possibilites: [-1] 
expected returns: [[159.47725]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0. 0. 3. 8. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 21. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   40.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -240.0 

action type: buy - action 6.0
Learning step: -16.18918228149414
desired expected reward: 139.35922241210938






Player: 1 
cards in hand: [ 0.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 21. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8. 6. 8. 0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 28. 30. 21. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8. 6. 8. 0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 21. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8. 6. 8. 0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [0. 3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [ 3.  4.  1.  0. 11.] 
adversary cards in discard: [8. 0. 0. 3. 8. 8. 6. 8. 0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3.  4.  1.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[132.71669]
 [125.40985]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  4.  1.  0. 11.] 
cards in discard: [8. 0. 0. 3. 8. 8. 6. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -3.5949292182922363
desired expected reward: 155.88232421875



action possibilites: [-1] 
expected returns: [[190.88756]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 4. 1. 0.] 
cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 59 

action type: gain_card_n - action 8
Learning step: 1.0724514722824097
desired expected reward: 124.52283477783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[184.21036]
 [184.213  ]
 [184.2173 ]
 [184.21036]
 [185.91444]
 [184.99965]
 [193.89235]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 4. 1. 0.] 
cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
adversary owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0  3] -> size -> 13 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: -2.8586814403533936
desired expected reward: 188.02886962890625






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 29  0  0  0  0  3  8  0  0  8  0  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10. 11.  3.  4.  1.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  0  3  8  0  0  8  0  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10. 11.  3.  4.  1.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 29.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  0  3  8  0  0  8  0  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 28. 30. 20. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10. 11.  3.  4.  1.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  3. 29.  3.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 14.  3.  0. 10.] 
adversary cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10. 11.  3.  4.  1.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0. 14.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
expected returns: [[197.53484]
 [189.02612]
 [188.3492 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 10.] 
cards in discard: [ 8.  0.  0.  3.  8.  8.  6.  8.  0. 10. 11.  3.  4.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -4.3903303146362305
desired expected reward: 189.5020294189453



action possibilites: [-1. 14. 11.] 
expected returns: [[150.95027]
 [142.71309]
 [142.97234]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10] -> size -> 20 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  9.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action 10.0
Learning step: -4.12175178527832
desired expected reward: 183.83309936523438



action possibilites: [-1. 14.] 
expected returns: [[156.60335]
 [148.64264]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  3.  0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8.  0.  0. 29.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 69 

action type: gain_card_n - action 5
Learning step: -0.1545265167951584
desired expected reward: 141.53546142578125



action possibilites: [-1] 
expected returns: [[172.50394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action 14.0
Learning step: 0.44920656085014343
desired expected reward: 149.0918426513672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[163.92253]
 [163.92514]
 [163.92923]
 [163.92253]
 [164.29832]
 [165.50966]
 [167.54636]
 [165.26735]
 [164.65878]
 [166.11821]
 [172.92499]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 11. 14.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [ 8. 29.] 
adversary owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 80 

action type: take_action - action -1
Learning step: -0.8966827392578125
desired expected reward: 171.6072540283203






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [ 8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  0  0  3  8  0  0  8  0  3  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 1. 4.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  3  8  0  0  8  0  3  3] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 1. 4.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  3  8  0  0  8  0  3  3] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 1. 4.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 29.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 3. 0. 1. 4.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
adversary victory points: 5
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [8. 3. 0. 1. 4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[119.80492]
 [111.25329]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 1. 4.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  8.] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: buy - action -1.0
Learning step: -5.058642864227295
desired expected reward: 167.86636352539062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[109.33588 ]
 [109.33854 ]
 [109.34261 ]
 [109.33588 ]
 [110.935165]
 [110.07739 ]
 [118.60528 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 1. 4.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 28. 30. 19. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  8.] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[-5  0  5 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -2.46258544921875
desired expected reward: 116.77168273925781



buy possibilites: [-1] 
expected returns: [[124.00014]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 1. 4.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 28. 30. 18. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [ 8. 29.  0.  8.] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5.  0.  6. 30.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 33.0 

action type: buy - action 3.0
Learning step: -1.0271275043487549
desired expected reward: 108.31548309326172






Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 8. 29.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.  8.  3.  0.  1.  4.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3] -> size -> 22 
adversary victory points: 6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [ 8. 29.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 18. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [3. 6. 8. 0. 0.] 
adversary cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.  8.  3.  0.  1.  4.] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3] -> size -> 22 
adversary victory points: 6
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [3. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[188.7135 ]
 [180.67236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.  8.  3.  0.  1.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: buy - action -1
Learning step: -0.5093799829483032
desired expected reward: 123.49076080322266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[179.45537]
 [179.4619 ]
 [179.45537]
 [188.21796]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.  8.  3.  0.  1.  4.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 28. 30. 18. 29.  8.  6. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 6 

Reward from previous game state: 
[-5  0  6 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 31 

action type: take_action - action -1.0
Learning step: -3.7618396282196045
desired expected reward: 184.2461395263672



buy possibilites: [-1] 
expected returns: [[176.99019]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 0. 0.] 
cards in discard: [11. 10. 11. 14.  0.  3.  0.  3.  8.  3.  0.  1.  4.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
adversary victory points: 3
player victory points: 5 

Reward from previous game state: 
[  -5.    0.    5.   20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -280.0 

action type: buy - action 6.0
Learning step: -18.99049186706543
desired expected reward: 160.4648895263672






Player: 1 
cards in hand: [8. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [29  0  3  8  0  0  8  0  3  3  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  8  0  3  3  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  8  0  3  3  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 6. 10.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8.] 
expected returns: [[128.60101]
 [120.04851]
 [120.05396]
 [120.05396]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -4.589876174926758
desired expected reward: 172.4003143310547



action possibilites: [-1.  8.  8. 14.] 
expected returns: [[121.06303]
 [112.80187]
 [112.80187]
 [113.40539]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  8 10  0  3  8  3  0  0  8  0  0 14  3  0  1  4  8  6 10 11  3  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action 10.0
Learning step: -0.9329776763916016
desired expected reward: 119.51205444335938



action possibilites: [-1.] 
expected returns: [[181.8758]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: trash_cards_n_from_hand - action 13
Learning step: 1.9785298109054565
desired expected reward: 114.2520523071289





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[170.8352 ]
 [170.8352 ]
 [180.48474]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [12. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: -1.6761703491210938
desired expected reward: 180.19961547851562



buy possibilites: [-1] 
expected returns: [[179.99274]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3.  8.  0.] 
adversary cards in discard: [0. 8. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  30   0   0  40 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 40 

action type: buy - action 0.0
Learning step: -2.4919240474700928
desired expected reward: 168.34327697753906






Player: 1 
cards in hand: [ 3. 29.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  8.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  8.  0.] 
cards in discard: [0. 8. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  8.  0.] 
cards in discard: [0. 8. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 4. 8.] 
adversary cards in discard: [ 0. 10.  8.  6.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 4. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[148.13614]
 [139.40916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 4. 8.] 
cards in discard: [ 0. 10.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -4.285822868347168
desired expected reward: 175.7069091796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[138.04478]
 [138.05171]
 [138.04478]
 [147.6249 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 8.] 
cards in discard: [ 0. 10.  8.  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -2.692125082015991
desired expected reward: 144.38157653808594



buy possibilites: [-1] 
expected returns: [[167.96736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 4. 8.] 
cards in discard: [ 0. 10.  8.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 0.0 

action type: buy - action 0.0
Learning step: -3.0814666748046875
desired expected reward: 134.1331787109375






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  1.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  3.  3.  1.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  3.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[198.77254]
 [190.90309]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3.  3.  1.] 
cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -2.5458905696868896
desired expected reward: 165.42147827148438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[191.52704]
 [191.53053]
 [191.5346 ]
 [191.52704]
 [193.22353]
 [192.31792]
 [201.09299]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  3.  3.  1.] 
cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  8.] 
adversary cards in discard: [8. 0. 0. 0. 0.] 
adversary owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -4.017019271850586
desired expected reward: 193.32159423828125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 29.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  8.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  0  8  0  3  3  0  0  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 3 0 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 3 0 0 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [8. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 3 0 0 0 0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  0.  6.] 
adversary cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
adversary owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[160.11534]
 [151.66048]
 [152.50009]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  0.  6.] 
cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [11 10  3  8  3  0  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 0 0 0 0] -> size -> 8 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -4.587173938751221
desired expected reward: 196.50579833984375



action possibilites: [-1] 
expected returns: [[209.47899]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 0 0 0 0] -> size -> 8 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.3014030456542969
desired expected reward: 148.5388946533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[204.38454]
 [204.38454]
 [214.26698]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [ 0. 10.  8.  6.  0.  0.  3.  0.  4.  8.  0. 11.  3.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 3 0 0 0 0] -> size -> 8 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1
Learning step: -2.7996881008148193
desired expected reward: 206.67930603027344






Player: 1 
cards in hand: [0. 0. 8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 3 0 0 0 0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [10.  8.  1.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 0 0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [10.  8.  1.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 0 0] -> size -> 7 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 28. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [10.  8.  1.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [10.  8.  1.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [10.  8.  1.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[141.59758]
 [132.82253]
 [132.83118]
 [132.82253]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  1.  3. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [10  3  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -5.141930103302002
desired expected reward: 209.1250457763672



action possibilites: [-1] 
expected returns: [[152.26553]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.20191116631031036
desired expected reward: 131.35580444335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[141.17067]
 [141.17842]
 [141.17067]
 [151.0531 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 27. 30. 18. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: -1.4296276569366455
desired expected reward: 150.83590698242188



buy possibilites: [-1] 
expected returns: [[167.07256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1. 10.] 
cards in discard: [3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 78 

action type: buy - action 3.0
Learning step: 0.6002113223075867
desired expected reward: 141.77862548828125






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [11.  4.  6.  3.  3.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 0 0 1] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  8. 10. 10.] 
adversary cards in hand: [11.  4.  6.  3.  3.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [11.  4.  6.  3.  3.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [11.  4.  6.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[113.048416]
 [105.707   ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  4.  6.  3.  3.] 
cards in discard: [ 3.  8. 10.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: -3.3840606212615967
desired expected reward: 163.68849182128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[105.429245]
 [105.429245]
 [114.36012 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  6.  3.  3.] 
cards in discard: [ 3.  8. 10.  1. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 8. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -0.7291297912597656
desired expected reward: 112.6632080078125



buy possibilites: [-1] 
expected returns: [[139.05556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  4.  6.  3.  3.] 
cards in discard: [ 3.  8. 10.  1. 10.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  50   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 20 

action type: buy - action 0.0
Learning step: -1.1427124738693237
desired expected reward: 104.28652954101562






Player: 1 
cards in hand: [0. 0. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  8.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 8.] 
cards in discard: [11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
adversary victory points: 5
player victory points: 0 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[122.46469]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: -1.7295864820480347
desired expected reward: 137.3259735107422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[117.19978 ]
 [117.202995]
 [117.20719 ]
 [117.19978 ]
 [117.19978 ]
 [117.572624]
 [118.81206 ]
 [120.2544  ]
 [120.86872 ]
 [118.56631 ]
 [119.03412 ]
 [117.951996]
 [118.174065]
 [119.42638 ]
 [126.304016]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 7. 27. 30. 17. 29.  8.  5. 10.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -0.8671470880508423
desired expected reward: 119.9986801147461



buy possibilites: [-1] 
expected returns: [[150.42668]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 17. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5. 50.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  8.  0.] 
sum of rewards: 58.0 

action type: buy - action 16.0
Learning step: 0.4059692323207855
desired expected reward: 117.97858428955078






Player: 1 
cards in hand: [ 0. 10.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 17. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 27. 30. 17. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0.  8.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [6. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.  0.  0.  0.  0.  0.] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [6. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[142.90536]
 [134.29959]
 [134.29959]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 8. 3. 0.] 
cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: -2.483496904373169
desired expected reward: 147.9431915283203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[131.45824]
 [131.45824]
 [140.85628]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 8. 3. 0.] 
cards in discard: [ 3.  8. 10.  1. 10.  0. 11.  4.  6.  3.  3. 16.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [11.  0.  0.  1.  8.] 
adversary cards in discard: [ 3.  0. 10.  0.  0.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3] -> size -> 11 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -2.005009412765503
desired expected reward: 138.689453125



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  0.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  8.] 
cards in discard: [ 3.  0. 10.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  7.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 3.  0. 10.  0.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 3.  0. 10.  0.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  7. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 3.  0. 10.  0.  0.  8. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [0. 3. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
adversary victory points: 5
player victory points: 1 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[171.85466]
 [163.24889]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  3  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: -1.2958240509033203
desired expected reward: 139.5604705810547



action possibilites: [-1] 
expected returns: [[165.59157]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.8622734546661377
desired expected reward: 158.89939880371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[157.66261]
 [157.6703 ]
 [157.66261]
 [167.06065]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 16. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1
Learning step: -2.2276675701141357
desired expected reward: 163.36390686035156



buy possibilites: [-1] 
expected returns: [[176.7116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [11.  8.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 68 

action type: buy - action 3.0
Learning step: -0.5075035095214844
desired expected reward: 157.16278076171875






Player: 1 
cards in hand: [11.  8.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 15. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 27. 30. 15. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3] -> size -> 22 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0.  3.  0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 14. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10. 11.  1.  0.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3] -> size -> 22 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 11.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[147.27528]
 [138.93405]
 [139.79579]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 11.  1.  0.] 
cards in discard: [3. 8. 0. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 14. 29.  8.  5.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -4.164508819580078
desired expected reward: 172.54708862304688



action possibilites: [-1] 
expected returns: [[137.52718]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [3. 8. 0. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   20    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -261 

action type: gain_card_n - action 3
Learning step: -16.809412002563477
desired expected reward: 120.26604461669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[129.71774]
 [129.72107]
 [129.72542]
 [129.71774]
 [130.10426]
 [131.38719]
 [133.51796]
 [131.13297]
 [130.49661]
 [132.02353]
 [139.11578]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [3. 8. 0. 3. 0. 6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 7. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1
Learning step: -1.9655609130859375
desired expected reward: 135.56161499023438



buy possibilites: [-1] 
expected returns: [[155.2162]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.] 
cards in discard: [3. 8. 0. 3. 0. 6. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 6. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 10.  1.  0.  0.] 
adversary cards in discard: [ 3. 11.  8.  0.  3.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 9.0 

action type: buy - action 0.0
Learning step: -2.5435218811035156
desired expected reward: 127.17420959472656






Player: 1 
cards in hand: [ 0. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  1.  0.  0.] 
cards in discard: [ 3. 11.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 16.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.  0.] 
cards in discard: [ 3. 11.  8.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 6. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  7.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 16.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  1.  0.  0.] 
cards in discard: [ 3. 11.  8.  0.  3.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  8.  0.  3. 16.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.] 
adversary owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0] -> size -> 24 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[144.18608]
 [135.29796]
 [134.87854]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  3. 16.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  0  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 14. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1
Learning step: -3.7412478923797607
desired expected reward: 151.47496032714844



action possibilites: [-1] 
expected returns: [[144.58061]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 54 

action type: gain_card_n - action 1
Learning step: -2.2198803424835205
desired expected reward: 161.23899841308594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[135.08545]
 [135.08545]
 [144.63863]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1
Learning step: -1.6165176630020142
desired expected reward: 142.96409606933594



buy possibilites: [-1] 
expected returns: [[135.51294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3.  3. 10. 11.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  30   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: 20 

action type: buy - action 0.0
Learning step: -2.705230712890625
desired expected reward: 132.3802032470703






Player: 1 
cards in hand: [ 3.  3. 10. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 11.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  4.  6.  8.  6.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.  8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 5. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  4.  6.  8.  6.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 11.  8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  4.  6.  8.  6.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
adversary victory points: 5
player victory points: 2 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [10.  4.  6.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[80.97733]
 [72.59562]
 [72.61353]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4.  6.  8.  6.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  1.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: buy - action -1
Learning step: -3.5779855251312256
desired expected reward: 131.93495178222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[72.658   ]
 [72.658   ]
 [81.834045]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  6.  8.  6.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  4.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  1.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
adversary victory points: 2
player victory points: 5 

Reward from previous game state: 
[-5  0  5 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 30 

action type: take_action - action -1.0
Learning step: -0.8438568115234375
desired expected reward: 80.13347625732422



buy possibilites: [-1] 
expected returns: [[147.3485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4.  6.  8.  6.] 
cards in discard: [ 3.  8.  0.  3.  0.  6.  0. 11.  0. 10.  1.  0.  3.  0. 16.  3.  8.  3.
  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 0. 11. 14.  0.  1.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[  -5    0    4   20    0    0    0    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -281 

action type: buy - action 6.0
Learning step: -14.367558479309082
desired expected reward: 58.29043960571289






Player: 1 
cards in hand: [ 0. 11. 14.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 14.  0.  1.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 29.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  1.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 27. 30. 13. 29.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  1.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 4. 27. 30. 13. 29.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  1.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.  4.] 
cards in deck: 5 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 13. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[138.35785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 13. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[   -5     0     4   -10     0     0     0   -60     0     0     0     0
     0 -1200    57     0] 
sum of rewards: -1214 

action type: discard_down_to_3_cards - action 3
Learning step: -64.72596740722656
desired expected reward: 77.3900146484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[130.21576]
 [130.21872]
 [130.22273]
 [130.21576]
 [131.85582]
 [130.97975]
 [139.46533]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 13. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -4.425014972686768
desired expected reward: 132.4564971923828



buy possibilites: [-1] 
expected returns: [[134.35988]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3. 6. 3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 12. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 8. 10.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 2.0 

action type: buy - action 3.0
Learning step: -3.3880393505096436
desired expected reward: 126.8346939086914






Player: 1 
cards in hand: [ 8. 10.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 12. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [3. 6. 3. 0. 0. 0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 12. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [3. 6. 3. 0. 0. 0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  0.  0.  0.] 
cards in discard: [ 0.  3.  3. 10. 11.  8.  4. 14.  0. 11.  0.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [3. 6. 3. 0. 0. 0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[114.484436]
 [106.01769 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [3. 6. 3. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -4.778608322143555
desired expected reward: 129.58126831054688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[105.77378]
 [105.78076]
 [105.77378]
 [115.02337]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [3. 6. 3. 0. 0. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -3.6968491077423096
desired expected reward: 108.91108703613281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  6.  3. 10.] 
adversary cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  6.  6.  3. 10.] 
adversary cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
adversary victory points: 5
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[110.70309]
 [102.21751]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 10.] 
cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -3.8922436237335205
desired expected reward: 111.1311264038086



action possibilites: [-1. 16.] 
expected returns: [[124.18935 ]
 [115.024055]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action 10.0
Learning step: -1.8355945348739624
desired expected reward: 98.72005462646484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[112.18746 ]
 [112.18746 ]
 [121.740654]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  3.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -3.112159013748169
desired expected reward: 121.07718658447266



buy possibilites: [-1] 
expected returns: [[132.25662]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6.  3. 16.] 
cards in discard: [3. 6. 3. 0. 0. 0. 0. 0. 3. 3. 8. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [ 4.  8.  3.  0. 11.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -301.0 

action type: buy - action 6.0
Learning step: -17.480384826660156
desired expected reward: 90.64280700683594






Player: 1 
cards in hand: [ 4.  8.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  8.  3.  0. 11.] 
cards in discard: [ 3. 10.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  8.  6. 11.] 
adversary cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3  6] -> size -> 28 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 4.  8.  3.  0. 11.] 
cards in discard: [ 3. 10.  8.  0. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  8.  6. 11.] 
adversary cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3  6] -> size -> 28 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11.] 
expected returns: [[112.17778]
 [103.84   ]
 [103.86493]
 [104.69968]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  6. 11.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8  6 10 11  3  6  0  0  3  0 16  3  6  0  3
  0  6  3  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -5.273190498352051
desired expected reward: 126.98342895507812



action possibilites: [-1] 
expected returns: [[165.37563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.6306164264678955
desired expected reward: 115.40074157714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[155.02284]
 [155.02284]
 [164.40437]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 11.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1
Learning step: -4.208990573883057
desired expected reward: 161.16664123535156






Player: 1 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [8. 4. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [8. 4. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [ 3. 10.  8.  0. 14.  4.  8.  3.  0. 11.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [8. 4. 1. 0. 3.] 
adversary cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [8. 4. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[149.22523]
 [141.19804]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 4. 1. 0. 3.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1.0
Learning step: -5.4520487785339355
desired expected reward: 158.95233154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[141.09448]
 [141.09703]
 [141.09923]
 [141.09448]
 [142.64546]
 [141.81502]
 [149.86624]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 1. 0. 3.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  6. 10. 10.] 
adversary cards in hand: [10.  3.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -4.7494893074035645
desired expected reward: 144.4757537841797



buy possibilites: [-1] 
expected returns: [[187.1924]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 4. 1. 0. 3.] 
cards in discard: [ 3.  6.  3.  0.  0.  0.  0.  0.  3.  3.  8.  6. 10.  0.  6.  6.  3. 16.
  8. 10.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  5. 10. 10.] 
adversary cards in hand: [10.  3.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0] -> size -> 19 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 8 

action type: buy - action 10.0
Learning step: -2.4789211750030518
desired expected reward: 139.33607482910156






Player: 1 
cards in hand: [10.  3.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  5. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
adversary victory points: 5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  1.] 
cards in discard: [10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[72.23746]
 [64.16697]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -8.376832962036133
desired expected reward: 178.81556701660156



action possibilites: [-1.] 
expected returns: [[88.41397]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: 11 

action type: take_action - action 10.0
Learning step: -0.5519758462905884
desired expected reward: 61.273826599121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[80.35692 ]
 [80.359344]
 [80.36151 ]
 [80.35692 ]
 [81.85743 ]
 [81.05418 ]
 [88.845314]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 27. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 10 

action type: take_action - action -1.0
Learning step: -2.076721668243408
desired expected reward: 86.33724975585938



buy possibilites: [-1] 
expected returns: [[106.06152]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 6. 0.] 
cards in discard: [1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 10.  0.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 28 

action type: buy - action 1.0
Learning step: -0.23158226907253265
desired expected reward: 80.12775421142578






Player: 1 
cards in hand: [ 0.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11. 10.  0.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 1. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [3. 3. 8. 8. 0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
adversary victory points: 5
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [3. 3. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[123.740814]
 [115.42796 ]
 [115.42796 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  8.  4.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: buy - action -1
Learning step: -3.161912679672241
desired expected reward: 102.89961242675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[114.23181]
 [114.23181]
 [123.31546]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 1. 26. 30. 11. 28.  8.  2.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  8.  4.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1.0
Learning step: -4.003846645355225
desired expected reward: 118.86735534667969



buy possibilites: [-1] 
expected returns: [[114.645744]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 8. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 3. 14.  0.  8.  4.] 
adversary cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -321.0 

action type: buy - action 6.0
Learning step: -19.18206214904785
desired expected reward: 95.04975128173828






Player: 1 
cards in hand: [ 3. 14.  0.  8.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  8.  4.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [ 1.  3. 11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 4.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 4.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  4. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 4.] 
cards in discard: [10.  0. 11. 10.  3.  0.  1.  0.  0.  0. 11. 10.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  3. 10. 10.] 
adversary cards in hand: [11.  0.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[84.30902]
 [77.22725]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  3. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[   -5     0     4   -20     0     0     0     0     0     0     0     0
     0 -1500    41     0] 
sum of rewards: -1480 

action type: discard_down_to_3_cards - action 5
Learning step: -79.0143051147461
desired expected reward: 57.633506774902344



action possibilites: [-1] 
expected returns: [[130.37897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: 8 

action type: gain_card_n - action 8
Learning step: -0.48849257826805115
desired expected reward: 75.95188903808594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[118.63772 ]
 [118.641235]
 [118.63772 ]
 [127.83485 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -3.846285343170166
desired expected reward: 126.53268432617188



buy possibilites: [-1] 
expected returns: [[127.130615]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -31.0 

action type: buy - action 0.0
Learning step: -4.6214470863342285
desired expected reward: 114.01626586914062






Player: 1 
cards in hand: [11.  0.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [16.  3.  0.  4.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [16.  3.  0.  4.  0.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0.] 
adversary owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10  0] -> size -> 32 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [16.  3.  0.  4.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[113.560104]
 [104.73139 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  4.  0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  3  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0
  6  3  6 10  1  6 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  6.  9.  2. 10. 10.] 
adversary cards in hand: [4. 0. 0. 3. 8.] 
adversary cards in discard: [11.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -4.949752330780029
desired expected reward: 122.18086242675781



action possibilites: [-1] 
expected returns: [[132.11856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 4. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [4. 0. 0. 3. 8.] 
adversary cards in discard: [11.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 4 

action type: gain_card_n - action 6
Learning step: -2.8161368370056152
desired expected reward: 116.95995330810547





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[120.15378]
 [120.15027]
 [129.3474 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 11. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [4. 0. 0. 3. 8.] 
adversary cards in discard: [11.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1
Learning step: -4.432155132293701
desired expected reward: 127.68640899658203



buy possibilites: [-1] 
expected returns: [[105.37391]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 4. 0.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [4. 0. 0. 3. 8.] 
adversary cards in discard: [11.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   8   0] 
sum of rewards: 7 

action type: buy - action 3.0
Learning step: -3.286776304244995
desired expected reward: 116.86701202392578






Player: 1 
cards in hand: [4. 0. 0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 0. 0. 3. 8.] 
cards in discard: [11.  0.  0.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  8. 10.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3. 16.  0.  4.  0.] 
adversary owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14  3] -> size -> 33 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 0. 0. 3. 8.] 
cards in discard: [11.  0.  0.  3.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 3. 10.  6.  8. 10.] 
adversary cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3. 16.  0.  4.  0.] 
adversary owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14  3] -> size -> 33 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  6.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10.] 
expected returns: [[120.67441 ]
 [112.231155]
 [112.25993 ]
 [112.231155]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  6.  8. 10.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3. 16.  0.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [10  8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6
  3  6 10  1  6 10  0 14  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [10.  0.  1. 14.  0.] 
adversary cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -3.744408130645752
desired expected reward: 101.62950134277344



action possibilites: [-1] 
expected returns: [[116.73543]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3. 16.  0.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [10.  0.  1. 14.  0.] 
adversary cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 2
Learning step: -2.8981258869171143
desired expected reward: 106.5953369140625





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[108.178085]
 [116.49231 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 10.] 
cards in discard: [ 1. 10.  3.  0.  0.  6.  0.  6.  3.  3.  8.  8.  0.  1.  3. 10.  0. 11.
  0.  0. 14.  3. 16.  0.  4.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [10.  0.  1. 14.  0.] 
adversary cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -3.358288526535034
desired expected reward: 113.37713623046875






Player: 1 
cards in hand: [10.  0.  1. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1. 14.  0.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0. 10.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1. 14.  0.  3.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0. 10.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10. 14.] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [8. 6. 6.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [8. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[75.32821 ]
 [67.701515]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0. 10.] 
adversary cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8. 25. 10. 10. 14.  0.  1.  0.  3.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[   -5     0     4   -20     0     0     0     0     0     0     0     0
     0 -1500    41     0] 
sum of rewards: -1480 

action type: discard_down_to_3_cards - action 3
Learning step: -79.01270294189453
desired expected reward: 52.734886169433594





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[65.68987 ]
 [73.925896]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 6.] 
cards in discard: [6. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [11. 10.  0.  0. 10.] 
adversary cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8. 25. 10. 10. 14.  0.  1.  0.  3.] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -3.1647799015045166
desired expected reward: 70.56300354003906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0. 10.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8. 25. 10. 10. 14.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4.  6. 10.  0.  0.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  0. 10.] 
cards in discard: [11.  0.  0.  3.  8.  4.  0.  0.  3.  8. 25. 10. 10. 14.  0.  1.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4.  6. 10.  0.  0.] 
adversary cards in discard: [6. 0. 8. 6. 6.] 
adversary owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 4.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[80.74131]
 [73.44964]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 4.  6. 10.  0.  0.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -3.010821580886841
desired expected reward: 70.91507720947266



action possibilites: [-1.] 
expected returns: [[54.038216]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [4. 6. 0. 0. 3.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action 10.0
Learning step: -2.506622076034546
desired expected reward: 70.9430160522461





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[49.761642]
 [49.75946 ]
 [55.58069 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [4. 6. 0. 0. 3.] 
cards in discard: [6. 0. 8. 6. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 26. 30. 10. 28.  8.  1.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1.0
Learning step: -1.5877693891525269
desired expected reward: 52.45044708251953



Player 1 won the game! 



Player 0 bought cards:
Copper: 13 
Silver: 2 
Gold: 0 
Estate: 9 
Duchy: 1 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 1 
Chapel: 4 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 1 
Village: 2 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [4. 6. 0. 0. 3.] 
cards in discard: [6. 0. 8. 6. 6. 6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 8  8  0  0  0  1  4  8 10 11  3  6  0  0  3  0 16  3  6  0  3  0  6  3
  6 10  1  6 10  0 14  3  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 26. 30. 10. 28.  8.  0.  9.  6.  0.  9.  9.  5.  9.  2. 10. 10.] 
adversary cards in hand: [ 4. 11.  8.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  0  0  0  0  1 10 11  3 11 10  3 14  0  4  3  0 10  0  0 10 25] -> size -> 24 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -30    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -812 

action type: buy - action 6.0
Learning step: -43.087974548339844
desired expected reward: 6.671485900878906



