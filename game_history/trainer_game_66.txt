 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[300.71716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    3  -80    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -582 

action type: buy - action -1.0
Learning step: -30.488584518432617
desired expected reward: -2.716939926147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[278.38428]
 [290.62558]
 [286.6297 ]
 [254.12627]
 [299.69226]
 [287.70377]
 [285.6148 ]
 [305.33032]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.687885284423828
desired expected reward: 295.5207214355469



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[321.1013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -8.64026165008545
desired expected reward: 296.69012451171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[292.23743]
 [303.44275]
 [299.23572]
 [270.56088]
 [297.87985]
 [312.2462 ]
 [300.93454]
 [302.5527 ]
 [281.2427 ]
 [298.21472]
 [292.78107]
 [318.65012]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [3. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.759608268737793
desired expected reward: 311.4073791503906



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [3. 0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[296.58936]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -9.823390007019043
desired expected reward: 308.82672119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[272.9508 ]
 [285.08063]
 [281.16742]
 [256.95517]
 [248.87898]
 [279.1402 ]
 [294.072  ]
 [282.1974 ]
 [303.71597]
 [284.21252]
 [261.08664]
 [269.36905]
 [280.14767]
 [255.98064]
 [274.56854]
 [299.39392]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.020149230957031
desired expected reward: 289.1628112792969



buy possibilites: [-1] 
expected returns: [[268.62784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    3.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -7.5 

action type: buy - action 11.0
Learning step: -9.034472465515137
desired expected reward: 285.0374755859375






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 0. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[306.25864]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1
Learning step: -7.1177287101745605
desired expected reward: 261.5101013183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[290.5897 ]
 [296.1262 ]
 [267.8774 ]
 [299.3528 ]
 [309.80014]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [1. 0. 0. 3. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -9.21156120300293
desired expected reward: 298.0624084472656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [1. 0. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[269.51123]
 [265.3316 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: buy - action -1.0
Learning step: -10.021086692810059
desired expected reward: 299.7790832519531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[254.16911]
 [264.09454]
 [259.09033]
 [231.7109 ]
 [269.98758]
 [262.23303]
 [258.28622]
 [274.44073]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -12 

action type: take_action - action -1.0
Learning step: -8.169466018676758
desired expected reward: 262.8277282714844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[288.0707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: buy - action -1.0
Learning step: -8.344950675964355
desired expected reward: 266.0958251953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[270.0669 ]
 [281.25345]
 [276.3992 ]
 [246.49916]
 [287.6504 ]
 [278.8374 ]
 [275.17694]
 [290.56982]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 28. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1.0
Learning step: -9.144775390625
desired expected reward: 278.7257995605469



buy possibilites: [-1] 
expected returns: [[285.70294]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 1. 3.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 3.0
Learning step: -7.841644287109375
desired expected reward: 268.55755615234375






Player: 1 
cards in hand: [0. 0. 0. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0 1 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 1. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[263.5526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -8.920843124389648
desired expected reward: 276.7821044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[236.16919]
 [248.04681]
 [243.65077]
 [212.20323]
 [242.2137 ]
 [256.0926 ]
 [245.33955]
 [247.16559]
 [223.9798 ]
 [242.61005]
 [237.13518]
 [260.6481 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11] -> size -> 15 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.076471328735352
desired expected reward: 254.781494140625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  3.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[296.96564]
 [294.0531 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -6.933204650878906
desired expected reward: 253.71493530273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[279.43027]
 [283.6095 ]
 [261.62936]
 [286.1516 ]
 [296.7873 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  3.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8] -> size -> 16 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.764806747436523
desired expected reward: 285.175537109375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 5 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[252.7773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -9.738874435424805
desired expected reward: 287.0484619140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[228.76129]
 [239.7466 ]
 [234.62888]
 [205.889  ]
 [234.22885]
 [245.74742]
 [237.55345]
 [238.70462]
 [216.75569]
 [233.58585]
 [228.55533]
 [248.77252]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.71453857421875
desired expected reward: 243.41845703125



buy possibilites: [-1] 
expected returns: [[269.39102]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 1. 3.] 
adversary cards in discard: [ 8. 11.  0.  3.  0.  3.  0.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -41.0 

action type: buy - action 0.0
Learning step: -7.426765441894531
desired expected reward: 221.33450317382812






Player: 1 
cards in hand: [0. 3. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 1. 3.] 
cards in discard: [ 8. 11.  0.  3.  0.  3.  0.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 11.] 
adversary cards in discard: [0. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0] -> size -> 13 
adversary victory points: 4
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[275.3928]
 [269.125 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.9395751953125
desired expected reward: 261.4514465332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[252.15935]
 [264.1961 ]
 [261.31512]
 [228.6537 ]
 [273.63217]
 [260.91858]
 [260.11072]
 [279.85306]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 29. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -8.106462478637695
desired expected reward: 263.8984680175781



buy possibilites: [-1] 
expected returns: [[261.98645]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  3. 11.] 
cards in discard: [0. 0. 0. 0. 3. 0. 1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 7 

action type: buy - action 1.0
Learning step: -6.965110778808594
desired expected reward: 257.2309875488281






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8. 10. 10.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0 16] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[260.67288]
 [255.37099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0 16] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.848971843719482
desired expected reward: 254.13748168945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[236.2183 ]
 [243.77228]
 [213.93468]
 [244.78232]
 [260.8767 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0 16] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.913815498352051
desired expected reward: 251.38848876953125



buy possibilites: [-1] 
expected returns: [[209.737]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 8. 3.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0 16] -> size -> 18 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -3 

action type: buy - action 8.0
Learning step: -7.670034885406494
desired expected reward: 237.1123046875






Player: 1 
cards in hand: [3. 0. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  1  3 11  8  0 16] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [16.  0.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 1. 0. 3.] 
adversary cards in discard: [ 8.  0.  0. 11.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [3. 0. 1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[254.67845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -5.347470283508301
desired expected reward: 204.3895263671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[235.93248]
 [246.39369]
 [242.51878]
 [216.23357]
 [241.22249]
 [253.54698]
 [244.04744]
 [245.65651]
 [225.91965]
 [241.65636]
 [236.85608]
 [257.48856]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 0. 3.] 
cards in discard: [ 8.  0.  0. 11.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  3.  3.  0.] 
adversary cards in discard: [16.  0.  0.  0.  3.  0.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -7.615570068359375
desired expected reward: 245.24575805664062



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [16.  0.  0.  0.  3.  0.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [16.  0.  0.  0.  3.  0.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 27. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  3.  0.] 
cards in discard: [16.  0.  0.  0.  3.  0.  8.  3.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[281.0503 ]
 [276.37268]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -7.663577556610107
desired expected reward: 249.82498168945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[259.2226 ]
 [271.5057 ]
 [267.163  ]
 [234.18333]
 [265.4664 ]
 [279.67203]
 [268.69287]
 [270.3486 ]
 [246.79182]
 [265.94543]
 [260.28076]
 [284.34964]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3] -> size -> 18 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -8.886305809020996
desired expected reward: 270.7049255371094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 26. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 1. 3. 3. 3.] 
adversary cards in discard: [11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [0. 1. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[259.06732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3] -> size -> 19 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -10.009146690368652
desired expected reward: 274.3404846191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[239.06876]
 [248.98056]
 [244.64494]
 [217.81554]
 [255.1342 ]
 [247.00728]
 [243.97089]
 [258.23407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 3. 3. 3.] 
cards in discard: [11.  0.  0.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  8. 11.] 
adversary cards in discard: [3. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3] -> size -> 19 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: take_action - action -1.0
Learning step: -8.713754653930664
desired expected reward: 247.2122802734375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  8. 11.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [3. 0. 3. 3. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [3. 0. 3. 3. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 8.] 
cards in discard: [3. 0. 3. 3. 0. 0. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 3. 0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [8. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[258.39935]
 [245.52448]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 3. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11  3  0  1  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1.0
Learning step: -7.712759494781494
desired expected reward: 229.0007781982422



action possibilites: [-1] 
expected returns: [[294.7165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: trash_cards_n_from_hand - action 1
Learning step: -6.4126152992248535
desired expected reward: 232.4621124267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[273.26065]
 [284.72644]
 [282.22372]
 [249.92622]
 [294.68814]
 [281.65018]
 [281.31647]
 [301.32944]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 25. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -22 

action type: take_action - action -1
Learning step: -9.314470291137695
desired expected reward: 285.4020080566406



buy possibilites: [-1] 
expected returns: [[252.2616]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  0.  0.  0.  0.  1.  3.  3.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 24. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -30.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -9.0 

action type: buy - action 3.0
Learning step: -8.885303497314453
desired expected reward: 273.3384704589844






Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8. 10.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  0.  0. 11.  3.  3.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 3. 3. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [3. 3. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[229.99002]
 [215.76299]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -8.624588012695312
desired expected reward: 243.6370086669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[204.37955]
 [177.87381]
 [228.08551]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 8.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3] -> size -> 15 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -7.647802829742432
desired expected reward: 220.6357879638672



buy possibilites: [-1] 
expected returns: [[224.87708]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 3. 3. 8.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -51 

action type: buy - action 0.0
Learning step: -7.7092437744140625
desired expected reward: 196.67031860351562






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  0.] 
adversary cards in discard: [0. 3. 3. 3. 3. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[207.69595]
 [203.01326]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [0. 3. 3. 3. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -7.641297817230225
desired expected reward: 217.23577880859375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[183.6832 ]
 [193.27177]
 [190.25229]
 [164.13913]
 [188.57884]
 [200.60884]
 [190.95631]
 [192.61519]
 [174.2028 ]
 [189.50908]
 [185.09903]
 [205.1503 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.  0.] 
cards in discard: [0. 3. 3. 3. 3. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 11.] 
adversary cards in discard: [1. 0. 0. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -7.052071571350098
desired expected reward: 200.9583282470703



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  3.  3.  8.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [1. 0. 0. 0. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [ 0.  3.  3.  3.  3.  8.  0.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[213.97566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  3.  3.  3.  8.  0.  0.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -6.572147369384766
desired expected reward: 198.5781707763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[195.20181]
 [204.0809 ]
 [191.40085]
 [201.42274]
 [183.64816]
 [177.7939 ]
 [199.76282]
 [210.79579]
 [201.83133]
 [218.24593]
 [203.1453 ]
 [186.72525]
 [192.73912]
 [200.49142]
 [183.12009]
 [196.26064]
 [215.51181]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  3.  3.  3.  8.  0.  0.  0. 11.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1.0
Learning step: -6.924670696258545
desired expected reward: 203.53614807128906



buy possibilites: [-1] 
expected returns: [[215.96164]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  3.  3.  3.  8.  0.  0.  0. 11.  0. 25.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.    0.    4.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -8.5 

action type: buy - action 25.0
Learning step: -6.478158473968506
desired expected reward: 211.7677459716797






Player: 1 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 27. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 17 
adversary victory points: 4
player victory points: 6 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[167.75735]
 [164.30106]
 [155.84131]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1
Learning step: -8.203737258911133
desired expected reward: 207.75790405273438



action possibilites: [-1] 
expected returns: [[189.0547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: trash_cards_n_from_hand - action 1
Learning step: -3.6663734912872314
desired expected reward: 158.69854736328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[176.10883]
 [181.58987]
 [151.74297]
 [184.87463]
 [191.8276 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [6. 0. 3. 8. 3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -5.373576641082764
desired expected reward: 183.68112182617188






Player: 1 
cards in hand: [6. 0. 3. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 8. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  1.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
adversary victory points: 4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 8. 3.] 
cards in discard: [ 1.  0.  0.  0.  0.  3.  3.  0.  3.  0. 11.  1.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 25.  1.  3.] 
adversary cards in discard: [ 8. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
adversary victory points: 4
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 25.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[222.58075]
 [229.63127]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 25.  1.  3.] 
cards in discard: [ 8. 11.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  9.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1] -> size -> 24 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: buy - action -1.0
Learning step: -5.576654434204102
desired expected reward: 186.25096130371094



action possibilites: [-1] 
expected returns: [[219.05145]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: 1 

action type: take_action - action 25.0
Learning step: -6.375448703765869
desired expected reward: 220.70668029785156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[190.5654 ]
 [202.10632]
 [197.80435]
 [174.72168]
 [166.41974]
 [196.41924]
 [209.68726]
 [199.39815]
 [219.48679]
 [200.86961]
 [178.31795]
 [186.35085]
 [196.65028]
 [173.36176]
 [191.1195 ]
 [213.90048]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25] -> size -> 16 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -1 

action type: take_action - action -1
Learning step: -6.395981311798096
desired expected reward: 212.6554718017578



buy possibilites: [-1] 
expected returns: [[233.44888]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 1. 3. 0. 0.] 
cards in discard: [ 8. 11.  0.  0. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  1.  0.  0. 16.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6] -> size -> 25 
adversary victory points: 6
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -20.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: 7.0 

action type: buy - action 29.0
Learning step: -4.440880298614502
desired expected reward: 196.4287109375






Player: 1 
cards in hand: [ 3.  1.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 11.  0.  0. 29. 25.  0.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 16.] 
cards in discard: [6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 11.  0.  0. 29. 25.  0.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 16.] 
cards in discard: [ 6. 10.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [ 8. 11.  0.  0. 29. 25.  0.  3.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[203.23584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8. 11.  0.  0. 29. 25.  0.  3.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -7.744549751281738
desired expected reward: 225.70433044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[178.96835]
 [188.81328]
 [185.60101]
 [159.07837]
 [195.61304]
 [186.2451 ]
 [184.3652 ]
 [199.11145]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 8. 11.  0.  0. 29. 25.  0.  3.  1.  3.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 6. 0. 3. 3.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10] -> size -> 26 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -6.205120086669922
desired expected reward: 192.81243896484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 6. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[152.98782]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -7.1495513916015625
desired expected reward: 191.96188354492188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[136.66772 ]
 [144.8028  ]
 [141.67235 ]
 [118.569405]
 [140.8279  ]
 [150.07448 ]
 [142.92528 ]
 [143.93958 ]
 [127.476746]
 [140.87466 ]
 [137.39806 ]
 [152.49657 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 26. 30. 24. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -4.73911714553833
desired expected reward: 144.41732788085938



buy possibilites: [-1] 
expected returns: [[152.42957]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 26. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3.  1. 11.  0.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0] -> size -> 27 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 2.0 

action type: buy - action 3.0
Learning step: -3.55395245552063
desired expected reward: 138.11839294433594






Player: 1 
cards in hand: [ 8.  3.  1. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  1. 11.  0.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 26. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 1. 0.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 8.  3. 11. 25.  0.] 
adversary cards in discard: [3. 0. 3. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8.  3. 11. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[195.04587]
 [180.82303]
 [190.41104]
 [197.86374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 11. 25.  0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0. 11.  8.  3.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0] -> size -> 29 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -3.2938637733459473
desired expected reward: 149.1356964111328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[171.77061]
 [153.68799]
 [193.4698 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 11. 25.  0.] 
cards in discard: [3. 0. 3. 0. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 3.] 
adversary cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0. 11.  8.  3.
  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0] -> size -> 29 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -5.548581600189209
desired expected reward: 187.23533630371094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0. 11.  8.  3.
  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0. 11.  8.  3.
  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 3.] 
cards in discard: [ 6. 10.  3.  1.  0.  0. 16.  0.  0.  6.  0.  3.  3.  1.  0. 11.  8.  3.
  1.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[157.85785]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1.0
Learning step: -6.121689319610596
desired expected reward: 187.34812927246094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.31891 ]
 [149.83829 ]
 [145.32257 ]
 [115.542465]
 [157.17429 ]
 [147.2132  ]
 [144.12228 ]
 [160.42477 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: take_action - action -1.0
Learning step: -4.4841461181640625
desired expected reward: 153.3737030029297



buy possibilites: [-1] 
expected returns: [[162.75597]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [ 3.  0.  3.  0.  0.  0.  8.  3. 11. 25.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5.  0.  5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 2.0 

action type: buy - action 8.0
Learning step: -3.5986499786376953
desired expected reward: 143.61453247070312






Player: 1 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 29.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
adversary victory points: 5
player victory points: 5 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[120.72977]
 [113.9297 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  1.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 0 

action type: buy - action -1
Learning step: -5.539588928222656
desired expected reward: 157.21636962890625



action possibilites: [-1.] 
expected returns: [[172.2559]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 21 

action type: take_action - action 29.0
Learning step: -0.4816741943359375
desired expected reward: 107.66696166992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[154.86426]
 [162.19109]
 [149.64119]
 [157.53117]
 [144.57446]
 [137.96811]
 [158.3265 ]
 [165.4275 ]
 [161.14171]
 [174.32697]
 [161.54271]
 [145.67921]
 [150.084  ]
 [157.06964]
 [142.33237]
 [153.57654]
 [165.71204]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 25. 30. 23. 30.  8.  8.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
adversary victory points: 5
player victory points: 5 

Reward from previous game state: 
[-5  0  5  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 20 

action type: take_action - action -1.0
Learning step: -3.932687759399414
desired expected reward: 168.32321166992188



buy possibilites: [-1] 
expected returns: [[154.16753]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 1. 0.] 
cards in discard: [6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 6 
card supply: [20. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.  -10.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -291.0 

action type: buy - action 6.0
Learning step: -17.979639053344727
desired expected reward: 119.9885025024414






Player: 1 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [10.  1.  0.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [10.  1.  0.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 3. 8. 0.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[125.926346]
 [116.11534 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [ 6. 29.  0.  3.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1
Learning step: -5.487857341766357
desired expected reward: 148.67967224121094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[115.22825 ]
 [119.699814]
 [103.90602 ]
 [119.68152 ]
 [128.91145 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 8. 0.] 
cards in discard: [ 6. 29.  0.  3.  0.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  0.  0.  1.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -4.092138767242432
desired expected reward: 121.83419036865234



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 10.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.  1.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 1. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 25. 30. 23. 30.  8.  7.  9.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 1. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[161.69884]
 [160.39299]
 [152.2287 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  8.] 
cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  6.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0 16] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -3.403350591659546
desired expected reward: 125.50810241699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[144.68428]
 [150.64435]
 [124.65419]
 [151.96329]
 [162.56725]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0.  8.] 
cards in discard: [ 6. 29.  0.  3.  0.  1.  0.  3.  0.  3.  8.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  6.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0 16] -> size -> 33 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -5.177791118621826
desired expected reward: 156.5210418701172



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1
  6 10  0  1  0  0 10  0 16] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 6.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 29.  3. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[82.65085 ]
 [77.266846]
 [88.36375 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3. 25.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 30.  8.  7.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0  0] -> size -> 34 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: buy - action -1.0
Learning step: -6.839270114898682
desired expected reward: 155.7279815673828



action possibilites: [-1] 
expected returns: [[152.97192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0  0  6] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action 25.0
Learning step: -0.3502880036830902
desired expected reward: 84.49283599853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[129.22705]
 [114.09801]
 [146.30554]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 0. 3. 3.] 
adversary cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0  0  6] -> size -> 35 
adversary victory points: 5
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 9 

action type: take_action - action -1
Learning step: -4.117118835449219
desired expected reward: 148.85479736328125






Player: 1 
cards in hand: [0. 8. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 3. 3.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6
 10  0  1  0  0 10  0 16  0  0  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [10.  1.  0.  0.  0.  0.  0.  0.  3.  0.  0.  1. 16. 10.  3.  0.  0.  1.
  6.  0.  0. 16.  3.  3.  6.  6.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[101.79314]
 [ 93.99092]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: buy - action -1.0
Learning step: -4.1248931884765625
desired expected reward: 142.18067932128906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[ 91.133224]
 [ 98.894966]
 [ 95.73833 ]
 [ 75.959816]
 [103.270775]
 [ 97.04993 ]
 [ 94.71846 ]
 [104.85214 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [25.  3. 29.  3.  0.  8.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6.  0.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0] -> size -> 33 
adversary victory points: 2
player victory points: 4 

Reward from previous game state: 
[-5  0  4 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 19 

action type: take_action - action -1.0
Learning step: -1.9040672779083252
desired expected reward: 99.8890609741211



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6.  0.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  7.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 11.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 11.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 25. 30. 23. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 11.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3.] 
cards in discard: [8. 3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  6.  0. 11.  0.] 
adversary cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[127.76318 ]
 [124.798836]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0. 11.  0.] 
cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -1.9369163513183594
desired expected reward: 102.91520690917969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[111.6393  ]
 [120.269455]
 [118.01837 ]
 [ 93.23106 ]
 [116.10401 ]
 [126.368195]
 [117.75105 ]
 [118.70824 ]
 [102.524826]
 [116.64984 ]
 [112.23619 ]
 [129.30527 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0. 11.  0.] 
cards in discard: [25.  3. 29.  3.  0.  8.  3.  0.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  8.  0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8  3] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -3.208998918533325
desired expected reward: 124.55416870117188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  3.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  8.  0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1
  0  0 10  0 16  0  0  6  0  8  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  1.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [11.  1.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[123.37712]
 [122.36124]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  1.  0.  0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -3.2991883754730225
desired expected reward: 126.0060806274414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 98.42243 ]
 [107.53973 ]
 [103.31328 ]
 [ 81.07484 ]
 [103.08503 ]
 [111.63453 ]
 [105.58508 ]
 [106.393936]
 [ 88.440956]
 [102.15777 ]
 [ 97.41455 ]
 [112.309654]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 25. 30. 22. 30.  8.  6.  8.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  1.  0.  0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -3.2173287868499756
desired expected reward: 117.88645935058594



buy possibilites: [-1] 
expected returns: [[131.73018]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1.  3.  0.  0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  3.  1.  0.  0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3  0] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 41 

action type: buy - action 16.0
Learning step: 0.03829345852136612
desired expected reward: 99.5510025024414






Player: 1 
cards in hand: [16.  3.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  1.  0.  0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  1  6 10  0  1  0
  0 10  0 16  0  0  6  0  8  3  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[117.26258]
 [108.04896]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [16. 11.  1.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1
Learning step: -3.5570991039276123
desired expected reward: 128.17308044433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[108.092766]
 [114.67612 ]
 [112.99024 ]
 [ 95.29953 ]
 [111.39718 ]
 [120.1256  ]
 [112.8325  ]
 [113.862335]
 [101.88615 ]
 [112.28195 ]
 [109.00853 ]
 [123.38101 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [16. 11.  1.  3.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -2.791524648666382
desired expected reward: 114.47105407714844



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  8.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 25.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
adversary victory points: 4
player victory points: 3 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[137.03629]
 [141.01288]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 25.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: buy - action -1.0
Learning step: -2.5717239379882812
desired expected reward: 120.80927276611328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[119.21029]
 [103.03376]
 [137.30846]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 25.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 22. 30.  8.  6.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
adversary victory points: 3
player victory points: 4 

Reward from previous game state: 
[-5  0  4 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 9 

action type: take_action - action -1.0
Learning step: -3.5359489917755127
desired expected reward: 133.50035095214844



buy possibilites: [-1] 
expected returns: [[114.69611]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 25.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -302.0 

action type: buy - action 6.0
Learning step: -17.6710262298584
desired expected reward: 85.36272430419922






Player: 1 
cards in hand: [3. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  6. 29.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.  3.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  6.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  6. 29.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.  3.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 8.  6. 29.  0.  3.] 
adversary cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.  3.  3.  0. 25.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
expected returns: [[91.52441]
 [84.31028]
 [85.03251]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 29.  0.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.  3.  3.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  1.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -3.8340165615081787
desired expected reward: 110.86209869384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[80.68563]
 [67.04731]
 [92.83564]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 29.  0.  3.] 
cards in discard: [16. 11.  1.  3.  0.  0.  0.  0.  0.  0.  8.  6.  3.  3.  0. 25.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 10. 10.  1.] 
adversary cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -2.7493739128112793
desired expected reward: 88.77503967285156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  1.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  1.  3.] 
cards in discard: [ 8.  3. 11.  6.  0.  0.  3.  0.  8. 16.  3.  0.  1. 16.  3.  0.  0. 11.
  0.  0.  0.  0.  0.  8.  3.  0.  6.  6.  0. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[6.5568323]
 [1.3039482]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  1.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -4.627890110015869
desired expected reward: 88.207763671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[-1.7306733 ]
 [ 1.8693054 ]
 [ 0.45661926]
 [-8.603346  ]
 [-0.02204657]
 [ 4.7172203 ]
 [ 1.1074882 ]
 [ 1.5720818 ]
 [-4.949789  ]
 [ 0.30014014]
 [-1.1999626 ]
 [ 6.7413845 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  1.  3.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10] -> size -> 38 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -0.3622193932533264
desired expected reward: 6.194610118865967



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  1.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1.  3.  1.  0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  7.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 25.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [16.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  6.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 25.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [16.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16] -> size -> 39 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 24. 30. 22. 30.  8.  5.  6.  7.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 25.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 0.] 
cards in discard: [16. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 24. 30. 22. 30.  8.  5.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 16.  3.  0. 25.] 
adversary cards in discard: [0. 0. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 25.] 
expected returns: [[97.75003]
 [86.48484]
 [99.67718]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0. 25.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  5.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11] -> size -> 40 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: 1.7411235570907593
desired expected reward: 8.482511520385742



action possibilites: [-1] 
expected returns: [[74.91912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  0.  3.  8.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action 25.0
Learning step: -2.398179531097412
desired expected reward: 97.27901458740234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[56.535866]
 [62.26492 ]
 [39.59355 ]
 [64.53731 ]
 [76.59467 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  0.  3.  8.] 
cards in discard: [0. 0. 8. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11.  6.  3.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6] -> size -> 41 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -1.336312174797058
desired expected reward: 73.58280944824219






Player: 1 
cards in hand: [11.  6.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  3.  0.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 29.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 29.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 29.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 6. 11. 29.  0.  6.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6. 11. 29.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[108.73415 ]
 [105.03208 ]
 [ 96.887215]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11. 29.  0.  6.] 
cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -1.0495920181274414
desired expected reward: 75.54507446289062



action possibilites: [-1] 
expected returns: [[70.76867]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  6.] 
cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 37 

action type: gain_card_n - action 9
Learning step: -1.876552939414978
desired expected reward: 104.56940460205078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[50.06228 ]
 [27.314613]
 [69.91584 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 29.  0.  6.] 
cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  3. 16.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1
Learning step: -0.8319401144981384
desired expected reward: 69.93672943115234






Player: 1 
cards in hand: [ 0.  8.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  3. 16.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10. 11.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 16.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10. 11.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  3. 16.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [12. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 1. 3.] 
adversary cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10. 11.  6. 29.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[61.51707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10. 11.  6. 29.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -1.7116575241088867
desired expected reward: 68.20417785644531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[44.435616]
 [52.915436]
 [48.830082]
 [30.120628]
 [57.602695]
 [51.056995]
 [47.907143]
 [59.12299 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 1. 3.] 
cards in discard: [ 0.  0.  8.  0.  0. 25.  0. 16.  3.  0.  3.  8. 10. 11.  6. 29.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 1. 0. 3. 6.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0] -> size -> 44 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: take_action - action -1.0
Learning step: -1.4752416610717773
desired expected reward: 60.04182815551758



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 1. 0. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 24. 30. 22. 30.  8.  4.  6.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 6.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 29. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[51.179928]
 [45.90884 ]
 [43.770878]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 8 

action type: buy - action -1.0
Learning step: -1.4587321281433105
desired expected reward: 57.66427230834961



action possibilites: [-1. 29.] 
expected returns: [[52.72926]
 [48.36291]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  6.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  4.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action 10.0
Learning step: 0.3699056804180145
desired expected reward: 44.140777587890625



action possibilites: [-1.] 
expected returns: [[69.05341]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 2 
buys: 0 
player value: 1 
card supply: [12. 24. 30. 22. 30.  8.  4.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 29.0
Learning step: 1.5355558395385742
desired expected reward: 49.898475646972656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[59.281147]
 [64.07088 ]
 [62.503765]
 [51.7483  ]
 [67.95453 ]
 [62.95088 ]
 [62.221157]
 [69.80013 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 22. 30.  8.  4.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  3 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: 0.4251914918422699
desired expected reward: 69.47860717773438



buy possibilites: [-1] 
expected returns: [[114.34023]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 6. 0. 0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -263.0 

action type: buy - action 6.0
Learning step: -13.164759635925293
desired expected reward: 38.58353805541992






Player: 1 
cards in hand: [3. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 16.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 16.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0. 0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  6. 16.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[83.25886]
 [72.56724]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  6. 16.] 
cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -4.062150001525879
desired expected reward: 110.27808380126953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[72.59143 ]
 [75.86063 ]
 [63.732624]
 [75.96727 ]
 [84.83454 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  6. 16.] 
cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0. 10.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -2.535270929336548
desired expected reward: 80.72358703613281



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [10.  0. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1. 10. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 16.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [25.  0.  0.  3.  3.] 
adversary cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [25.  0.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[19.827621]
 [29.50296 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  3.  3.] 
cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  3.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0] -> size -> 46 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -3.7898647785186768
desired expected reward: 81.04467010498047



action possibilites: [-1] 
expected returns: [[89.899086]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0. 8.] 
cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 47 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 25.0
Learning step: 1.4475821256637573
desired expected reward: 30.95052719116211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[78.99524 ]
 [83.80404 ]
 [81.88901 ]
 [70.07328 ]
 [87.95545 ]
 [82.35583 ]
 [81.499725]
 [90.28909 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0. 8.] 
cards in discard: [ 6. 10. 29.  0.  0.  3.  6.  3.  3.  0.  0.  6. 16.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  0.  8.  0.  0.] 
adversary cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
adversary owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 47 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -1.718226432800293
desired expected reward: 88.18086242675781






Player: 1 
cards in hand: [10.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.  0.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 8.] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  0  3 11  8  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0
 10  0 16  0  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 47 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6] -> size -> 43 
action values: 1 
buys: 1 
player value: 0 
card supply: [11. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [16. 11. 11.  1.  3.  1.  0.  6.  0.  0. 11.  6.  3.  0.  0.  0.  0.  8.
  3. 16.  0. 16.  0.  1.  0.  3.  6.  0.  3.  0.  6.  0.  0. 10.  0. 10.
  0.  0. 16.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8.  0.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[22.142014]
 [19.104332]
 [21.197983]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 1. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 44 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -3.6832566261291504
desired expected reward: 86.60582733154297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.964388]
 [18.839754]
 [18.107271]
 [10.206159]
 [17.873465]
 [20.366371]
 [18.473331]
 [18.853388]
 [14.752296]
 [18.117304]
 [17.313454]
 [21.367552]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0.  1. 11.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 1. 1. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 44 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -0.3245428204536438
desired expected reward: 21.817455291748047



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 1. 1. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 1. 3. 3.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0
  0  6  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0] -> size -> 42 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 24. 30. 22. 30.  8.  2.  5.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1.] 
cards in discard: [16.] 
cards in deck: 39 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [10.  3.  8.  3.  0.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  3.  8.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[90.73879]
 [78.98727]
 [80.30004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  8.  3.  0.] 
cards in discard: [ 0.  8.  0.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  1. 11.] 
adversary cards in discard: [16.  8.  1.  1.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1.0
Learning step: 2.228517770767212
desired expected reward: 23.596059799194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[73.57439 ]
 [61.955257]
 [89.46106 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.  0.] 
cards in discard: [ 0.  8.  0.  1. 11.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  1. 11.] 
adversary cards in discard: [16.  8.  1.  1.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -1.3712742328643799
desired expected reward: 89.60692596435547



buy possibilites: [-1] 
expected returns: [[125.98862]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  8.  3.  0.] 
cards in discard: [ 0.  8.  0.  1. 11.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8. 11.  0.  1. 11.] 
adversary cards in discard: [16.  8.  1.  1.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16] -> size -> 43 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  30.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -0.9939754605293274
desired expected reward: 72.58041381835938






Player: 1 
cards in hand: [ 8. 11.  0.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0.  1. 11.] 
cards in discard: [16.  8.  1.  1.] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  6.  3. 29.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 11.] 
cards in discard: [16.  8.  1.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  6.  3. 29.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 11.] 
cards in discard: [16.  8.  1.  1.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  6.  3. 29.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  1. 11.] 
cards in discard: [16.  8.  1.  1.  0.  0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 16.  6.  3. 29.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  6.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29.] 
expected returns: [[85.38887]
 [78.1936 ]
 [80.42226]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6.  3. 29.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: buy - action -1
Learning step: -3.080099582672119
desired expected reward: 122.90851593017578



action possibilites: [-1. 16.] 
expected returns: [[63.46745]
 [54.75723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  6.  3.  3.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action 29.0
Learning step: -0.2988700866699219
desired expected reward: 80.12339782714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[52.013233]
 [39.124363]
 [63.51427 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  6.  3.  3.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  3.  0. 16.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1.0
Learning step: 0.4524843394756317
desired expected reward: 63.919918060302734






Player: 1 
cards in hand: [ 3.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 22. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0. 16.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 6. 0. 0. 3.] 
adversary cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[78.68038]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -0.5554050803184509
desired expected reward: 62.958866119384766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[68.767426]
 [73.25711 ]
 [70.587975]
 [63.28615 ]
 [77.016   ]
 [71.70619 ]
 [70.07287 ]
 [78.81614 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  6.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.4019346237182617
desired expected reward: 77.27845001220703



buy possibilites: [-1] 
expected returns: [[107.91694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [ 0.  8.  0.  1. 11.  0. 10.  3.  8.  3.  0. 29.  6. 16.  6.  3.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11.  0.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3] -> size -> 46 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 35 

action type: buy - action 11.0
Learning step: 0.32733041048049927
desired expected reward: 77.34334564208984






Player: 1 
cards in hand: [16.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  6.  0. 25.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[6.034123]
 [5.639458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -4.412606716156006
desired expected reward: 103.50433349609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[4.589882 ]
 [5.838652 ]
 [4.319431 ]
 [4.828974 ]
 [7.4112554]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 25.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.6892593502998352
desired expected reward: 6.723381519317627



buy possibilites: [-1] 
expected returns: [[37.198624]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 25.  0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  0.  3.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -0.042525388300418854
desired expected reward: 4.547362327575684






Player: 1 
cards in hand: [ 0. 16.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 16.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0.  0.  3.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 1.  6.  0.  8. 16.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
expected returns: [[93.68713]
 [85.80402]
 [84.72716]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  0.  8. 16.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: 1.026127815246582
desired expected reward: 38.22475051879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[84.77434 ]
 [90.40472 ]
 [88.858025]
 [74.39345 ]
 [94.59443 ]
 [88.86021 ]
 [88.13258 ]
 [96.8124  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6.  0.  8. 16.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -1.764406442642212
desired expected reward: 91.92276000976562



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 24. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[52.125042]
 [45.84157 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1] -> size -> 49 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.858042001724243
desired expected reward: 93.95436096191406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[45.53779 ]
 [48.78922 ]
 [37.271503]
 [48.969723]
 [55.24923 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 3.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 6. 6.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1] -> size -> 49 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.6166958212852478
desired expected reward: 51.50834274291992



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 23. 30. 21. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 5. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [10. 11.  3.  3.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10. 11.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[126.84816 ]
 [115.780235]
 [124.03302 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  3.  3.  0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0. 10.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: 0.38235607743263245
desired expected reward: 55.63159942626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[111.55925 ]
 [ 97.666504]
 [129.08716 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0. 10.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -3.2136268615722656
desired expected reward: 121.968994140625



buy possibilites: [-1] 
expected returns: [[115.21154]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  3.  3.  0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0. 10.] 
adversary cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -23.0 

action type: buy - action 0.0
Learning step: -4.1357035636901855
desired expected reward: 107.4235610961914






Player: 1 
cards in hand: [ 0. 16.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  0. 10.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  6.  0.  6.] 
cards in discard: [16.  8.  1.  1.  0.  0. 11.  8.  0.  1. 11.  3.  3.  3.  0. 16.  0. 14.
  0. 11. 16.  0.  0.  0.  0. 16.  0.  0.  3.  1.  0.  0. 10.  0.  6.  3.
  0.  0.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
adversary victory points: 2
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[79.99829]
 [75.7112 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -3.6380672454833984
desired expected reward: 111.57347106933594



action possibilites: [-1. 11.] 
expected returns: [[67.11897 ]
 [66.569855]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 29.0
Learning step: -0.9288986325263977
desired expected reward: 74.78228759765625



action possibilites: [-1] 
expected returns: [[111.89829]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 56 

action type: gain_card_n - action 9
Learning step: 1.9710495471954346
desired expected reward: 68.90428924560547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[100.58807 ]
 [104.581535]
 [103.558784]
 [ 92.878746]
 [102.63204 ]
 [107.707   ]
 [103.4882  ]
 [104.004456]
 [ 96.62835 ]
 [103.08643 ]
 [101.105225]
 [109.413345]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  9. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 47 

action type: take_action - action -1
Learning step: -0.8720012903213501
desired expected reward: 111.02629089355469



buy possibilites: [-1] 
expected returns: [[73.588135]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 0.  3.  6.  0. 25.  0.  1.  6.  0.  8. 16.  0.  8.  6.  0.  3.  0. 10.
 11.  3.  3.  0. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  0.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 79 

action type: buy - action 14.0
Learning step: 0.7743152976036072
desired expected reward: 97.40266418457031






Player: 1 
cards in hand: [ 0. 16.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3. 10.] 
cards in discard: [] 
cards in deck: 46 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6
  0  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0
  1  3  0] -> size -> 51 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 45 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [1. 0.] 
cards in deck: 45 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 2. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10.  8.  6.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [10.  8.  6.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 14.] 
expected returns: [[41.39344 ]
 [37.436172]
 [36.743546]
 [34.852856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  0. 14.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.9465526342391968
desired expected reward: 71.6415786743164





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[37.37846 ]
 [34.421326]
 [42.123917]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  0. 14.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.32502326369285583
desired expected reward: 41.068416595458984



buy possibilites: [-1] 
expected returns: [[62.30316]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  6.  0. 14.] 
cards in discard: [0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 1. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [1. 0. 3. 3. 0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  20.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -13.0 

action type: buy - action 0.0
Learning step: -1.1171013116836548
desired expected reward: 36.261348724365234






Player: 1 
cards in hand: [1. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 11.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 1. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 11.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3. 3. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [10. 11. 11.  3.  0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.] 
expected returns: [[10.882   ]
 [12.012126]
 [11.832131]
 [11.832131]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  3.  0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1
Learning step: -1.999656081199646
desired expected reward: 60.303504943847656



action possibilites: [-1. 11. 11.] 
expected returns: [[97.96399 ]
 [96.425026]
 [96.425026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 38 

action type: take_action - action 10.0
Learning step: 3.490445852279663
desired expected reward: 15.502541542053223





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[92.36867 ]
 [81.265564]
 [93.13646 ]
 [98.76766 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  3.  0.  0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1.0
Learning step: -0.9204792380332947
desired expected reward: 97.04350280761719






Player: 1 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  5.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[7.833928 ]
 [3.0677488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 16.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6. 11.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8] -> size -> 54 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -3.9426400661468506
desired expected reward: 94.82503509521484





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[ 2.7529485]
 [-2.5937662]
 [ 2.8605683]
 [ 7.010869 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 16.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  3.  6. 11.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8] -> size -> 54 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.5583768486976624
desired expected reward: 8.392305374145508



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [16.  0.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  6. 11.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  3.  6.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  3.  6.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1.] 
cards in deck: 30 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0.  1.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[53.16263 ]
 [55.883045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8  1] -> size -> 55 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 1.6504526138305664
desired expected reward: 10.440374374389648





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[44.403896]
 [42.893196]
 [30.66199 ]
 [42.067425]
 [47.32778 ]
 [42.943905]
 [43.30075 ]
 [34.3396  ]
 [41.935253]
 [39.350773]
 [48.580402]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0.  3.  0.  1.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 16.  6.  0.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.] 
adversary owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8  1] -> size -> 55 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -0.8042295575141907
desired expected reward: 52.358394622802734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 16.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  6.  0.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0
  8  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1
  3  0  1  0  0  8  1] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  4.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [0. 3. 8. 0. 0.] 
adversary cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
adversary victory points: 2
player victory points: 0 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[99.81871]
 [98.18722]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6
  0 11  0  0 10 14  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.6564540863037109
desired expected reward: 49.236854553222656



action possibilites: [-1] 
expected returns: [[104.96608]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: trash_cards_n_from_hand - action 1
Learning step: -1.1729434728622437
desired expected reward: 95.52066040039062





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[100.88527 ]
 [ 99.569275]
 [ 87.40214 ]
 [104.658   ]
 [ 99.636856]
 [ 99.133125]
 [106.58835 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  5.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 26 

action type: take_action - action -1
Learning step: -1.6383323669433594
desired expected reward: 103.32774353027344



buy possibilites: [-1] 
expected returns: [[78.64376]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 10.  8.  6.  0. 14. 10. 11. 11.  3.  0.  0.  3.  0.  3.  0. 16. 25.
  0.  3.  0.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [16.  0.  0. 10.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 44 

action type: buy - action 11.0
Learning step: -1.2634152173995972
desired expected reward: 103.39458465576172






Player: 1 
cards in hand: [16.  0.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 10.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 10.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  5. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 10.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  6.  6. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[64.98567 ]
 [61.31146 ]
 [54.362267]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  6. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10] -> size -> 56 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: -2.2310454845428467
desired expected reward: 76.41271209716797





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[45.904297]
 [66.23964 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  6. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [6. 8. 1. 0. 0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10] -> size -> 56 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -1.5891048908233643
desired expected reward: 63.39654541015625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 8. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 14.  0.  0.] 
adversary cards in discard: [11.  0.  6.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  4.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 14.  0.  0.] 
adversary cards in discard: [11.  0.  6.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 1. 0. 0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 8.  0. 14.  0.  0.] 
adversary cards in discard: [11.  0.  6.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [ 8.  0. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[132.85733]
 [128.41542]
 [117.7291 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 14.  0.  0.] 
cards in discard: [11.  0.  6.  6. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3. 14. 10.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -0.10623359680175781
desired expected reward: 66.13338470458984





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[128.39929 ]
 [125.8174  ]
 [109.903946]
 [131.28441 ]
 [127.067795]
 [124.93801 ]
 [132.19814 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 14.  0.  0.] 
cards in discard: [11.  0.  6.  6. 29.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [11.  0.  3. 14. 10.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -3.452160596847534
desired expected reward: 129.40516662597656



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  0.  3. 14. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 14. 10.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3. 14. 10.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  0. 25.  0.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  0. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[8.349114]
 [2.719926]
 [5.318532]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 25.  0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: -6.1590189933776855
desired expected reward: 126.03910064697266





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[ 2.3759053]
 [-1.4619678]
 [ 1.1095293]
 [10.109078 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 25.  0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 20. 30.  8.  2.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: 0.01937894895672798
desired expected reward: 8.36849594116211



buy possibilites: [-1] 
expected returns: [[1.932936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 25.  0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11  6] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [16.  0.  6.  1.  0.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -15.133410453796387
desired expected reward: -16.595380783081055






Player: 1 
cards in hand: [16.  0.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  1.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11  6] -> size -> 32 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  1.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11] -> size -> 57 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11  6] -> size -> 32 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  1.  0.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  3. 16.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11  6] -> size -> 32 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[37.322857]
 [31.200605]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  3. 16.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0
 11  0  0 10 14  0 11  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  3. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0.4539145529270172
desired expected reward: 2.386850595474243



action possibilites: [-1] 
expected returns: [[-4.813237]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 20 

action type: gain_card_n - action 9
Learning step: -1.9535343647003174
desired expected reward: 54.951194763183594





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-5.0998   ]
 [-4.179471 ]
 [-5.6793165]
 [-5.2716813]
 [-5.139251 ]
 [-4.2261176]
 [-5.825185 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  3.  3.  9.  9.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: 0.335345596075058
desired expected reward: -4.477891445159912



buy possibilites: [-1] 
expected returns: [[106.61636]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  3.  9.  9.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 11.  8.] 
adversary cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0.] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: 22 

action type: buy - action 11.0
Learning step: 3.7624523639678955
desired expected reward: -1.5092289447784424






Player: 1 
cards in hand: [ 0.  0.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.  8.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  3.  9.  9.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  3.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  3.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [ 1.  0. 10. 16.  0.  0.  0.  0.  1.  0.  3.  3.  0.  8.  0.  3.  0.  6.
  1.  1. 11. 16.  0.  3.  6.  8. 16.  6.  0.  0. 10. 16.  0.  0. 10.  0.
 11.  6.  8.  1.  0.  0. 11.  0.  3. 14. 10. 10. 16.  0.  6.  1.  0. 29.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29  8] -> size -> 60 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  3.  0.  3. 11.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[70.6816  ]
 [69.099594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0.  1. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29  8] -> size -> 60 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1
Learning step: -4.550612926483154
desired expected reward: 102.06575012207031





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
expected returns: [[62.59216 ]
 [52.494183]
 [62.85203 ]
 [69.76215 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  3. 11.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8.  0.  1. 16. 10.] 
adversary cards in discard: [] 
adversary owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29  8] -> size -> 60 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -2.864797592163086
desired expected reward: 67.8167953491211



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0.  1. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 16. 10.] 
cards in discard: [] 
cards in deck: 55 
card top of deck: [] 
played cards: [] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29  8] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  8.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.  8. 16. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 16. 14.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [10.] 
owned cards: [11  0 16  3  3  0  0  6  0  1  6 10  0  1  0  0 10  0 16  0  0  6  0  8
  3  0  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3 14  0  1  3
  0  1  0  0  8  1  8 10 11 10 29  8] -> size -> 60 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  8.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  8.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 54 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 11.  1.  0.  8.] 
adversary cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  1.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[37.108974]
 [33.84475 ]
 [28.255354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  0.  8.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 10. 11.] 
adversary cards in discard: [10.  8.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -3.504885196685791
desired expected reward: 66.25726318359375





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.904533]
 [34.490913]
 [22.61477 ]
 [39.2141  ]
 [33.62975 ]
 [34.181488]
 [42.47833 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  1.  0.  8.] 
cards in discard: [11.  0.  6.  6. 29.  8.  0. 14.  0.  0.  6.  3. 10.  0. 25.  0. 15. 11.
 16.  0.  0.  0.  0.  3.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 3.  3.  8. 10. 11.] 
adversary cards in discard: [10.  8.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -1.801836609840393
desired expected reward: 35.30712890625



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3.  8. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 10. 11.] 
cards in discard: [10.  8.  0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 10. 11.] 
cards in discard: [10.  8.  0.] 
cards in deck: 49 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 29.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [ 0. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[83.65565 ]
 [78.65426 ]
 [78.492325]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  0.  6. 10.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -1.085055947303772
desired expected reward: 41.39326095581055





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[73.50867 ]
 [73.718254]
 [63.974903]
 [75.27271 ]
 [73.45632 ]
 [74.02479 ]
 [76.84925 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [29.  8.  0.  6. 10.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1.0
Learning step: -3.303326368331909
desired expected reward: 80.35230255126953



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  6. 10.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.] 
cards in deck: 44 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  6.] 
adversary cards in discard: [ 0. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  6.] 
adversary cards in discard: [ 0. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8] -> size -> 57 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 20. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  6.] 
adversary cards in discard: [ 0. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  6. 10.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [29.] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0. 15.  6. 11.  6.] 
adversary cards in discard: [ 0. 29.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
adversary victory points: -1
player victory points: 1 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  6. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
expected returns: [[-6.7602253]
 [-7.6060963]
 [-7.0386043]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6. 11.  6.] 
cards in discard: [ 0. 29.  0.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 30.  8.  1.  4.  2.  2.  9.  8.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: buy - action -1.0
Learning step: -5.2993669509887695
desired expected reward: 71.54987335205078



action possibilites: [-1] 
expected returns: [[24.61909]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  6.  6.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 30.  8.  1.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 10 

action type: gain_card_n - action 6
Learning step: 1.4016776084899902
desired expected reward: -5.553284645080566





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[13.873873]
 [26.639181]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  6.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 21. 30. 19. 30.  8.  1.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
adversary victory points: 1
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -20   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -6 

action type: take_action - action -1
Learning step: -1.0133136510849
desired expected reward: 23.605775833129883



buy possibilites: [-1] 
expected returns: [[25.623835]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  6.  6.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 19. 30.  8.  0.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 1.  0.  3.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.] 
adversary owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
adversary victory points: 1
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -30.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -317.0 

action type: buy - action 6.0
Learning step: -15.967157363891602
desired expected reward: -2.0932884216308594






Player: 1 
cards in hand: [ 1.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  0. 16.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0
  1 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0
  0  8  1  8 10 11 10 29  8  3] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 19. 30.  8.  0.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
adversary victory points: -2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 18. 30.  8.  0.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 18. 30.  8.  0.  4.  2.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11.] 
cards in deck: 38 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 18. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 8. 11.  0. 11.  0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
adversary victory points: -2
player victory points: 2 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 11.] 
expected returns: [[7.577274 ]
 [2.6587567]
 [6.077267 ]
 [6.077267 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  0. 11.  0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 18. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
adversary victory points: 2
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: buy - action -1
Learning step: -3.486055850982666
desired expected reward: 22.137779235839844



action possibilites: [-1] 
expected returns: [[30.84606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 17. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0  -1   0   0   4   0] 
sum of rewards: -13 

action type: gain_card_n - action 1
Learning step: -0.0869237557053566
desired expected reward: 2.532278060913086





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[25.794054]
 [26.427397]
 [30.021013]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 17. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
adversary victory points: 2
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: take_action - action -1
Learning step: -1.7002155780792236
desired expected reward: 29.145843505859375



buy possibilites: [-1] 
expected returns: [[19.88268]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11.  0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 16. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
adversary victory points: 2
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -20   0   0  20   0   0   0   0  -2   0   0   8   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: -0.7923431396484375
desired expected reward: 25.001726150512695






Player: 1 
cards in hand: [ 6. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 16. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 16. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  0.  3.  0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [ 0.  0.  6.  3. 25.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  6.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[3.6230671]
 [1.8779504]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3. 25.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -2.6737897396087646
desired expected reward: 17.208890914916992



action possibilites: [-1] 
expected returns: [[-11.765342]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6.  3.  0. 10.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -14 

action type: take_action - action 25.0
Learning step: -1.0586178302764893
desired expected reward: 0.8193340301513672





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[-12.59925  ]
 [-14.03883  ]
 [-10.230217 ]
 [-13.6379385]
 [-14.532688 ]
 [-10.118339 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6.  3.  0. 10.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -0.4202324450016022
desired expected reward: -12.185574531555176






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [16.  6.  3.  1. 11.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3] -> size -> 60 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  9.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [16.  6.  3.  1. 11.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [16.  6.  3.  1. 11.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [16.  6.  3.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-11.8036995]
 [ -8.324297 ]
 [ -9.964767 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.  3.  1. 11.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0 11  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11
  0  0 10 14  0 11  6 15 11 29  6  3  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3. 10.  9.] 
adversary cards in hand: [16. 16.  0.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -1.45323646068573
desired expected reward: -11.57156753540039



action possibilites: [-1] 
expected returns: [[15.717856]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 1.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [16. 16.  0.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0  -2   0   0  25   0] 
sum of rewards: 8 

action type: gain_card_n - action 11
Learning step: 0.16026388108730316
desired expected reward: 12.028021812438965





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
expected returns: [[15.648793]
 [15.747014]
 [15.716298]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 15. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [16. 16.  0.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -1.1821354627609253
desired expected reward: 14.535720825195312



buy possibilites: [-1] 
expected returns: [[-6.627203]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 1.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 14. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [16. 16.  0.  0. 16.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0  20   0   0   0   0  -3   0   0   8   0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: -0.8815520405769348
desired expected reward: 14.767247200012207






Player: 1 
cards in hand: [16. 16.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 16.  0.  0. 16.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0 16  0  0  6  0  8  3  0  1
 11  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0
  8  1  8 10 11 10 29  8  3  3 11  3 25] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 14. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3] -> size -> 61 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3] -> size -> 61 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  2.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 16.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [3. 8. 0. 0. 0.] 
adversary cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [3. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-10.3945675]
 [-12.594303 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0
  0 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -1.616603136062622
desired expected reward: -8.243805885314941



action possibilites: [-1] 
expected returns: [[-6.6734676]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.7921226620674133
desired expected reward: -12.928336143493652





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3. 11.  8. 10. -1.] 
expected returns: [[-7.5762444]
 [-6.2143383]
 [-6.798213 ]
 [-7.629051 ]
 [-6.1310863]
 [-6.673462 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.0633172988891602
desired expected reward: -7.736784934997559



buy possibilites: [-1] 
expected returns: [[4.8205214]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 0. 29.  0.  0. 10. 29.  6. 11.  0. 15.  6.  6.  3.  3. 11.  8.  0. 11.
  0. 25.  0.  0.  6.  3.  0. 10. 22.  3. 16.  6.  3.  1. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  2.  9.  9.] 
adversary cards in hand: [0. 0. 1. 0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0  -3   0   0  18   0] 
sum of rewards: -10 

action type: buy - action 10.0
Learning step: -0.08498378098011017
desired expected reward: -6.216073989868164






Player: 1 
cards in hand: [0. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8] -> size -> 62 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8. 10.  2.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  0.  0.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 68 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[53.510174]
 [51.147213]
 [51.057056]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 14.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  1.  0.  8. 11.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1
Learning step: -1.30760657787323
desired expected reward: 3.5129146575927734



action possibilites: [-1] 
expected returns: [[24.394361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 14.0
Learning step: -3.253979444503784
desired expected reward: 47.803077697753906





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.079075]
 [18.161232]
 [12.163308]
 [17.671915]
 [22.920324]
 [18.929157]
 [27.103107]
 [19.339285]
 [12.57691 ]
 [13.334476]
 [17.56659 ]
 [11.787411]
 [15.182215]
 [23.911913]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  8.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -1.977643609046936
desired expected reward: 22.416717529296875



buy possibilites: [-1] 
expected returns: [[33.888866]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [14.] 
cards in deck: 33 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  7.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  0. 11.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -40.   0.   0.  20.   0.   0.   0.   0.  -4.   0.   0.
   8.   0.] 
sum of rewards: -21.0 

action type: buy - action 14.0
Learning step: -0.9163450598716736
desired expected reward: 11.66054630279541






Player: 1 
cards in hand: [ 0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  4.  1.  1.  8.  7.  7.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 25.  0.  6.] 
adversary cards in discard: [14. 14.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10 14] -> size -> 39 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23 16] -> size -> 64 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  3.  1.  1.  8.  7.  7.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 25.  0.  6.] 
adversary cards in discard: [14. 14.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10 14] -> size -> 39 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8. 16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23 16] -> size -> 64 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  3.  1.  1.  8.  7.  7.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 22. 25.  0.  6.] 
adversary cards in discard: [14. 14.  0.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10 14] -> size -> 39 
adversary victory points: 0
player victory points: 4 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 1 
Gold: 0 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 5 

Remodel: 1 
Workshop: 4 
Chapel: 2 
Witch: 1 
Poacher: 1 
Militia: 2 
Market: 0 
Village: 1 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 0. 22. 25.  0.  6.] 
cards in discard: [14. 14.  0.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  1  8  3  0 25 29  3  8  6 16  6 10  6  0 11  0  0
 10 14  0 11  6 15 11 29  6  3  3 22  3 10 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 21. 30. 13. 30.  8.  0.  3.  1.  0.  8.  7.  7.  9.  2.  9.  9.] 
adversary cards in hand: [0. 0.] 
adversary cards in discard: [10.  8.  0.  3.  3.  8. 10. 11.  0.  3. 29.  8.  6. 10.  0.  3. 11. 16.
  1.  3.  0.  3.  6. 10.  0.  3.  0. 25.  0.  0.  1.  0.  0.  3.  8. 16.
  0.  0. 16. 23.  0.  0.  1.  0.  0.  1.  8. 16.  8.] 
adversary owned cards: [11  3  3  0  0  6  0  6 10  0  1  0  0 10  0  0  0  6  0  8  3  0  1 11
  8 10 16 11  6  0  0  0 16  0  6  0 16  0  0  3  0  1  3  0  1  0  0  8
  1  8 10 11 10 29  8  3  3 11  3 25  3  8 23 16  8] -> size -> 65 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5 -500    0  -40    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -545 

action type: buy - action -1
Learning step: -28.944442749023438
desired expected reward: 4.944423675537109



