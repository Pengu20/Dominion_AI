 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.928488]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.262789726257324
desired expected reward: -11.503127098083496





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.776644]
 [21.68763 ]
 [20.659676]
 [17.224554]
 [23.541332]
 [22.658302]
 [21.630346]
 [22.270758]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5937317609786987
desired expected reward: 21.77594566345215



buy possibilites: [-1] 
expected returns: [[21.23745]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [16.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.443742752075195
desired expected reward: 7.780813217163086






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [16.  0.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.507221]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5482110977172852
desired expected reward: 20.689239501953125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[20.852762]
 [22.763748]
 [21.735792]
 [18.300674]
 [21.33469 ]
 [24.61745 ]
 [23.734419]
 [24.603199]
 [21.182333]
 [22.706463]
 [23.093317]
 [23.346878]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 6] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9.  9. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5931198596954346
desired expected reward: 22.160436630249023



buy possibilites: [-1] 
expected returns: [[23.655865]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 6.  0.  3.  3.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 10. 16.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5051369071006775
desired expected reward: 24.112314224243164






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 16.  0.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 6. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [3. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.092224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6138944625854492
desired expected reward: 23.041969299316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.896194]
 [22.807182]
 [21.779226]
 [18.344107]
 [24.660881]
 [23.777855]
 [22.749897]
 [23.390306]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6131189465522766
desired expected reward: 22.79463768005371



buy possibilites: [-1] 
expected returns: [[24.174175]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [ 8. 16.  3. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.03866809606552124
desired expected reward: 22.71122932434082






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [ 8. 16.  3. 10.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3.  0.  0.  0. 11.] 
adversary cards in discard: [10.  3.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10] -> size -> 13 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.685608]
 [23.956182]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [10.  3.  6.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  9.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6278195381164551
desired expected reward: 23.546356201171875



action possibilites: [-1] 
expected returns: [[25.907944]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  6.  0.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.6478128433227539
desired expected reward: 19.121829986572266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.942356]
 [25.853344]
 [24.825388]
 [21.39027 ]
 [27.707043]
 [26.824015]
 [25.796059]
 [26.43647 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  6.  0.  0.  0. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  9.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.05613979324698448
desired expected reward: 25.851804733276367



buy possibilites: [-1] 
expected returns: [[24.92595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [10.  3.  6.  0.  0.  0. 16.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 30. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 10.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.929985046386719
desired expected reward: 12.460283279418945






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3. 10.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 30. 30.  8.  8.  8.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1.  0.  0.] 
cards in discard: [16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[23.081867]
 [22.441458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [16.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6555220484733582
desired expected reward: 24.270427703857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.70354 ]
 [21.586567]
 [18.151451]
 [23.585196]
 [23.19765 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [16.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6201801896095276
desired expected reward: 22.708024978637695



buy possibilites: [-1] 
expected returns: [[23.51676]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 10.  3.  0.] 
cards in discard: [0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3. 16.  0.  3.] 
adversary cards in discard: [16.  3. 10.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5222263336181641
desired expected reward: 20.181312561035156






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 16.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [16.  3. 10.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 16.  0.] 
adversary cards in discard: [ 0.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [16.  3. 10.  1.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  9. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 16.  0.] 
adversary cards in discard: [ 0.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16.  0.  3.] 
cards in discard: [16.  3. 10.  1.  0.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  6.  0. 16.  0.] 
adversary cards in discard: [ 0.  0.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[21.878092]
 [19.910376]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 16.  0.] 
cards in discard: [ 0.  0.  6. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6331390738487244
desired expected reward: 22.883621215820312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[20.032742]
 [21.905603]
 [20.893679]
 [17.565536]
 [23.756372]
 [22.874653]
 [21.846146]
 [22.497177]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 16.  0.] 
cards in discard: [ 0.  0.  6. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  9.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5791206955909729
desired expected reward: 21.385866165161133



buy possibilites: [-1] 
expected returns: [[21.140936]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 16.  0.] 
cards in discard: [ 0.  0.  6. 10.  3.  0. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.1007113829255104
desired expected reward: 23.65566062927246






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 3. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  0.  6. 10.  3.  0. 11.  0.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  3.  3.] 
adversary cards in discard: [ 0.  0.  6. 10.  3.  0. 11.  0.  6.  0. 16.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11] -> size -> 17 
adversary victory points: 1
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  0. 11.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.916395]
 [24.132118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0.  0.  6. 10.  3.  0. 11.  0.  6.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5353055596351624
desired expected reward: 20.60563087463379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[20.943382]
 [21.79189 ]
 [18.529438]
 [23.7574  ]
 [23.379925]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0.  0.  6. 10.  3.  0. 11.  0.  6.  0. 16.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6071878671646118
desired expected reward: 22.36594009399414



buy possibilites: [-1] 
expected returns: [[22.704258]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  3.  3.] 
cards in discard: [ 0.  0.  6. 10.  3.  0. 11.  0.  6.  0. 16.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [16.  0. 16.  3.  0.] 
adversary cards in discard: [3. 3. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.325361967086792
desired expected reward: 21.466527938842773






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [16.  0. 16.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 16.  3.  0.] 
cards in discard: [3. 3. 8. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 16 10  8  1 16  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 3. 8. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 3. 8. 0. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  8. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3. 3. 8. 0. 0. 6. 8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  3.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[21.590565]
 [20.93925 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6058973073959351
desired expected reward: 22.098360061645508



action possibilites: [-1. 11.] 
expected returns: [[22.43106 ]
 [23.690258]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10. 10. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.061667345464229584
desired expected reward: 21.12139129638672



action possibilites: [-1.] 
expected returns: [[25.994555]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 7
Learning step: 1.2140370607376099
desired expected reward: 20.844228744506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.971565]
 [25.860765]
 [24.831976]
 [21.500036]
 [27.711533]
 [26.82981 ]
 [25.801023]
 [26.452337]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.5414645671844482
desired expected reward: 26.53601837158203



buy possibilites: [-1] 
expected returns: [[24.652508]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [29. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1.  0.  0.  8. 10.] 
adversary cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 10.0
Learning step: 1.074820637702942
desired expected reward: 26.875844955444336






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8. 10.] 
cards in discard: [ 3.  3.  8.  0.  0.  6.  8. 16.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  9. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  8. 16.] 
cards in discard: [29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  0. 11.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[22.140194]
 [23.315638]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  7.  8.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6490426659584045
desired expected reward: 24.00346565246582



action possibilites: [-1] 
expected returns: [[24.10735]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  8.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.6298568844795227
desired expected reward: 19.07219886779785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.025892]
 [23.936403]
 [22.907614]
 [19.541645]
 [25.78717 ]
 [24.90545 ]
 [23.876661]
 [24.527973]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  8.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.022183170542120934
desired expected reward: 24.085166931152344



buy possibilites: [-1] 
expected returns: [[23.198559]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0.49071407318115234
desired expected reward: 25.253074645996094






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 3.] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  1 16  8  6  8 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  0.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11] -> size -> 22 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  0.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [16.  3.  6.  0.  0.] 
adversary cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11] -> size -> 22 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [16.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[22.307316]
 [20.643116]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  0.  0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6178855895996094
desired expected reward: 22.580673217773438



action possibilites: [-1] 
expected returns: [[21.503525]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 2
Learning step: -8.970573425292969
desired expected reward: 12.574798583984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.291252]
 [17.00219 ]
 [21.614767]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01242828369140625
desired expected reward: 21.515953063964844



buy possibilites: [-1] 
expected returns: [[20.89401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0.] 
cards in discard: [29. 10. 10. 11.  3.  0.  0.  0. 16. 11. 11.  0.  3.  0.  0.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 3. 6. 3.] 
adversary cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.0906495675444603
desired expected reward: 19.381900787353516






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [8. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3. 6. 3.] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  1 16  8  6  8 29] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [29. 10.  1.  0.  0.  8. 16.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [11. 10.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0] -> size -> 23 
adversary victory points: 1
player victory points: -1 





Player: 0 
cards in hand: [11. 10.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[23.251886]
 [24.465803]
 [22.638474]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 1. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5274984836578369
desired expected reward: 20.366512298583984



action possibilites: [-1] 
expected returns: [[26.883991]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0.2358068823814392
desired expected reward: 25.784975051879883





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[24.41772 ]
 [21.948624]
 [26.873596]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  3.] 
cards in discard: [10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  6.  6.  7.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
adversary victory points: -1
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09501331299543381
desired expected reward: 26.788978576660156



buy possibilites: [-1] 
expected returns: [[25.719563]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  3.] 
cards in discard: [10.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  5.  6.  7.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 1. 29.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.938403129577637
desired expected reward: 13.010220527648926






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [ 1. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  5.  6.  7.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6. 29.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6] -> size -> 25 
adversary victory points: 0
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 29. 30. 29. 30.  8.  5.  6.  7.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6. 29.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6] -> size -> 25 
adversary victory points: 0
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 29.  0.  8.  0.] 
cards in discard: [11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  5.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  0. 11.  6. 29.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6] -> size -> 25 
adversary victory points: 0
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0. 11.  6. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[20.858368]
 [22.00077 ]
 [21.99491 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6. 29.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  5.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  8.  6. 10.  8.] 
adversary cards in discard: [11.  1. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29 11] -> size -> 12 
adversary victory points: -1
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6931653022766113
desired expected reward: 25.026397705078125



action possibilites: [-1] 
expected returns: [[19.563898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 29.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  8.  6. 10.  8.] 
adversary cards in discard: [11.  1. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29 11] -> size -> 12 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: gain_card_n - action 3
Learning step: -8.928479194641113
desired expected reward: 10.53482723236084





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.531498]
 [18.291508]
 [15.320811]
 [20.051905]
 [19.70557 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  6. 29.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  8.  6. 10.  8.] 
adversary cards in discard: [11.  1. 29.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  6  8 29 11] -> size -> 12 
adversary victory points: -1
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.057906243950128555
desired expected reward: 19.62180519104004






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [16.  8.  6. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  6. 10.  8.] 
cards in discard: [11.  1. 29.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  1 16  8  6  8 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  3. 16.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  8.] 
cards in discard: [11.  1. 29.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  3. 16.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 10.  8.] 
cards in discard: [11.  1. 29.  0.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 16. 10.  3. 16.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
adversary victory points: -1
player victory points: -1 





Player: 0 
cards in hand: [ 0. 16. 10.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 16.] 
expected returns: [[19.31429 ]
 [17.574572]
 [18.759989]
 [17.574572]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 10.  3. 16.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10 16  6  0 11  3 29 10 16 11  6  0 10
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7. 10.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 29.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5345302820205688
desired expected reward: 18.777379989624023



action possibilites: [-1] 
expected returns: [[27.28192]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 29.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 40 

action type: gain_card_n - action 9
Learning step: 0.7199191451072693
desired expected reward: 26.271286010742188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.220743]
 [22.908289]
 [27.484533]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  4.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 29.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.09902212023735046
desired expected reward: 27.182897567749023



buy possibilites: [-1] 
expected returns: [[26.65048]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 29.  0. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.957418441772461
desired expected reward: 13.950872421264648






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [16. 29.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 29. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 29.  0. 10.  0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 10  8  1 16  8  8 29 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 10.  0.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.66748]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [ 0. 16. 29. 10.  0.] 
adversary owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6796702146530151
desired expected reward: 25.970809936523438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.836758]
 [25.427309]
 [24.55868 ]
 [21.716188]
 [24.23606 ]
 [26.997398]
 [26.249594]
 [26.995674]
 [24.102692]
 [25.371185]
 [25.698368]
 [25.908672]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  6.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [ 0. 16. 29. 10.  0.] 
adversary owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6535198092460632
desired expected reward: 25.04592514038086



buy possibilites: [-1] 
expected returns: [[24.27621]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10.  6. 11. 10.  6.  6.  3.  6. 11.  0.  0.  6. 29. 25.  6. 16.  0. 10.
  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  8. 11.  8.  8.] 
adversary cards in discard: [ 0. 16. 29. 10.  0.] 
adversary owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 11.0
Learning step: -0.5700216889381409
desired expected reward: 26.4273738861084






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 0.  8. 11.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  8.  8.] 
cards in discard: [ 0. 16. 29. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  8  1 16  8  8 29 11  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.] 
cards in discard: [ 0. 16. 29. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.] 
cards in discard: [ 0. 16. 29. 10.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6. 25. 11.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6. 25. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.] 
expected returns: [[20.221867]
 [22.91762 ]
 [21.440628]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 25. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0] -> size -> 10 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.648814857006073
desired expected reward: 23.627395629882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.954878]
 [15.519345]
 [20.328344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 25. 11.  0.  3.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16.  0.  0. 11.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0] -> size -> 10 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5651114583015442
desired expected reward: 19.716495513916016



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [16.  0.  0. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 11.  1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  8. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 25. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  1.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 25. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  1.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0. 11.  6.  0.] 
adversary cards in discard: [ 6. 25. 11.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[21.98754 ]
 [23.158337]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11.  6.  0.] 
cards in discard: [ 6. 25. 11.  0.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  6.  5.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 29. 10.] 
adversary cards in discard: [29. 11. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5211078524589539
desired expected reward: 19.807235717773438



action possibilites: [-1] 
expected returns: [[20.866285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 29. 10.] 
adversary cards in discard: [29. 11. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 4
Learning step: 0.5958477258682251
desired expected reward: 19.037456512451172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.945383]
 [19.678177]
 [16.825567]
 [21.412409]
 [21.065338]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  7.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 29. 10.] 
adversary cards in discard: [29. 11. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.033494625240564346
desired expected reward: 20.8997802734375



buy possibilites: [-1] 
expected returns: [[23.820711]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 0.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  8.  0. 29. 10.] 
adversary cards in discard: [29. 11. 16.  0.  0.  1.] 
adversary owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0.30017584562301636
desired expected reward: 21.71258544921875






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [ 8.  8.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  0. 29. 10.] 
cards in discard: [29. 11. 16.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 10  1 16  8  8 29 11  0 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 10.  0.  0. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [29. 11. 16.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 10.  0.  0. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [29. 11. 16.  0.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [16. 10.  0.  0. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [16. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10. 10.] 
expected returns: [[20.554792]
 [18.718527]
 [19.971819]
 [19.971819]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 10.  0.  0. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6551229357719421
desired expected reward: 23.16558837890625



action possibilites: [-1. 16. 10. 11.] 
expected returns: [[20.528276]
 [18.846323]
 [19.99706 ]
 [21.675688]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 10. 11.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  6.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.06661909073591232
desired expected reward: 20.036596298217773



action possibilites: [-1. 16. 10.] 
expected returns: [[20.612314]
 [19.045881]
 [20.1159  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 39 

action type: gain_card_n - action 6
Learning step: 0.8907657265663147
desired expected reward: 17.220352172851562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.712713]
 [19.392069]
 [16.81326 ]
 [20.994184]
 [20.656277]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  5.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.637953519821167
desired expected reward: 21.25026512145996



buy possibilites: [-1] 
expected returns: [[19.571173]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 8.  1. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 8.0
Learning step: 0.8656718134880066
desired expected reward: 21.859853744506836






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 29.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1 16  8  8 11  0 29] -> size -> 9 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  5.  5.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 29.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 29.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [16.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 29.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0.] 
cards in discard: [16. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 29.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  6.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[17.65832]
 [18.71684]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 29.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  8. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5450541377067566
desired expected reward: 19.026119232177734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.74236 ]
 [13.936986]
 [17.69187 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  3. 29.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [23.  8. 16.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5099572539329529
desired expected reward: 17.14836311340332



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [23.  8. 16.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 16.  8.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  8. 16.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  6. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


action possibilites: [-1.  8. 16.  8. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
action values: 1 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  6. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23] -> size -> 11 
action values: 0 
buys: 2 
player value: 2 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  4.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  6. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  8. 11.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 29. 30. 29. 30.  8.  3.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  6. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16.  0.  8. 11.] 
cards in discard: [8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  3.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 6. 11.  3.  6. 10.] 
adversary cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
adversary victory points: -2
player victory points: 0 





Player: 0 
cards in hand: [ 6. 11.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[18.285612]
 [19.403002]
 [17.746214]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  6. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 30.  8.  3.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 16.  1.  0.  0.] 
adversary cards in discard: [ 8.  0. 23.  8. 16.  0.  8. 11.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.48479220271110535
desired expected reward: 17.207075119018555



action possibilites: [-1] 
expected returns: [[17.145334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  6. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  3.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 16.  1.  0.  0.] 
adversary cards in discard: [ 8.  0. 23.  8. 16.  0.  8. 11.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: gain_card_n - action 0
Learning step: 0.14365613460540771
desired expected reward: 16.35598373413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.354748]
 [13.568342]
 [17.104176]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  3.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 16.  1.  0.  0.] 
adversary cards in discard: [ 8.  0. 23.  8. 16.  0.  8. 11.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
adversary victory points: 0
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.10043506324291229
desired expected reward: 17.245769500732422



buy possibilites: [-1] 
expected returns: [[16.22035]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  6. 10.] 
cards in discard: [ 6. 25. 11.  0.  3. 16.  8. 11.  6.  0.  6.  0.  8.  8. 10. 11. 16.  0.
  0. 10.  0.  3.  6.  3. 29.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [29. 16.  1.  0.  0.] 
adversary cards in discard: [ 8.  0. 23.  8. 16.  0.  8. 11.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[  -5    0    0    0    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -285 

action type: buy - action 6.0
Learning step: -8.786735534667969
desired expected reward: 4.781607627868652






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [29. 16.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 16.  1.  0.  0.] 
cards in discard: [ 8.  0. 23.  8. 16.  0.  8. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 16. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  0. 23.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
action values: 1 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0] -> size -> 13 
action values: 0 
buys: 2 
player value: 6 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10. 10.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 


buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  0.  8.] 
cards in discard: [15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.  0.  8.] 
cards in discard: [15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 23.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3. 11.  6.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 3. 11.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.221395]
 [21.420183]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  5.  3.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8. 11.] 
adversary cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4164222776889801
desired expected reward: 15.80392837524414



action possibilites: [-1] 
expected returns: [[23.533703]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  4.  3.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8. 11.] 
adversary cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 5
Learning step: 0.4181288778781891
desired expected reward: 18.768768310546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.542725]
 [22.318062]
 [19.218283]
 [24.15673 ]
 [23.747747]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  4.  3.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8. 11.] 
adversary cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.018829593434929848
desired expected reward: 23.514873504638672



buy possibilites: [-1] 
expected returns: [[23.573215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 0. 0.] 
cards in discard: [11.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 16.  8.  8. 11.] 
adversary cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  8  0] 
sum of rewards: 22 

action type: buy - action 8.0
Learning step: 0.18281684815883636
desired expected reward: 24.339548110961914






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [ 0. 16.  8.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  8. 11.] 
cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
adversary victory points: -3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  8.  8.] 
cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  8.] 
cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  8.  8.] 
cards in discard: [15.  0. 29. 23. 16.  1.  0.  0.  8.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 3.  8.  0. 10.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
adversary victory points: -3
player victory points: 0 





Player: 0 
cards in hand: [ 3.  8.  0. 10.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[19.957552]
 [20.351719]
 [19.430893]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10.  6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6471853256225586
desired expected reward: 22.926029205322266



action possibilites: [-1.  8. 16.] 
expected returns: [[17.35727 ]
 [17.727634]
 [15.815061]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  6. 16.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  6 11 10  6  0 11  3 29 10 16 11  6  0 10  6
  6 25  6 11 16  8  8  8  0  6 11  8] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.04682121053338051
desired expected reward: 19.477712631225586



action possibilites: [-1.] 
expected returns: [[21.761824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 13
Learning step: 0.7350417971611023
desired expected reward: 18.85028648376465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.85748 ]
 [17.621933]
 [21.995193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [29.  1. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.6098640561103821
desired expected reward: 22.371686935424805






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [29.  1. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
adversary victory points: -4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 28. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
adversary victory points: -4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1. 16.  0.  0.] 
cards in discard: [1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0. 11.  3. 10.  8.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
adversary victory points: -4
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11.  3. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.  8.] 
expected returns: [[17.668495]
 [18.762772]
 [17.170033]
 [18.043919]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  3. 10.  8.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  2.  4.  4.  2.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6199989914894104
desired expected reward: 21.375194549560547



action possibilites: [-1] 
expected returns: [[19.489948]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  2.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 6
Learning step: 0.36388885974884033
desired expected reward: 14.055741310119629





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[17.56839 ]
 [15.591262]
 [19.542427]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  2.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.053906477987766266
desired expected reward: 19.543855667114258



buy possibilites: [-1] 
expected returns: [[16.570755]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  8.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [8. 0. 8. 8. 0.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.] 
adversary owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -8.843745231628418
desired expected reward: 6.747518539428711






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [8. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8. 8. 0.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16  8  8 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
adversary victory points: -5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 6. 11.  0.  6.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [ 6. 11.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[14.913989]
 [15.835392]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  6.  6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 16. 23. 15.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.484720915555954
desired expected reward: 16.086034774780273



action possibilites: [-1] 
expected returns: [[15.577302]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16. 23. 15.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -1  0  0  9  0] 
sum of rewards: 23 

action type: gain_card_n - action 9
Learning step: 0.3549097776412964
desired expected reward: 16.976638793945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[13.872245 ]
 [12.0718565]
 [15.647596 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 16. 23. 15.] 
adversary cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
adversary owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 17 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.13199767470359802
desired expected reward: 15.70930004119873






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 0.  0. 16. 23. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 16. 23. 15.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
adversary victory points: -5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16. 23.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
adversary victory points: -5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 23.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  1.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
adversary victory points: -5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16. 23.] 
cards in discard: [ 1. 29.  1. 16.  0.  0.  0.  8.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0.  6. 16.  3.  6.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
adversary victory points: -5
player victory points: 0 





Player: 0 
cards in hand: [ 0.  6. 16.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[14.384757]
 [13.151319]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  1. 29.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4719166159629822
desired expected reward: 15.120621681213379





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.847037]
 [11.337315]
 [14.347554]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  1.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  1. 29.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.44352349638938904
desired expected reward: 13.94123363494873



buy possibilites: [-1] 
expected returns: [[13.382997]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 16.  3.  6.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 29. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 8.  1. 29.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8] -> size -> 17 
adversary victory points: 0
player victory points: -6 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   -2.
    0. -300.    0.    0.] 
sum of rewards: -307.0 

action type: buy - action 6.0
Learning step: -9.409597396850586
desired expected reward: 1.9277172088623047






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 8.  1. 29.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.  1. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 29. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
adversary victory points: -6
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.  1.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.  1.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  5. 10.  9.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.  1.] 
cards in discard: [ 3. 10.] 
cards in deck: 12 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 29. 11.  8.  0.] 
adversary cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
adversary victory points: -6
player victory points: 1 





Player: 0 
cards in hand: [ 0. 29. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[10.591221]
 [11.453017]
 [11.448039]
 [10.896308]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11.  8.  0.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  6 11 10  6  0 11  3 29 10 11  6  0 10  6  6 25  6
 11 16  8  8  8  0  6 11  8  8  6 10  6] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [23.  0. 16. 16.  1.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10] -> size -> 19 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4342225193977356
desired expected reward: 12.948774337768555



action possibilites: [-1] 
expected returns: [[10.1989]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [23.  0. 16. 16.  1.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10] -> size -> 19 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.3098503053188324
desired expected reward: 8.551121711730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.848687]
 [10.240264]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [11.  8. 11.  3.  6.  0.  0. 10.  8.  6.  8.  6. 11.  0.  3. 10.  8. 10.
 11.  6.  0.  6.  6.  6.  0.  6. 16.  3.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [23.  0. 16. 16.  1.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.] 
adversary owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10] -> size -> 19 
adversary victory points: 1
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24571111798286438
desired expected reward: 10.444611549377441






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [23.  0. 16. 16.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 16. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 16. 16.  1.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 16 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 30. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  1.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 27. 29. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 27. 29. 28. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
adversary victory points: -6
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  0.  1.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 3.  6. 10.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
adversary victory points: -6
player victory points: 2 





Player: 0 
cards in hand: [ 3.  6. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[11.483825]
 [11.059114]
 [13.66294 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 10.  0. 25.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3268439471721649
desired expected reward: 9.913419723510742



action possibilites: [-1. 25.] 
expected returns: [[10.304162]
 [12.412578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  0. 25.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [22. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.238892063498497
desired expected reward: 11.325047492980957





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.626425]
 [10.325015]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 25.  6.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.24215374886989594
desired expected reward: 10.546316146850586



buy possibilites: [-1] 
expected returns: [[10.070076]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  0. 25.  6.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 15.  0.] 
adversary cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
adversary victory points: 2
player victory points: -6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  0.  0.] 
sum of rewards: 14.0 

action type: buy - action 0.0
Learning step: 0.2669430375099182
desired expected reward: 8.893367767333984






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0] -> size -> 36 
adversary victory points: -6
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 27. 29. 27. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0] -> size -> 36 
adversary victory points: -6
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 15.  0.] 
cards in discard: [ 3. 10. 11.  8.  1. 29.  1.  2.  3. 16. 23.  0.  1.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [ 0. 11.  0.  6.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0] -> size -> 36 
adversary victory points: -6
player victory points: 3 





Player: 0 
cards in hand: [ 0. 11.  0.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[14.248037]
 [15.197109]
 [14.58706 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  6.  8.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  9.] 
adversary cards in hand: [16.  0. 23.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.2968981862068176
desired expected reward: 9.773178100585938



action possibilites: [-1] 
expected returns: [[13.919742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  8.] 
adversary cards in hand: [16.  0. 23.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -2  0  0 16  0] 
sum of rewards: 29 

action type: gain_card_n - action 8
Learning step: 0.5719695091247559
desired expected reward: 15.378229141235352





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[12.5198765]
 [13.029095 ]
 [13.996811 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  8.] 
adversary cards in hand: [16.  0. 23.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.1725292056798935
desired expected reward: 14.092270851135254



buy possibilites: [-1] 
expected returns: [[13.007229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 8.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  8.] 
adversary cards in hand: [16.  0. 23.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -3.  0.  0.  0.  0.] 
sum of rewards: 12.0 

action type: buy - action 0.0
Learning step: 0.12250708043575287
desired expected reward: 12.64238452911377






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [16.  0. 23.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 23.  8.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16 23  8  0 15  0  1  0  1  0  8  3 10  2  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  4. 10.  8.] 
adversary cards in hand: [11. 11.  3.  8. 16.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  3. 10.  8.] 
adversary cards in hand: [11. 11.  3.  8. 16.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0.] 
cards in discard: [10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  3. 10.  8.] 
adversary cards in hand: [11. 11.  3.  8. 16.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0] -> size -> 38 
adversary victory points: -6
player victory points: 3 





Player: 0 
cards in hand: [11. 11.  3.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8. 16.] 
expected returns: [[10.874555 ]
 [11.7754135]
 [11.7754135]
 [11.210374 ]
 [ 9.623888 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  3.  8. 16.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7. 10.  9.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [10. 16.  0.  8.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4226522743701935
desired expected reward: 12.584576606750488



action possibilites: [-1] 
expected returns: [[10.564082]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8. 16.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [10. 16.  0.  8.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 27 

action type: gain_card_n - action 6
Learning step: 0.6822841763496399
desired expected reward: 8.636908531188965





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.295983]
 [10.620613]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8. 16.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [10. 16.  0.  8.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.23903053998947144
desired expected reward: 10.803112983703613



buy possibilites: [-1] 
expected returns: [[9.845392]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  8. 16.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [10. 16.  0.  8.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0  0  0] 
sum of rewards: 10 

action type: buy - action 0.0
Learning step: 0.12449712306261063
desired expected reward: 9.420480728149414






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  0.] 
cards in discard: [10. 16.  0.  8.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [8. 8. 6. 6. 6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.  2.] 
cards in discard: [10. 16.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [8. 8. 6. 6. 6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  2.] 
cards in discard: [10. 16.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [8. 8. 6. 6. 6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.  2.] 
cards in discard: [10. 16.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 5 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [8. 8. 6. 6. 6.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
adversary owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
adversary victory points: -6
player victory points: 3 





Player: 0 
cards in hand: [8. 8. 6. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[10.379727]
 [10.668397]
 [10.668397]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 6. 6. 6.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  6 11 10  6  0 11  3 10 11  6  0 10  6  6 25  6 11 16
  8  8  8  0  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
adversary victory points: 3
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.33415186405181885
desired expected reward: 9.511240005493164



action possibilites: [-1] 
expected returns: [[13.511793]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 6
Learning step: 0.3680950999259949
desired expected reward: 7.827385425567627





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[12.077306]
 [13.568   ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [3. 1. 0. 0. 3.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.18084926903247833
desired expected reward: 13.692642211914062






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [3. 1. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 11.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 11.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 0. 3.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  0. 11.  8.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
adversary victory points: -3
player victory points: 3 





Player: 0 
cards in hand: [ 6.  6.  0. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[ 9.768327]
 [10.580712]
 [10.072794]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11.  8.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 11 10  0 11  3 10 11  0 10  6  6 25  6 11 16  8  8  0
  6 11  8  8  6 10  6  0 15  0 14  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 8.  1.  1. 15. 11.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
adversary victory points: 3
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.44963932037353516
desired expected reward: 13.118359565734863



action possibilites: [-1] 
expected returns: [[10.902568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 8.  1.  1. 15. 11.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.26211678981781006
desired expected reward: 10.340788841247559





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.334544 ]
 [10.9729805]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 8.  1.  1. 15. 11.] 
adversary cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.231257826089859
desired expected reward: 11.133825302124023






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 8.  1.  1. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 11.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  1. 15. 11.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1.  1. 11.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  1. 11.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1.  1. 11.] 
cards in discard: [10. 16.  0.  8.  0.  0. 10.  0. 29.  3.  0.  2.  1.  3.  1.  0.  0.  3.
  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [11.  3.  0. 10.  0.] 
adversary cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [11.  3.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[ 9.77078  ]
 [10.5528755]
 [ 9.444806 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0. 10.  0.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  3. 10.  8.] 
adversary cards in hand: [ 1.  8. 11.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.37367671728134155
desired expected reward: 10.599305152893066



action possibilites: [-1] 
expected returns: [[9.074233]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 1.  8. 11.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 7
Learning step: 0.5747631192207336
desired expected reward: 8.642532348632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.932381]
 [8.3731  ]
 [9.191193]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  0.] 
cards in discard: [ 0. 10.  3.  6.  0. 25.  6. 15.  0. 11.  0.  0.  6.  8. 14.  0. 11. 11.
  3.  8. 16.  8.  8.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 1.  8. 11.  1. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0] -> size -> 24 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.26846519112586975
desired expected reward: 9.342698097229004






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 11.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.  1. 10.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 26. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  1. 10.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  1. 10.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  4.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  1. 10.] 
cards in discard: [ 1. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [ 8. 10.  0.  6. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 10.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[7.885206 ]
 [8.2460165]
 [7.518144 ]
 [7.518144 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0.  6. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.34296736121177673
desired expected reward: 8.848224639892578



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[8.537451]
 [8.887887]
 [8.184136]
 [9.437684]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  6. 10. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3 10  0 11  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8
  8  6 10  6  0 15  0 14  0 10] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.31787383556365967
desired expected reward: 7.8360185623168945



action possibilites: [-1. 10.] 
expected returns: [[11.235683]
 [10.885012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.8644322156906128
desired expected reward: 10.933422088623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.873983]
 [11.385689]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.8261300921440125
desired expected reward: 12.061814308166504






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8. 15.] 
adversary cards in discard: [10.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11] -> size -> 26 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  8.] 
adversary cards in hand: [10. 11.  0.  8. 15.] 
adversary cards in discard: [10.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  7.] 
adversary cards in hand: [10. 11.  0.  8. 15.] 
adversary cards in discard: [10.  8.  6. 10.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [10. 11.  0.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8. 15.] 
expected returns: [[10.696749 ]
 [10.327899 ]
 [11.641142 ]
 [11.063973 ]
 [10.5834675]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8. 15.] 
cards in discard: [10.  8.  6. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  7.] 
adversary cards in hand: [ 8. 16. 10.  0.  3.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3758780360221863
desired expected reward: 11.009810447692871



action possibilites: [-1] 
expected returns: [[11.784485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 15.] 
cards in discard: [10.  8.  6. 10. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 16. 10.  0.  3.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0.7218178510665894
desired expected reward: 11.785791397094727





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[10.316534]
 [11.892896]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8. 15.] 
cards in discard: [10.  8.  6. 10. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 16. 10.  0.  3.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.21472011506557465
desired expected reward: 11.999204635620117






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 8. 16. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16. 10.  0.  3.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [10. 25.  0. 16.  6.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 10.  0.  3.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [10. 25.  0. 16.  6.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 16. 10.  0.  3.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [10. 25.  0. 16.  6.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [10. 25.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 16.] 
expected returns: [[8.117523 ]
 [7.8314147]
 [9.707509 ]
 [7.131692 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  0. 16.  6.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [15.  1.  2.  3.  1.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.41754600405693054
desired expected reward: 11.475349426269531



action possibilites: [-1. 25. 16.] 
expected returns: [[ 8.90996 ]
 [10.618549]
 [ 7.8672  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 16.  6.  3.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [15.  1.  2.  3.  1.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.31406453251838684
desired expected reward: 8.145479202270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.5704007]
 [8.863036 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  0. 16.  6.  3.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [15.  1.  2.  3.  1.] 
adversary cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.2703339755535126
desired expected reward: 9.18029499053955






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [15.  1.  2.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  2.  3.  1.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 11.  6.  0. 10.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  2.  3.  1.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 7 
card supply: [16. 25. 29. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 11.  6.  0. 10.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  2.  3.  1.] 
cards in discard: [ 1. 11. 11.  1.  8.  1. 10. 15.  0.  0.  3.  0.  0.  0.  8. 16. 10.  0.
  3.  2.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 11.  6.  0. 10.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
adversary owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 11.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
expected returns: [[15.892611]
 [16.217709]
 [16.731834]
 [15.560954]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  6.  0. 10.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  0  3 10 11  0 10 25  6 11 16  8  8  0  6 11  8  8  6
 10  6  0 15  0 14  0 10 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.24550774693489075
desired expected reward: 8.617528915405273



action possibilites: [-1] 
expected returns: [[10.156051]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.14989708364009857
desired expected reward: 13.650727272033691





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 8.785209]
 [10.181723]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24636122584342957
desired expected reward: 10.402411460876465



buy possibilites: [-1] 
expected returns: [[9.25337]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 1.  0.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.28360411524772644
desired expected reward: 9.068812370300293






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 14.  3.  0.  3.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  6.] 
adversary cards in hand: [ 8. 14.  3.  0.  3.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  0. 29.] 
cards in discard: [15.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [ 8. 14.  3.  0.  3.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 8. 14.  3.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[8.907859]
 [9.223456]
 [7.738446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  3.  0.  3.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3357965052127838
desired expected reward: 8.917573928833008





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[7.57809 ]
 [8.903336]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.  3.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.32931679487228394
desired expected reward: 8.57854175567627



buy possibilites: [-1] 
expected returns: [[10.973534]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  3.  0.  3.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [8. 0. 1. 0. 0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.26212063431739807
desired expected reward: 7.315969944000244






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [15.  1.  0.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [15.  1.  0.  0.  0. 29.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [14. 25. 28. 26. 30.  8.  0.  4.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 1. 0. 0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 25. 28. 26. 30.  8.  0.  3.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [ 0.  0.  0.  6. 11.] 
adversary cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0] -> size -> 33 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0.  0.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[8.064649]
 [8.789167]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  6. 11.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  3.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [15.  2.  3.  1.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38996270298957825
desired expected reward: 10.58357048034668



action possibilites: [-1] 
expected returns: [[7.574629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [15.  2.  3.  1.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 3
Learning step: 0.7912552952766418
desired expected reward: 8.0671968460083





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[6.368105]
 [7.363558]
 [6.796967]
 [8.352774]
 [7.310555]
 [7.591206]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  9.  2. 10.  5.] 
adversary cards in hand: [15.  2.  3.  1.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3015983998775482
desired expected reward: 7.876227378845215



buy possibilites: [-1] 
expected returns: [[5.7614803]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6.] 
cards in discard: [10.  8.  6. 10. 15. 11. 10.  0.  8. 15. 10. 25.  0. 16.  6.  3.  0.  8.
  6.  0.  0.  8. 14.  3.  0.  3. 16. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  9.  1. 10.  5.] 
adversary cards in hand: [15.  2.  3.  1.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.8311789035797119
desired expected reward: 8.141733169555664






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [15.  2.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  2.  3.  1.  1.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  9.  1. 10.  5.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  3.  1.  1.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16] -> size -> 31 
action values: 0 
buys: 1 
player value: 7 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  9.  1. 10.  5.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  2.  3.  1.  1.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 6. 16.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16 10] -> size -> 35 
adversary victory points: -1
player victory points: 3 





Player: 0 
cards in hand: [ 6. 16.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[10.82444 ]
 [ 9.616861]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25  6 11 16  8  8  0  6 11  8  8  6 10  6
  0 15  0 14  0 10 15  0  0 16 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 26. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [10.  2. 16.  0.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.21425960958003998
desired expected reward: 5.547220706939697



action possibilites: [-1] 
expected returns: [[10.543922]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [10.  2. 16.  0.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 19 

action type: gain_card_n - action 1
Learning step: 0.4748261272907257
desired expected reward: 7.337661266326904





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.338259 ]
 [ 9.8357525]
 [10.762463 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [3.] 
cards in deck: 30 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [10.  2. 16.  0.  1.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.24010562896728516
desired expected reward: 10.784028053283691






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [10.  2. 16.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  2. 16.  0.  1.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 16. 15.] 
adversary cards in discard: [ 3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 16.  0.  1. 10.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 16. 15.] 
adversary cards in discard: [ 3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 2. 16.  0.  1.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 16. 15.] 
adversary cards in discard: [ 3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 16.  0.  1.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23] -> size -> 32 
action values: 0 
buys: 1 
player value: 7 
card supply: [14. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 16. 15.] 
adversary cards in discard: [ 3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 2. 16.  0.  1.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 7 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [ 3.  0.  0. 16. 15.] 
adversary cards in discard: [ 3. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 3.  0.  0. 16. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.] 
expected returns: [[9.207542]
 [8.024556]
 [9.109114]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 16. 15.] 
cards in discard: [ 3. 16.  3.  0.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
 15  0 14  0 10 15  0  0 16 10  3] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  8.  1. 10.  5.] 
adversary cards in hand: [11. 11. 15.  8.  0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.37978264689445496
desired expected reward: 10.38267993927002



action possibilites: [-1] 
expected returns: [[8.585149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 11. 15.  8.  0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 25  0] 
sum of rewards: 40 

action type: gain_card_n - action 10
Learning step: 0.970909833908081
desired expected reward: 11.612048149108887





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.2570214]
 [7.770571 ]
 [8.726545 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23.] 
cards in deck: 25 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 11. 15.  8.  0.] 
adversary cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.27728286385536194
desired expected reward: 8.862431526184082






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [11. 11. 15.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  8.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  6.  3. 15.  0.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  8.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  6.  3. 15.  0.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11. 15.  8.  0.] 
cards in discard: [15.  1.  0.  0.  0. 29. 16.  8.  0.  1.  0.  0. 23. 15.  2.  3.  1.  1.
  0. 10. 10.  2. 16.  0.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  6.  3. 15.  0.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  6.  3. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[9.067846]
 [8.98549 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  3. 15.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0
  0 14  0 10 15  0  0 16 10  3 23] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [15. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.3169298470020294
desired expected reward: 8.409614562988281



action possibilites: [-1] 
expected returns: [[6.5114713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [15. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: 0.24880573153495789
desired expected reward: 9.234295845031738





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[5.4796314]
 [6.380225 ]
 [5.8640246]
 [5.6932354]
 [7.26588  ]
 [7.272767 ]
 [5.6053567]
 [6.3304234]
 [6.507743 ]
 [6.5726976]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [12. 25. 28. 25. 30.  8.  0.  2.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [15. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.322825163602829
desired expected reward: 6.834296226501465



buy possibilites: [-1] 
expected returns: [[5.390642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16.] 
cards in deck: 20 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23 16] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [15. 11.  0.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 16.0
Learning step: 1.2958046197891235
desired expected reward: 6.989040374755859






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [15. 11.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23 16] -> size -> 35 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  3.  3.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23 16] -> size -> 35 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  3.  3.] 
cards in discard: [0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  0. 10.  0.  8.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23 16] -> size -> 35 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[10.29314 ]
 [ 9.970288]
 [10.663223]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  8.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0
 14  0 10 15  0  0 16 10  3 23 16] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.20273186266422272
desired expected reward: 5.187910079956055



action possibilites: [-1] 
expected returns: [[10.315248]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.31907692551612854
desired expected reward: 8.2935152053833





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 9.076716]
 [10.451078]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.2445065975189209
desired expected reward: 10.559754371643066



buy possibilites: [-1] 
expected returns: [[9.014824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8.  0.  0.  0. 10.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.] 
adversary owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.2723540961742401
desired expected reward: 9.349071502685547






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [ 8.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  0. 10.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 10. 10.  6. 10.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
adversary owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  1 11  0 29 16  8  0 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0
  1 11 15  0  2 15 16 23  0  0  0] -> size -> 35 
action values: 2 
buys: 0 
player value: 0 
card supply: [10. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 10. 10.  6. 10.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
adversary owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 10. 10.  6. 10.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
adversary owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 10. 10.  6. 10.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
adversary owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 10. 10.  6. 10.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
adversary owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
adversary victory points: 1
player victory points: 3 





Player: 0 
cards in hand: [10. 10. 10.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 10.] 
expected returns: [[8.035194]
 [7.7242  ]
 [7.7242  ]
 [7.7242  ]
 [7.7242  ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 10.  6. 10.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3381650447845459
desired expected reward: 8.676658630371094



action possibilites: [-1. 10. 10. 10.] 
expected returns: [[8.167229 ]
 [7.8471413]
 [7.8471413]
 [7.8471413]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  6. 10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.3020133376121521
desired expected reward: 8.026212692260742



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[11.185337]
 [10.864416]
 [10.864416]
 [11.588402]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 10.  0.  8.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 3  3  0  3 10  0 10 25 11 16  8  8  0  6 11  8  8  6 10  6  0  0 14  0
 10 15  0  0 16 10  3 23 16  0] -> size -> 34 
action values: 3 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 10.0
Learning step: 0.9265162944793701
desired expected reward: 8.77365779876709



action possibilites: [-1. 10.] 
expected returns: [[8.065723 ]
 [7.8094845]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 6
Learning step: 1.492608904838562
desired expected reward: 9.526106834411621





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[6.948482]
 [8.136717]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 10.  8.] 
owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
adversary owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1.0
Learning step: 1.4884732961654663
desired expected reward: 9.55419635772705






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  0  1  0  1  0  8  3 10  2  3  3 10  0  1  0  1 11 15
  0  2 15 16 23  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8. 25.  6. 14. 11.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
adversary owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8. 25.  6. 14. 11.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
adversary owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 8. 25.  6. 14. 11.] 
adversary cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
adversary owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 8. 25.  6. 14. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 14. 11.] 
expected returns: [[11.3368635]
 [11.684527 ]
 [13.137084 ]
 [10.182538 ]
 [12.174924 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  6. 14. 11.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0 10 25 11 16  8  8  0 11  8  8  6 10  6  0  0 14  0 10 15
  0  0 16 10  3 23 16  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 15.  1. 29.  0.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.2682068645954132
desired expected reward: 7.868510723114014



action possibilites: [-1] 
expected returns: [[6.8423877]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 15.  1. 29.  0.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 11
Learning step: 0.16002072393894196
desired expected reward: 12.220832824707031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.7961  ]
 [6.962381]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 15.  1. 29.  0.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3129349648952484
desired expected reward: 7.155322551727295



buy possibilites: [-1] 
expected returns: [[7.790352]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 3. 16.  3.  0.  0. 23. 16.  3.  0.  0. 16. 15.  6.  3.  0.  0.  8. 10.
  0. 10. 10.  8. 10.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [11. 15.  1. 29.  0.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.3579156696796417
desired expected reward: 6.154016017913818






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [11. 15.  1. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 29.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  1. 29.  0.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  0  1  0  1 11 15  0  2 15
 16 23  0  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 6. 23.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 29.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 6. 23.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 25. 28. 25. 30.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 6. 23.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  1. 29.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4.] 
cards in deck: 13 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0  4] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 6. 23.  0.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 6. 23.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.  8. 11.] 
expected returns: [[6.5333652]
 [5.210293 ]
 [6.863345 ]
 [7.3095927]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23.  0.  8. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16
 10  3 23 16  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 16.  0. 23. 15.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0  4] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3139355480670929
desired expected reward: 7.476416110992432



action possibilites: [-1] 
expected returns: [[6.316606]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 23. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 16.  0. 23. 15.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0  4] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.37404105067253113
desired expected reward: 5.116816997528076





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.2757177]
 [6.4678984]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 23. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [10. 16.  0. 23. 15.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0  4] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.3234075605869293
desired expected reward: 6.640013694763184






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [10. 16.  0. 23. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 23. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0. 23. 15.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  0  1 11 15  0  2 15 16
 23  0  0  0  0  4] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [ 8.  6. 23. 11.] 
adversary owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16. 23.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [ 8.  6. 23. 11.] 
adversary owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16. 23.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  3.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [ 8.  6. 23. 11.] 
adversary owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16. 23.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  2.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [3. 0. 0. 8. 8.] 
adversary cards in discard: [ 8.  6. 23. 11.] 
adversary owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [3. 0. 0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[8.339241]
 [8.67687 ]
 [8.67687 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 8.] 
cards in discard: [ 8.  6. 23. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  3  0 10 16  8  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10
  3 23 16  0  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  2.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  3.  1.  1. 16.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4 11] -> size -> 30 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.25387516617774963
desired expected reward: 6.214023113250732



action possibilites: [-1] 
expected returns: [[8.102686]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 8.  6. 23. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  2.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  3.  1.  1. 16.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4 11] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: 0.34936296939849854
desired expected reward: 6.539869785308838





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.264573 ]
 [7.6856594]
 [8.482959 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 8.  6. 23. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  2.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [ 0.  3.  1.  1. 16.] 
adversary cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4 11] -> size -> 30 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.29034656286239624
desired expected reward: 8.39303207397461






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  1.  1. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1.  1. 16.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8  3 10  2  3  3 10  1  1 11 15  0  2 15 16 23
  0  0  0  0  4 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  2.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [16.  3.  0. 16.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [16.  3.  0. 16.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  5.] 
adversary cards in hand: [16.  3.  0. 16.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1.] 
cards in discard: [ 0. 15. 11.  0.  3.  3.  0. 10.  8.  0.  8.  1.  4. 15. 11.  1. 29. 11.
 15. 10. 16. 23. 11. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [16.  3.  0. 16.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
adversary victory points: 1
player victory points: 5 





Player: 0 
cards in hand: [16.  3.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 16.] 
expected returns: [[9.906159]
 [8.868438]
 [8.868438]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0. 16.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [11. 16.  2.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.31811031699180603
desired expected reward: 8.559015274047852





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 8.708334]
 [ 9.171554]
 [10.001322]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0. 16.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 25. 28. 25. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [11. 16.  2.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
adversary victory points: 5
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.34811460971832275
desired expected reward: 9.55804443359375



buy possibilites: [-1] 
expected returns: [[9.041095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0. 16.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [11. 16.  2.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.09021511673927307
desired expected reward: 9.081338882446289






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [11. 16.  2.  1.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  2.  1.  2.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [10. 16.  3. 10.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  2.  1.  2.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 8 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  9.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [10. 16.  3. 10.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  2.  1.  2.] 
cards in discard: [25.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [10. 16.  3. 10.  0.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
adversary victory points: 2
player victory points: 5 





Player: 0 
cards in hand: [10. 16.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 10.] 
expected returns: [[6.5461526]
 [6.298306 ]
 [5.602759 ]
 [6.298306 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3. 10.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [15. 11. 11. 29.  1.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25] -> size -> 32 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3555203080177307
desired expected reward: 8.685574531555176





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[5.361978 ]
 [6.5292172]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3. 10.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [15. 11. 11. 29.  1.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25] -> size -> 32 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.28273019194602966
desired expected reward: 6.26342248916626



buy possibilites: [-1] 
expected returns: [[8.224805]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 16.  3. 10.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 25. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [15. 11. 11. 29.  1.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25] -> size -> 32 
adversary victory points: 5
player victory points: 2 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.22449888288974762
desired expected reward: 5.137479305267334






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [15. 11. 11. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 11. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11. 29.  1.] 
cards in discard: [25. 11. 16.  2.  1.  2.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 15.  8.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 29.  1.] 
cards in discard: [25. 11. 16.  2.  1.  2.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 15.  8.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 29.  1.] 
cards in discard: [25. 11. 16.  2.  1.  2.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 28. 24. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 15.  8.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 29.  1.] 
cards in discard: [25. 11. 16.  2.  1.  2.  1.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [ 0. 10.  6. 15.  8.] 
adversary cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10.  6. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.  8.] 
expected returns: [[6.525977 ]
 [6.2922416]
 [6.4756474]
 [6.841796 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6. 15.  8.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [23. 10.  0. 15. 10.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.3274914622306824
desired expected reward: 7.897313594818115



action possibilites: [-1. 15.  8.] 
expected returns: [[8.620368]
 [8.567614]
 [8.953566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 15.  8.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [23. 10.  0. 15. 10.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.3532315790653229
desired expected reward: 6.645472526550293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[7.4861817]
 [7.9083285]
 [8.667441 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 15.  8.  0.] 
cards in discard: [ 8.  6. 23. 11.  8.  0.  0.  3. 16.  3.  0. 16.  0.  0. 10. 16.  3. 10.
  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [23. 10.  0. 15. 10.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0.27696406841278076
desired expected reward: 8.897331237792969






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [23. 10.  0. 15. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 15. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  0. 15. 10.] 
cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 


action possibilites: [-1. 23. 15. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0. 15. 10. 16.] 
cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16 23  0
  0  0  0  4 11 11 15 25  1  3] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  1.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [16.  0.  3.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
adversary victory points: 2
player victory points: 6 


Player 1 won the game! 



Player 0 bought cards:
Copper: 10 
Silver: 0 
Gold: 0 
Estate: 2 
Duchy: 0 
Province: 0 
Curse: 7 

Remodel: 1 
Workshop: 4 
Chapel: 3 
Witch: 0 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [16.  0.  3.  0. 10.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  0 10 16  8  0 11  8  8  6 10  6  0  0  0 10 15  0  0 16 10  3 23
 16  0  0  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 28. 23. 29.  8.  0.  1.  0.  0.  8.  7.  9.  7.  1. 10.  4.] 
adversary cards in hand: [ 0. 15. 10.] 
adversary cards in discard: [25. 11. 16.  2.  1.  2.  1.  3. 11. 15. 11. 29.  1. 11.] 
adversary owned cards: [ 1 11 29 16  8 15  1  1  8 10  2  3  3 10  1  1 11 15  0  2 15 16  0  0
  0  0  4 11 11 15 25  1  3 11] -> size -> 34 
adversary victory points: 6
player victory points: 2 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.410021781921387
desired expected reward: -6.742580413818359



