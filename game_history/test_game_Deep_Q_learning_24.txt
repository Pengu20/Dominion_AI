 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.148361]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0     -150        0        0       20        0
        0        0        0     -160        0        0        0        0] 
sum of rewards: -3000295 

action type: gain_card_n - action 0
Learning step: -120011.5390625
desired expected reward: -120018.0625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[16.888027]
 [21.47821 ]
 [20.004827]
 [13.691256]
 [19.912514]
 [23.308847]
 [20.178442]
 [25.364807]
 [16.40211 ]
 [18.705065]
 [20.85334 ]
 [19.459146]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 19.75080680847168



buy possibilites: [-1] 
expected returns: [[23.962143]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 123 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 25.364803314208984






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [29.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.034664]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 23.962142944335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[22.281342]
 [26.647322]
 [25.281504]
 [18.671719]
 [28.472733]
 [25.384317]
 [24.018496]
 [25.180077]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 24.50499725341797



buy possibilites: [-1] 
expected returns: [[22.42485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [29.  0.  0.  0.  3.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 28.472732543945312






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[24.992516]
 [28.211452]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 22.424850463867188



action possibilites: [-1] 
expected returns: [[31.293114]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 31.66234588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.362629]
 [32.675083]
 [31.323338]
 [24.78761 ]
 [31.265602]
 [34.388893]
 [31.428185]
 [36.71333 ]
 [27.836824]
 [30.076435]
 [32.149284]
 [31.169956]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.293113708496094



buy possibilites: [-1] 
expected returns: [[38.792053]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [10. 29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0   0   0   0 128   0] 
sum of rewards: 143 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.71333694458008






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3.  3. 29.  0.  3.] 
adversary cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[53.607758]
 [60.712692]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 29.  0.  3.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 38.79205322265625



action possibilites: [-1.] 
expected returns: [[44.50335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 60.777366638183594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[42.173702]
 [47.836395]
 [46.03191 ]
 [37.415718]
 [50.114532]
 [46.25632 ]
 [44.451843]
 [45.172417]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 44.50334930419922



buy possibilites: [-1] 
expected returns: [[34.19058]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 0.] 
cards in discard: [10. 29. 11.  0.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 50.114532470703125






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [11. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [11. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[27.899866]
 [31.033764]
 [31.033764]
 [33.371696]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.19057846069336



action possibilites: [-1. 11. 11.] 
expected returns: [[32.880947]
 [36.013577]
 [36.013577]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 33.159305572509766



action possibilites: [-1] 
expected returns: [[43.361526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 37.777217864990234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[36.737453]
 [42.388763]
 [40.702168]
 [32.37188 ]
 [40.571526]
 [44.692913]
 [40.728203]
 [47.51661 ]
 [36.344624]
 [39.041595]
 [41.995937]
 [42.12638 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.36152648925781



buy possibilites: [-1] 
expected returns: [[58.351433]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.] 
cards in discard: [10. 29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 47.5166015625






Player: 1 
cards in hand: [29.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 29  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 10.  0.] 
adversary cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[51.37368 ]
 [52.867737]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 10.  0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 58.35143280029297



action possibilites: [-1.] 
expected returns: [[61.668156]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 53.06793212890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[56.175377]
 [64.95941 ]
 [62.088715]
 [48.60735 ]
 [68.53366 ]
 [62.620316]
 [59.749607]
 [59.245403]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  8.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 61.668155670166016



buy possibilites: [-1] 
expected returns: [[104.05067]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11. 11.  0.  0.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 8. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 68.53364562988281






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 8. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0 8 0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  7.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [ 0.  8.  3.  0.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 10. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[58.67182 ]
 [56.303413]
 [64.59318 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 104.05066680908203



action possibilites: [-1. 10. 29.] 
expected returns: [[62.901497]
 [59.848904]
 [68.86584 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0. 29.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 64.09686279296875



action possibilites: [-1. 10.] 
expected returns: [[67.83547]
 [64.75069]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 68.86583709716797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[62.599525]
 [68.25085 ]
 [66.56424 ]
 [59.90255 ]
 [58.233955]
 [66.43359 ]
 [70.55498 ]
 [66.59028 ]
 [76.07566 ]
 [73.37868 ]
 [62.206696]
 [67.701324]
 [64.90368 ]
 [62.050003]
 [67.85801 ]
 [67.98846 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9. 10.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 67.83546447753906



buy possibilites: [-1] 
expected returns: [[40.837357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 285 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 76.0756607055664






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 0. 11. 11. 29.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0. 11. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 29.] 
expected returns: [[ 90.073555]
 [ 99.06147 ]
 [ 99.06147 ]
 [101.7535  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11. 29.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 40.83735656738281



action possibilites: [-1. 11. 11.] 
expected returns: [[119.46187]
 [128.55453]
 [128.55453]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  0.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  8.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 101.69762420654297



action possibilites: [-1] 
expected returns: [[121.4786]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 131.33981323242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[113.91901 ]
 [122.69606 ]
 [119.70278 ]
 [106.66378 ]
 [119.148384]
 [126.34066 ]
 [120.35054 ]
 [129.819   ]
 [112.578606]
 [117.357285]
 [121.39003 ]
 [115.547165]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  6. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 121.47859954833984



buy possibilites: [-1] 
expected returns: [[36.996677]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  0. 11.] 
adversary cards in discard: [22.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 163 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 129.81898498535156






Player: 1 
cards in hand: [ 8.  3.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  0. 11.] 
cards in discard: [22.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5. 10. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 0.] 
cards in discard: [22.  0.  0.  0.  0.  0. 14.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [ 3.  3. 11. 10.  0.] 
adversary cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3.  3. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[84.80573]
 [91.20963]
 [85.27064]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 11. 10.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  7.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.99667739868164



action possibilites: [-1] 
expected returns: [[61.971794]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 93.30587768554688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[60.391777]
 [57.59525 ]
 [62.19243 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  0.] 
cards in discard: [25. 29. 29.  0. 10.  3.  0.  0. 10. 29. 29. 11.  0. 11.  0.  0. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 61.97179412841797






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 30. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [10.  3.  0.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[57.52928 ]
 [54.444504]
 [62.91951 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 62.19242858886719



action possibilites: [-1. 10. 29.] 
expected returns: [[102.008965]
 [ 99.08947 ]
 [108.45545 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0. 29.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 62.691612243652344



action possibilites: [-1. 10.] 
expected returns: [[86.37997]
 [83.46047]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 108.45545196533203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[77.59748 ]
 [83.88825 ]
 [81.98283 ]
 [74.539635]
 [72.65504 ]
 [81.82511 ]
 [86.46377 ]
 [82.07842 ]
 [92.596825]
 [89.53899 ]
 [77.11516 ]
 [83.15262 ]
 [80.173004]
 [76.86184 ]
 [83.40592 ]
 [83.09249 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  9.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 86.37996673583984



buy possibilites: [-1] 
expected returns: [[91.63813]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  0.  0.  0.] 
cards in discard: [25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 14.] 
adversary cards in discard: [3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 250   0] 
sum of rewards: 255 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 92.5968246459961






Player: 1 
cards in hand: [ 0.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [3. 0. 0. 0. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0.  0. 14.] 
cards in discard: [3. 0. 0. 0. 3. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 3. 10. 11. 11. 11.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25] -> size -> 23 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11. 11.] 
expected returns: [[ 92.49782]
 [ 94.16041]
 [101.56524]
 [101.56524]
 [101.56524]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11. 11.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  6.  9. 10.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: 0
desired expected reward: 91.63813018798828



action possibilites: [-1] 
expected returns: [[57.52647]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: -18 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 103.19249725341797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.160095]
 [50.98859 ]
 [57.57242 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 11. 11.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  8.  3. 11.] 
adversary cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 57.52647018432617






Player: 1 
cards in hand: [ 0.  0.  8.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  3. 11.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10. 10.  6.  9.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 29. 10.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  6.  9.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 29. 10.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  6.  9.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 29. 10.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3.] 
cards in discard: [ 3.  0.  0.  0.  3.  3.  3.  0.  0.  0.  0. 14. 16.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  6.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0. 29. 10.  0.] 
adversary cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
adversary victory points: 3
player victory points: 5 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [25.  0. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29. 10.] 
expected returns: [[57.48452 ]
 [70.83174 ]
 [67.25948 ]
 [57.810604]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 29. 10.  0.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8. 10.  9.  6.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8] -> size -> 21 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 57.572410583496094



action possibilites: [-1] 
expected returns: [[50.962868]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  0.  0. 29.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 70.83173370361328





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[45.5313  ]
 [51.198524]
 [49.441353]
 [40.958042]
 [53.513508]
 [49.603447]
 [47.84628 ]
 [49.475433]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0.  0. 29.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  6.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 50.962867736816406



buy possibilites: [-1] 
expected returns: [[16.503735]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  0.  0. 29.] 
cards in discard: [25. 29. 29. 10.  3.  0.  0.  0. 10. 11.  3. 10. 11. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0.  3.  0. 22.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6] -> size -> 22 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  54   0] 
sum of rewards: 9 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 53.51348876953125






Player: 1 
cards in hand: [ 0.  0.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 22.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 22.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  0. 22.] 
cards in discard: [6. 0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [10.  0. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  0. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[90.10555]
 [87.26798]
 [87.26798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  3. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 16.503734588623047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[83.09669 ]
 [87.350395]
 [78.29875 ]
 [87.43504 ]
 [88.42509 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 8.  3.  0.  3. 14.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 87.36519622802734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  3.  0.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  0.  3. 14.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [25.  0.  0. 25. 29.] 
adversary cards in discard: [10.  0. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 3.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 0.  0. 25.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[74.807045]
 [89.46627 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  9.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0] -> size -> 24 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 722   0] 
sum of rewards: 687 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 131.72547912597656



action possibilites: [-1] 
expected returns: [[21.360102]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 29.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 88.56552124023438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[17.723574]
 [20.444046]
 [14.221286]
 [20.634903]
 [19.151009]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  5.  8.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.3601016998291



buy possibilites: [-1] 
expected returns: [[3.5934489]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 29.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [11.  0.  3.  0. 16.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6] -> size -> 25 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 20.634906768798828






Player: 1 
cards in hand: [11.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0. 16.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 16.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  3.  0. 16.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8] -> size -> 26 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[69.8612  ]
 [74.84661 ]
 [69.938934]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  5.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 3.5934488773345947



action possibilites: [-1] 
expected returns: [[19.874798]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 76.99821472167969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.214726]
 [18.649916]
 [ 9.292133]
 [19.022877]
 [16.841637]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  7.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.874797821044922



buy possibilites: [-1] 
expected returns: [[39.420204]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [0. 0. 0. 0. 8.] 
adversary cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 19.02286720275879






Player: 1 
cards in hand: [0. 0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 8.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0.  0.  0.  3.  0. 22.  0. 14.  8.  3.  0.  3.  6.  0. 11.  0.  3.
  0. 16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 29. 10.] 
adversary cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 29. 10.] 
expected returns: [[-6.9397917]
 [-6.9397917]
 [-6.9397917]
 [-6.9397917]
 [-6.9397917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 29. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 39.420204162597656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-6.9397917]
 [-6.9397917]
 [-6.9397917]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 29. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -6.939791679382324



buy possibilites: [-1] 
expected returns: [[-4.84953]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 11. 29. 10.] 
cards in discard: [10.  0. 10.  3.  0. 25. 29.  8. 25.  0.  0. 10. 29. 10.  8. 11.  3.  0.
  0. 10.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 16.  8.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: 0
desired expected reward: -6.939791679382324






Player: 1 
cards in hand: [ 3. 16.  8.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  8.  6.  3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  8  0 11 22 14  0  3  3 16  8  6  0  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  5.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [29.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3.] 
cards in discard: [29.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 0. 29. 11. 11.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 11. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[56.286728]
 [61.78685 ]
 [58.837265]
 [58.837265]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 11. 11.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: -4.849530220031738



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[33.396   ]
 [36.205215]
 [36.205215]
 [40.95947 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 25.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 28. 30.  8.  8.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0] -> size -> 24 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 59.38232421875



action possibilites: [-1] 
expected returns: [[18.330952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 11.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 28. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.9594612121582





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[14.602473]
 [16.180475]
 [12.694339]
 [16.179365]
 [16.256369]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 11.  3. 29. 29.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 28. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [ 3. 11.  0.  6.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6] -> size -> 25 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.330951690673828






Player: 1 
cards in hand: [ 3. 11.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  6.  0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9. 10.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 28. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 28. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9.  9.] 
adversary cards in hand: [10. 10.  0.  0. 11.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10. 10.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 11.] 
expected returns: [[58.76499]
 [60.80999]
 [60.80999]
 [64.8209 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0. 11.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  4.  9.  9.] 
adversary cards in hand: [14.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 16.25637435913086



action possibilites: [-1] 
expected returns: [[20.263424]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [14.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 42 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 66.7004165649414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[18.419647]
 [22.02946 ]
 [13.752972]
 [22.331268]
 [20.02802 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  6.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [14.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.263423919677734



buy possibilites: [-1] 
expected returns: [[43.630413]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0.  0.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [14.  0.  8.  0.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 22.331268310546875






Player: 1 
cards in hand: [14.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8.  0.  0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 25. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  4.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 25. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 3. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[21.870327]
 [28.418034]
 [21.802168]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 10.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  7.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29] -> size -> 28 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 728   0] 
sum of rewards: 723 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 31.99151611328125



action possibilites: [-1] 
expected returns: [[13.580732]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 10. 11.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.41802978515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.788093]
 [ 9.216239]
 [13.718944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 10. 11.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 0.  3.  0. 22.  0.] 
adversary cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6] -> size -> 29 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.580732345581055






Player: 1 
cards in hand: [ 0.  3.  0. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 22.  0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 22.  0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  5.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 22.  0.] 
cards in discard: [29.  0. 16.  3.  6.  3.  6. 15.  3. 11.  3.  0.  6.  0. 29. 14.  0.  8.
  0.  0.  6.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [10. 29.  0.  0. 10.] 
adversary cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [10. 29.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10.] 
expected returns: [[-6.9397917]
 [-6.9397917]
 [-6.7007465]
 [-6.9397917]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 29.  0.  0. 10.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.71893310546875



action possibilites: [-1. 10. 10.] 
expected returns: [[54.280556]
 [51.515457]
 [51.515457]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -6.700751304626465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[48.910286]
 [54.97328 ]
 [53.065147]
 [44.999207]
 [57.57552 ]
 [53.18743 ]
 [51.279297]
 [54.044403]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  5.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.28054428100586



buy possibilites: [-1] 
expected returns: [[68.89686]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.  3.] 
cards in discard: [29. 25.  0. 11. 11.  3. 29. 29. 10.  8. 11. 10. 10.  0.  0.  0.  0. 25.
  3. 10. 10. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 99 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 57.57550048828125






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  3.  9.  9.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [15.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  3.  9.  8.] 
adversary cards in hand: [ 3. 11.  8.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11] -> size -> 32 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  8.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.  8.] 
expected returns: [[16.869207]
 [18.198078]
 [15.433955]
 [15.433955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  8.  0.  8.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  3.  9.  8.] 
adversary cards in hand: [16. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 68.89685821533203



action possibilites: [-1] 
expected returns: [[19.92981]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 8.] 
cards in discard: [10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [16. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0 27  0] 
sum of rewards: 72 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 19.37285614013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[15.777095]
 [12.275906]
 [19.839836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 8.] 
cards in discard: [10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [16. 15.  6.  0. 11.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15] -> size -> 31 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.9298095703125






Player: 1 
cards in hand: [16. 15.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  6.  0. 11.] 
cards in discard: [15.  0.  0.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 30. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  6.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  6.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  6.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [ 0. 10. 10.  0.  3.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[39.77074 ]
 [41.017487]
 [41.017487]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.  0.  3.] 
cards in discard: [10. 11.  3.  8.  0.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [22.  0.  6. 29.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 19.839839935302734



action possibilites: [-1. 10. 11.] 
expected returns: [[29.582516]
 [30.188652]
 [34.244316]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3. 11.] 
cards in discard: [10. 11.  3.  8.  0.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  2.  9.  8.] 
adversary cards in hand: [22.  0.  6. 29.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 10.0
Learning step: 0
desired expected reward: 41.01749801635742



action possibilites: [-1. 10.] 
expected returns: [[1.0690992]
 [0.9543202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [22.  0.  6. 29.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.588871002197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-0.16999364]
 [ 2.0704734 ]
 [-2.7639174 ]
 [ 2.258982  ]
 [ 0.84636354]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  4.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [22.  0.  6. 29.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 1.0691030025482178



buy possibilites: [-1] 
expected returns: [[0.07596278]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [22.  0.  6. 29.  0.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 81 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 2.258979082107544






Player: 1 
cards in hand: [22.  0.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  0.  6. 29.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [10. 11.  0. 10.  0.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8] -> size -> 35 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  0.  6. 29.  0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [10. 11.  0. 10.  0.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8] -> size -> 35 
adversary victory points: 3
player victory points: 2 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [10. 11.  0. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 10.] 
expected returns: [[-5.0585537]
 [-5.6887884]
 [-3.4277444]
 [-5.6887884]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0. 10.  0.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  1.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 0.07596278190612793



action possibilites: [-1] 
expected returns: [[10.522592]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -10   0   0  27   0] 
sum of rewards: 62 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -2.692915916442871





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.066033]
 [11.664673]
 [ 6.128338]
 [11.754424]
 [11.488029]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  3.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 10.522591590881348



buy possibilites: [-1] 
expected returns: [[57.28518]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  0.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [0. 3. 8. 3. 3.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 41 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 11.754422187805176






Player: 1 
cards in hand: [0. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 3. 3.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0
  6 15  3 29  6  8 15  1  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0. 29. 10. 10.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0. 29. 10. 10.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [29.  0. 29. 10. 10.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [29.  0. 29. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10. 10.] 
expected returns: [[4.34319  ]
 [6.2576313]
 [6.2576313]
 [2.280546 ]
 [2.280546 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 10. 10.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 29.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 57.285179138183594



action possibilites: [-1. 10. 10. 11.] 
expected returns: [[17.643389]
 [16.261866]
 [16.261866]
 [19.522572]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 11.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  8.] 
adversary cards in hand: [ 3.  0.  6.  3. 29.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 3.836585283279419



action possibilites: [-1] 
expected returns: [[28.080437]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  0.  6.  3. 29.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 189 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 20.515243530273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.481041]
 [28.457275]
 [22.378872]
 [28.576302]
 [28.189884]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  2.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  0.  6.  3. 29.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.08043670654297



buy possibilites: [-1] 
expected returns: [[36.280037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 10.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 3.  0.  6.  3. 29.] 
adversary cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -40   0   0  16   0] 
sum of rewards: 131 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.576292037963867






Player: 1 
cards in hand: [ 3.  0.  6.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 29.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  8. 29. 10.  0.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  8. 29. 10.  0.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [15.  0.  0.  3.  0.  0.  1.  0. 11. 16. 15.  6.  0. 22.  0.  6. 29.  0.
  8.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11.  8. 29. 10.  0.] 
adversary cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
adversary victory points: 3
player victory points: -1 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [11.  8. 29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 10.] 
expected returns: [[44.27525 ]
 [46.695545]
 [44.05294 ]
 [48.52076 ]
 [42.86184 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8. 29. 10.  0.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 36.28003692626953



action possibilites: [-1. 11. 10. 25.] 
expected returns: [[22.607714]
 [22.464466]
 [19.467922]
 [25.787798]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 25.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  6.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  6. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0] -> size -> 29 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 45.156455993652344



action possibilites: [-1] 
expected returns: [[35.235588]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  3. 29.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  6. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.787792205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.57728 ]
 [37.3454  ]
 [27.389324]
 [37.74614 ]
 [35.235584]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3. 29.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  4.  1.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  6. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: 35.23558807373047



buy possibilites: [-1] 
expected returns: [[64.29705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.  0.  3. 29.] 
cards in discard: [10. 11.  3.  8.  0.  8. 10.  8. 10. 11.  0. 10.  0.  3. 10.  8. 11. 10.
  0. 10.  0. 29. 15.  8. 29. 11.  0. 10. 10.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0.  0.  8.  6. 14.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6] -> size -> 30 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0 -50   0   0  16   0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 37.746131896972656






Player: 1 
cards in hand: [ 0.  0.  8.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  6. 14.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [29. 29. 11.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  6. 14.] 
cards in discard: [6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 29. 30. 27. 30.  8.  5.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [29. 29. 11.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  6. 14.] 
cards in discard: [6. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [29. 29. 11.  0. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29. 29. 11.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11. 25.] 
expected returns: [[90.27584 ]
 [93.35186 ]
 [93.35186 ]
 [91.2631  ]
 [95.546165]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0. 25.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  5.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0] -> size -> 31 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: 64.29705047607422



action possibilites: [-1] 
expected returns: [[43.92598]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 95.54617309570312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[40.44494 ]
 [37.673027]
 [43.501015]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29. 11.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [0. 0. 0. 0. 6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6] -> size -> 32 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 43.92597961425781






Player: 1 
cards in hand: [0. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 10. 25.  8.  0.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  4.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 10. 25.  8.  0.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 0. 10. 25.  8.  0.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [ 0. 10. 25.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8.] 
expected returns: [[-6.7283363]
 [-6.5608244]
 [-0.7421317]
 [-5.7668962]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  8.  0.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  4.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11. 15.  3.  1.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11] -> size -> 33 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 43.501007080078125



action possibilites: [-1] 
expected returns: [[98.960594]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  0. 10.  8.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 27. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11. 15.  3.  1.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -0.742135763168335





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[96.89398 ]
 [99.53421 ]
 [93.667274]
 [99.029976]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0. 10.  8.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 27. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11. 15.  3.  1.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6] -> size -> 34 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 98.9605941772461



buy possibilites: [-1] 
expected returns: [[86.90485]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  0. 10.  8.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [11. 15.  3.  1.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6] -> size -> 34 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -60   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 3.0
Learning step: 0
desired expected reward: 99.53421020507812






Player: 1 
cards in hand: [11. 15.  3.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  3.  1.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  7.] 
adversary cards in hand: [ 8.  3.  8. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
adversary victory points: 4
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3.  1.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  3.  1.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 8.  3.  8. 11. 11.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
adversary victory points: 4
player victory points: -4 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 8.  3.  8. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 11.] 
expected returns: [[76.00592]
 [76.59631]
 [76.59631]
 [80.99794]
 [80.99794]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 11. 11.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 29. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: 86.90484619140625



action possibilites: [-1] 
expected returns: [[67.701775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3.  8. 11.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0 -70   0   0  27   0] 
sum of rewards: 212 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: 78.35430908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[66.134514]
 [62.2807  ]
 [68.68231 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3.  8. 11.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
adversary victory points: -4
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: 67.70177459716797






Player: 1 
cards in hand: [ 0.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
adversary victory points: 4
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 26. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
adversary victory points: 4
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11. 10.  0. 10. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
adversary victory points: 4
player victory points: -3 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [11. 10.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 10. 10.] 
expected returns: [[-1.4246861]
 [-1.0685744]
 [-3.1831849]
 [-3.1831849]
 [-3.1831849]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 10. 10.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [22.  3.  3. 16.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 68.68230438232422



action possibilites: [-1] 
expected returns: [[13.705386]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [22.  3.  3. 16.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0 -80   0   0  27   0] 
sum of rewards: 172 

action type: gain_card_n - action 1
Learning step: 0
desired expected reward: -2.109762668609619





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.58262 ]
 [ 8.424871]
 [13.326702]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10. 10.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [22.  3.  3. 16.  0.] 
adversary cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
adversary victory points: -3
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: take_action - action -1
Learning step: 0
desired expected reward: 13.7053861618042






Player: 1 
cards in hand: [22.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 16.] 
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  3. 16.  0.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  8.  0. 29.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  8.  0. 29.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 25. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  8.  0. 29.] 
cards in discard: [ 6.  0.  0.  0.  8.  6. 14.  6. 11.  0.  0.  0.  0.  6.  6. 15.  0. 11.
 15.  3.  1.  6.  3.  0.  0. 15.  0.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 29.] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[54.21398 ]
 [52.564137]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 6.  0.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 13.326701164245605





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
expected returns: [[50.441944]
 [56.212433]
 [54.199062]
 [46.898956]
 [58.841846]
 [54.21398 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  3.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 6.  0.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.2139778137207



buy possibilites: [-1] 
expected returns: [[72.14095]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  2.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 6.  0.  3.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0 -90   0   0  54   0] 
sum of rewards: 139 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 58.84184265136719






Player: 1 
cards in hand: [ 6.  0.  3.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  0. 15.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29
  6  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  2.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0.  8.  8. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  2.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0.  8.  8. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
adversary victory points: 4
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  2.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0.  8.  8. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
adversary victory points: 4
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0.] 
cards in discard: [11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3 11] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [10.  0.  8.  8. 10.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
adversary victory points: 4
player victory points: -2 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10.  0.  8.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 10.] 
expected returns: [[33.03461 ]
 [32.23793 ]
 [33.503365]
 [33.503365]
 [32.23793 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8. 10.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 10 29 11 10 29 11 25 10 29 10 25 10
 11  8 10  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 15.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3 11] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 72.14095306396484



action possibilites: [-1] 
expected returns: [[14.299172]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 15.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3 11] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: trash_cards_n_from_hand - action 9
Learning step: 0
desired expected reward: 38.64234924316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.764127 ]
 [ 7.4050207]
 [14.299176 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 0.  8. 15.  6.  0.] 
adversary cards in discard: [11. 15.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3 11] -> size -> 38 
adversary victory points: -2
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.299172401428223






Player: 1 
cards in hand: [ 0.  8. 15.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 15.  6.  0.] 
cards in discard: [11. 15.  6.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 22 14  0  3  3 16  8  6  0  0  6  0 29  0  6 15  3 29  6
  8 15  1  0  6  0  6 11  6 15  0  3  3 11] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [15. 29. 10.  8. 29.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
adversary victory points: 4
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [11. 15.  6.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [15. 29. 10.  8. 29.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [11. 15.  6.  3.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [15. 29. 10.  8. 29.] 
adversary cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
adversary victory points: 4
player victory points: -1 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [15. 29. 10.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 29. 10.  8. 29.] 
expected returns: [[65.09262]
 [67.39741]
 [74.14113]
 [64.54685]
 [66.47233]
 [74.14113]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 10.  8. 29.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.  8.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  6.  0.  3.  1.] 
adversary cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.299172401428223



action possibilites: [-1. 15. 29. 10.] 
expected returns: [[33.646614]
 [37.68605 ]
 [43.127052]
 [35.799717]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 29. 10.] 
cards in discard: [25. 29. 29. 11.  0.  3. 11.  3. 25.  0. 10.  8.  0. 10.  8.  1. 11.  8.
  3.  8. 11.  1. 11. 10.  0. 10. 10. 11.  0.  0.  0. 10.  3.  8.  0. 10.
  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  6.  0.  3.  1.] 
adversary cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 68.09430694580078



action possibilites: [-1. 10.] 
expected returns: [[60.17757 ]
 [57.039967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [15.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  6.  0.  3.  1.] 
adversary cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 38.56509780883789





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[55.25531 ]
 [57.674988]
 [52.849022]
 [59.747974]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [15.  8.] 
cards in deck: 36 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 1 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  6.  0.  3.  1.] 
adversary cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[ -5   0   0 150   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 185 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 60.17757034301758






Player: 1 
cards in hand: [11.  6.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  3.  1.] 
cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 1.  3. 10.  8. 10.] 
adversary cards in discard: [15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  0.  3.  1.] 
cards in discard: [11. 15.  6.  3.  0.  8.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  1.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [ 1.  3. 10.  8. 10.] 
adversary cards in discard: [15.  8. 29. 29. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
adversary victory points: 4
player victory points: -1 


Player 0 won the game! 



Player 0 bought cards:
Copper: 1 
Silver: 0 
Gold: 0 
Estate: 1 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 6 
Chapel: 7 
Witch: 2 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 1.  3. 10.  8. 10.] 
cards in discard: [15.  8. 29. 29. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11 29 11 29 11 25 10 29 10 25 10 11 10
  8  0 10  8 11 10 10  8 10  8 15  8  8  3  1  1 11] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 24. 30.  8.  3.  9.  0.  0.  8.  3.  9. 10.  0.  9.  6.] 
adversary cards in hand: [11.  6.  0.  3.  1.] 
adversary cards in discard: [11. 15.  6.  3.  0.  8.  0. 11.] 
adversary owned cards: [ 0  0  0 11 22 14  0  3  3 16  8  0  0  6  0 29  0  6  3 29  6  8 15  1
  0  6  0  6 11  6 15  0  3  3 11 11] -> size -> 36 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[     -5 3000000       0     150       0       0       0       0       0
       0       0       0       0       0       0       0] 
sum of rewards: 3000145 

action type: buy - action -1.0
Learning step: 120003.40625
desired expected reward: 120063.15625



