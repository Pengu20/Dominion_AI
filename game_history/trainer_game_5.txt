 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[348.87863]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0  -50    0    0    0  -30    0    0    0    0    0    0
    0    0] 
sum of rewards: -585 

action type: buy - action 0.0
Learning step: -32.367942810058594
desired expected reward: 29.990894317626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[331.1028 ]
 [332.27246]
 [333.2921 ]
 [332.7448 ]
 [332.79276]
 [335.59586]
 [332.97513]
 [337.75098]
 [335.0485 ]
 [333.99487]
 [336.6494 ]
 [345.73694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14.  0.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.033976554870605
desired expected reward: 341.6391906738281



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14.  0.  0.  0.  0.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [0. 0. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[385.46042]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.659209251403809
desired expected reward: 337.0777587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[368.41586]
 [369.58545]
 [370.60516]
 [370.05783]
 [372.9088 ]
 [370.28818]
 [371.30795]
 [383.05   ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -11.008926391601562
desired expected reward: 376.88616943359375



buy possibilites: [-1] 
expected returns: [[387.95038]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [0. 0. 0. 3. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 8. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -8.950390815734863
desired expected reward: 360.6351013183594






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 8. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 3. 0.] 
cards in discard: [0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0] -> size -> 13 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[337.4152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -11.829623222351074
desired expected reward: 376.1207580566406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[322.1047 ]
 [323.27435]
 [324.29407]
 [323.74673]
 [323.79462]
 [326.59775]
 [323.97705]
 [328.75293]
 [326.0504 ]
 [324.99677]
 [327.65137]
 [336.7389 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.692545890808105
desired expected reward: 331.1028747558594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 8. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 8. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 0.  3.  8.  0.  3.  0. 15.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[370.55557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -8.575894355773926
desired expected reward: 328.1629943847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[354.74628]
 [355.9159 ]
 [356.93564]
 [356.38828]
 [359.2393 ]
 [356.61862]
 [357.63834]
 [369.38043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 3. 0. 0. 0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  3.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.501851081848145
desired expected reward: 361.10040283203125



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [ 3.  3.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 14.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 3. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[368.9331]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -10.191971778869629
desired expected reward: 359.1884460449219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[353.19168]
 [354.36133]
 [355.381  ]
 [353.81403]
 [354.83374]
 [354.8816 ]
 [357.6847 ]
 [355.06403]
 [358.78625]
 [359.8399 ]
 [357.13742]
 [358.55597]
 [356.08374]
 [356.955  ]
 [358.73834]
 [367.82584]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8.  3.  3. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.569159507751465
desired expected reward: 361.74420166015625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  3.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  3.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10. 10. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8.  3.  3. 14. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [0. 3. 0. 0. 1.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[392.0727]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1.0
Learning step: -9.646106719970703
desired expected reward: 358.1797180175781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[376.2634 ]
 [377.433  ]
 [378.45276]
 [377.90536]
 [380.7564 ]
 [378.13574]
 [379.15546]
 [390.89758]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -11.093570709228516
desired expected reward: 382.0257873535156



buy possibilites: [-1] 
expected returns: [[386.72693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [0. 3. 0. 0. 1. 1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [10. 15.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -9.370293617248535
desired expected reward: 368.06268310546875






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [10. 15.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  0.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[382.16702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  8.  0.] 
adversary cards in discard: [ 8. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.782807350158691
desired expected reward: 375.9441223144531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[368.28644]
 [369.45602]
 [370.47574]
 [369.92847]
 [372.7794 ]
 [370.1587 ]
 [371.1785 ]
 [382.92056]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  8.  0.] 
adversary cards in discard: [ 8. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -10.847171783447266
desired expected reward: 373.75457763671875



buy possibilites: [-1] 
expected returns: [[364.3966]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  3. 14.  8.  0.] 
adversary cards in discard: [ 8. 10. 15.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10  8] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 10.0
Learning step: -9.53753662109375
desired expected reward: 361.6408996582031






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  8.  0.] 
cards in discard: [ 8. 10. 15.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 14  8  0 15 10  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10. 15.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8. 10. 15.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 1. 3. 0.] 
adversary cards in discard: [10.  3.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[397.02826]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.374098777770996
desired expected reward: 355.02252197265625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[386.97205]
 [388.1502 ]
 [389.1756 ]
 [387.60388]
 [388.62927]
 [388.6772 ]
 [391.49088]
 [388.85544]
 [392.6025 ]
 [393.66623]
 [390.94455]
 [392.3763 ]
 [389.8808 ]
 [390.7663 ]
 [392.55457]
 [401.70633]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8. 10. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -11.071464538574219
desired expected reward: 386.5166015625



buy possibilites: [-1] 
expected returns: [[385.801]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 3. 0.] 
cards in discard: [10.  3.  0.  3.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -26.400943756103516
desired expected reward: 362.2283630371094






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  8. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8  8] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [0. 0. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[368.6398]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.61115550994873
desired expected reward: 374.1898498535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[350.2494 ]
 [351.4276 ]
 [352.45297]
 [350.88123]
 [351.90665]
 [351.95453]
 [354.76822]
 [352.1328 ]
 [355.87982]
 [356.9436 ]
 [354.2219 ]
 [355.65366]
 [353.15814]
 [354.0436 ]
 [355.83194]
 [364.98367]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -11.076973915100098
desired expected reward: 359.0960998535156



buy possibilites: [-1] 
expected returns: [[333.0086]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 0.] 
cards in discard: [22.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 3. 8. 0. 8.] 
adversary cards in discard: [8. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8  8] -> size -> 15 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  50   0] 
sum of rewards: 37 

action type: buy - action 22.0
Learning step: -8.359487533569336
desired expected reward: 345.6841125488281






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [0. 3. 8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8. 0. 8.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  8  0 15 10  8  8] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [22.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [22.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [8. 0. 0. 3. 3. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [0. 1. 0. 3. 0.] 
adversary cards in discard: [22.  0.  0.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [0. 1. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[377.57584]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [22.  0.  0.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -8.292378425598145
desired expected reward: 324.7162170410156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[360.64957]
 [361.8278 ]
 [362.85315]
 [361.28146]
 [362.30685]
 [362.35474]
 [365.16843]
 [362.53305]
 [366.2801 ]
 [367.3438 ]
 [364.62213]
 [366.0539 ]
 [363.5584 ]
 [364.44382]
 [366.23218]
 [375.38388]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [22.  0.  0.  3.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9. 10.  8.  9.  9.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -10.74109935760498
desired expected reward: 367.3945617675781



buy possibilites: [-1] 
expected returns: [[361.59857]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 0.] 
cards in discard: [22.  0.  0.  3.  1.  0. 23.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 3. 10. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 47 

action type: buy - action 23.0
Learning step: -7.816725254058838
desired expected reward: 358.2371520996094






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [ 3. 10. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 30. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10. 15.  0.  0.] 
cards in discard: [3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8  3] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  6. 10.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [ 1.  6. 10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[331.20728]
 [319.38174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 10. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.314502716064453
desired expected reward: 350.2840576171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[315.91544]
 [317.09357]
 [318.11893]
 [317.57263]
 [320.43423]
 [317.79883]
 [318.8242 ]
 [330.64966]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  3.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 10. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -9.981123924255371
desired expected reward: 322.7593994140625



buy possibilites: [-1] 
expected returns: [[323.3422]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  3.  0.] 
cards in discard: [1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [0. 8. 8. 3. 0.] 
adversary cards in discard: [ 3.  3. 10. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8  3] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: 5 

action type: buy - action 1.0
Learning step: -8.32948112487793
desired expected reward: 308.7641296386719






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [0. 8. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 3. 0.] 
cards in discard: [ 3.  3. 10. 15.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  8  0 15 10  8  8  3] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [23.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 3.  3. 10. 15.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [23.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  3. 10. 15.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  7. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [23.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 3.  3. 10. 15.  0.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [23.  0.  0.  0.  3.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [23.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[352.1989 ]
 [342.86893]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  0.  0.  0.  3.] 
cards in discard: [ 1.  1.  6. 10.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -8.469705581665039
desired expected reward: 314.87249755859375



action possibilites: [-1.] 
expected returns: [[397.85776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  1.  6. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 23.0
Learning step: -7.2452712059021
desired expected reward: 334.6961364746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[386.04324]
 [387.22144]
 [388.24677]
 [386.6751 ]
 [387.7005 ]
 [387.7484 ]
 [390.56213]
 [387.92667]
 [391.67374]
 [392.7375 ]
 [390.0158 ]
 [391.44757]
 [388.95206]
 [389.8375 ]
 [391.62582]
 [400.77753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [ 1.  1.  6. 10.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 0 
buys: 2 
player value: 5 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [10.  0.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -10.155847549438477
desired expected reward: 387.701904296875






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [10.  0.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 22.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0. 23.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 22.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0. 23.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  0. 22.] 
adversary cards in discard: [ 1.  1.  6. 10.  3.  0. 23.  0.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 1.  3.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[301.22546]
 [290.2854 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 22.] 
cards in discard: [ 1.  1.  6. 10.  3.  0. 23.  0.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -13.495513916015625
desired expected reward: 387.28204345703125



action possibilites: [-1] 
expected returns: [[348.50266]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  4] 
sum of rewards: 21 

action type: take_action - action 22.0
Learning step: -5.172129154205322
desired expected reward: 276.0966491699219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[334.0046 ]
 [335.15857]
 [334.58023]
 [336.16205]
 [334.6205 ]
 [336.20233]
 [335.62396]
 [335.6791 ]
 [338.43643]
 [335.85117]
 [339.53534]
 [340.57907]
 [337.89838]
 [339.30817]
 [336.8546 ]
 [337.72635]
 [339.48022]
 [348.48166]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 8 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 8.  0. 15.  0.  8.] 
adversary cards in discard: [10.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1
Learning step: -8.86580753326416
desired expected reward: 339.6368408203125






         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 15.  0.  8.] 
cards in discard: [10.  0.  0.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 15 10  8  8  3  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [22.  1.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  0.  0.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [22.  1.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 15.  0.] 
cards in discard: [10.  0.  0.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  1. 10.] 
adversary cards in discard: [22.  1.  3.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  3.  0.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[340.854  ]
 [329.22693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [22.  1.  3.  0.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -10.01027774810791
desired expected reward: 338.4714050292969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[326.37216]
 [327.52615]
 [328.5296 ]
 [327.99155]
 [328.0467 ]
 [330.804  ]
 [328.2187 ]
 [332.94666]
 [330.26596]
 [329.2222 ]
 [331.84775]
 [340.84924]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [22.  1.  3.  0.  0.  0.  0.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  8.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -9.573073387145996
desired expected reward: 329.7090148925781



buy possibilites: [-1] 
expected returns: [[330.38538]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  1. 10.] 
cards in discard: [22.  1.  3.  0.  0.  0.  0.  1. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.   0.   2.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 1.5 

action type: buy - action 10.0
Learning step: -8.952439308166504
desired expected reward: 320.2697448730469






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  0 15 10  8  3  8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 23.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 15 10  8  3  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 23.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 15 10  8  3  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 23.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  0 15 10  8  3  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 23.  6.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 1. 23.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[287.72717]
 [278.55362]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 23.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  3  0 15 10  8  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -10.198013305664062
desired expected reward: 320.1873779296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[277.8541 ]
 [279.00806]
 [280.0115 ]
 [279.4735 ]
 [282.28595]
 [279.70068]
 [280.70413]
 [292.33118]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  6.  3.  0.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  6. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  3  0 15 10  8  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -8.207358360290527
desired expected reward: 281.8599853515625



buy possibilites: [-1] 
expected returns: [[284.21072]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 23.  6.  3.  0.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0. 15.  0.  8.] 
adversary cards in discard: [0. 8. 3.] 
adversary owned cards: [ 0  3  0 15 10  8  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -1.0 

action type: buy - action 8.0
Learning step: -7.640291690826416
desired expected reward: 272.06036376953125






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 15.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 15.  0.  8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  0 15 10  8  3  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15 10  8  3  8  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [0. 8. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15 10  8  3  8  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  9.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [ 0.  8.  3. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  0 15 10  8  3  8  0 14] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  0.  0.  1.  0.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10.  0.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[291.5242]
 [279.8972]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [ 8.  1. 23.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 15 10  8  3  8  0 14] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -7.866725921630859
desired expected reward: 276.343994140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[279.05875]
 [280.21274]
 [281.2162 ]
 [279.6747 ]
 [280.67813]
 [280.7333 ]
 [283.49057]
 [280.90533]
 [284.58948]
 [285.63327]
 [282.95255]
 [284.3623 ]
 [281.90878]
 [282.78052]
 [284.53436]
 [293.53583]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.  0.] 
cards in discard: [ 8.  1. 23.  6.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15.  0.  8.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  0 15 10  8  3  8  0 14] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -8.260016441345215
desired expected reward: 283.4666748046875



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [15.  0.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  0 15 10  8  3  8  0 14] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  3  8  0 14] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 15  8  3  8  0 14] -> size -> 7 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  0.  3.  0. 10.] 
adversary cards in discard: [ 8.  1. 23.  6.  3.  0. 10.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[309.60162]
 [297.97458]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 8.  1. 23.  6.  3.  0. 10.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15. 14.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  3  8  0 14] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -7.453759670257568
desired expected reward: 286.08209228515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[295.90176]
 [298.05917]
 [297.52118]
 [297.74832]
 [310.37888]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 10.] 
cards in discard: [ 8.  1. 23.  6.  3.  0. 10.  0.  0.  1.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15. 14.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 15  8  3  8  0 14] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -8.22150993347168
desired expected reward: 300.3595275878906



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [15. 14.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 14.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 15  8  3  8  0 14] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  3  8  0 14] -> size -> 6 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  3  8  0 14] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 27. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.] 
cards in discard: [1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  8  3  8  0 14  1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [10.  3.  1. 22.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10.  3.  1. 22.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
expected returns: [[266.9328 ]
 [255.30571]
 [256.17746]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1. 22.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  3  8  0 14  1] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -9.189257621765137
desired expected reward: 301.1895446777344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[253.95433]
 [255.10832]
 [256.1118 ]
 [255.57372]
 [258.38617]
 [255.8009 ]
 [256.80438]
 [268.43143]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1. 22.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  3  8  0 14  1] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -7.229666233062744
desired expected reward: 262.5289611816406



buy possibilites: [-1] 
expected returns: [[283.25406]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1. 22.  0.] 
cards in discard: [1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  8. 14.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [15  8  3  8  0 14  1] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 25 

action type: buy - action 1.0
Learning step: -5.132199764251709
desired expected reward: 249.9761199951172






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [ 1.  8. 14.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 14.  0.  8.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  8  3  8  0 14  1] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  1.  0. 23.  0.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  0 14  1] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  1.  0. 23.  0.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 14.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8  0 14  1] -> size -> 6 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  1.  0. 23.  0.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0.  1.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[305.96512]
 [296.7916 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 23.  0.] 
cards in discard: [ 1. 10.  3.  1. 22.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  0 14  1] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -6.973762512207031
desired expected reward: 276.2803039550781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[294.28967]
 [295.44293]
 [296.44186]
 [294.90442]
 [295.90332]
 [295.96362]
 [298.71106]
 [296.13306]
 [299.8119 ]
 [300.85242]
 [298.17255]
 [299.58218]
 [297.13202]
 [298.0031 ]
 [299.75165]
 [308.73843]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  0. 23.  0.] 
cards in discard: [ 1. 10.  3.  1. 22.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  8.  3. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8  0 14  1] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -8.04366397857666
desired expected reward: 296.2020568847656



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [ 1.  0.  8.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  8.  3. 15.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8  0 14  1] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 1. 6. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1] -> size -> 5 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 1. 6. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1] -> size -> 5 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 25. 30. 29. 30.  8.  9. 10. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 1. 6. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 3.] 
cards in discard: [16.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 25. 30. 29. 30.  8.  9.  9. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [8. 1. 6. 0. 3.] 
adversary cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [8. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[274.53885]
 [261.93347]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 0. 3.] 
cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9.  9. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  8. 15.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1.0
Learning step: -9.008627891540527
desired expected reward: 299.7297668457031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[261.32413]
 [262.4774 ]
 [263.47632]
 [262.9378 ]
 [265.7455 ]
 [263.16748]
 [264.1664 ]
 [275.77286]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 0. 3.] 
cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 25. 30. 29. 30.  8.  9.  9. 10.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  8. 15.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -7.252362251281738
desired expected reward: 266.2688293457031



buy possibilites: [-1] 
expected returns: [[249.77356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 0. 3.] 
cards in discard: [ 1. 10.  3.  1. 22.  0.  0.  1.  0. 23.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [16.  8. 15.  3. 14.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 25 

action type: buy - action 11.0
Learning step: -6.417370796203613
desired expected reward: 259.3281555175781






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [16.  8. 15.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8. 15. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8. 15.  3. 14.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14  1 16] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 14.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3. 14.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 10.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 1. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[299.5888]
 [287.9824]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -5.426331520080566
desired expected reward: 244.34722900390625



action possibilites: [-1. 23.] 
expected returns: [[271.6595 ]
 [262.50323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 23.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
action values: 2 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action 10.0
Learning step: -7.084190368652344
desired expected reward: 282.7432556152344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[259.3706 ]
 [260.5239 ]
 [261.52283]
 [260.98428]
 [261.04456]
 [263.79202]
 [261.214  ]
 [265.93338]
 [263.25348]
 [262.21295]
 [264.8326 ]
 [273.81937]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 23.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 27 

action type: take_action - action -1.0
Learning step: -6.1998724937438965
desired expected reward: 265.4595947265625



buy possibilites: [-1] 
expected returns: [[288.5928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 23.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 4 
card supply: [26. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  8.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0] -> size -> 7 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2.  10.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -3.0 

action type: buy - action 0.0
Learning step: -6.625194072723389
desired expected reward: 252.7454376220703






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [14.  3. 15.  8.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 15.  8.  1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14  1 16  0] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  1.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16  0] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  1.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  1.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16  0] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 25. 30. 29. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  1.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.  1.] 
cards in discard: [3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [15.] 
owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0. 10.  1.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 1.  0.  0. 10.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[294.2176 ]
 [282.61115]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0. 10.  1.] 
cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1
Learning step: -8.052557945251465
desired expected reward: 280.5402526855469



action possibilites: [-1.] 
expected returns: [[335.152]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 1. 0.] 
cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 18 

action type: take_action - action 10.0
Learning step: -5.638751983642578
desired expected reward: 275.9546813964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[326.25473]
 [327.40793]
 [326.8278 ]
 [328.4069 ]
 [326.86942]
 [327.8684 ]
 [327.92862]
 [330.67612]
 [328.09805]
 [331.77692]
 [332.81744]
 [330.13757]
 [331.5472 ]
 [329.09695]
 [329.9681 ]
 [331.7167 ]
 [340.70346]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 1. 0.] 
cards in discard: [ 0. 10.  1.  3.  0.  0. 23.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 7 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [14.  3. 15.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: -8.3720703125
desired expected reward: 326.7799377441406






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [14.  3. 15.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 15.  0. 16.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1.  0.  0.  3. 11.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 16.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 16.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  8 14  1 16  0  3] -> size -> 8 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  5. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0. 16.] 
cards in discard: [8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [14.] 
owned cards: [15  3  8 14  1 16  0  3  8] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 3.] 
adversary cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [1. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[264.92502]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 3.] 
cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8. 16.  8.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0  3  8] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[  -5    0    2    0    0    0    0 -210    0    0    0    0    0 -300
  108    0] 
sum of rewards: -405 

action type: discard_down_to_3_cards - action 5
Learning step: -25.099536895751953
desired expected reward: 190.65383911132812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[247.55344]
 [248.70668]
 [249.70563]
 [249.16711]
 [251.97482]
 [249.39679]
 [250.39574]
 [262.00217]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 3.] 
cards in discard: [ 0. 10.  1.  3.  0.  0. 23. 10.  1.  0.  0.  1.  0.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 8. 16.  8.  3.  1.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14  1 16  0  3  8] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.581994533538818
desired expected reward: 256.33502197265625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 8. 16.  8.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 16.  8.  3.  1.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14  1 16  0  3  8] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 22.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  8.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8 14 16  0  3  8] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 22.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8 14 16  0  3  8] -> size -> 8 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 22.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  8.  3.] 
cards in discard: [0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  8. 22.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  8. 22.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[270.7999 ]
 [258.19452]
 [260.06454]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 22.  6.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: buy - action -1.0
Learning step: -7.236912727355957
desired expected reward: 254.7652587890625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[257.11218]
 [258.72583]
 [271.5609 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.  6.  3.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  9.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -3 

action type: take_action - action -1.0
Learning step: -7.720402717590332
desired expected reward: 263.69866943359375



buy possibilites: [-1] 
expected returns: [[273.2706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 22.  6.  3.] 
cards in discard: [6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  0.  3. 14. 15.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -314.0 

action type: buy - action 6.0
Learning step: -21.832447052001953
desired expected reward: 223.7882537841797






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  3. 14. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 14. 15.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14. 15.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14 16  0  3  8  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  4. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 14. 15.] 
cards in discard: [8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14 16  0  3  8  0  8] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 10.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 





Player: 0 
cards in hand: [ 3.  1.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[272.9731]
 [261.7529]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 10.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14 16  0  3  8  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -8.301010131835938
desired expected reward: 264.9696044921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[259.86795]
 [260.97244]
 [261.93274]
 [261.41028]
 [261.48218]
 [264.12576]
 [261.64188]
 [266.19983]
 [263.60327]
 [262.60217]
 [265.12683]
 [273.82242]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 10.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 3.  8.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [15  3  8 14 16  0  3  8  0  8] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.285033226013184
desired expected reward: 264.164306640625



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [ 3.  8.  8.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  8.  3. 16.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [15  3  8 14 16  0  3  8  0  8] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  8.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 23.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3 14 16  0  3  8  0  8  6] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 23.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3 14 16  0  3  8  0  8  6] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [25. 25. 30. 28. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 23.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3.] 
cards in discard: [6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [15  3 14 16  0  3  8  0  8  6  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 1. 11.  0.  0. 23.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
adversary victory points: 1
player victory points: 1 





Player: 0 
cards in hand: [ 1. 11.  0.  0. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
expected returns: [[267.49307]
 [257.7964 ]
 [258.6378 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0. 23.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0. 14.] 
adversary cards in discard: [ 6.  0. 16.  3.  8.  3.] 
adversary owned cards: [15  3 14 16  0  3  8  0  8  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: -7.950266361236572
desired expected reward: 265.8721618652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[254.29471]
 [255.39919]
 [256.35947]
 [255.83702]
 [255.90892]
 [258.5525 ]
 [256.06857]
 [260.62656]
 [258.03   ]
 [257.0289 ]
 [259.55356]
 [268.24915]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0. 23.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 25. 30. 28. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0. 14.] 
adversary cards in discard: [ 6.  0. 16.  3.  8.  3.] 
adversary owned cards: [15  3 14 16  0  3  8  0  8  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: take_action - action -1.0
Learning step: -7.655426025390625
desired expected reward: 259.69378662109375



buy possibilites: [-1] 
expected returns: [[257.9642]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0. 23.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0. 14.] 
adversary cards in discard: [ 6.  0. 16.  3.  8.  3.] 
adversary owned cards: [15  3 14 16  0  3  8  0  8  6  0] -> size -> 11 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5.  0.  2. 10.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 9.0 

action type: buy - action 3.0
Learning step: -6.563778877258301
desired expected reward: 249.79568481445312






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [15.  8.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 14.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0. 14.] 
cards in discard: [ 6.  0. 16.  3.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [15  3 14 16  0  3  8  0  8  6  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 6.  0. 16.  3.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 6.  0. 16.  3.  8.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [1. 0. 1. 3. 0.] 
adversary cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [1. 0. 1. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[247.21715]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: buy - action -1
Learning step: -7.034733772277832
desired expected reward: 250.92947387695312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[242.54703]
 [243.65147]
 [243.08823]
 [244.61179]
 [243.129  ]
 [244.08931]
 [244.16124]
 [246.80478]
 [244.32094]
 [247.87779]
 [248.87888]
 [246.28233]
 [247.64616]
 [245.28123]
 [246.1226 ]
 [247.8059 ]
 [256.5014 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 6 
card supply: [24. 25. 30. 27. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  2 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 7 

action type: take_action - action -1.0
Learning step: -6.25684118270874
desired expected reward: 238.78660583496094



buy possibilites: [-1] 
expected returns: [[255.58968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 0.] 
cards in discard: [ 6.  0.  8. 22.  6.  3.  3.  1.  0.  0. 10.  3.  1. 11.  0.  0. 23.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 4 
card supply: [24. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [3. 6. 8. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 20.0 

action type: buy - action 3.0
Learning step: -5.47982120513916
desired expected reward: 239.13194274902344






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [3. 6. 8. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3. 0.] 
cards in discard: [] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3  8  0  8  6  0] -> size -> 8 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8. 3. 0.] 
cards in discard: [0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[263.68845]
 [252.46825]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -6.0103068351745605
desired expected reward: 249.57937622070312



action possibilites: [-1. 22.] 
expected returns: [[243.76231]
 [233.38348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action 10.0
Learning step: -5.309673309326172
desired expected reward: 247.326416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[232.25536]
 [233.3598 ]
 [234.3201 ]
 [233.79765]
 [236.51312]
 [234.02925]
 [234.98955]
 [246.2098 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 38 

action type: take_action - action -1.0
Learning step: -4.875204563140869
desired expected reward: 238.8871307373047



buy possibilites: [-1] 
expected returns: [[245.70528]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0.  0. 22.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [ 0.  3.  0.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 56 

action type: buy - action 1.0
Learning step: -3.3396217823028564
desired expected reward: 230.02020263671875






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  0.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0.  8. 16.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3  8  0  8  6  0  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  7.  9.  9.] 
adversary cards in hand: [11.  0.  0. 23.  1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  8  0  8  6  0  0 10] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0.  0. 23.  1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  8  0  8  6  0  0 10] -> size -> 9 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0.  0. 23.  1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [11.  0.  0. 23.  1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  0. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 23.] 
expected returns: [[249.1039 ]
 [239.40724]
 [240.24864]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 23.  1.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -5.380405426025391
desired expected reward: 240.3248748779297



action possibilites: [-1. 11.  8.] 
expected returns: [[266.46097]
 [256.7643 ]
 [254.28047]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  1.  8.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1] -> size -> 26 
action values: 1 
buys: 1 
player value: 1 
card supply: [22. 24. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 23.0
Learning step: -3.6483025550842285
desired expected reward: 235.46804809570312



action possibilites: [-1] 
expected returns: [[294.6967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 23. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 77 

action type: gain_card_n - action 1
Learning step: -1.6140578985214233
desired expected reward: 240.28060913085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[286.17236]
 [287.2338 ]
 [288.1616 ]
 [286.72354]
 [287.6513 ]
 [287.7372 ]
 [290.29648]
 [287.89127]
 [291.34952]
 [292.31668]
 [289.7862 ]
 [291.1096 ]
 [288.81906]
 [289.63217]
 [291.26364]
 [299.73135]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1] -> size -> 27 
action values: 0 
buys: 2 
player value: 5 
card supply: [22. 23. 30. 26. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 68 

action type: take_action - action -1
Learning step: -4.7112250328063965
desired expected reward: 289.9854736328125



buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[224.81067]
 [225.87209]
 [226.79985]
 [226.28958]
 [228.93475]
 [226.52957]
 [227.45734]
 [238.36966]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [22. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 40  0  0  0  0  0  0  0  4  0] 
sum of rewards: 83 

action type: buy - action 3.0
Learning step: -5.018091678619385
desired expected reward: 283.14349365234375



buy possibilites: [-1] 
expected returns: [[276.32025]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1. 8.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.  40. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: 49.0 

action type: buy - action 0.0
Learning step: -2.5733261108398438
desired expected reward: 222.2373046875






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [16  3  8  0  8  6  0  0 10  0] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0 10  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0 10  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  3. 10.  3.  3.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  3. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[194.95207]
 [184.03978]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10.  3.  3.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 16. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [16  8  8  0 10  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -7.581456184387207
desired expected reward: 268.7388000488281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[179.79901]
 [181.27795]
 [193.358  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10.  3.  3.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  0. 16. 10.] 
adversary cards in discard: [8.] 
adversary owned cards: [16  8  8  0 10  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -3.4697234630584717
desired expected reward: 189.87655639648438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  0. 16. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16. 10.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16. 10.] 
cards in discard: [8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0] -> size -> 6 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  3. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16. 10.] 
cards in discard: [8. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0  8] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [1. 1. 0. 0. 1.] 
adversary cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [1. 1. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[214.80556]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  8] -> size -> 7 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -2.908998966217041
desired expected reward: 190.4490203857422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[200.36687]
 [201.4283 ]
 [200.8787 ]
 [202.35608]
 [200.91803]
 [202.39545]
 [201.8458 ]
 [201.93173]
 [204.49097]
 [202.08582]
 [205.54404]
 [206.5112 ]
 [203.98073]
 [205.3041 ]
 [203.01357]
 [203.82668]
 [205.45813]
 [213.92589]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 8 
card supply: [21. 23. 30. 25. 30.  8.  7.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  8] -> size -> 7 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -4.046541690826416
desired expected reward: 209.68243408203125



buy possibilites: [-1] 
expected returns: [[179.41116]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 1. 0. 0. 1.] 
cards in discard: [ 1. 10.  0.  3.  0.  0. 22.  1.  3.  0. 23. 11.  0.  0.  1.  8.  3.  3.
 10.  3.  3.  2.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 23. 29. 25. 30.  8.  7.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  8.  8. 16.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0 10  0  8] -> size -> 7 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   40.    0.    0.    0.    0.    0. 1700.    0.    0.
    0.    0.   18.    0.] 
sum of rewards: 1757.0 

action type: buy - action 2.0
Learning step: 81.84281921386719
desired expected reward: 282.72149658203125






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [10.  8.  8. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8. 16.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0 10  0  8] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  7.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8 10  0  8  6] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8.  8.] 
cards in discard: [6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8 10  0  8  6] -> size -> 7 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [3. 3. 0. 6. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: -1 





Player: 0 
cards in hand: [3. 3. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[240.74445]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8 10  0  8  6] -> size -> 7 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: buy - action -1
Learning step: -1.126179575920105
desired expected reward: 178.2849884033203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[227.14662]
 [228.62555]
 [240.7056 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 6.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8.  6. 10.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8 10  0  8  6] -> size -> 7 
adversary victory points: -1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 49 

action type: take_action - action -1.0
Learning step: -4.224595546722412
desired expected reward: 235.5255584716797



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  6. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 10.  8.  0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8 10  0  8  6] -> size -> 7 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  8.  3. 22.] 
adversary cards in discard: [3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0  8] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  8.  3. 22.] 
adversary cards in discard: [3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0  8] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  8.  3. 22.] 
adversary cards in discard: [3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  0  8  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [10.  1.  8.  3. 22.] 
adversary cards in discard: [3. 3. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10.  1.  8.  3. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 22.] 
expected returns: [[266.3454 ]
 [255.4331 ]
 [254.50531]
 [256.2462 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  8.  3. 22.] 
cards in discard: [3. 3. 0. 6. 6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -4.209029674530029
desired expected reward: 236.49656677246094



action possibilites: [-1.  8. 22.] 
expected returns: [[254.7897 ]
 [242.94963]
 [244.69049]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  3. 22.  0.] 
cards in discard: [3. 3. 0. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 60 

action type: take_action - action 10.0
Learning step: -4.087937831878662
desired expected reward: 250.56407165527344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[244.43869]
 [245.50012]
 [246.42789]
 [245.9176 ]
 [248.56277]
 [246.15758]
 [247.08536]
 [257.99765]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  3. 22.  0.] 
cards in discard: [3. 3. 0. 6. 6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 0.  8.  8.  8. 16.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  0  8  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: -4.10786771774292
desired expected reward: 250.6818389892578






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 0.  8.  8.  8. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  8.  8. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  0  8  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  8  0] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  8  0] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 16.] 
cards in discard: [0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  0  8  0  0] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 3.  1.  0.  0. 11.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 3.  1.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[192.96234]
 [183.52747]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -6.674088954925537
desired expected reward: 251.3235626220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[186.82901]
 [187.89043]
 [188.81819]
 [188.30795]
 [188.39386]
 [190.95311]
 [188.54793]
 [192.97331]
 [190.44283]
 [189.47571]
 [191.92026]
 [200.388  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 29. 25. 30.  8.  6.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -3.289524555206299
desired expected reward: 189.271728515625



buy possibilites: [-1] 
expected returns: [[191.9377]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  0.  0. 11.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 4 
card supply: [19. 23. 29. 25. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [ 8.  0. 16.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  0  8  0  0] -> size -> 6 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -272.0 

action type: buy - action 6.0
Learning step: -18.69615936279297
desired expected reward: 169.5989990234375






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [ 8.  0. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 16.  0.  0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  0  8  0  0] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 25. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 25. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 29. 25. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [2. 1. 1. 1. 0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
adversary victory points: 3
player victory points: 1 





Player: 0 
cards in hand: [2. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[193.4691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: buy - action -1
Learning step: -4.361497402191162
desired expected reward: 187.57620239257812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[187.41068]
 [188.47343]
 [187.92262]
 [189.40051]
 [187.95686]
 [189.43474]
 [188.88394]
 [188.97734]
 [191.53505]
 [189.13011]
 [192.5898 ]
 [193.55109]
 [191.01851]
 [192.34358]
 [190.05717]
 [190.8657 ]
 [192.49637]
 [200.96169]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 10 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  6.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1.0
Learning step: -4.335914134979248
desired expected reward: 188.34800720214844



buy possibilites: [-1] 
expected returns: [[175.95099]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 1. 1. 0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 7 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8. 3. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 3] -> size -> 5 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  20.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 22.5 

action type: buy - action 10.0
Learning step: -4.418962001800537
desired expected reward: 185.63821411132812






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [8. 3. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[177.40115]
 [166.49666]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -3.4905598163604736
desired expected reward: 172.46043395996094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[165.65233]
 [166.7151 ]
 [167.64218]
 [167.1256 ]
 [169.77675]
 [167.37178]
 [168.29884]
 [179.20335]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  9.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.5193443298339844
desired expected reward: 173.04405212402344



buy possibilites: [-1] 
expected returns: [[204.64816]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [ 3.  3.  0.  6.  6. 10.  1.  8.  3. 22.  0.  6.  3.  1.  0.  0. 11. 10.
  2.  1.  1.  1.  0. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 46 

action type: buy - action 11.0
Learning step: -1.584252953529358
desired expected reward: 168.19247436523438






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  0.  3.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  0.  3.  1. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  0.  3.  1. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[187.67648]
 [179.05844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3.  1. 23.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -4.695678234100342
desired expected reward: 199.95248413085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[175.15733]
 [176.22011]
 [177.14719]
 [175.70354]
 [176.63062]
 [176.72403]
 [179.28174]
 [176.8768 ]
 [180.33647]
 [181.29778]
 [178.7652 ]
 [180.0903 ]
 [177.80386]
 [178.61241]
 [180.24306]
 [188.70836]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3.  1. 23.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.7824370861053467
desired expected reward: 182.37950134277344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [8. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [11.  0.  1.  3.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  1.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[200.00743]
 [190.58083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [ 1.  0.  3.  1. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.593369722366333
desired expected reward: 185.114990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[188.8779 ]
 [189.94067]
 [190.86774]
 [190.3512 ]
 [193.0023 ]
 [190.59735]
 [191.52444]
 [202.42891]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  3.  3.] 
cards in discard: [ 1.  0.  3.  1. 23.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.166006565093994
desired expected reward: 195.7821502685547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 2. 0. 6. 0.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 2. 0. 6. 0.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [0. 2. 0. 6. 0.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [0. 2. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[211.56]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 0. 6. 0.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.9828689098358154
desired expected reward: 198.44607543945312





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[197.3627 ]
 [198.42548]
 [197.87468]
 [199.35252]
 [197.90889]
 [198.836  ]
 [198.9294 ]
 [201.48709]
 [199.0821 ]
 [202.54182]
 [203.50313]
 [200.97054]
 [202.29565]
 [200.00922]
 [200.81776]
 [202.44844]
 [210.91373]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 0. 6. 0.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 6 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.507058143615723
desired expected reward: 206.09640502929688



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  1.  3. 10. 22.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [ 1.  1.  3. 10. 22.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 1.  1.  3. 10. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 22.] 
expected returns: [[183.03088]
 [172.12639]
 [172.93492]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  3. 10. 22.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -5.159210205078125
desired expected reward: 205.75450134277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[171.98381]
 [173.04657]
 [173.97366]
 [173.45708]
 [173.55049]
 [176.10823]
 [173.70326]
 [178.12425]
 [175.59166]
 [174.63034]
 [177.06955]
 [185.5348 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 10. 22.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  5.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.591834783554077
desired expected reward: 177.3331298828125



buy possibilites: [-1] 
expected returns: [[166.73134]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  3. 10. 22.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.  30.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 32.5 

action type: buy - action 10.0
Learning step: -3.260474443435669
desired expected reward: 171.36985778808594






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [10.  0. 11.  8.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [10.  0. 11.  8.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [10.  0. 11.  8.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [10.  0. 11.  8.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 11.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[226.76082]
 [215.95322]
 [217.42003]
 [215.03882]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  8.  3.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -1.9545681476593018
desired expected reward: 164.77676391601562



action possibilites: [-1. 11.  8.] 
expected returns: [[242.83539]
 [233.4946 ]
 [231.1134 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  3.  6.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action 10.0
Learning step: -2.9648330211639404
desired expected reward: 211.91603088378906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[225.98068]
 [227.42224]
 [239.40091]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  8.  3.  6.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -4.457250118255615
desired expected reward: 238.378173828125






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22. 10.  0. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  0. 10.  0.  3.] 
adversary cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22. 10.  0. 11.  8.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[228.01913]
 [217.21152]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.  3.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22. 10.  0. 11.  8.  3.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -5.50471830368042
desired expected reward: 233.89617919921875



action possibilites: [-1.] 
expected returns: [[228.65265]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22. 10.  0. 11.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 10.0
Learning step: -3.2658913135528564
desired expected reward: 213.9456329345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[219.01212]
 [220.06163]
 [220.976  ]
 [220.45369]
 [223.09155]
 [220.71036]
 [221.62476]
 [232.43237]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 0.] 
cards in discard: [ 1.  0.  3.  1. 23. 11.  0.  1.  3.  3.  0.  2.  0.  6.  0. 10.  1.  1.
  3. 10. 22. 10.  0. 11.  8.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1.0
Learning step: -3.925032138824463
desired expected reward: 224.7276153564453






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 0.  0. 10.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[200.35675]
 [189.54916]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -5.799034595489502
desired expected reward: 226.63333129882812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[187.65465]
 [188.70412]
 [189.61852]
 [188.18182]
 [189.0962 ]
 [189.20375]
 [191.73409]
 [189.3529 ]
 [192.78615]
 [193.73067]
 [191.21179]
 [192.52945]
 [190.26726]
 [191.06264]
 [192.67862]
 [201.0749 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  1.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -4.167660236358643
desired expected reward: 195.28512573242188



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [18. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [11.  1. 11.  0.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [11.  1. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[243.14517]
 [233.80438]
 [233.80438]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  1. 11.  0.  0.] 
cards in discard: [ 0.  0. 10.  0.  1.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  8.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.2753098011016846
desired expected reward: 197.79957580566406



action possibilites: [-1] 
expected returns: [[279.01065]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 64 

action type: gain_card_n - action 8
Learning step: -2.054943084716797
desired expected reward: 228.59869384765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[273.24884]
 [274.2983 ]
 [275.21268]
 [274.6904 ]
 [274.79794]
 [277.32828]
 [274.94708]
 [279.32486]
 [276.80597]
 [275.86148]
 [278.2728 ]
 [286.66907]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  2. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 48 

action type: take_action - action -1
Learning step: -5.219520568847656
desired expected reward: 273.7911376953125



buy possibilites: [-1] 
expected returns: [[268.0718]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 11.  0.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  1. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 30.  0.  0. 20.  0.  0.  0.  0. -1.  0.  0.  2.  0.] 
sum of rewards: 49.0 

action type: buy - action 8.0
Learning step: -5.2657389640808105
desired expected reward: 269.68133544921875






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  1. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8] -> size -> 36 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  1. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 3. 3. 8. 0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8] -> size -> 36 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [0. 3. 3. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[196.10205]
 [184.38004]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  1. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -7.703244209289551
desired expected reward: 260.3685607910156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[184.4205 ]
 [186.38435]
 [185.86206]
 [186.11876]
 [197.84073]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  1. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -3.9788734912872314
desired expected reward: 190.28594970703125



buy possibilites: [-1] 
expected returns: [[148.01678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 8. 0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 34 

action type: buy - action 8.0
Learning step: -4.253744602203369
desired expected reward: 181.86500549316406






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [10.  3.  6.  1.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [10.  3.  6.  1.  6.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [10.  3.  6.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[145.33806]
 [134.57767]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  6.  1.  6.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -2.819586992263794
desired expected reward: 145.19720458984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[133.19783]
 [135.15303]
 [134.62566]
 [146.55812]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  6.  1.  6.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.6264665126800537
desired expected reward: 141.6433868408203



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [2. 1. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [2. 1. 0. 3. 3.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [2. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[150.21898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [2. 1. 0. 3. 3.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -2.5479798316955566
desired expected reward: 144.01016235351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[138.62796]
 [139.63557]
 [139.10301]
 [140.51227]
 [139.1273 ]
 [140.00398]
 [140.11423]
 [142.54257]
 [143.55377]
 [144.45477]
 [142.03429]
 [143.30116]
 [141.1333 ]
 [141.8919 ]
 [143.44356]
 [151.74734]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [2. 1. 0. 3. 3.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.8146488666534424
desired expected reward: 147.40432739257812



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  3. 22.  1.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  3. 22.  1.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  3. 22.  1.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  3. 22.  1.  0.] 
adversary cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 1.  3. 22.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[141.4402 ]
 [131.46707]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 22.  1.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -3.0650393962860107
desired expected reward: 148.68231201171875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[119.139755]
 [120.18521 ]
 [121.09495 ]
 [119.657845]
 [120.56759 ]
 [120.682304]
 [123.201904]
 [124.2515  ]
 [125.18638 ]
 [122.67453 ]
 [123.98917 ]
 [121.73965 ]
 [122.52691 ]
 [124.13677 ]
 [132.50003 ]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 22.  1.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  7.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.8079967498779297
desired expected reward: 138.6322021484375



buy possibilites: [-1] 
expected returns: [[157.92513]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 22.  1.  0.] 
cards in discard: [ 0.  0. 10.  0.  1. 14.  8. 11.  1. 11.  0.  0.  8.  0.  3.  3.  8.  0.
 10.  3.  6.  1.  6.  2.  1.  0.  3.  3. 14.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3. 30.  0.  0.  0.  0.  0.  0.  0. -3.  0.  0.  8.  0.] 
sum of rewards: 33.0 

action type: buy - action 14.0
Learning step: -0.9304108023643494
desired expected reward: 121.74411010742188






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [ 6. 10. 10.  6. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [ 6. 10. 10.  6. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [ 6. 10. 10.  6. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 6. 10. 10.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 23.] 
expected returns: [[152.2618 ]
 [141.50139]
 [141.50139]
 [143.75092]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  6. 23.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -3.1779255867004395
desired expected reward: 154.7471923828125



action possibilites: [-1. 10. 10.] 
expected returns: [[205.77875]
 [195.01834]
 [195.01834]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10. 10.  6.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 20  0  0  0  0  0  0  0  0  1] 
sum of rewards: 49 

action type: take_action - action 23.0
Learning step: -0.15593567490577698
desired expected reward: 142.83470153808594



action possibilites: [-1. 10.] 
expected returns: [[219.58548]
 [208.82509]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
action values: 2 
buys: 1 
player value: 1 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 40  0  0  0  0  0  0  0  0  2] 
sum of rewards: 70 

action type: take_action - action 10.0
Learning step: -1.3750633001327515
desired expected reward: 193.64328002929688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[207.20897]
 [208.25444]
 [209.16417]
 [208.6368 ]
 [208.75153]
 [211.27109]
 [213.2556 ]
 [210.74376]
 [209.80887]
 [212.20598]
 [220.56926]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  1.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14] -> size -> 38 
action values: 0 
buys: 2 
player value: 4 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  6.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 68 

action type: take_action - action -1.0
Learning step: -2.7329909801483154
desired expected reward: 216.8524932861328



buy possibilites: [ 0.  6. -1.] 
expected returns: [[219.85152]
 [221.27934]
 [233.2118 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 10.  6.  0.  1.] 
cards in discard: [14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [23. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0 40  0  0  0  0 -4  0  0 16  0] 
sum of rewards: 80 

action type: buy - action 14.0
Learning step: -1.3914955854415894
desired expected reward: 209.35226440429688






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[130.3772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: -7.363643169403076
desired expected reward: 225.84815979003906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[117.34959 ]
 [119.005264]
 [118.558495]
 [128.835   ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -2.2340264320373535
desired expected reward: 126.51921081542969



buy possibilites: [-1] 
expected returns: [[148.277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.  30.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -7.0 

action type: buy - action 0.0
Learning step: -2.881247043609619
desired expected reward: 114.46833801269531






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
adversary victory points: 3
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3.  0.  0. 11. 10.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
adversary victory points: 3
player victory points: 0 





Player: 0 
cards in hand: [ 3.  0.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[113.45959]
 [105.25098]
 [104.01025]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: -3.5507259368896484
desired expected reward: 144.7262725830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[103.27258 ]
 [104.928345]
 [104.473206]
 [115.018135]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 23. 29. 24. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: -1.6786857843399048
desired expected reward: 109.70264434814453



buy possibilites: [-1] 
expected returns: [[83.482704]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11. 10.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0 -6  0  0  8  0] 
sum of rewards: 41 

action type: buy - action 3.0
Learning step: -1.3180557489395142
desired expected reward: 103.61027526855469






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  8.  8. 14.  3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  8.  8. 14.  3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 1.  8.  8. 14.  3.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 1.  8.  8. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 14.] 
expected returns: [[140.55458]
 [130.09816]
 [130.09816]
 [131.68723]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  8. 14.  3.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: 0.8486465811729431
desired expected reward: 84.33135223388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[129.44127]
 [131.13252]
 [130.66772]
 [141.37172]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  8.  8. 14.  3.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -1.9958785772323608
desired expected reward: 138.55870056152344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 2. 1.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [3. 0. 0. 2. 1.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [3. 0. 0. 2. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[160.4917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 2. 1.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -1.5075229406356812
desired expected reward: 139.86419677734375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[146.99524]
 [147.97517]
 [147.45407]
 [148.82666]
 [147.47209]
 [148.3236 ]
 [148.4407 ]
 [150.8073 ]
 [151.79395]
 [152.66342]
 [150.30423]
 [151.53424]
 [149.43472]
 [150.1617 ]
 [151.6768 ]
 [159.52315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 2. 1.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 7 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -2.5974960327148438
desired expected reward: 157.89419555664062



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10.  1.  0.  0.  1.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10.  1.  0.  0.  1.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10.  1.  0.  0.  1.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [10.  1.  0.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[111.04478]
 [101.38672]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0.  0.  1.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -3.5858285427093506
desired expected reward: 155.9373016357422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 99.053505]
 [ 99.99003 ]
 [ 99.49075 ]
 [100.80503 ]
 [ 99.50809 ]
 [100.323105]
 [100.43535 ]
 [102.701004]
 [103.64559 ]
 [104.477936]
 [102.21906 ]
 [103.396965]
 [101.38673 ]
 [102.082695]
 [103.533325]
 [111.04478 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  1.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  8.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -1.2111233472824097
desired expected reward: 109.83364868164062



buy possibilites: [-1] 
expected returns: [[83.94407]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0.  0.  1.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5.   0.   4.  40.   0.   0.   0.   0.   0.   0.   0.  -7.   0.   0.
  4.5  0. ] 
sum of rewards: 36.5 

action type: buy - action 11.0
Learning step: -1.4213085174560547
desired expected reward: 101.2796859741211






         -------------------- Turn: 55 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8. 22.  1. 14.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8. 22.  1. 14.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 6.  8. 22.  1. 14.] 
adversary cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 6.  8. 22.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22. 14.] 
expected returns: [[78.27022 ]
 [68.236916]
 [69.645996]
 [69.773636]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8. 22.  1. 14.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.5679100155830383
desired expected reward: 83.37615966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[66.818726]
 [68.45429 ]
 [68.00482 ]
 [78.27022 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 22.  1. 14.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 23. 29. 23. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.29740601778030396
desired expected reward: 77.97280883789062



buy possibilites: [-1] 
expected returns: [[78.9404]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8. 22.  1. 14.] 
cards in discard: [14. 23. 10.  6. 10.  6.  0.  1.  0.  3.  3.  0.  0.  3.  3.  3.  0.  0.
 11. 10.  1.  8.  8. 14.  3.  3.  0.  0.  2.  1. 11. 10.  1.  0.  0.  1.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0 -8  0  0  8  0] 
sum of rewards: 50 

action type: buy - action 3.0
Learning step: 0.8534446954727173
desired expected reward: 69.30773162841797






         -------------------- Turn: 56 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 10. 14.  1. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3. 10. 14.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 11.] 
expected returns: [[165.7361 ]
 [154.97089]
 [155.89857]
 [156.43556]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 14.  1. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: 2.1890714168548584
desired expected reward: 81.12947082519531



action possibilites: [-1] 
expected returns: [[225.23738]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  1. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action 14.0
Learning step: 0.7793647646903992
desired expected reward: 156.5488739013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[213.38629]
 [214.43196]
 [215.34058]
 [214.80359]
 [214.92902]
 [217.4543 ]
 [219.43512]
 [216.9173 ]
 [215.98961]
 [218.382  ]
 [226.75485]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10. 10.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: -2.776506185531616
desired expected reward: 222.46087646484375



buy possibilites: [-1] 
expected returns: [[227.20601]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  1. 11.] 
cards in discard: [29.] 
cards in deck: 38 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0 -9  0  0 32  0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: -1.2481071949005127
desired expected reward: 218.18699645996094






         -------------------- Turn: 57 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [14.  6.  0.  0.  8.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [14.  6.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[161.3635 ]
 [151.81024]
 [150.03645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  0.  0.  8.] 
cards in discard: [29. 14.  3. 10.  1. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1
Learning step: -5.330917835235596
desired expected reward: 221.87509155273438





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[148.96692]
 [150.85854]
 [150.33784]
 [161.94159]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  0.  0.  8.] 
cards in discard: [29. 14.  3. 10.  1. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -1.9930180311203003
desired expected reward: 158.59286499023438



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10. 14.  0.  1.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10. 14.  0.  1.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10. 14.  0.  1.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [10. 14.  0.  1.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [10. 14.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14.] 
expected returns: [[88.10613]
 [79.68458]
 [80.40848]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  0.  1.  0.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -3.696126699447632
desired expected reward: 158.2454833984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[79.401215]
 [80.220665]
 [80.93464 ]
 [80.512596]
 [80.60875 ]
 [82.59212 ]
 [84.136055]
 [82.170074]
 [81.44619 ]
 [83.31601 ]
 [89.89546 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 14.  0.  1.  0.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 0.062891386449337
desired expected reward: 87.42640686035156



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 59 -------------------- 
Player: 1 
cards in hand: [8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[49.849483]
 [42.92516 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -0.9148708581924438
desired expected reward: 88.9805908203125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[41.088318]
 [41.85068 ]
 [42.520573]
 [42.12273 ]
 [42.213356]
 [44.082638]
 [45.537743]
 [43.6848  ]
 [43.002556]
 [44.76488 ]
 [51.024097]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 1.0686349868774414
desired expected reward: 50.91811752319336



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 60 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 23.  3.  1.  3.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 23.  3.  1.  3.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [ 3. 23.  3.  1.  3.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 3. 23.  3.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[105.23038]
 [ 97.4226 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  3.  1.  3.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 2.2694456577301025
desired expected reward: 53.29354476928711



action possibilites: [-1.] 
expected returns: [[93.91322]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 3. 2.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  3] 
sum of rewards: 73 

action type: take_action - action 23.0
Learning step: 0.8919178247451782
desired expected reward: 98.31450653076172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[81.28877 ]
 [82.1876  ]
 [81.7123  ]
 [82.97936 ]
 [81.72304 ]
 [82.511215]
 [82.618256]
 [84.81755 ]
 [85.727165]
 [86.52973 ]
 [84.34941 ]
 [85.4833  ]
 [83.546844]
 [84.21259 ]
 [85.62012 ]
 [92.91682 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 2.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29] -> size -> 44 
action values: 0 
buys: 2 
player value: 6 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  4.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 0.7907204031944275
desired expected reward: 94.70394134521484



buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[12.412303]
 [12.899286]
 [13.338069]
 [13.075038]
 [14.406549]
 [13.662267]
 [19.48886 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 3. 2.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0] -> size -> 3 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  50   0   0  20   0   0   0   0 -10   0   0   9   0] 
sum of rewards: 69 

action type: buy - action 10.0
Learning step: -0.3527641296386719
desired expected reward: 83.19407653808594






         -------------------- Turn: 61 -------------------- 
Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 22. 10.  3.  1.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 22. 10.  3.  1.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 22. 10.  3.  1.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 0. 22. 10.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[57.475468]
 [49.96691 ]
 [49.391796]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22. 10.  3.  1.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 2.7561378479003906
desired expected reward: 22.2450008392334



action possibilites: [-1. 22.] 
expected returns: [[57.660786]
 [50.1711  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  3.  1.  6.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action 10.0
Learning step: 2.282660722732544
desired expected reward: 51.674461364746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[47.66907 ]
 [48.444084]
 [49.11929 ]
 [48.72016 ]
 [50.687042]
 [49.603237]
 [57.66079 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  3.  1.  6.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1.0
Learning step: 1.8253099918365479
desired expected reward: 59.4860954284668






         -------------------- Turn: 62 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8. 1. 6. 3. 8.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8. 1. 6. 3. 8.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [8. 1. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[22.775827]
 [15.359582]
 [15.359582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 6. 3. 8.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: 0.06985092163085938
desired expected reward: 57.73063659667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[14.330333]
 [15.518889]
 [15.186063]
 [22.775827]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 6. 3. 8.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: 1.803510069847107
desired expected reward: 24.5793399810791



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 10.  1. 11.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 10.  1. 11.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 23. 29. 22. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 10.  1. 11.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  3. 10.  1. 11.] 
adversary cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 0.  3. 10.  1. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[75.69556 ]
 [67.42019 ]
 [68.534325]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  1. 11.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1.0
Learning step: 2.502366781234741
desired expected reward: 25.278196334838867



action possibilites: [-1. 11.] 
expected returns: [[86.39073]
 [79.23822]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 6. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action 10.0
Learning step: 1.4933632612228394
desired expected reward: 69.64021301269531





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[76.18204]
 [76.96576]
 [77.6506 ]
 [77.24441]
 [79.23823]
 [78.14208]
 [86.39073]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 6. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 60 

action type: take_action - action -1.0
Learning step: 0.5331718325614929
desired expected reward: 86.92390441894531



buy possibilites: [-1] 
expected returns: [[64.749245]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  1. 11.  3.] 
cards in discard: [29. 14.  3. 10.  1. 11. 14.  6.  0.  0.  8. 10. 14.  0.  1.  0. 11.  0.
  0.  0.  0. 10. 23.  3.  3.  1.  3.  2. 10.  0. 22.  3.  1.  6.  8.  1.
  6.  3.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 5. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [3. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3] -> size -> 4 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[ -5.   0.   5.  40.   0.   0.  20. -30.   0.   0.   0. -11.   0.   0.
   0.   0.] 
sum of rewards: 19.0 

action type: buy - action 0.0
Learning step: -1.4022438526153564
desired expected reward: 74.77979278564453






         -------------------- Turn: 64 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [14.  8.  2.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [14.  8.  2.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [14.  8.  2.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [14.  8.  2.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.  8.] 
expected returns: [[212.20285]
 [202.55792]
 [200.7555 ]
 [200.7555 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  2.  8.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: buy - action -1
Learning step: 3.40399432182312
desired expected reward: 68.15323638916016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[192.98473]
 [194.0125 ]
 [194.91069]
 [194.37782]
 [194.49736]
 [196.99289]
 [198.92084]
 [196.46   ]
 [195.55582]
 [197.8971 ]
 [206.10497]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  2.  8.  0.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 0 0 3 0] -> size -> 5 
adversary victory points: 1
player victory points: 5 

Reward from previous game state: 
[-5  0  5 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 40 

action type: take_action - action -1.0
Learning step: -4.009167671203613
desired expected reward: 206.63365173339844



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 65 -------------------- 
Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0 0 3 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 23.  0. 14.] 
adversary cards in discard: [14.  8.  2.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 23.  0. 14.] 
adversary cards in discard: [14.  8.  2.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 3.  0. 23.  0. 14.] 
adversary cards in discard: [14.  8.  2.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0. 23.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
expected returns: [[154.17412]
 [145.806  ]
 [144.52917]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 23.  0. 14.] 
cards in discard: [14.  8.  2.  8.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -4.425867557525635
desired expected reward: 201.6790771484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[140.28305]
 [142.20901]
 [141.67615]
 [153.40327]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 23.  0. 14.] 
cards in discard: [14.  8.  2.  8.  0.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: take_action - action -1.0
Learning step: -1.8274677991867065
desired expected reward: 151.58226013183594



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 66 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0. 11. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 4. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0. 11. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  0. 11. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
adversary victory points: 5
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0. 11. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10.] 
expected returns: [[79.94659]
 [72.2758 ]
 [71.10701]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 11. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  9.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 50 

action type: buy - action -1.0
Learning step: -3.454536199569702
desired expected reward: 149.94876098632812



action possibilites: [-1] 
expected returns: [[105.74814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[ -5   0   5  50   0   0  20   0   0   0   0 -12   0   0  16   0] 
sum of rewards: 74 

action type: gain_card_n - action 9
Learning step: 2.5348172187805176
desired expected reward: 73.42514038085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[ 91.63842]
 [ 93.25508]
 [ 92.80781]
 [102.7573 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 29. 21. 30.  8.  5.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 5 

Reward from previous game state: 
[-5  0  5 50  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 70 

action type: take_action - action -1
Learning step: 0.43255576491355896
desired expected reward: 106.18069458007812



buy possibilites: [-1] 
expected returns: [[73.337685]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[  -5.    0.    4.   40.    0.    0.   20.    0.    0.    0.    0.  -13.
    0. -300.    0.    0.] 
sum of rewards: -254.0 

action type: buy - action 6.0
Learning step: -15.690292358398438
desired expected reward: 77.11752319335938






         -------------------- Turn: 67 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [ 0.  8.  1. 10.  0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 0.  8.  1. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[37.28004 ]
 [28.542723]
 [29.207287]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.9455909729003906
desired expected reward: 72.39208984375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[21.696314]
 [22.4069  ]
 [23.034891]
 [22.662348]
 [22.745613]
 [24.490847]
 [25.838823]
 [24.118305]
 [23.485943]
 [25.123207]
 [31.076124]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6] -> size -> 48 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  8.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.7028940320014954
desired expected reward: 37.982933044433594



buy possibilites: [-1] 
expected returns: [[76.20311]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1. 10.  0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  40   0   0   0   0   0   0   0 -14   0   0  32   0] 
sum of rewards: 57 

action type: buy - action 15.0
Learning step: 3.3084099292755127
desired expected reward: 28.431612014770508






         -------------------- Turn: 68 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [29. 10.  0.  0. 10.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 10.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 10.] 
expected returns: [[19.017286]
 [14.448884]
 [12.500959]
 [12.500959]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.  0. 10.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -1.48527991771698
desired expected reward: 74.71782684326172



action possibilites: [-1. 29. 10.] 
expected returns: [[29.340553]
 [24.53226 ]
 [22.283297]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action 10.0
Learning step: 2.817716121673584
desired expected reward: 17.713623046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[20.5624  ]
 [21.848677]
 [21.486702]
 [29.340553]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0. 10.  3.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1.0
Learning step: 2.0704753398895264
desired expected reward: 31.411029815673828






         -------------------- Turn: 69 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 11. 11.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 11. 11.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1.  0.  3. 11. 11.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 1.  0.  3. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.] 
expected returns: [[68.296585]
 [59.766167]
 [59.766167]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  3. 11. 11.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 1.951130747795105
desired expected reward: 31.291685104370117





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[56.00521 ]
 [56.9665  ]
 [57.806583]
 [57.30201 ]
 [59.76617 ]
 [58.414883]
 [68.29658 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  3. 11. 11.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.03747749328613281
desired expected reward: 68.25910949707031



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 70 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  6. 14.  3.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  6. 14.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[39.380657]
 [32.115242]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -0.6225304007530212
desired expected reward: 67.67405700683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.546595]
 [30.568613]
 [39.380657]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 14.  3.  3.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: 0.7921504974365234
desired expected reward: 40.172813415527344



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 71 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [6. 1. 1. 1. 0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [6. 1. 1. 1. 0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 3. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [6. 1. 1. 1. 0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [6. 1. 1. 1. 0.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [6. 1. 1. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[101.742714]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 1. 1. 0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: 2.2701783180236816
desired expected reward: 41.650840759277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 89.17329 ]
 [ 90.15629 ]
 [ 89.64488 ]
 [ 91.01186 ]
 [ 89.64359 ]
 [ 90.499176]
 [ 90.60951 ]
 [ 93.00552 ]
 [ 93.98215 ]
 [ 94.847115]
 [ 92.48635 ]
 [ 93.70621 ]
 [ 91.627174]
 [ 92.32205 ]
 [ 93.87051 ]
 [101.74271 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 1. 0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15] -> size -> 49 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 2. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: take_action - action -1.0
Learning step: -0.9605369567871094
desired expected reward: 100.78218078613281



buy possibilites: [-1] 
expected returns: [[75.55115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 1. 1. 0.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 7 
card supply: [ 1. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.   0. -30.   0.   0.   0. -15.   0.   0.
   0.   0.] 
sum of rewards: -6.0 

action type: buy - action 0.0
Learning step: -3.0587635040283203
desired expected reward: 86.1145248413086






         -------------------- Turn: 72 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1. 22.  3. 10.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.  6.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1. 22.  3. 10.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.  6.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1. 22.  3. 10.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.  6.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 0] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 1. 22.  3. 10.  3.] 
adversary cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.  6.  1.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [ 1. 22.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 10.] 
expected returns: [[62.518654]
 [53.554733]
 [52.89195 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  3. 10.  3.] 
cards in discard: [14.  8.  2.  8.  0.  3.  0. 23.  0. 14. 15.  6. 11.  6.  0. 10.  0. 15.
  0.  8.  1. 10.  0. 10. 29.  0.  0. 10.  3.  1.  0.  3. 11. 11.  3.  6.
 14.  3.  3.  0.  6.  1.  1.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: -0.4955459535121918
desired expected reward: 75.05560302734375



action possibilites: [-1] 
expected returns: [[119.03903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3. 10.  3.  6. 23. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 79 

action type: LIBRARY: skip_action_card - action 1
Learning step: -3.7421517372131348
desired expected reward: 203.66844177246094





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[112.67993]
 [112.26273]
 [121.43686]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3. 10.  3.  6. 23. 29.] 
cards in discard: [] 
cards in deck: 41 
card top of deck: [] 
played cards: [22. 15.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 0] -> size -> 2 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 79 

action type: take_action - action -1
Learning step: 0.658367931842804
desired expected reward: 119.69740295410156






         -------------------- Turn: 73 -------------------- 
Player: 1 
cards in hand: [8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 0] -> size -> 2 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [14.  1.  6.  6.  1.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [14.  1.  6.  6.  1.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [14.  1.  6.  6.  1.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
adversary victory points: 4
player victory points: 0 





Player: 0 
cards in hand: [14.  1.  6.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[45.25886 ]
 [38.283745]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  6.  6.  1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1.0
Learning step: -3.145535945892334
desired expected reward: 118.29132080078125



action possibilites: [-1] 
expected returns: [[60.66882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action 14.0
Learning step: 2.328244686126709
desired expected reward: 42.06431579589844





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[50.732487]
 [50.341167]
 [51.39316 ]
 [50.335857]
 [50.99653 ]
 [51.077667]
 [52.922436]
 [53.66122 ]
 [54.326374]
 [52.52581 ]
 [53.445698]
 [51.870445]
 [52.393703]
 [53.578857]
 [59.735336]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0] -> size -> 50 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  9.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 1.1749101877212524
desired expected reward: 61.84373092651367



buy possibilites: [-1] 
expected returns: [[38.071903]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16.] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4.  40.   0.   0.  20.   0.   0.   0.   0. -16.   0.   0.
   8.   0.] 
sum of rewards: 51.0 

action type: buy - action 16.0
Learning step: 0.8527342081069946
desired expected reward: 51.93040466308594






         -------------------- Turn: 74 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16] -> size -> 51 
adversary victory points: 4
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [11. 11.  0. 10. 10.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16] -> size -> 51 
adversary victory points: 4
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 10. 10.] 
expected returns: [[0.98423743]
 [0.31162658]
 [0.31162658]
 [0.20487852]
 [0.20487852]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  0. 10. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  7.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 39 

action type: buy - action -1
Learning step: 0.061553001403808594
desired expected reward: 38.13345718383789



action possibilites: [-1] 
expected returns: [[0.9842374]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[ -5   0   4  40   0   0  20   0   0   0   0 -17   0   0   9   0] 
sum of rewards: 51 

action type: gain_card_n - action 4
Learning step: 2.5696940422058105
desired expected reward: 2.6187217235565186





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[0.11610749]
 [0.9842374 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 29. 21. 30.  8.  4.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 4 

Reward from previous game state: 
[-5  0  4 40  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 59 

action type: take_action - action -1
Learning step: 2.9177041053771973
desired expected reward: 3.9019415378570557



buy possibilites: [-1] 
expected returns: [[0.9842374]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0. 10. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[  -5.    0.    3.   30.    0.    0.   20.    0.    0.    0.    0.  -18.
    0. -300.    0.    0.] 
sum of rewards: -270.0 

action type: buy - action 6.0
Learning step: -13.483660697937012
desired expected reward: -13.367552757263184






         -------------------- Turn: 75 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  3.  3. 10.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  3.  3. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[2.059694  ]
 [0.53043485]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1
Learning step: 1.3879191875457764
desired expected reward: 2.3721566200256348





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[0.38350862]
 [2.059694  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: take_action - action -1.0
Learning step: 1.3332613706588745
desired expected reward: 3.392955780029297



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 76 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3. 14.  0.  8. 11.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3. 14.  0.  8. 11.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
adversary victory points: 3
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3. 14.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 11.] 
expected returns: [[4.17483  ]
 [1.878529 ]
 [1.4966985]
 [1.9943465]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  0.  8. 11.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1  1 10  6 22 23  1 10  8  1 11  0  6  3
  3  1  1  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6
 15  0 16 11  6] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  3 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 28 

action type: buy - action -1.0
Learning step: 1.369398832321167
desired expected reward: 3.4290931224823



action possibilites: [-1] 
expected returns: [[70.67566]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: trash_cards_n_from_hand - action 12
Learning step: 3.355858325958252
desired expected reward: 5.042739391326904





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[62.176147]
 [70.67566 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 37 

action type: take_action - action -1
Learning step: -0.1447807401418686
desired expected reward: 70.53087615966797






         -------------------- Turn: 77 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 3.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[8.161741 ]
 [3.5221784]
 [3.8217897]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: -2.5362048149108887
desired expected reward: 68.13945770263672





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[3.6050415]
 [3.424899 ]
 [8.161741 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.5882299542427063
desired expected reward: 8.749975204467773



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 78 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 8. 14.  0.  3.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 14.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
expected returns: [[5.0980673]
 [2.184854 ]
 [2.581233 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0.  3.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: buy - action -1.0
Learning step: 0.43697890639305115
desired expected reward: 10.555398941040039





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[2.2386417]
 [2.1207447]
 [5.0980673]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  3.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6] -> size -> 50 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  3.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  2 20  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 17 

action type: take_action - action -1.0
Learning step: 0.6863632202148438
desired expected reward: 5.784430980682373



buy possibilites: [-1] 
expected returns: [[2.06498]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 14.  0.  3.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6] -> size -> 51 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 23. 29. 21. 30.  8.  2.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.   10.    0.    0.    0.    0.    0.    0.    0.  -16.
    0. -300.    0.    0.] 
sum of rewards: -310.0 

action type: buy - action 6.0
Learning step: -15.559576988220215
desired expected reward: -13.438831329345703






         -------------------- Turn: 79 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  2.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6] -> size -> 51 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  2.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [1. 0. 0. 0. 1.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6] -> size -> 51 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [1. 0. 0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.197472]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  2.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1
Learning step: 0.8761941194534302
desired expected reward: 2.941174030303955





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[22.582275]
 [22.25853 ]
 [23.133469]
 [22.251593]
 [22.802792]
 [22.867483]
 [24.421938]
 [25.040138]
 [25.601004]
 [24.086185]
 [24.856453]
 [23.534937]
 [23.968182]
 [24.974453]
 [30.19747 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6] -> size -> 51 
action values: 0 
buys: 1 
player value: 7 
card supply: [ 0. 23. 29. 21. 30.  8.  2.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: -0.6030262112617493
desired expected reward: 29.594446182250977



buy possibilites: [-1] 
expected returns: [[31.404736]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 1.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
action values: 0 
buys: 0 
player value: 7 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -17.
    0. -300.    0.    0.] 
sum of rewards: -322.0 

action type: buy - action 6.0
Learning step: -16.533533096313477
desired expected reward: 6.269258499145508






         -------------------- Turn: 80 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  1. 15.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  1. 15.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 6.  0.  1. 15.  0.] 
adversary cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 6.  0.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[21.040466]
 [16.312906]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  1. 15.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -1.3753045797348022
desired expected reward: 30.029430389404297





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[14.168571]
 [14.662707]
 [14.366219]
 [14.424106]
 [15.816444]
 [16.86892 ]
 [15.514605]
 [15.022421]
 [16.312906]
 [21.040466]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 15.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 23. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.8915109634399414
desired expected reward: 20.14896011352539



buy possibilites: [-1] 
expected returns: [[6.6698327]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  1. 15.  0.] 
cards in discard: [22. 15.  1.  3. 10.  3.  6. 23. 29. 16. 14.  1.  6.  6.  1. 11.  6. 11.
 11.  0. 10. 10.  3.  3.  3. 10.  0.  8. 14.  3.  8.  0.  0. 10.  6.  8.
 14.  0.  3.  0.  6.  1.  0.  0.  0.  1.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  -18.
   0.    0.    4.5   0. ] 
sum of rewards: -18.5 

action type: buy - action 1.0
Learning step: -1.4833574295043945
desired expected reward: 12.685215950012207






         -------------------- Turn: 81 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0. 10.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0. 10.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [10.  0. 10.  1.  2.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [10.  0. 10.  1.  2.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[169.3168 ]
 [159.32013]
 [159.32013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  1.  2.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 3.129760503768921
desired expected reward: 9.799592971801758





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[154.62581]
 [154.11835]
 [155.49011]
 [154.1073 ]
 [154.97159]
 [155.07332]
 [157.49084]
 [158.44579]
 [159.29903]
 [156.97235]
 [158.16254]
 [156.11914]
 [156.79082]
 [158.34406]
 [166.1158 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  1.  2.] 
cards in discard: [] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -5.051412105560303
desired expected reward: 163.55055236816406



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 82 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [22. 15.  1.  8.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [22. 15.  1.  8.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [22. 15.  1.  8.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [22. 15.  1.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22. 15.  8.] 
expected returns: [[128.08582]
 [120.65134]
 [121.8899 ]
 [119.42675]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22. 15.  1.  8.  6.] 
cards in discard: [10.  0. 10.  1.  2.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -5.740993499755859
desired expected reward: 160.3748016357422



action possibilites: [-1] 
expected returns: [[125.67851]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  8.  6.  1.  3.  1.] 
cards in discard: [10.  0. 10.  1.  2.] 
cards in deck: 40 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  4] 
sum of rewards: 19 

action type: take_action - action 22.0
Learning step: -2.254800796508789
desired expected reward: 118.39654541015625





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[118.79943 ]
 [118.405945]
 [119.469284]
 [118.39753 ]
 [119.06738 ]
 [119.14567 ]
 [121.01976 ]
 [121.76927 ]
 [122.44017 ]
 [120.61786 ]
 [121.54698 ]
 [119.95641 ]
 [120.47697 ]
 [121.68985 ]
 [127.79946 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  8.  6.  1.  3.  1.] 
cards in discard: [10.  0. 10.  1.  2.] 
cards in deck: 40 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -2.7438881397247314
desired expected reward: 122.93462371826172






         -------------------- Turn: 83 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  3.  1. 15.  0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  3.  1. 15.  0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [ 0.  3.  1. 15.  0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 0.  3.  1. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[96.25942]
 [90.14982]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  1. 15.  0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1
  3  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16
 11  6  6  6  1] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -4.510940074920654
desired expected reward: 123.28852081298828



action possibilites: [-1] 
expected returns: [[149.92097]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1] -> size -> 52 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 15.0
Learning step: -0.2638908326625824
desired expected reward: 89.88592529296875





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  2.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[138.30247]
 [137.89421]
 [138.99812]
 [137.88344]
 [138.57907]
 [138.6596 ]
 [140.61267]
 [141.37805]
 [142.06291]
 [140.19362]
 [141.14401]
 [139.50876]
 [140.0401 ]
 [141.29753]
 [147.54263]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1] -> size -> 52 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  9.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -3.513920307159424
desired expected reward: 146.4070587158203



buy possibilites: [-1] 
expected returns: [[147.48627]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23.] 
cards in deck: 35 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.  -18.
   0.    0.   12.5   0. ] 
sum of rewards: 9.5 

action type: buy - action 23.0
Learning step: -3.2637596130371094
desired expected reward: 137.8802490234375






         -------------------- Turn: 84 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  6. 14.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  6.  6.  6. 14.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0.  6.  6.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[37.4977  ]
 [31.517136]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6.  6. 14.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -6.816641330718994
desired expected reward: 140.6696319580078



action possibilites: [-1] 
expected returns: [[99.3578]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 14.0
Learning step: 1.4096935987472534
desired expected reward: 32.92683410644531





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
expected returns: [[89.52949 ]
 [90.259834]
 [89.81998 ]
 [91.955154]
 [90.79612 ]
 [99.35782 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 6.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -2.071549892425537
desired expected reward: 97.2862548828125






         -------------------- Turn: 85 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [10. 11.  0.  0.  3.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [10. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[60.15719]
 [53.1674 ]
 [54.12267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  0.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  6.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -3.9166581630706787
desired expected reward: 95.44114685058594



action possibilites: [-1] 
expected returns: [[57.779987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[ -5   0   0   0   0   0  20   0   0   0   0 -19   0   0   9   0] 
sum of rewards: 5 

action type: gain_card_n - action 4
Learning step: -1.0390113592147827
desired expected reward: 50.74220657348633





----------- BUY PHASE ----------- 
buy possibilites: [ 3.  6. -1.] 
expected returns: [[50.152542]
 [49.778545]
 [57.779987]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.9017137885093689
desired expected reward: 56.878273010253906






         -------------------- Turn: 86 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [3. 1. 0. 8. 0.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [3. 1. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[88.96882 ]
 [80.620026]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.1874929666519165
desired expected reward: 56.59249496459961





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[80.13708 ]
 [80.794754]
 [80.39862 ]
 [80.474884]
 [82.337166]
 [83.72505 ]
 [81.936226]
 [81.28084 ]
 [82.99255 ]
 [88.9688  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 8. 0.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -2.7769312858581543
desired expected reward: 86.19187927246094



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 87 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 1. 16.  0. 23.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 1. 16.  0. 23.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8] -> size -> 1 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 1. 16.  0. 23.  6.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 





Player: 0 
cards in hand: [ 1. 16.  0. 23.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 23.] 
expected returns: [[46.332508]
 [38.694973]
 [40.81696 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 16.  0. 23.  6.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -3.7087807655334473
desired expected reward: 85.2600326538086





----------- BUY PHASE ----------- 
buy possibilites: [ 1.  3.  6. 11. 10. -1.] 
expected returns: [[38.38978 ]
 [38.98395 ]
 [38.626015]
 [40.363316]
 [39.420437]
 [46.332516]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 16.  0. 23.  6.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.5961874723434448
desired expected reward: 44.73632049560547



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 88 -------------------- 
Player: 1 
cards in hand: [8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 6.  3. 11. 14.  3.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.  1. 16.
  0. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8] -> size -> 1 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [ 6.  3. 11. 14.  3.] 
adversary cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.  1. 16.
  0. 23.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
adversary victory points: 0
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 6.  3. 11. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[47.912376]
 [41.992374]
 [41.634434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 11. 14.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.  1. 16.
  0. 23.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -1.5375827550888062
desired expected reward: 44.794925689697266





----------- BUY PHASE ----------- 
buy possibilites: [ 6. -1.] 
expected returns: [[40.255077]
 [47.912376]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 11. 14.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.  1. 16.
  0. 23.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11] -> size -> 54 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  1.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -1.613716959953308
desired expected reward: 46.29866027832031



Player 1 won the game! 



Player 0 bought cards:
Copper: 5 
Silver: 6 
Gold: 1 
Estate: 5 
Duchy: 0 
Province: 0 
Curse: 8 

Remodel: 1 
Workshop: 3 
Chapel: 3 
Witch: 0 
Poacher: 1 
Militia: 2 
Market: 2 
Village: 5 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 6.  3. 11. 14.  3.] 
cards in discard: [10.  0. 10.  1.  2. 22. 15.  1.  8.  6.  1.  3.  1. 23. 15.  3.  1.  0.
 14.  0.  6.  6.  6. 11. 11. 10.  0.  0.  3.  3.  1.  0.  8.  0.  1. 16.
  0. 23.  6.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  1  1 10  6 22 23  1 10  8  1  0  6  3  3  1  1  3
  0  2  6 10 11 10 14  8  8 14 14  0  3 11  3 29 10  0 15  6 15  0 16 11
  6  6  6  1 23 11  6] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 0. 22. 29. 21. 30.  8.  0.  8.  5.  0. 10.  9.  5.  8.  3.  9.  7.] 
adversary cards in hand: [8.] 
adversary cards in discard: [] 
adversary owned cards: [8] -> size -> 1 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[  -5 -500   -1  -10    0    0    0    0    0    0    0  -20    0 -300
    0    0] 
sum of rewards: -836 

action type: buy - action 6.0
Learning step: -43.8127555847168
desired expected reward: -3.55767822265625



