 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.576649]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.804713249206543
desired expected reward: 6.019057273864746





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.252552]
 [24.387547]
 [24.37512 ]
 [24.250435]
 [24.333782]
 [24.545137]
 [24.42078 ]
 [24.652689]
 [24.42045 ]
 [24.408352]
 [24.55724 ]
 [24.842407]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6372787356376648
desired expected reward: 24.19139862060547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.359121]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6266819834709167
desired expected reward: 24.21572494506836





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[24.720573]
 [24.855574]
 [24.843143]
 [24.718456]
 [25.01316 ]
 [24.888802]
 [24.876377]
 [25.310432]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6550608277320862
desired expected reward: 24.924959182739258



buy possibilites: [-1] 
expected returns: [[25.549026]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [ 0.  0.  0.  0.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 10.0
Learning step: -0.08802640438079834
desired expected reward: 24.788347244262695






Player: 1 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[24.418564]
 [23.984509]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6591811776161194
desired expected reward: 24.88984489440918



action possibilites: [-1.] 
expected returns: [[25.788467]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.006521301344037056
desired expected reward: 24.236818313598633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[25.091343]
 [25.226337]
 [25.213911]
 [25.089226]
 [25.383928]
 [25.259573]
 [25.247143]
 [25.6812  ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.0574212446808815
desired expected reward: 25.731046676635742



buy possibilites: [-1] 
expected returns: [[26.337713]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 8.0
Learning step: 0.028758887201547623
desired expected reward: 25.288330078125






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.008419]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.675365686416626
desired expected reward: 25.6623477935791





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[24.415558]
 [24.550558]
 [24.53813 ]
 [24.413443]
 [24.496792]
 [24.708145]
 [24.583788]
 [24.815699]
 [24.58346 ]
 [24.57136 ]
 [24.720245]
 [25.005417]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6471802592277527
desired expected reward: 24.568601608276367



buy possibilites: [-1] 
expected returns: [[25.499573]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 8. 10.  0.  0.  0.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.614657402038574
desired expected reward: 14.798785209655762






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 0. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.486923]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6345551013946533
desired expected reward: 24.86501693725586





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.200775]
 [26.335772]
 [26.323345]
 [26.19866 ]
 [26.493362]
 [26.369005]
 [26.356577]
 [26.790632]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6733527183532715
desired expected reward: 26.034467697143555



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 1] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [0. 0. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [10.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.354975]
 [25.920918]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6771308779716492
desired expected reward: 26.113500595092773



action possibilites: [-1.  8.] 
expected returns: [[27.047276]
 [26.625645]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.05021306872367859
desired expected reward: 26.03107452392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[26.164755]
 [26.299755]
 [26.287327]
 [26.16264 ]
 [26.457344]
 [26.332987]
 [26.320559]
 [26.754616]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 8.] 
cards in discard: [0. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 1. 0. 3. 3.] 
adversary cards in discard: [15.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.08391460031270981
desired expected reward: 26.963361740112305






Player: 1 
cards in hand: [0. 1. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 3. 3.] 
cards in discard: [15.  3.  0.  0.  0.  0. 14.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.99358]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6374762058258057
desired expected reward: 25.133071899414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.638329]
 [26.75778 ]
 [26.634583]
 [26.803537]
 [27.213861]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6837649345397949
desired expected reward: 26.520063400268555



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  0. 15.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14] -> size -> 13 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9. 10. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [25.] 
cards in deck: 9 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0.  8. 10.  0.] 
adversary cards in discard: [6. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
adversary victory points: 2
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[29.521318]
 [29.110992]
 [29.098246]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8. 10.  0.] 
cards in discard: [6. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6570008993148804
desired expected reward: 26.556859970092773



action possibilites: [-1.  8.] 
expected returns: [[29.59056 ]
 [29.180239]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 13 
action values: 2 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.1190401241183281
desired expected reward: 29.148216247558594



action possibilites: [-1.] 
expected returns: [[29.194704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 0
Learning step: 0.4648857116699219
desired expected reward: 30.18684196472168





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.794798]
 [28.927   ]
 [28.914248]
 [28.791052]
 [29.081337]
 [28.960009]
 [28.947258]
 [29.37033 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  9. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
adversary victory points: 4
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0.4792118966579437
desired expected reward: 29.67391586303711



buy possibilites: [-1] 
expected returns: [[30.048828]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [6. 0. 3. 3. 0. 6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.  8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 3 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  0. 14.] 
adversary cards in discard: [25. 15.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -265.0 

action type: buy - action 6.0
Learning step: -8.498218536376953
desired expected reward: 20.29283332824707






Player: 1 
cards in hand: [ 3.  0.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  0. 14.] 
cards in discard: [25. 15.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 6. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [25. 15.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [25. 15.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9. 10.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [25. 15.  0.  3.  0. 29.] 
cards in deck: 4 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.754665]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 5
Learning step: -0.6040160655975342
desired expected reward: 25.02472496032715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.34695 ]
 [29.343203]
 [29.922483]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 1 
card supply: [30. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7386078238487244
desired expected reward: 29.246742248535156



buy possibilites: [-1] 
expected returns: [[28.559752]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [6. 0. 0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [15.  1.  3.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.7305310368537903
desired expected reward: 28.616416931152344






Player: 1 
cards in hand: [15.  1.  3.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  9. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  1.  3.  3.  0.] 
cards in discard: [10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [6. 0. 8. 0. 0.] 
adversary cards in discard: [6. 0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [6. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.062956]
 [27.652632]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 0. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.711762011051178
desired expected reward: 27.847990036010742





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[27.42278 ]
 [27.554983]
 [27.542233]
 [27.419037]
 [27.70932 ]
 [27.58799 ]
 [27.57524 ]
 [27.998314]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 0. 0. 3. 3. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7072213888168335
desired expected reward: 27.555051803588867



buy possibilites: [-1] 
expected returns: [[28.22665]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 0. 0.] 
cards in discard: [6. 0. 0. 3. 3. 0. 6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [14.  0.  0.  3.  0.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.676191329956055
desired expected reward: 17.742841720581055






Player: 1 
cards in hand: [14.  0.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [10. 15.  1.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [10. 15.  1.  3.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3.  0.] 
cards in discard: [10. 15.  1.  3.  3.  0.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[28.185612]
 [27.762537]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7008528709411621
desired expected reward: 27.52579689025879



action possibilites: [-1.] 
expected returns: [[30.568022]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.048322733491659164
desired expected reward: 27.261241912841797





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[30.215778]
 [30.347002]
 [30.334078]
 [30.211721]
 [30.500788]
 [30.380604]
 [30.367678]
 [30.786123]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.14708879590034485
desired expected reward: 30.42093276977539



buy possibilites: [-1] 
expected returns: [[28.806784]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 0.  0. 25.  3. 29.] 
adversary cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 10.0
Learning step: 0.38144078850746155
desired expected reward: 30.749122619628906






Player: 1 
cards in hand: [ 0.  0. 25.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 29.] 
cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 25.  3. 29.] 
cards in discard: [10. 15.  1.  3.  3.  0.  1. 14.  0.  0.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [0. 0. 8. 0. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[28.202564]
 [27.797045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7181013226509094
desired expected reward: 28.088682174682617





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.759438]
 [27.890657]
 [27.877733]
 [27.755379]
 [27.837755]
 [28.044441]
 [27.924261]
 [28.147358]
 [27.921124]
 [27.911337]
 [28.054228]
 [28.329782]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  3.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [14.  0.  0. 10.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7065624594688416
desired expected reward: 27.655853271484375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  0.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0. 10.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1. 14. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  9.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  0.  3. 25.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [10.  6.  6.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [10.  6.  6.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.743107]
 [29.324663]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [ 8. 10. 14.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6873679757118225
desired expected reward: 27.642414093017578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.255081]
 [29.251028]
 [29.825426]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  6.  6.  3.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 1 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3. 29.  3.  1.  0.] 
adversary cards in discard: [ 8. 10. 14.  0.  0.  3. 25.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7379897236824036
desired expected reward: 29.1937255859375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 29.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  3.  1.  0.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8] -> size -> 18 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  9. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  8.  0.  0. 10.] 
adversary cards in discard: [10.  6.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[28.239548]
 [27.834028]
 [27.821104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [10.  6.  6.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.74887615442276
desired expected reward: 29.076549530029297





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[27.849665]
 [27.96796 ]
 [27.845606]
 [28.01449 ]
 [28.42001 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [10.  6.  6.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7069358229637146
desired expected reward: 27.69246482849121



buy possibilites: [-1] 
expected returns: [[29.789366]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0.  0. 10.] 
cards in discard: [10.  6.  6.  6.  3.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  0.  1. 15.] 
adversary cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 3.0
Learning step: -0.4362504482269287
desired expected reward: 27.531709671020508






Player: 1 
cards in hand: [ 3.  0.  0.  1. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6.  6.  6.  3.  3.  3.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  7. 10. 10.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6.  6.  6.  3.  3.  3.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0.  1. 15.] 
cards in discard: [ 8. 10. 14.  0.  0.  3. 25. 14. 29.  3.  3.  1.  0.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [10.  6.  6.  6.  3.  3.  3.  8.  0.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.268154]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  6.  6.  6.  3.  3.  3.  8.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7658182978630066
desired expected reward: 29.023548126220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[26.05467 ]
 [26.185892]
 [26.172972]
 [26.05062 ]
 [26.132994]
 [26.339678]
 [26.2195  ]
 [26.442595]
 [26.216362]
 [26.206575]
 [26.349468]
 [26.625017]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [10.  6.  6.  6.  3.  3.  3.  8.  0.  0. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.667483389377594
desired expected reward: 25.79562759399414



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 10.  3.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  8. 29.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1. 10.  8. 11.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1.  8. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  8. 11. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 11. 14.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  7. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  8. 11. 14.] 
cards in discard: [10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[32.506176]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6055489778518677
desired expected reward: 26.01947021484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[32.352745]
 [32.483967]
 [32.47104 ]
 [32.348686]
 [32.63775 ]
 [32.517567]
 [32.504646]
 [32.92309 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  7. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7881858348846436
desired expected reward: 31.897674560546875



buy possibilites: [-1] 
expected returns: [[32.46115]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 0.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.779619216918945
desired expected reward: 22.56907081604004






Player: 1 
cards in hand: [3. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  9.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 0.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [10.  6.  0.  8.  6.] 
adversary cards in discard: [6. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[30.682974]
 [30.26453 ]
 [30.277452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  8.  6.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3. 15.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.8020156621932983
desired expected reward: 31.659135818481445





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.217611]
 [29.213274]
 [29.778265]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.  6.] 
cards in discard: [6. 0. 3. 3. 0. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  6. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3. 15.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7412579655647278
desired expected reward: 29.2846736907959



buy possibilites: [-1] 
expected returns: [[31.651625]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  8.  6.] 
cards in discard: [6. 0. 3. 3. 0. 0. 6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0. 25.  3.  3. 15.] 
adversary cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.694056510925293
desired expected reward: 19.51921844482422






Player: 1 
cards in hand: [ 0. 25.  3.  3. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  3.  3. 15.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  3.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  6. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  3.] 
cards in discard: [10. 29. 10.  1.  3.  8. 11. 14. 29.  3.  0.  0.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  3.  3.] 
adversary cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.242851]
 [29.832872]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  3.  3.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 14. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7823818922042847
desired expected reward: 30.869243621826172



action possibilites: [-1.] 
expected returns: [[29.356901]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 14. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.14056377112865448
desired expected reward: 29.81981086730957





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[28.829578]
 [28.958864]
 [28.946068]
 [28.825241]
 [29.111307]
 [28.99305 ]
 [28.980255]
 [29.390232]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 28. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 14. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1253511905670166
desired expected reward: 29.231550216674805



buy possibilites: [-1] 
expected returns: [[33.1257]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 6.  0.  3.  3.  0.  0.  6. 10.  6.  0.  8.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [29. 14. 14.  1.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 17.0 

action type: buy - action 3.0
Learning step: -0.010562152601778507
desired expected reward: 28.935503005981445






Player: 1 
cards in hand: [29. 14. 14.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  1.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  8.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 14.  1.  0.] 
cards in discard: [8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.85939]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11. 15.  8.  3. 10.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.7437983155250549
desired expected reward: 29.58258628845215





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.276482]
 [29.392967]
 [29.272142]
 [29.43995 ]
 [29.837135]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [0. 6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [11. 15.  8.  3. 10.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7428523302078247
desired expected reward: 29.35173797607422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 15.  8.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15.  8. 10.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15.  8.  3. 10.] 
cards in discard: [ 8. 14. 29. 14.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  3. 10.] 
cards in discard: [ 8. 14. 29. 14.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  3. 10.] 
cards in discard: [ 8. 14. 29. 14.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [8. 6. 0. 6. 0.] 
adversary cards in discard: [0. 6. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[30.10409 ]
 [29.706907]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 6. 0.] 
cards in discard: [0. 6. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7286537289619446
desired expected reward: 29.10848045349121





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.617912]
 [29.734398]
 [29.613575]
 [29.781382]
 [30.178566]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 6. 0.] 
cards in discard: [0. 6. 3. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  5. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7453680634498596
desired expected reward: 29.552579879760742



buy possibilites: [-1] 
expected returns: [[32.346832]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 6. 0. 6. 0.] 
cards in discard: [0. 6. 3. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 25.  0.  3.  3.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.698765754699707
desired expected reward: 19.914810180664062






Player: 1 
cards in hand: [ 0. 25.  0.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  0.  3.  3.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [0. 6. 3. 0. 0. 6. 8. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  0.  3.  3.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  3.  3.] 
adversary cards in discard: [0. 6. 3. 0. 0. 6. 8. 6. 0. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6] -> size -> 21 
adversary victory points: -1
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 10.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.191275]
 [28.781294]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [0. 6. 3. 0. 0. 6. 8. 6. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.814696192741394
desired expected reward: 31.532136917114258





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.745718]
 [28.741379]
 [29.306368]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [0. 6. 3. 0. 0. 6. 8. 6. 0. 6. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  4. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7238083481788635
desired expected reward: 28.555307388305664



buy possibilites: [-1] 
expected returns: [[31.759512]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.  3.] 
cards in discard: [0. 6. 3. 0. 0. 6. 8. 6. 0. 6. 0. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 1. 10.  3.  0. 10.] 
adversary cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.678766250610352
desired expected reward: 19.062612533569336






Player: 1 
cards in hand: [ 1. 10.  3.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  3.  0. 10.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0. 10.  0.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  0. 29.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 3 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 29.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  8.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  0. 29.] 
cards in discard: [ 8. 14. 29. 14.  1.  0. 15. 11.  8.  3. 10.  0. 25.  0.  3.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  3.  6.] 
adversary cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  6.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[30.054375]
 [29.644396]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3.  6.] 
cards in discard: [ 0.  6.  3.  0.  0.  6.  8.  6.  0.  6.  0.  6.  3.  0. 10.  3.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7889363169670105
desired expected reward: 30.9705753326416



action possibilites: [-1.] 
expected returns: [[31.923733]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.08142413944005966
desired expected reward: 28.806018829345703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.136917]
 [31.132364]
 [31.695843]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 6. 6.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 0. 3. 1. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.17804837226867676
desired expected reward: 31.745683670043945






Player: 1 
cards in hand: [0. 0. 3. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 1. 3.] 
cards in discard: [1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [0. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[29.76078 ]
 [29.365421]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [10.  0.  6.  3.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [1. 0. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.788723349571228
desired expected reward: 30.907121658325195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.40054 ]
 [29.517622]
 [29.39598 ]
 [29.564102]
 [29.95946 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [10.  0.  6.  3.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 8. 29.  0.  0. 29.] 
adversary cards in discard: [1. 0. 0. 3. 1. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7353248596191406
desired expected reward: 29.151578903198242



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8. 29.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  0.  0. 29.] 
cards in discard: [1. 0. 0. 3. 1. 3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0. 29.  3.] 
cards in discard: [1. 0. 0. 3. 1. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  3.] 
cards in discard: [1. 0. 0. 3. 1. 3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 27. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0.  0. 29.  3.] 
cards in discard: [1. 0. 0. 3. 1. 3. 1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 6. 3.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.605839]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14. 29. 15. 10. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7274225354194641
desired expected reward: 29.232038497924805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[30.107956]
 [30.103401]
 [30.66688 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  3. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14. 29. 15. 10. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.749315619468689
desired expected reward: 29.856523513793945



buy possibilites: [-1] 
expected returns: [[32.411694]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [14. 29. 15. 10. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -305.0 

action type: buy - action 6.0
Learning step: -9.71277904510498
desired expected reward: 20.390621185302734






Player: 1 
cards in hand: [14. 29. 15. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 15. 10. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 15. 10. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 10.  0.  3.  0.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15. 10. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15. 10. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15. 10. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  3.  0.] 
adversary cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
adversary victory points: -3
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[29.746105]
 [29.339008]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  1.  0. 11. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.6708559989929199
desired expected reward: 27.045154571533203



action possibilites: [-1.] 
expected returns: [[32.53762]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  1.  0. 11. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.08852525800466537
desired expected reward: 29.250484466552734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.02943 ]
 [32.146515]
 [32.024876]
 [32.192993]
 [32.588352]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  2. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  1.  0. 11. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.1872430145740509
desired expected reward: 32.35037612915039



buy possibilites: [-1] 
expected returns: [[26.907444]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  6.  3.  6.  6.  0.  8.  6.  0.  6.  6.  6.  0.  3.  6.  3.  0.
  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 26. 30. 27. 30.  8.  1. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [25.  1.  0. 11. 10.] 
adversary cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.228218078613281
desired expected reward: 22.79665756225586






Player: 1 
cards in hand: [25.  1.  0. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 11. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 27. 30.  8.  1. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  1.  0. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  9.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  1.  0. 10.] 
cards in discard: [ 1.  0.  0.  3.  1.  3.  1. 29.  8.  0.  0. 29.  3.  0. 14. 29. 15. 10.
 10.  3. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 6. 10.  0.  3.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 6. 10.  0.  3.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[32.23334 ]
 [31.826246]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 10.  0.  3.  6.] 
cards in discard: [] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6191587448120117
desired expected reward: 26.288284301757812



action possibilites: [-1.] 
expected returns: [[32.43873]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.16796435415744781
desired expected reward: 31.784400939941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[31.775505]
 [31.770954]
 [32.334435]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [28. 26. 30. 26. 30.  8.  1. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.18679304420948029
desired expected reward: 32.25193405151367



buy possibilites: [-1] 
expected returns: [[30.502022]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 3.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [ 3. 15.  3.  8. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.    0.    0.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -285.0 

action type: buy - action 6.0
Learning step: -9.172642707824707
desired expected reward: 22.598308563232422






Player: 1 
cards in hand: [ 3. 15.  3.  8. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 14.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  3.  8. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  8. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  8. 14.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.439186]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [15.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7979491949081421
desired expected reward: 29.704072952270508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[24.985218]
 [25.115578]
 [25.104881]
 [25.271788]
 [25.151114]
 [25.140417]
 [25.552431]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 26. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [15.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6479297876358032
desired expected reward: 24.791255950927734



buy possibilites: [-1] 
expected returns: [[30.676472]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [10.  0.  0. 29.  3.] 
adversary cards in discard: [15.  3.  3.  8. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 1.0
Learning step: -0.041364382952451706
desired expected reward: 25.0742130279541






Player: 1 
cards in hand: [10.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 29.  3.] 
cards in discard: [15.  3.  3.  8. 14.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29.  3.  1.] 
cards in discard: [15.  3.  3.  8. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  1.] 
cards in discard: [15.  3.  3.  8. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  8. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 29.  3.  1.] 
cards in discard: [15.  3.  3.  8. 14. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [6. 0. 3. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 0. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.831583]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [14. 11. 10.  1. 10.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7780625224113464
desired expected reward: 29.898408889770508





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[27.287678]
 [27.40734 ]
 [27.453571]
 [27.854889]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [14. 11. 10.  1. 10.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6954448819160461
desired expected reward: 27.136138916015625



buy possibilites: [-1] 
expected returns: [[27.216133]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [14. 11. 10.  1. 10.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6828609108924866
desired expected reward: 26.604816436767578






Player: 1 
cards in hand: [14. 11. 10.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 11. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 11. 10.  1. 10.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.  0.  6.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14. 11. 10.  1. 10.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [6. 3. 8. 0. 6.] 
adversary cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.  0.  6.  0.  3.  0.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [6. 3. 8. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[26.906414]
 [26.5051  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.  0.  6.  0.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6856521368026733
desired expected reward: 26.530481338500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.455479]
 [27.022692]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 8. 0. 6.] 
cards in discard: [ 6. 10.  6.  0.  3.  6.  3.  1.  6.  0.  0.  0.  6.  0.  6.  0.  3.  0.
  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [11. 25. 29.  0.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.675836443901062
desired expected reward: 26.23057746887207



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 25. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29.  0.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  7.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  0.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 29.  0.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 6.  8.  6.  3. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[31.08677 ]
 [30.685453]
 [30.674757]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  3.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6365469098091125
desired expected reward: 26.38614273071289



action possibilites: [-1.  8. 10.] 
expected returns: [[31.008537]
 [30.607224]
 [30.596527]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  3.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.14693041145801544
desired expected reward: 30.5278263092041





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[30.485352]
 [31.052565]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6.  3. 10.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0] -> size -> 27 
action values: 2 
buys: 1 
player value: 0 
card supply: [26. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  3.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.15658652782440186
desired expected reward: 30.851953506469727



buy possibilites: [-1] 
expected returns: [[26.729809]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  8.  6.  3. 10.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
action values: 2 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [ 3.  1. 29.  3.  0.] 
adversary cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: -0.18389751017093658
desired expected reward: 30.301454544067383






Player: 1 
cards in hand: [ 3.  1. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 29.  3.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 29.  3.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 25. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 29.  3.  0.] 
cards in discard: [15.  3.  3.  8. 14. 14. 10.  0.  0. 29.  3.  1. 14. 11. 10.  1. 10.  8.
  0. 11. 25. 29.  0.  0.  1.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [1. 0. 0. 3. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.852356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0  1] -> size -> 33 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6594445109367371
desired expected reward: 26.070363998413086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.577183]
 [27.707544]
 [27.696848]
 [27.585453]
 [27.655216]
 [27.863754]
 [27.74308 ]
 [27.953493]
 [27.961914]
 [27.740803]
 [27.784313]
 [27.732382]
 [27.652939]
 [27.872171]
 [28.144394]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5. 10.  9.] 
adversary cards in hand: [0. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0  1] -> size -> 33 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6931314468383789
desired expected reward: 27.159225463867188



buy possibilites: [-1] 
expected returns: [[25.172987]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 3. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [0. 3. 1. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0  1] -> size -> 33 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 50  0] 
sum of rewards: 45 

action type: buy - action 22.0
Learning step: 0.7847282290458679
desired expected reward: 28.437667846679688






Player: 1 
cards in hand: [0. 3. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 1. 0. 8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  1 15 14 25 29 10  1  8 14 11 10 29 10  8 29
  1  1  0  3 11 14  8  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 26. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6. 0. 0.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [3. 6. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.762842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [15. 10.  0.  3.  8.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6136797666549683
desired expected reward: 24.559307098388672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[27.142101]
 [27.263632]
 [27.310156]
 [27.715029]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [15. 10.  0.  3.  8.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6871651411056519
desired expected reward: 26.818557739257812



buy possibilites: [-1] 
expected returns: [[20.999306]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6. 0. 0.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [15. 10.  0.  3.  8.] 
adversary cards in discard: [3. 8. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.7437704205513
desired expected reward: 26.398332595825195






Player: 1 
cards in hand: [15. 10.  0.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10.  0.  3.  8.] 
cards in discard: [3. 8. 0. 3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [6. 3. 3. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 


action possibilites: [-1. 15.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  8. 14.] 
cards in discard: [3. 8. 0. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [6. 3. 3. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 


action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  3.  8.] 
cards in discard: [3. 8. 0. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [24. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  8.] 
cards in discard: [3. 8. 0. 3. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 24. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  3.  8.] 
cards in discard: [3. 8. 0. 3. 0. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [10. 14.] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [3. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[24.892694]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 6.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.7037431001663208
desired expected reward: 26.4668025970459





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.287027]
 [24.859955]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 6.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [ 0. 14. 29.  0.  0.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1] -> size -> 34 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6381575465202332
desired expected reward: 24.25453758239746



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 14. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14. 29.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 29.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  5.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 14. 29.  0.  0.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.946987]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [25. 11.  1.  1. 14.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6863552927970886
desired expected reward: 24.173599243164062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[19.458645]
 [19.580172]
 [19.626696]
 [20.03157 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [25. 11.  1.  1. 14.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5410794019699097
desired expected reward: 19.405908584594727



buy possibilites: [-1] 
expected returns: [[18.708899]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0. 10.  6.  8.  6.  3. 10. 22.  1.  0.  0.  3.  0.  0.  3.  6.  6.  0.
  0.  6.  3.  3.  6.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [25. 11.  1.  1. 14.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.5373159050941467
desired expected reward: 18.921329498291016






Player: 1 
cards in hand: [25. 11.  1.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  1.  1. 14.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  1.  1. 14.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 23. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25. 11.  1.  1. 14.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[30.613781]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10  1] -> size -> 36 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.38982224464416504
desired expected reward: 18.319076538085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[30.095457]
 [30.227072]
 [30.216982]
 [30.385777]
 [30.263506]
 [30.25342 ]
 [30.668383]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 8.  0. 11.  3. 10.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10  1] -> size -> 36 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7494770884513855
desired expected reward: 29.864303588867188



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 8.  0. 11.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  3. 10.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3 15 14 25 29 10  1  8 14 11 10 29 10  8 29  1
  1  0  3 11 14  8  0  1  3  1 10  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  6.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  6.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  6.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 0. 22.  6.  6.  6.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0. 22.  6.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[27.385227]
 [26.889275]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 22.  6.  6.  6.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 29.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0] -> size -> 34 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7845895886421204
desired expected reward: 29.883792877197266





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.904945]
 [27.47787 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 22.  6.  6.  6.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 3.  3. 10. 29. 29.] 
adversary cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0] -> size -> 34 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6854454874992371
desired expected reward: 26.69978141784668



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  3. 10. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 10. 29. 29.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 29. 29.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0] -> size -> 34 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 10. 29. 29.] 
cards in discard: [ 3.  8.  0.  3.  0.  1. 10. 14. 15.  0.  3.  8. 10.  0. 14. 29.  0.  0.
  1. 25. 11.  1.  1. 14.  0.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 6.  0.  6.  3. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.3396  ]
 [25.924637]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  3. 10.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  1.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6995131373405457
desired expected reward: 26.778356552124023



action possibilites: [-1.] 
expected returns: [[29.06008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  1.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: -0.022608259692788124
desired expected reward: 25.902029037475586





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.631384]
 [29.204308]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 3. 6.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [11.  3.  1.  1.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.11756343394517899
desired expected reward: 28.942516326904297






Player: 1 
cards in hand: [11.  3.  1.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  1.  1.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  6. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  1.  1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  7. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  6. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3.  1.  1.  1.] 
cards in discard: [14.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 1.  3.  0.  6. 10.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  0.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[26.324844]
 [25.909882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  0.  6. 10.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.7514612674713135
desired expected reward: 28.452848434448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[25.162884]
 [25.292866]
 [25.283215]
 [25.450447]
 [25.329521]
 [25.319868]
 [25.728113]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  0.  6. 10.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 0.  3. 14.  3.  0.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6562830805778503
desired expected reward: 25.123464584350586



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 14.  3.  0.] 
cards in discard: [14. 11.  3.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 8. 6. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [14. 11.  3.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [14. 11.  3.  1.  1.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14] -> size -> 36 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  7.  6. 10.  4.  9.  9.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29.] 
cards in deck: 25 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [8. 0. 3.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [8. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[17.189304]
 [16.790712]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 3.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6
  6  1  0  0 22  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  1. 14.  3.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.6839562654495239
desired expected reward: 23.07503890991211



action possibilites: [-1] 
expected returns: [[22.467016]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  1. 14.  3.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0.18375039100646973
desired expected reward: 16.92219352722168





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.18831 ]
 [22.753544]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  1. 14.  3.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.01252773217856884
desired expected reward: 22.479543685913086



buy possibilites: [-1] 
expected returns: [[21.871716]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [ 8. 10.  1. 14.  3.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: 15.0 

action type: buy - action 0.0
Learning step: 0.014003677293658257
desired expected reward: 22.202316284179688






Player: 1 
cards in hand: [ 8. 10.  1. 14.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  1. 14.  3.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1. 14.  3.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29] -> size -> 37 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.  1. 14.  3.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 6. 0. 6. 0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.657602]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5892466306686401
desired expected reward: 21.282468795776367





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[20.36155 ]
 [20.491537]
 [20.481888]
 [20.649117]
 [20.528193]
 [20.518538]
 [20.926783]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  8.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5530326962471008
desired expected reward: 20.104570388793945



buy possibilites: [-1] 
expected returns: [[21.361425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  0. 22.  6.  6.  6. 10.  6.  0.  6.  3.  6.  1.  3.
  0.  6. 10.  0.  6.  0.  8.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  7.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [15.  8.  0.  0.  0.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: -0.005178566090762615
desired expected reward: 20.643938064575195






Player: 1 
cards in hand: [15.  8.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  0.  0.  0.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  7.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0.  0.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  7.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  8.  0.  0.  0.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[29.214973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [29. 29.  3.  3. 10.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4840855300426483
desired expected reward: 20.87734031677246





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[28.795542]
 [28.925526]
 [28.915874]
 [28.873915]
 [29.083105]
 [28.96218 ]
 [29.178871]
 [28.959677]
 [28.952528]
 [29.090256]
 [29.360771]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11] -> size -> 32 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  4.  9.  9.] 
adversary cards in hand: [29. 29.  3.  3. 10.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.7211165428161621
desired expected reward: 28.49385643005371



buy possibilites: [-1] 
expected returns: [[28.835577]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [10.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [29. 29.  3.  3. 10.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: -0.5 

action type: buy - action 10.0
Learning step: -0.5808022022247314
desired expected reward: 28.371723175048828






Player: 1 
cards in hand: [29. 29.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  3. 10.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  3. 29.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  1.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 1 
buys: 0 
player value: 3 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11] -> size -> 39 
action values: 1 
buys: 1 
player value: 3 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  6.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29. 29. 29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 6.  6.  0. 22.  3.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[25.622454]
 [25.133091]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 22.  3.] 
cards in discard: [10.  0.  0.  6.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 1. 14. 10.  0. 25.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7480868697166443
desired expected reward: 28.08749008178711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.057789]
 [25.623022]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 22.  3.] 
cards in discard: [10.  0.  0.  6.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 1. 14. 10.  0. 25.] 
adversary cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6520059108734131
desired expected reward: 24.970449447631836



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 14. 10.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 25.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 14. 10.  0. 25.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [ 3.  6. 10.  6.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 10.  0. 25.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [10.  6.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 25.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6. 10.  3.  9.  9.] 
adversary cards in hand: [10.  6.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1. 10.  0. 25.] 
cards in discard: [14. 11.  3.  1.  1.  1. 29. 14.  0.  3.  3.  0.  0.  8. 10.  1. 14.  3.
 11. 15.  8.  0.  0.  0. 10.  3.  1. 11. 29. 29. 29.  3.  8. 23.] 
cards in deck: 2 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [10.  6.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[17.748194]
 [17.34592 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23] -> size -> 41 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 6
Learning step: -0.8009896278381348
desired expected reward: 27.054216384887695





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.162607]
 [17.72031 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 3. 14.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23] -> size -> 41 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.49872487783432007
desired expected reward: 17.249469757080078



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3. 14.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23] -> size -> 41 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  5.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  1.  0.  0.] 
cards in discard: [11.] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [11.  0.  6.  0.  6.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [11.  0.  6.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[26.77876 ]
 [26.505348]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  3.  1.  3. 11.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11] -> size -> 42 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.4015806317329407
desired expected reward: 17.318729400634766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[26.320124]
 [26.438986]
 [26.485003]
 [26.877825]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  3.  1.  3. 11.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11] -> size -> 42 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6740632653236389
desired expected reward: 26.10469627380371



buy possibilites: [-1] 
expected returns: [[24.341894]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  6.  0.  6.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 1.  3.  1.  3. 11.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11] -> size -> 42 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.6840137243270874
desired expected reward: 25.6361083984375






Player: 1 
cards in hand: [ 1.  3.  1.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  1.  3. 11.] 
cards in discard: [11.  3. 14.  1.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  3. 10.  8.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  3. 10.  8.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  6.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  3. 10.  8.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 1. 3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8.] 
cards in deck: 31 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 6.  3. 10.  8.  0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 10.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[21.610197]
 [21.207922]
 [21.217375]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  8.  0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  1.  3.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8] -> size -> 44 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6555760502815247
desired expected reward: 23.686317443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.040777]
 [21.598478]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  8.  0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 0.  8. 10.  1.  3.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8] -> size -> 44 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.573864221572876
desired expected reward: 21.036333084106445



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 10.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  1.  3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [0. 6. 3. 1. 0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  1.  3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 22. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [0. 6. 3. 1. 0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  1.  3.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [0. 6. 3. 1. 0.] 
adversary cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [0. 6. 3. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.948729]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 1. 0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [14. 29. 15.  0. 29.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.556992769241333
desired expected reward: 21.041486740112305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.399607]
 [22.527922]
 [22.518469]
 [22.477102]
 [22.683897]
 [22.564486]
 [22.778055]
 [22.5617  ]
 [22.555035]
 [22.690563]
 [22.957308]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1. 0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  5.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [14. 29. 15.  0. 29.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6003243327140808
desired expected reward: 22.348403930664062



buy possibilites: [-1] 
expected returns: [[23.072945]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 1. 0.] 
cards in discard: [10.  0.  0.  6.  0.  0.  6.  6.  0. 22.  3.  3.  6. 10.  6.  0.  0. 11.
  0.  6.  0.  6.  6.  3. 10.  8.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [14. 29. 15.  0. 29.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5246686339378357
desired expected reward: 22.039817810058594






Player: 1 
cards in hand: [14. 29. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29. 15. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 29. 15.  0. 29.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 15.  0. 29.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  0. 29.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1] -> size -> 45 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  3.  9.  9.] 
adversary cards in hand: [6. 0. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 15.  0. 29.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [6. 0. 6.] 
adversary cards in discard: [10.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.141912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [10.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [29.  0.  3.  1.  1.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 3
Learning step: -0.7570347785949707
desired expected reward: 28.977128982543945





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[26.604351]
 [27.162052]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [10.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [29.  0.  3.  1.  1.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6813981533050537
desired expected reward: 26.460514068603516



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0.  3.  1.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  3.  1.  1.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  0.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  0.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10] -> size -> 46 
action values: 0 
buys: 1 
player value: 7 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  9.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  0.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  0.  0.  3.] 
adversary cards in discard: [10.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 6. 22.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[27.597898]
 [27.114902]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  0.  0.  3.] 
cards in discard: [10.  0.  6.  0.  6.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 29. 14. 25.  8.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6771122217178345
desired expected reward: 26.484941482543945



action possibilites: [-1] 
expected returns: [[22.67898]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 3. 6. 0. 0.] 
cards in discard: [10.  0.  6.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 29. 14. 25.  8.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 22.0
Learning step: -0.12531778216362
desired expected reward: 26.98958396911621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[22.30125 ]
 [22.429564]
 [22.420113]
 [22.378746]
 [22.58554 ]
 [22.466131]
 [22.679699]
 [22.463343]
 [22.45668 ]
 [22.592205]
 [22.858953]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6. 0. 0.] 
cards in discard: [10.  0.  6.  0.  6.] 
cards in deck: 22 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 21. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 29. 14. 25.  8.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.0067353630438447
desired expected reward: 22.685714721679688



buy possibilites: [-1] 
expected returns: [[22.97533]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 3. 6. 0. 0.] 
cards in discard: [10.  0.  6.  0.  6.  1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [22.] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 29. 14. 25.  8.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5.   0.   0.   0.   0.   0.  20.   0.   0.   0.   0.  -1.   0.   0.
  4.5  0. ] 
sum of rewards: 18.5 

action type: buy - action 1.0
Learning step: 0.13313546776771545
desired expected reward: 22.236652374267578






Player: 1 
cards in hand: [11. 29. 14. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 14. 25.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 14. 25.  8.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0.  6.  1.  6.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 14. 25.  8.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25] -> size -> 47 
action values: 1 
buys: 1 
player value: 0 
card supply: [17. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0.  6.  1.  6.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 14. 25.  8.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  0.  6.  1.  6.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [10.  0.  6.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[19.776943]
 [19.378704]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  1.  6.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8.  0. 10. 14.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0] -> size -> 48 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6332746148109436
desired expected reward: 22.342056274414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[19.526035]
 [19.653133]
 [19.643831]
 [19.807856]
 [19.689545]
 [19.680243]
 [20.078484]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  1.  6.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8.  0. 10. 14.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0] -> size -> 48 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5354485511779785
desired expected reward: 19.241497039794922



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  8.  0. 10. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10. 14.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10. 14.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 10. 14.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  3.  3.  6. 11.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  3.  3.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[20.20032 ]
 [19.929691]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  3.  6. 11.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 23.  0.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.  0.  3.  8.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5413877964019775
desired expected reward: 19.537097930908203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.683624]
 [20.236073]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  6. 11.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1] -> size -> 36 
action values: 1 
buys: 1 
player value: 0 
card supply: [15. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 23.  0.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.  0.  3.  8.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5458511114120483
desired expected reward: 19.654468536376953



buy possibilites: [-1] 
expected returns: [[16.842913]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3.  3.  6. 11.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11. 10.  0. 23.  0.] 
adversary cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.  0.  3.  8.  0. 10. 14.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -2  0  0  0  0] 
sum of rewards: -7 

action type: buy - action 0.0
Learning step: -0.6236581206321716
desired expected reward: 19.059967041015625






Player: 1 
cards in hand: [11. 10.  0. 23.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0. 23.  0.] 
cards in discard: [11.  3. 14.  1.  0.  0.  0.  8. 11.  1.  3.  1.  3.  1.  0.  8. 10.  1.
  3. 10. 14. 29. 15.  0. 29.  3. 25. 29.  0.  1.  1.  0.  0. 11. 29. 14.
 25.  8.  0.  3.  8.  0. 10. 14.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1. 11. 10.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.  0.  1.] 
cards in discard: [] 
cards in deck: 43 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0] -> size -> 49 
action values: 1 
buys: 1 
player value: 1 
card supply: [14. 20. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 19. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [1.] 
cards in deck: 43 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1] -> size -> 50 
action values: 0 
buys: 2 
player value: 5 
card supply: [14. 19. 30. 25. 30.  8.  0. 10.  4.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 1. 11.] 
cards in deck: 43 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11] -> size -> 51 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  1.] 
cards in discard: [ 1. 11.  0.] 
cards in deck: 43 
card top of deck: [] 
played cards: [23. 11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
action values: 0 
buys: 0 
player value: 2 
card supply: [13. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 8. 0. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
adversary victory points: -6
player victory points: 6 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [0. 6. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[20.241163]
 [19.852224]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 8. 0. 0.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3 10  8  6  6  0  6 10  3  6  6  3  6  6  6  6  6
  1  0  0 22  0  0  0 11 10  0  8  1  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1. 29. 14.  3. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
adversary victory points: 6
player victory points: -6 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.4443887174129486
desired expected reward: 16.398523330688477



action possibilites: [-1] 
expected returns: [[19.457228]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1. 29. 14.  3. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0.06119195744395256
desired expected reward: 19.83148956298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.149641]
 [19.702091]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1. 29. 14.  3. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.07083486765623093
desired expected reward: 19.52806282043457



buy possibilites: [-1] 
expected returns: [[21.847197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1. 29. 14.  3. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.10490632802248001
desired expected reward: 19.254547119140625






Player: 1 
cards in hand: [ 1. 29. 14.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 29. 14.  3. 10.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 6 


action possibilites: [-1. 14. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 10.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0] -> size -> 52 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3. 10.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 3. 6. 8. 0.] 
adversary cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
adversary victory points: -5
player victory points: 6 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [0. 3. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[18.511068]
 [18.12213 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 8. 0.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3 10  8  6  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22
  0  0  0 11 10  0  8  1  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10. 15.  0.  1. 14.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -5 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6126831769943237
desired expected reward: 21.234514236450195



action possibilites: [-1] 
expected returns: [[22.633999]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10. 15.  0.  1. 14.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 9
Learning step: 0.14540645480155945
desired expected reward: 18.22042465209961





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.123785]
 [22.676231]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [10.  0.  6.  0.  6.  1. 22.  6.  0.  0.  3.  6.  0.  0. 10.  0.  6.  1.
  6.  0.  6.  3.  3.  6. 11.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10. 15.  0.  1. 14.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.006760196760296822
desired expected reward: 22.640758514404297






Player: 1 
cards in hand: [10. 15.  0.  1. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  1. 14.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1.  0.  8.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 15.  0.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 15.  0.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 1.  0. 10.] 
adversary cards in discard: [0. 8.] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 6 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 1.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[20.67313 ]
 [20.279762]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0. 10.] 
cards in discard: [0. 8.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 14.  0.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 7
Learning step: -0.7648537158966064
desired expected reward: 26.91079330444336



action possibilites: [-1.] 
expected returns: [[23.793842]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 14.  0.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 0.09144246578216553
desired expected reward: 20.371204376220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[23.364357]
 [23.490023]
 [23.48091 ]
 [23.440586]
 [23.642971]
 [23.525898]
 [23.735073]
 [23.52303 ]
 [23.516788]
 [23.649216]
 [23.910154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  8. 14.  0.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
adversary victory points: 6
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: -0.015609053894877434
desired expected reward: 23.77823257446289






Player: 1 
cards in hand: [ 3.  0.  8. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 14.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 19. 30. 25. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 14.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  8.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.] 
adversary owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[24.970234]
 [24.576868]
 [24.58598 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  8.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3 10  8  0  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0
 11 10  0  8  1  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.6072945594787598
desired expected reward: 23.3028621673584



action possibilites: [-1] 
expected returns: [[22.615776]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 4
Learning step: -0.04586637392640114
desired expected reward: 24.398534774780273





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.189468]
 [22.735268]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.00795467384159565
desired expected reward: 22.62373161315918



buy possibilites: [-1] 
expected returns: [[21.069921]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 29. 29. 29. 10.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: buy - action 0.0
Learning step: 0.005550098139792681
desired expected reward: 22.19502067565918






Player: 1 
cards in hand: [ 0. 29. 29. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 29. 29. 10.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1. 29. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 10.  3.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1. 29. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  8.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
action values: 2 
buys: 0 
player value: 1 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25 29  1  8 14 10 29 10  8 29  1  1  0  3
 11 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0
  0  1 11  0  0  3] -> size -> 54 
action values: 2 
buys: 0 
player value: 2 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 2 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 19. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29. 10. 29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 0. 0. 6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[22.944519]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  8. 14.  3.  0.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5411801934242249
desired expected reward: 20.52874183654785





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[22.35812 ]
 [22.483784]
 [22.474676]
 [22.636736]
 [22.519665]
 [22.510553]
 [22.903921]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 6.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  8. 14.  3.  0.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6007723212242126
desired expected reward: 22.343746185302734



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  8. 14.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  3.  0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6.  3. 22.  3.  6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1] -> size -> 54 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  4.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.] 
cards in deck: 14 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 6. 22.  6.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 6. 22.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[23.577892]
 [23.105455]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  6.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 11.  1.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 1
Learning step: -0.553470253944397
desired expected reward: 21.081661224365234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.04713 ]
 [23.592928]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  6.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0] -> size -> 30 
action values: 1 
buys: 1 
player value: 0 
card supply: [10. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 11.  1.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6119034290313721
desired expected reward: 22.96599006652832



buy possibilites: [-1] 
expected returns: [[22.118706]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  6.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0. 25. 25. 11.  1.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.6091675162315369
desired expected reward: 22.437963485717773






Player: 1 
cards in hand: [ 0. 25. 25. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 25. 11.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 25. 11.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 11.  1.  3.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  1.  3.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 9. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 11.  1.  3.  1.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 5 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [0. 6. 6. 1. 3.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [0. 6. 6. 1. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[23.098083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11.  3. 11.  0.  8.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0] -> size -> 56 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5710312724113464
desired expected reward: 21.54767417907715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[22.659916]
 [22.78558 ]
 [22.77647 ]
 [22.938532]
 [22.821457]
 [22.812347]
 [23.205715]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  3.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11.  3. 11.  0.  8.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0] -> size -> 56 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6022104024887085
desired expected reward: 22.495872497558594



buy possibilites: [-1] 
expected returns: [[18.98837]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 6. 1. 3.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [11.  3. 11.  0.  8.] 
adversary cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0] -> size -> 56 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: -3.0 

action type: buy - action 8.0
Learning step: -0.5688580274581909
desired expected reward: 22.03900718688965






Player: 1 
cards in hand: [11.  3. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 11.  0.  8.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  6.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  6. 11.  6.  0.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  6. 11.  6.  0.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  8.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29] -> size -> 57 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  6. 11.  6.  0.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 11.  0.  8.] 
cards in discard: [ 1. 11.  0. 23. 11. 10.  0.  0.  1.  1.  0. 29. 14.  3. 10.  0. 14. 10.
 15.  0.  1.  3.  3.  0.  8. 14.  0.  0.  3.  1. 29. 10. 29.  8.  1.  8.
 14.  0.  8.  3.  0.  0. 25.  0. 25. 11.  1.  3.  1. 29.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 7. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [10.  6. 11.  6.  0.] 
adversary cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [10.  6. 11.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[19.521732]
 [19.131226]
 [19.256557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6. 11.  6.  0.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29  0] -> size -> 58 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5165088176727295
desired expected reward: 18.47186279296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.942974]
 [19.48491 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.  6.  0.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29  0] -> size -> 58 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5333365797996521
desired expected reward: 18.98839569091797



buy possibilites: [-1] 
expected returns: [[22.632412]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6. 11.  6.  0.] 
cards in discard: [ 0.  8. 10.  1.  0.  0.  0.  8. 10.  3.  0.  6.  0.  0.  6.  3.  3.  0.
  6. 22.  6.  8.  0.  6.  6.  1.  3.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [1. 0. 8. 0. 1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29  0] -> size -> 58 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.] 
sum of rewards: -5.0 

action type: buy - action 0.0
Learning step: -0.48064887523651123
desired expected reward: 18.462326049804688






Player: 1 
cards in hand: [1. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 8. 0. 1.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  1  8 14 10 29 10  8 29  1  1  0  3 11
 14  8  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0
  1 11  0  0  3  1  8  0 29  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [] 
cards in deck: 53 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  2.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [8.] 
cards in deck: 53 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8] -> size -> 57 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  8. 10.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 3.  8. 10.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
expected returns: [[23.33249 ]
 [22.95095 ]
 [22.941986]
 [22.95095 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  8.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8] -> size -> 57 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.5864037275314331
desired expected reward: 22.046009063720703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.823288]
 [23.365223]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  6.  8.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0] -> size -> 33 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 6. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  8.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8] -> size -> 57 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.6069160103797913
desired expected reward: 22.725574493408203



buy possibilites: [-1] 
expected returns: [[23.73233]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  6.  8.] 
cards in discard: [0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 3.  0.  1. 11.  8.] 
adversary cards in discard: [8. 8. 0. 0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8] -> size -> 57 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action 0.0
Learning step: -0.5855091214179993
desired expected reward: 22.23777961730957






Player: 1 
cards in hand: [ 3.  0.  1. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 11.  8.] 
cards in discard: [8. 8. 0. 0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  9.] 
adversary cards in hand: [ 0.  6.  0. 22.  3.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [ 8.  8.  0.  0. 15.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  3.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [ 8.  8.  0.  0. 15.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15] -> size -> 58 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 5. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  3.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8.] 
cards in discard: [ 8.  8.  0.  0. 15.  0.] 
cards in deck: 48 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  6.  0. 22.  3.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 22.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[22.719147]
 [22.250149]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 22.  3.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 25. 14.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6253886222839355
desired expected reward: 23.10694122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[22.14315 ]
 [22.258953]
 [22.303543]
 [22.685085]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 22.  3.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  1.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 25. 14.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5962151288986206
desired expected reward: 22.12293243408203



buy possibilites: [-1] 
expected returns: [[23.976906]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  0. 22.  3.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0. 25. 14.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: -0.3273487687110901
desired expected reward: 21.976194381713867






Player: 1 
cards in hand: [ 0. 25. 14.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25. 14.  0.  0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 14.  0.  0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  3.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25. 14.  0.  0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.] 
cards in deck: 43 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0 11] -> size -> 60 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 1. 0. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [6. 0. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[20.9056]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0 11] -> size -> 60 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6497983932495117
desired expected reward: 23.327106475830078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.259254]
 [20.384024]
 [20.37506 ]
 [20.265837]
 [20.335028]
 [20.536016]
 [20.621319]
 [20.627447]
 [20.416815]
 [20.457523]
 [20.410688]
 [20.332193]
 [20.542145]
 [20.80119 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  8.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0 11] -> size -> 60 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.56166672706604
desired expected reward: 20.34393310546875



buy possibilites: [-1] 
expected returns: [[27.922928]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 1. 0. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 8.  0. 11.  0.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0 11] -> size -> 60 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -1  0  0 50  0] 
sum of rewards: 44 

action type: buy - action 25.0
Learning step: 0.9945513010025024
desired expected reward: 21.615867614746094






Player: 1 
cards in hand: [ 8.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 11 14  8
  0  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11
  0  0  3  1  8  0 29  0  8 15  0 11] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [6. 0. 6. 6. 0.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [6. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.062687]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.7875296473503113
desired expected reward: 27.135398864746094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[18.610725]
 [18.72653 ]
 [19.15266 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 18. 30. 24. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5234882235527039
desired expected reward: 18.53919792175293



buy possibilites: [-1] 
expected returns: [[21.942663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6. 0.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 0.  0.  3.  1. 10.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0 -2  0  0  8  0] 
sum of rewards: 1 

action type: buy - action 3.0
Learning step: -0.2920513153076172
desired expected reward: 18.434478759765625






Player: 1 
cards in hand: [ 0.  0.  3.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  8.  6.  0. 10.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 4. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  8.  6.  0. 10.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3.  1. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
action values: 0 
buys: 0 
player value: 4 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  8.  6.  0. 10.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[19.262447]
 [18.895313]
 [18.886112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  6.  0. 10.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [29.  0. 10. 14.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6081058979034424
desired expected reward: 21.334556579589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.79218 ]
 [19.314762]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  6.  0. 10.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [29.  0. 10. 14.  0.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5272632241249084
desired expected reward: 18.735183715820312



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  0. 10. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 14.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 10. 14.  0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  1.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
action values: 1 
buys: 0 
player value: 1 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
action values: 2 
buys: 0 
player value: 1 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0] -> size -> 60 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  6.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.683292]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [14.  8.  1. 29.  3.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.5227682590484619
desired expected reward: 18.791994094848633





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[19.113997]
 [19.234844]
 [19.225643]
 [19.187222]
 [19.38179 ]
 [19.470264]
 [19.265602]
 [19.260248]
 [19.387146]
 [19.636581]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 0.  3.  8. 10.  6.  8.  8.  0.  6.  0. 22.  3. 25.  6.  0.  1.  0.  0.
  3.  6.  0.  6.  6.  0.  3.  8.  6.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [14.  8.  1. 29.  3.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5370047092437744
desired expected reward: 19.14628791809082



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  8.  1. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  1. 29.  3.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  6.  0. 10. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  1. 29.  3.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 6. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.  3.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14] -> size -> 61 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 3. 18. 30. 23. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 6. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  1. 29.  3.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 18. 30. 22. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 3.  0. 11.] 
adversary cards in discard: [ 6. 10.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 65 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[27.315765]
 [27.06097 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [ 6. 10.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 22. 30.  8.  0. 10.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 1.  0.  0.  1. 25.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: discard_down_to_3_cards - action 6
Learning step: -0.43591001629829407
desired expected reward: 18.619272232055664



action possibilites: [-1] 
expected returns: [[23.854202]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 6. 10. 16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 1.  0.  0.  1. 25.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -3  0  0 16  0] 
sum of rewards: 28 

action type: gain_card_n - action 3
Learning step: 0.28332436084747314
desired expected reward: 27.188148498535156





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.392801]
 [23.915382]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 6. 10. 16.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 1.  0.  0.  1. 25.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: -0.016709404066205025
desired expected reward: 23.837491989135742



buy possibilites: [-1] 
expected returns: [[24.171421]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 6. 10. 16.  0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [ 1.  0.  0.  1. 25.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5.  0.  0.  0.  0.  0. 20.  0.  0.  0.  0. -4.  0.  0.  0.  0.] 
sum of rewards: 11.0 

action type: buy - action 0.0
Learning step: -0.11798412352800369
desired expected reward: 23.274816513061523






Player: 1 
cards in hand: [ 1.  0.  0.  1. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  0.  0.  1. 25.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  1. 25.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3] -> size -> 62 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  9.  2.  9.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  0.  0.  1. 25.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23] -> size -> 63 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [0. 0. 6. 6. 0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 66 -------------------- 
Player: 0 
cards in hand: [0. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.329063]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 10.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23] -> size -> 63 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.6826874613761902
desired expected reward: 23.488733291625977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[18.083483]
 [18.204327]
 [18.195127]
 [18.351276]
 [18.229736]
 [18.606066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [11.  3. 29.  3. 10.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23] -> size -> 63 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: -0.5072611570358276
desired expected reward: 17.821802139282227



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11.  3. 29.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 29.  3. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23] -> size -> 63 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [10.  8.  6.  1.  0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  3. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23] -> size -> 63 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [10.  8.  6.  1.  0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 29.  3. 10.] 
cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23  0] -> size -> 64 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [10.  8.  6.  1.  0.] 
adversary cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
adversary owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
adversary victory points: -3
player victory points: 8 





         -------------------- Turn: 67 -------------------- 
Player: 0 
cards in hand: [10.  8.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
expected returns: [[16.528622]
 [16.152288]
 [16.161488]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  6.  1.  0.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0  0 22  0  0  0 11 10
  0  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [23. 14.  3. 10.  1.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.  0. 11.  3. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23  0] -> size -> 64 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: -0.536713182926178
desired expected reward: 18.069355010986328



action possibilites: [-1] 
expected returns: [[21.452099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  1.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0 22  0  0  0 11 10  0
  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [23. 14.  3. 10.  1.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.  0. 11.  3. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23  0] -> size -> 64 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 2
Learning step: 0.1973896622657776
desired expected reward: 16.1259708404541





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.09726 ]
 [21.208904]
 [21.619843]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  1.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0 22  0  0  0 11 10  0
  8  1  0  0  0  0  8  0  0  8 25  3 16  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 1. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [23. 14.  3. 10.  1.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.  0. 11.  3. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23  0] -> size -> 64 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0.030831526964902878
desired expected reward: 21.48293113708496



Player 1 won the game! 



Player 0 bought cards:
Copper: 15 
Silver: 2 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 0 
Workshop: 1 
Chapel: 4 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 3 
Library: 1 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [10.  6.  1.] 
cards in discard: [ 6. 10. 16.  0. 11.  3.  0.  0.  0.  6.  6.  0.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3 10  8  6 10  3  6  6  3  6  6  6  6  6  1  0 22  0  0  0 11 10  0
  8  1  0  0  0  0  8  0  0  8 25  3 16  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 0. 18. 30. 22. 30.  8.  0.  9.  2.  0.  7.  5.  5.  8.  2.  9.  8.] 
adversary cards in hand: [23. 14.  3. 10.  1.] 
adversary cards in discard: [ 8.  8.  0.  0. 15.  0. 11.  3.  0.  1.  8. 11.  0. 25. 14.  0.  0.  8.
  0.  0.  0.  0.  0.  0.  3.  1. 10. 14.  0. 14. 29. 10.  0.  1.  0.  3.
 14.  8.  1. 29.  3. 23.  1.  0.  0.  1. 25.  0. 11.  3. 29.  3. 10.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3 15 14 25  8 14 10 29 10  8 29  1  0  3 14  8  0
  1  3  1 10  1  0  0 14 29  0 11 11 23 11  0  8  1 10 25  0  0  1 11  0
  0  3  1  8  0 29  0  8 15  0 11  0 14  3 23  0] -> size -> 64 
adversary victory points: 8
player victory points: -3 

Reward from previous game state: 
[  -5 -500    0    0    0    0   20    0    0    0    0   -4    0    0
    0    0] 
sum of rewards: -489 

action type: buy - action 0.0
Learning step: -15.29505443572998
desired expected reward: 5.540093421936035



