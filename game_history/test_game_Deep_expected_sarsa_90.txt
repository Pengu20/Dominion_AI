 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[55.224323]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[      -5 -3000000        0      -60        0        0       20        0
        0        0        0     -270        0        0       27        0] 
sum of rewards: -3000288 

action type: buy - action 11.0
Learning step: -120001.6640625
desired expected reward: -120247.828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[35.146175 ]
 [57.73262  ]
 [51.857975 ]
 [ 4.8256316]
 [77.205956 ]
 [60.329533 ]
 [54.4549   ]
 [53.722584 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 54.067134857177734



buy possibilites: [-1] 
expected returns: [[55.24159]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 77.20596313476562






Player: 1 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [11.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[63.497433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 55.2415885925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[45.883842]
 [67.88569 ]
 [62.163517]
 [19.072039]
 [65.46602 ]
 [87.435974]
 [70.48907 ]
 [90.56389 ]
 [42.390396]
 [64.686386]
 [64.31414 ]
 [64.10455 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 58.84401321411133



buy possibilites: [-1] 
expected returns: [[79.215256]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [11.  3.  0.  0.  0.  3. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 3. 3. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 90.56388854980469






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 3. 3. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  3. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[63.79343]
 [89.88896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 79.21525573730469



action possibilites: [-1. 11.] 
expected returns: [[69.45831]
 [89.72519]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3.  0. 11.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 87.4571533203125



action possibilites: [-1] 
expected returns: [[72.36076]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 32 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 91.3992919921875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 62.20492 ]
 [ 81.71503 ]
 [ 76.4575  ]
 [ 38.015373]
 [ 79.56688 ]
 [ 99.28449 ]
 [ 84.094925]
 [102.20474 ]
 [ 59.086704]
 [ 78.77994 ]
 [ 78.46234 ]
 [ 78.78556 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10] -> size -> 13 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1
Learning step: 0
desired expected reward: 72.36076354980469



buy possibilites: [-1] 
expected returns: [[88.96215]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0.] 
cards in discard: [10. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 133 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 102.20476531982422






Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[121.918846]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 88.96215057373047





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[106.09471 ]
 [126.71266 ]
 [121.190384]
 [ 80.55837 ]
 [124.4884  ]
 [144.60991 ]
 [129.15749 ]
 [147.72928 ]
 [102.8216  ]
 [123.63521 ]
 [123.32924 ]
 [123.83728 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 118.43191528320312



buy possibilites: [-1] 
expected returns: [[134.58484]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [0. 3. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0 128   0] 
sum of rewards: 93 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 147.72933959960938






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [0. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[87.884224]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 134.5848388671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[71.582375]
 [86.78333 ]
 [45.95592 ]
 [94.658195]
 [89.35023 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9. 10. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 83.99552917480469



buy possibilites: [-1] 
expected returns: [[84.33176]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0  16   0] 
sum of rewards: -19 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 94.658203125






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29. 10.] 
adversary cards in discard: [8. 0. 3. 3. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[100.51836]
 [124.43236]
 [100.59549]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29. 10.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 84.33175659179688



action possibilites: [-1. 10. 29.] 
expected returns: [[140.5605 ]
 [140.43842]
 [165.53645]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10. 29.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 119.75691223144531



action possibilites: [-1. 10.] 
expected returns: [[162.58711]
 [162.54259]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 165.5364532470703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[149.17406]
 [169.92647]
 [143.74693]
 [164.30893]
 [128.34091]
 [122.95981]
 [167.58226]
 [189.02861]
 [172.50414]
 [215.50352]
 [192.20839]
 [145.85599]
 [161.8116 ]
 [166.73167]
 [141.26743]
 [166.44211]
 [166.90976]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [8. 0. 3. 3. 0. 3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 6 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9. 10.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 162.5871124267578



buy possibilites: [-1] 
expected returns: [[212.46544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.  0.] 
cards in discard: [ 8.  0.  3.  3.  0.  3. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 3. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5.    0.    0.  -30.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.   62.5   0. ] 
sum of rewards: 67.5 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 215.5035400390625






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 3. 0. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 0] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  9.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [ 0.  3.  0.  0.  0.  3. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [29. 29. 29. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
adversary victory points: 3
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [29. 29. 29. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 29. 11.] 
expected returns: [[ 86.50284 ]
 [107.673294]
 [107.673294]
 [107.673294]
 [104.91423 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 29. 11.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: 0
desired expected reward: 212.46543884277344



action possibilites: [-1. 29. 29. 11.] 
expected returns: [[104.18359]
 [126.35014]
 [126.35014]
 [123.47748]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 103.27236938476562



action possibilites: [-1. 29. 11. 25.] 
expected returns: [[160.79904]
 [181.43138]
 [178.72739]
 [200.31273]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0. 25.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8. 10. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11] -> size -> 13 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 5 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 126.35014343261719



action possibilites: [-1] 
expected returns: [[143.86967]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 200.31271362304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[129.45053]
 [147.87349]
 [142.92523]
 [110.93302]
 [106.21906]
 [145.9069 ]
 [164.22919]
 [150.14026]
 [186.51   ]
 [167.04663]
 [126.4592 ]
 [140.73672]
 [145.10403]
 [122.34579]
 [144.85013]
 [145.62454]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: 25 

action type: take_action - action -1
Learning step: 0
desired expected reward: 143.8696746826172



buy possibilites: [-1] 
expected returns: [[203.28357]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11.  0.  0.  3.  0.] 
cards in discard: [25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 0. 3. 0.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6] -> size -> 14 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 -30   0   0  60   0   0   0   0   0   0   0 250   0] 
sum of rewards: 275 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 186.50999450683594






Player: 1 
cards in hand: [3. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3. 0.] 
cards in discard: [ 6. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 0.] 
adversary cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [3. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[152.925]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 203.2835693359375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[135.38225]
 [154.5318 ]
 [149.39447]
 [111.36912]
 [170.99673]
 [156.80634]
 [151.66895]
 [152.02066]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  8.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 146.97442626953125



buy possibilites: [-1] 
expected returns: [[159.90941]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 0.] 
cards in discard: [25. 29. 29. 25. 29. 11.  0.  0.  3.  0. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0. 11.  0.  0.  0.] 
adversary cards in discard: [ 6. 10.  3.  0.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 54  0] 
sum of rewards: 49 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 170.99673461914062






Player: 1 
cards in hand: [ 0. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 6. 10.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  0.  0.] 
cards in discard: [ 6. 10.  3.  0.  0.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 3. 25.  8. 10.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [ 3. 25.  8. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 10.] 
expected returns: [[ 96.80329]
 [137.36772]
 [101.36798]
 [ 96.50436]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25.  8. 10.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10] -> size -> 15 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 159.90940856933594



action possibilites: [-1] 
expected returns: [[91.621765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 10.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 132.49041748046875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[79.25566 ]
 [57.642036]
 [94.46881 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8. 10.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6] -> size -> 16 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 91.62176513671875






Player: 1 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [6. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [25.  0.  3.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [25.  0.  3.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[122.00546]
 [164.80841]
 [144.28813]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  3.  0. 29.] 
cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  8. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3] -> size -> 17 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 94.46881103515625



action possibilites: [-1] 
expected returns: [[128.59373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 29.  0. 29.] 
cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 159.05067443847656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[113.413376]
 [131.93538 ]
 [127.025116]
 [ 89.851265]
 [147.75528 ]
 [134.10391 ]
 [129.19365 ]
 [129.34712 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0. 29.] 
cards in discard: [25.  3.  8. 10.  0.  3. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  7.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 128.59373474121094



buy possibilites: [-1] 
expected returns: [[90.42715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  0. 29.  0. 29.] 
cards in discard: [25.  3.  8. 10.  0.  3. 11. 11.] 
cards in deck: 5 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  3.  0.  3.  0.] 
adversary cards in discard: [6. 3. 0. 0. 0. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6] -> size -> 18 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 54  0] 
sum of rewards: 69 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 147.75526428222656






Player: 1 
cards in hand: [10.  3.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  3.  0.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3. 6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 11.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3. 6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6] -> size -> 18 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 28. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3. 6. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  9.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0.] 
cards in discard: [6. 3. 0. 0. 0. 3. 3. 6. 0. 8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [11.  0.  0.  0. 29.] 
adversary cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[25.638058]
 [42.216442]
 [44.839115]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 29.] 
cards in discard: [25.  3.  8. 10.  0.  3. 11. 11. 25.  0.  3.  0. 29.  0. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 90.4271469116211



action possibilites: [-1. 11. 11.] 
expected returns: [[78.89866]
 [96.26304]
 [96.26304]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0. 11.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 43.067501068115234



action possibilites: [-1] 
expected returns: [[97.10977]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0 27  0] 
sum of rewards: 92 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 101.14820098876953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 85.31864 ]
 [103.62937 ]
 [ 98.73044 ]
 [ 62.24232 ]
 [101.70448 ]
 [119.37897 ]
 [105.802574]
 [122.22221 ]
 [ 82.333305]
 [100.90366 ]
 [100.64404 ]
 [101.45474 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10] -> size -> 21 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 65 

action type: take_action - action -1
Learning step: 0
desired expected reward: 97.10977172851562



buy possibilites: [-1] 
expected returns: [[128.26286]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 11.] 
cards in discard: [10. 29.] 
cards in deck: 14 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  30   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 193 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 122.22222137451172






Player: 1 
cards in hand: [0. 0. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  3. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  3. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 4 
card supply: [27. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 8. 11.  3.  3. 25.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 2 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 8. 11.  3.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 25.] 
expected returns: [[120.58178 ]
 [125.493164]
 [140.08472 ]
 [163.40495 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3. 25.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  7. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0] -> size -> 21 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 25 

action type: buy - action -1
Learning step: 0
desired expected reward: 128.2628631591797



action possibilites: [-1] 
expected returns: [[80.71619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11.  3.  3. 25. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 156.55014038085938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[56.58746]
 [36.32927]
 [70.92428]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11.  3.  3. 25. 10.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 6. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 3 

Reward from previous game state: 
[-5  0  0 30  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 45 

action type: take_action - action -1
Learning step: 0
desired expected reward: 80.7161865234375






Player: 1 
cards in hand: [0. 6. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  8.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3. 3. 0.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6. 8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 29.  3.] 
adversary cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[ 3.4022746]
 [17.252926 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 29.  3.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 70.92427825927734



action possibilites: [-1.] 
expected returns: [[20.464615]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 17.252914428710938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 6.926048 ]
 [20.04773  ]
 [16.43128  ]
 [-5.6451373]
 [-8.880736 ]
 [18.614408 ]
 [31.605934 ]
 [21.644537 ]
 [47.452625 ]
 [33.59448  ]
 [ 4.830972 ]
 [14.8033905]
 [18.028095 ]
 [ 1.9731522]
 [17.833525 ]
 [18.288696 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  8.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 20.464614868164062



buy possibilites: [-1] 
expected returns: [[8.573299]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [10. 29. 29. 11.  0.  0.  0. 11. 25.  8. 11.  3.  3. 25. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  3.  6.  3. 11.] 
adversary cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 325 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 47.45261764526367






Player: 1 
cards in hand: [ 0.  3.  6.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  6.  3. 11.] 
cards in discard: [0. 0. 0. 6. 0. 0. 6. 8. 0. 6. 3. 3. 0. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 29. 10.  0. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
adversary victory points: 3
player victory points: 1 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 29.] 
expected returns: [[67.841995]
 [87.35919 ]
 [67.2854  ]
 [87.35919 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 10.  0. 29.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: buy - action -1
Learning step: 0
desired expected reward: 8.573299407958984



action possibilites: [-1. 10. 29. 25.] 
expected returns: [[ 89.73596 ]
 [ 89.151985]
 [109.31859 ]
 [127.84903 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29. 25.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  6. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0] -> size -> 24 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 75 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 82.59259033203125



action possibilites: [-1] 
expected returns: [[96.76506]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 127.84901428222656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ 81.29492 ]
 [ 99.46616 ]
 [ 94.641815]
 [ 58.364082]
 [ 97.54219 ]
 [115.03804 ]
 [101.59651 ]
 [117.725624]
 [ 78.35353 ]
 [ 96.77337 ]
 [ 96.52575 ]
 [ 97.04783 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  6. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[-5  0  0 60  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 95 

action type: take_action - action -1
Learning step: 0
desired expected reward: 96.76506042480469



buy possibilites: [-1] 
expected returns: [[119.37334]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0. 29.  0.  0.] 
cards in discard: [29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 10.  8.  0.  0.] 
adversary cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6] -> size -> 25 
adversary victory points: 1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0  60   0   0  40   0   0   0   0   0   0   0 128   0] 
sum of rewards: 223 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 117.72565460205078






Player: 1 
cards in hand: [ 3. 10.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 10.] 
adversary cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
adversary victory points: 3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 10.] 
adversary cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
adversary victory points: 3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8.  0.  0.] 
cards in discard: [ 0.  0.  0.  6.  0.  0.  6.  8.  0.  6.  3.  3.  0.  0.  0.  3.  6.  3.
 11.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 25.  3. 10.] 
adversary cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
adversary victory points: 3
player victory points: 0 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 25.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[ 71.10236 ]
 [107.14955 ]
 [ 70.764175]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 25.  3. 10.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  5. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0] -> size -> 26 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 85 

action type: buy - action -1
Learning step: 0
desired expected reward: 119.37333679199219



action possibilites: [-1] 
expected returns: [[39.998974]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  3. 10. 29. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 107.14955139160156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.424107]
 [37.220577]
 [ 8.597643]
 [42.860645]
 [39.064724]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 29. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  7.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 105 

action type: take_action - action -1
Learning step: 0
desired expected reward: 39.99897384643555



buy possibilites: [-1] 
expected returns: [[15.352772]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  3. 10. 29. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 0. 0. 6.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: 0
player victory points: 3 

Reward from previous game state: 
[-5  0  0 90  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 121 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 42.860633850097656






Player: 1 
cards in hand: [6. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8] -> size -> 25 
adversary victory points: 3
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0. 0. 6.] 
cards in discard: [6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0.  0. 29. 11.] 
adversary cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8] -> size -> 25 
adversary victory points: 3
player victory points: -1 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  0. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-18.904076 ]
 [ -6.8279715]
 [ -8.56738  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 115 

action type: buy - action -1
Learning step: 0
desired expected reward: 15.352771759033203



action possibilites: [-1. 11. 11.] 
expected returns: [[-18.761633 ]
 [ -7.8563304]
 [ -7.8563304]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 135 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: -6.82796573638916



action possibilites: [-1] 
expected returns: [[-11.242279]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  27   0] 
sum of rewards: 182 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -4.776660919189453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[-18.905514]
 [-11.25508 ]
 [-13.492691]
 [-28.842527]
 [ -4.725534]
 [-10.258509]
 [-12.496115]
 [-11.04422 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11. 10.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  6.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 155 

action type: take_action - action -1
Learning step: 0
desired expected reward: -11.242279052734375



buy possibilites: [-1] 
expected returns: [[-26.50082]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.] 
cards in discard: [29. 29. 25.  3. 10.  0. 29.  0.  0.  8. 25.  0.  0.  3. 10. 29. 11. 10.
 11.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [0. 0. 6. 3. 8.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
adversary victory points: -1
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 120   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 209 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -4.725533485412598






Player: 1 
cards in hand: [0. 0. 6. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 3. 8.] 
cards in discard: [6. 6. 0. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0
  6  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [6. 6. 0. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [6. 6. 0. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 29. 10.  8. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
adversary victory points: 3
player victory points: -2 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0. 29. 10.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.  8. 25.] 
expected returns: [[ 65.75326 ]
 [ 85.689995]
 [ 65.1697  ]
 [ 69.789375]
 [104.4275  ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8. 25.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  4. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6] -> size -> 25 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 145 

action type: buy - action -1
Learning step: 0
desired expected reward: -26.50082015991211



action possibilites: [-1] 
expected returns: [[56.92945]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 99.73059844970703





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[32.808006]
 [44.084194]
 [14.061878]
 [50.480583]
 [46.514206]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  8.  0. 29.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  6.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 165 

action type: take_action - action -1
Learning step: 0
desired expected reward: 56.92945098876953



buy possibilites: [-1] 
expected returns: [[43.248367]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29. 10.  8.  0. 29.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 6.  0.  6.  0. 10.] 
adversary cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
adversary victory points: -2
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 150   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 181 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 50.48057174682617






Player: 1 
cards in hand: [ 6.  0.  6.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6.  0. 10.] 
cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6.  0. 10.] 
cards in discard: [6. 6. 0. 0. 0. 6. 8. 0. 6. 6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 11. 11. 25.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  0. 11. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 25.] 
expected returns: [[36.841656]
 [52.27972 ]
 [52.27972 ]
 [71.027916]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11. 25.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  3. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6] -> size -> 26 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1
Learning step: 0
desired expected reward: 43.24836730957031



action possibilites: [-1] 
expected returns: [[-2.8896356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11. 11. 29. 29.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 71.02791595458984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-15.933931 ]
 [-31.451866 ]
 [ -4.2926483]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 11. 11. 29. 29.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 0. 11.  8.  0.  3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6  6] -> size -> 27 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: take_action - action -1
Learning step: 0
desired expected reward: -2.8896355628967285






Player: 1 
cards in hand: [ 0. 11.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8.  0.  3.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0
  6  6  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11.  0.  3.  0.  8.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [11.  0.  3.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[-15.481144 ]
 [ -3.6452782]
 [-12.556361 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3.  0.  8.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -4.292640686035156



action possibilites: [-1] 
expected returns: [[-19.503565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -0.4018845558166504





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-30.110662]
 [-22.066906]
 [-44.09474 ]
 [-17.737753]
 [-20.142462]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  5.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.503564834594727



buy possibilites: [-1] 
expected returns: [[-29.52499]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 8.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -17.737775802612305






Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8] -> size -> 30 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [ 6.  6.  0.  0.  0.  6.  8.  0.  6.  6.  6.  0.  6.  0. 10.  6.  0.  8.
 11.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 3. 10. 11.  0.  0.] 
adversary cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8] -> size -> 30 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-11.229183 ]
 [-11.698101 ]
 [ -2.2166786]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 11.  0.  0.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1
Learning step: 0
desired expected reward: -29.52499008178711



action possibilites: [-1] 
expected returns: [[-30.577158]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  27   0] 
sum of rewards: 282 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 0.35078001022338867





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[-39.051304]
 [-32.876717]
 [-50.069298]
 [-29.441156]
 [-30.975035]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  4.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -30.577157974243164



buy possibilites: [-1] 
expected returns: [[-34.040497]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  0.  0.] 
cards in discard: [ 8. 25.  0. 29. 10.  8.  0. 29. 25.  3.  0. 11. 11. 29. 29. 10.  8. 11.
  0.  3.  0.  8. 10.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [8. 6. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 271 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -29.441162109375






Player: 1 
cards in hand: [8. 6. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6
  6  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 29. 10. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -6 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 8. 29. 10. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 10. 29. 25.] 
expected returns: [[37.54783 ]
 [40.68445 ]
 [52.890423]
 [36.954926]
 [52.890423]
 [66.95819 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 29. 25.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  2. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0] -> size -> 26 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 265 

action type: buy - action -1
Learning step: 0
desired expected reward: -34.040496826171875



action possibilites: [-1] 
expected returns: [[22.41534]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29. 10. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6] -> size -> 27 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 66.59609985351562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[10.384697]
 [-6.395872]
 [22.051418]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29. 10. 29.  3. 11.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  3. 11.  0.  0.] 
adversary cards in discard: [0. 8. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6] -> size -> 27 
adversary victory points: -6
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 270   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 285 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.415340423583984






Player: 1 
cards in hand: [ 0.  3. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [0. 8. 6. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 30. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  8. 25.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [0. 8. 6. 0. 0. 6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 30. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  8. 25.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 11.  0.  0.] 
cards in discard: [0. 8. 6. 0. 0. 6. 1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 10.  3.  8. 25.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 3. 10.  3.  8. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.] 
expected returns: [[31.807278]
 [31.309422]
 [35.242023]
 [63.52744 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8. 25.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  1. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1] -> size -> 28 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.051427841186523



action possibilites: [-1] 
expected returns: [[-0.6558442]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  3.  8. 11. 29.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6] -> size -> 29 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 63.52743148803711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-12.786377]
 [ -1.214066]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  3.  8. 11. 29.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 6. 0. 6. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6] -> size -> 29 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1
Learning step: 0
desired expected reward: -0.6558442115783691






Player: 1 
cards in hand: [0. 6. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 11. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  3.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 11. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 6. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 8. 10.  0. 11. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 8. 10.  0. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 11. 29.] 
expected returns: [[-32.279156]
 [-30.611107]
 [-33.1208  ]
 [-24.094444]
 [-22.596928]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.  0. 11. 29.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -1.2140636444091797



action possibilites: [-1. 10. 11.  8.] 
expected returns: [[-33.72443 ]
 [-34.479813]
 [-25.294186]
 [-31.957325]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 11.  8.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8] -> size -> 32 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -31.720932006835938



action possibilites: [-1] 
expected returns: [[-46.99036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 429 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -22.74300193786621





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-56.28487 ]
 [-51.511196]
 [-47.357807]
 [-47.030304]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 6.  0.  3.  6. 10.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.990360260009766






Player: 1 
cards in hand: [ 6.  0.  3.  6. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3.  6. 10.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 6. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  0.  0.  0. 29.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[-34.51048 ]
 [-24.608322]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 29.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -47.030303955078125



action possibilites: [-1.] 
expected returns: [[-26.131586]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -34.02029800415039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-35.6931  ]
 [-26.582325]
 [-29.198334]
 [-44.664677]
 [-27.448734]
 [-19.272713]
 [-25.46241 ]
 [ -8.865452]
 [-17.666681]
 [-37.2182  ]
 [-30.161163]
 [-28.034496]
 [-39.195095]
 [-28.127384]
 [-26.615063]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15] -> size -> 33 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  7.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -26.1315860748291



buy possibilites: [-1] 
expected returns: [[-25.364874]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  6.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 8. 0. 0. 6.] 
adversary cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0 250   0] 
sum of rewards: 595 

action type: buy - action 25.0
Learning step: 0
desired expected reward: -8.865450859069824






Player: 1 
cards in hand: [0. 8. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  6.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25] -> size -> 34 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  5.  2.  6.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25] -> size -> 34 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 0. 6.] 
cards in discard: [ 0.  8.  6.  0.  0.  6.  1.  0.  3. 11.  0.  0.  6.  8.  0.  6.  0.  6.
  6. 10.  6.  0.  3.  6.  6. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  2.  6.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [10. 11.  0.  8.  0.] 
adversary cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25] -> size -> 34 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [10. 11.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.  8.] 
expected returns: [[-59.678997]
 [-60.659584]
 [-52.83079 ]
 [-58.447407]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  0.  8.  0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  2.  6.  5. 10. 10.  4. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -25.3648738861084



action possibilites: [-1] 
expected returns: [[-52.480236]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  2.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0  64   0] 
sum of rewards: 409 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: -50.61860656738281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-61.4178  ]
 [-54.674385]
 [-50.974262]
 [-52.517437]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0. 15.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  2.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -52.4802360534668



buy possibilites: [-1] 
expected returns: [[-46.267933]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  0.] 
cards in discard: [25.  8. 29. 10. 29.  3. 11. 25.  3. 10.  3.  8. 11. 29.  8. 15. 29. 11.
 10.  0.  8. 10. 25. 29.  0.  0.  0.  0. 15.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -10   0   0  16   0] 
sum of rewards: 351 

action type: buy - action 8.0
Learning step: 0
desired expected reward: -50.97426223754883






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25.  0. 10. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [23. 29. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25.  0. 10. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [1.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [25.  0. 10. 15. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [25.  0. 10. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10. 15. 25.] 
expected returns: [[28.386398]
 [53.589977]
 [27.771866]
 [27.620914]
 [53.589977]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0. 10. 15. 25.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  8.  3.  6.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -46.2679328918457



action possibilites: [-1] 
expected returns: [[7.2536807]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 15. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  8.  3.  6.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 53.589962005615234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[-3.4080706]
 [ 4.9946227]
 [ 9.540894 ]
 [ 7.088366 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15. 25.  3.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  1.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  8.  3.  6.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 7.25368070602417



buy possibilites: [-1] 
expected returns: [[9.659321]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 15. 25.  3.  0.] 
cards in discard: [8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  8.  3.  6.  0.] 
adversary cards in discard: [1. 0. 0. 0. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -20   0   0  16   0] 
sum of rewards: 341 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 9.540885925292969






Player: 1 
cards in hand: [10.  8.  3.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8.  3.  6.  0.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  0 11  6 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6
  0  0  6  1  6  8 11  1] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  8.  8. 11.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  8.  8. 11.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [1. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  8.  8. 11.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [1. 0. 0. 0. 0. 0. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [29.  8.  8. 11.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [29.  8.  8. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8. 11.  8.] 
expected returns: [[-19.172506]
 [ -5.535403]
 [-16.305328]
 [-16.305328]
 [ -7.38236 ]
 [-16.305328]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  8. 11.  8.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6.  0.  6.  6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: 9.659320831298828



action possibilites: [-1.  8.  8.  8.] 
expected returns: [[-23.969046]
 [-20.95814 ]
 [-20.95814 ]
 [-20.95814 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 8.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29  8 25 25 11 11 10 29 25 29
  8 10 11  8 10  8 10  8 15 25 15  8  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6.  0.  6.  6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -17.751317977905273



action possibilites: [-1] 
expected returns: [[-3.6551466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6.  0.  6.  6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -23.138751983642578





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-15.637171]
 [ -5.025798]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11.  6.  0.  6.  6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -3.655146598815918






Player: 1 
cards in hand: [11.  6.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  0.  6.  6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6. 6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  3. 29.  3.  0.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [10.  3. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[-33.170883]
 [-34.20553 ]
 [-24.529406]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.  3.  0.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 11.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -5.025797367095947



action possibilites: [-1. 10. 29.] 
expected returns: [[-33.44955 ]
 [-34.127438]
 [-23.687216]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 11.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -32.893524169921875



action possibilites: [-1. 10.] 
expected returns: [[-46.53948 ]
 [-57.674946]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 2 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 11.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -32.7620849609375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-60.29797 ]
 [-59.381466]
 [-47.067272]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  6.  6. 11.  3.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -46.53946304321289






Player: 1 
cards in hand: [ 0.  6.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  6. 11.  3.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  8. 25.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  3.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  8. 25.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  6. 11.  3.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [10.  0.  8. 25.  8.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [10.  0.  8. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25.  8.] 
expected returns: [[-8.292937]
 [-9.690207]
 [-7.297488]
 [ 7.987662]
 [-7.297488]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8. 25.  8.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0  0] -> size -> 33 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -47.0672721862793



action possibilites: [-1] 
expected returns: [[-27.42494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  8.  8. 29. 11.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0  0] -> size -> 33 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 7.9876532554626465





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-36.132866]
 [-27.510998]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  8.  8. 29. 11.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [6. 0. 8. 1. 0.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
adversary owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0  0] -> size -> 33 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.42494010925293






Player: 1 
cards in hand: [6. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 1. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6
  1  6  8 11  1  0  0  0  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 29. 10.  0. 11.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 29. 10.  0. 11.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 29. 10.  0. 11.] 
adversary cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [11. 29. 10.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 10. 11.] 
expected returns: [[-61.56694 ]
 [-66.83522 ]
 [-60.420483]
 [-76.625916]
 [-66.83522 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 10.  0. 11.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.51099395751953



action possibilites: [-1. 10. 25.] 
expected returns: [[-86.257324]
 [-92.33003 ]
 [-65.55763 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11. 11. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: -71.96861267089844



action possibilites: [-1] 
expected returns: [[-140.25356]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -65.55762481689453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-160.46033]
 [-160.26074]
 [-162.9258 ]
 [-161.01335]
 [-161.48746]
 [-144.13599]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0. 10.] 
cards in discard: [ 8. 25.  0. 10. 15. 25.  3.  0. 11. 15. 29.  8.  3.  0.  3.  0. 29. 29.
 10. 25. 10.  0.  8.  8. 29. 11. 11. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [0. 8. 6. 0. 6.] 
adversary cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -140.25355529785156






Player: 1 
cards in hand: [0. 8. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 6. 0. 6.] 
cards in discard: [ 1.  0.  0.  0.  0.  0.  0.  8. 10.  0.  0. 11.  6.  0.  6.  6.  0.  0.
  6.  6. 11.  3.  8.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 3. 15.  0. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  0. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.  8.] 
expected returns: [[-11.2291   ]
 [-12.0608225]
 [ 14.758432 ]
 [ -8.749946 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0. 25.  8.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -144.13600158691406



action possibilites: [-1] 
expected returns: [[-18.336226]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  0.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 14.758430480957031





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-28.290466]
 [-18.503729]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  0.  8.  3. 11.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 10.  0.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -18.336225509643555






Player: 1 
cards in hand: [ 0.  0. 10.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  6.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 2 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0. 29. 11.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 29. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.  8.] 
expected returns: [[ 0.41904497]
 [13.240208  ]
 [11.33592   ]
 [ 2.8793359 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 29. 11.  8.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -18.503734588623047



action possibilites: [-1.  8.] 
expected returns: [[-16.915678]
 [-14.335545]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10
 11  8 10  8 10  8 15 25 15  8  8] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 1.4818143844604492



action possibilites: [-1] 
expected returns: [[8.102751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: -15.403631210327148





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-4.3981123]
 [ 7.489304 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 6. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 8.102750778198242






Player: 1 
cards in hand: [0. 0. 6. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6
  8 11  1  0  0  0  0 10] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  0. 29. 15. 29.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  0. 29. 15. 29.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11.  0. 29. 15. 29.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [11.  0. 29. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 15. 29.] 
expected returns: [[-27.674004]
 [-18.47227 ]
 [-16.83484 ]
 [-28.600494]
 [-16.83484 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 29. 15. 29.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 7.489311695098877



action possibilites: [-1. 29. 10.] 
expected returns: [[-37.312267]
 [-23.500933]
 [-39.29964 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -15.715276718139648



action possibilites: [-1.] 
expected returns: [[-31.126446]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -36.74458312988281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-40.363266]
 [-30.000317]
 [-32.842876]
 [-20.294374]
 [-31.586056]
 [-30.938261]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8] -> size -> 33 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  4.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -31.126445770263672



buy possibilites: [-1] 
expected returns: [[-38.719105]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 0. 8. 8. 0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0  54   0] 
sum of rewards: 419 

action type: buy - action 11.0
Learning step: 0
desired expected reward: -20.294374465942383






Player: 1 
cards in hand: [6. 0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 8. 8. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10. 25.  8. 29.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 8. 8. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [10. 25.  8. 29.  8.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [10. 25.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 29.  8.] 
expected returns: [[-41.980667]
 [-43.12959 ]
 [-26.35688 ]
 [-40.918743]
 [-34.030315]
 [-40.918743]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25.  8. 29.  8.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1
Learning step: 0
desired expected reward: -38.7191047668457



action possibilites: [-1] 
expected returns: [[11.585497]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 29.  8. 29. 25.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -26.356884002685547





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 3.0162034]
 [11.588226 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 29.  8. 29. 25.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: 11.58549690246582






Player: 1 
cards in hand: [6. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 25.  8. 11.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0. 25. 10.  8. 29.  8. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 10. 25.  8. 11.] 
adversary cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0. 25. 10.  8. 29.  8. 29. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3. 10. 25.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.  8. 11.] 
expected returns: [[ -89.45425 ]
 [-108.86921 ]
 [ -73.95483 ]
 [-101.719154]
 [ -92.683426]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10. 25.  8. 11.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0. 25. 10.  8. 29.  8. 29. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  1.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 11.588228225708008



action possibilites: [-1] 
expected returns: [[-27.654823]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 11.  0.  0.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0. 25. 10.  8. 29.  8. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  1.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -73.95484924316406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-35.66375 ]
 [-29.838171]
 [-27.970638]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 11.  0.  0.] 
cards in discard: [25.  3. 15.  0.  8.  3. 11. 11. 10. 29.  8. 11. 15.  0. 10. 11. 29. 29.
  0. 25. 10.  8. 29.  8. 29. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 0.  0.  6. 11.  1.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -27.654823303222656






Player: 1 
cards in hand: [ 0.  0.  6. 11.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  6. 11.  1.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  5. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  4. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 28. 30.  8.  0. 10.  3.  0.  6.  4. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 1.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 3. 29. 11. 11. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 3. 29. 11. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11. 10.] 
expected returns: [[ 6.767979 ]
 [18.464878 ]
 [16.645935 ]
 [16.645935 ]
 [ 5.9971642]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29. 11. 11. 10.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 11.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -27.97063636779785



action possibilites: [-1. 11. 11. 10.] 
expected returns: [[36.91311 ]
 [49.101498]
 [49.101498]
 [36.27035 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 10.] 
cards in discard: [ 3. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  0. 11.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.539976596832275



action possibilites: [-1] 
expected returns: [[21.313099]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.] 
cards in discard: [ 3. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  3.  0. 11.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0  64   0] 
sum of rewards: 429 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 39.75101089477539





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[11.809727]
 [21.287554]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10.] 
cards in discard: [ 3. 10. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  3.  0. 11.  0.] 
adversary cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.313098907470703






Player: 1 
cards in hand: [ 6.  3.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0. 11.  0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0.] 
cards in discard: [10. 10.  0.  0.  0.  6.  0.  8.  6.  0.  6.  0.  8.  8.  0.  6.  6.  6.
  0.  6. 29. 16. 11.  0.  0.  6.  1.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [29. 11. 10.  0. 29.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [29. 11. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 10. 29.] 
expected returns: [[-16.027195 ]
 [ -4.0574026]
 [ -5.8283377]
 [-16.807547 ]
 [ -4.0574026]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 10.  0. 29.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.287565231323242



action possibilites: [-1. 11. 10.] 
expected returns: [[-21.552813]
 [-11.30463 ]
 [-22.306206]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10.  0.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15] -> size -> 35 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  7.] 
adversary cards in hand: [ 6. 29. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -2.8145976066589355



action possibilites: [-1] 
expected returns: [[-15.089941]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 6. 29. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -10   0   0  64   0] 
sum of rewards: 419 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -19.28890609741211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-25.627466]
 [-17.81237 ]
 [-15.673332]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 6. 29. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: -15.089941024780273






Player: 1 
cards in hand: [ 6. 29. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  8.  3. 25.  0.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  8.  3. 25.  0.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  3. 10.  6.] 
adversary cards in hand: [ 8.  8.  3. 25.  0.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 0.] 
cards in discard: [10.  0. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 8.  8.  3. 25.  0.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 8.  8.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 25.] 
expected returns: [[-38.87187 ]
 [-36.98588 ]
 [-36.98588 ]
 [-18.023643]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3. 25.  0.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  1.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -15.673332214355469



action possibilites: [-1] 
expected returns: [[-40.716965]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  0. 10.  8.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  1.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.023643493652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-48.289387]
 [-40.542187]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8.  3.  0. 10.  8.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  6.  1.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -40.71696472167969






Player: 1 
cards in hand: [ 0. 10.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  1.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 15.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  1.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10] -> size -> 35 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 15.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  1.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [ 0. 10.  8. 11. 15.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  8. 11. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 11. 15.] 
expected returns: [[-31.77093 ]
 [-33.000202]
 [-30.777195]
 [-25.302254]
 [-33.075165]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 11. 15.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  6.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0] -> size -> 36 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -40.542179107666016



action possibilites: [-1] 
expected returns: [[-25.360434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8. 15.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0] -> size -> 36 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -20   0   0  64   0] 
sum of rewards: 389 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -30.777185440063477





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-33.79361 ]
 [-24.921703]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8. 15.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15.] 
cards in deck: 10 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [16. 11.  0.  0.  0.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0] -> size -> 36 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -25.36043357849121






Player: 1 
cards in hand: [16. 11.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  0.  0.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4. 10. 10.  2. 10.  5.] 
adversary cards in hand: [ 8. 25. 25. 29. 25.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 8. 25. 25. 29. 25.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 8. 25. 25. 29. 25.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  0.  0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 8. 25. 25. 29. 25.] 
adversary cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [ 8. 25. 25. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25. 29. 25.] 
expected returns: [[-41.010014]
 [-39.764248]
 [-25.076256]
 [-25.076256]
 [-32.65847 ]
 [-25.076256]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 25. 29. 25.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [0. 8. 0. 8. 1.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -24.92169761657715



action possibilites: [-1] 
expected returns: [[-69.847244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 29. 25.  3. 11.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [0. 8. 0. 8. 1.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -25.07625961303711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-92.31755]
 [-71.13019]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25. 29. 25.  3. 11.] 
cards in discard: [ 3. 10. 15. 29. 11. 11. 10. 29. 15. 15. 29. 11. 10.  0. 25.  8.  8.  3.
  0. 10.  8. 15. 11.  0. 10.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [0. 8. 0. 8. 1.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -69.84724426269531






Player: 1 
cards in hand: [0. 8. 0. 8. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 8. 1.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 3. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 1.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  5.] 
adversary cards in hand: [ 3. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 0. 8. 1.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [ 3. 11. 29.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 3. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[ 7.198629]
 [15.820038]
 [17.444279]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11. 29.  0.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -71.13020324707031



action possibilites: [-1. 11.] 
expected returns: [[22.629875]
 [33.00755 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.] 
cards in discard: [11.  0.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15] -> size -> 37 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  4.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 7.737722873687744



action possibilites: [-1] 
expected returns: [[19.201563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [11.  0. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0 -30   0   0  64   0] 
sum of rewards: 399 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 24.809768676757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[ 9.078461]
 [16.729805]
 [18.869755]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [11.  0. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 3. 6. 0. 8.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
adversary owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 365 

action type: take_action - action -1
Learning step: 0
desired expected reward: 19.201562881469727






Player: 1 
cards in hand: [6. 3. 6. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 6. 0. 8.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  3  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11
  1  0  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 15. 10. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 15. 10. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15] -> size -> 37 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 15. 10. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 15. 10. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [ 8. 15. 10. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 15. 10. 29. 10.] 
expected returns: [[-36.865303]
 [-34.782257]
 [-38.15933 ]
 [-38.0785  ]
 [-25.149426]
 [-38.0785  ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 10. 29. 10.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.86975860595703



action possibilites: [-1. 15. 10. 15.] 
expected returns: [[-17.031878]
 [-18.083914]
 [-17.958296]
 [-18.083914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 10. 15.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -36.11233139038086





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-27.298668]
 [-17.330091]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 10. 15.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [6. 6. 6. 0. 6.] 
adversary cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -17.03188705444336






Player: 1 
cards in hand: [6. 6. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 10. 25.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 10. 25.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6. 0. 6.] 
cards in discard: [10.  0. 10. 29.  6.  0.  0.  0.  0. 10.  6.  1.  0. 14.  0. 11. 16.  0.
  0.  0. 15.  0.  8.  0.  8.  1.  0.  8.  6.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  8. 10. 25.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10.  8. 10. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 10. 25.  8.] 
expected returns: [[-81.22868 ]
 [-91.935234]
 [-87.138725]
 [-91.935234]
 [-53.718716]
 [-87.138725]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10. 25.  8.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 14.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -17.33009147644043



action possibilites: [-1] 
expected returns: [[-46.62659]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  8. 10.  8.  0.  8.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 14.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -53.71866989135742





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-57.845898]
 [-46.19839 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  8. 10.  8.  0.  8.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [ 8. 14.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -46.626590728759766






Player: 1 
cards in hand: [ 8. 14.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 14.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0 11 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0
  0  0  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 25. 11. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 25. 11. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [14. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 25. 11. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.] 
cards in discard: [0.] 
cards in deck: 34 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [29. 25. 11. 29. 10.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [29. 25. 11. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 11. 29. 10.] 
expected returns: [[-35.46335 ]
 [-26.870293]
 [-18.6416  ]
 [-28.284395]
 [-26.870293]
 [-36.479214]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 11. 29. 10.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -46.19838333129883



action possibilites: [-1] 
expected returns: [[-13.73494]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11. 29. 10. 25. 29.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -18.641590118408203





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-21.560295]
 [-13.666693]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 11. 29. 10. 25. 29.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [0. 1. 1. 0. 0.] 
adversary cards in discard: [ 0.  8. 14.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -13.734939575195312






Player: 1 
cards in hand: [0. 1. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [15. 15. 11.  0.  3.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 7 
card supply: [13. 27. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [15. 15. 11.  0.  3.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 1. 0. 0.] 
cards in discard: [ 0.  8. 14.  6.  1.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [15. 15. 11.  0.  3.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [15. 15. 11.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11.] 
expected returns: [[-43.67976 ]
 [-44.843746]
 [-44.843746]
 [-36.3522  ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11.  0.  3.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  3.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -13.666681289672852



action possibilites: [-1] 
expected returns: [[-44.003254]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  0.  3.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0 -40   0   0  64   0] 
sum of rewards: 369 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -42.30373001098633





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-51.744488]
 [-44.00326 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  0.  3.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  2.] 
adversary cards in hand: [10.  0.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -44.00325393676758






Player: 1 
cards in hand: [10.  0.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15. 25. 11.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15. 11. 15. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  2. 10.  2.] 
adversary cards in hand: [ 3. 15. 25. 11.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15. 11. 15. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 3. 15. 25. 11.  8.] 
adversary cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15. 11. 15. 15.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -8 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 3. 15. 25. 11.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25. 11.  8.] 
expected returns: [[-116.095  ]
 [-132.72618]
 [-114.45883]
 [-127.40953]
 [-128.90364]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 25. 11.  8.] 
cards in discard: [11.  0. 15. 29. 11.  3.  0.  8. 10. 29. 15. 10. 15. 25. 10.  8. 10.  8.
  0.  8. 25. 29. 11. 29. 10. 25. 29. 15. 11. 15. 15.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 325 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -44.00325393676758



action possibilites: [-1] 
expected returns: [[-19.242817]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15. 11.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -114.45879364013672





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-27.61208]
 [-19.31206]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15. 11.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  8.  0. 16.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
adversary victory points: -8
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 330   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 345 

action type: take_action - action -1
Learning step: 0
desired expected reward: -19.242816925048828






Player: 1 
cards in hand: [ 0.  8.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 28. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 16.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [11. 10. 29.  0.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
adversary victory points: 3
player victory points: -7 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[-25.423265]
 [-16.237764]
 [-26.24433 ]
 [-14.554417]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  0.  0.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -19.312047958374023



action possibilites: [-1. 11. 10.] 
expected returns: [[-29.519745]
 [-20.51496 ]
 [-30.367535]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0. 10.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  2.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -24.7391300201416



action possibilites: [-1] 
expected returns: [[-40.98903]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0 -50   0   0  64   0] 
sum of rewards: 349 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: -27.640304565429688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-61.81546 ]
 [-53.180946]
 [-41.318653]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15.] 
cards in deck: 26 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 0.  0. 10. 10.  0.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 335 

action type: take_action - action -1
Learning step: 0
desired expected reward: -40.98902893066406






Player: 1 
cards in hand: [ 0.  0. 10. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11.  3. 10. 15. 15.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10. 10.  0.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11.  3. 10. 15. 15.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [11.  3. 10. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 15. 15.] 
expected returns: [[-47.88246 ]
 [-49.62501 ]
 [-53.406834]
 [-53.38574 ]
 [-53.38574 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3. 10. 15. 15.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6. 29.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -41.31864929199219





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-55.89451]
 [-47.92635]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  3. 10. 15. 15.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6. 29.  0.  0.  6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -47.882469177246094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 6. 29.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 29.  0.  0.  6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 10. 29.  8.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 


action possibilites: [-1. 15.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6. 15.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 10. 29.  8.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 10. 29.  8.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 15.] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [11. 10. 29.  8.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [11. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.  8.] 
expected returns: [[-25.080193]
 [-18.51115 ]
 [-26.259802]
 [-17.106777]
 [-24.027225]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 29.  8.  0.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 295 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -47.92634963989258



action possibilites: [-1. 10. 29.] 
expected returns: [[-49.78256 ]
 [-59.539776]
 [-51.235195]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: -16.29439926147461





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-61.148647]
 [-60.867325]
 [-49.915043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 8. 0. 6. 6.] 
adversary cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
adversary owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
adversary victory points: -7
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 300   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 315 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -49.78256607055664






Player: 1 
cards in hand: [0. 8. 0. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 6. 6.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  6  0  8  0  6  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0
  0 10 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15.  3. 25.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15.  3. 25.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 0.  8. 14.  6.  1.  0.  1.  1.  0.  0. 10. 10.  0.  0.  0.  6.  3.  0.
  8.  0. 16.  6.  0.  0. 10. 10.  0.  0.  0. 29. 15.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 2 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15.  3. 25.  0.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -5 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15. 15.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 25.] 
expected returns: [[-34.042564]
 [-36.820152]
 [-36.820152]
 [-19.47535 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3. 25.  0.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -49.915042877197266



action possibilites: [-1] 
expected returns: [[-62.71034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15.  3.  0.  8. 25.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: -19.47534942626953





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-74.63422 ]
 [-62.710323]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 15.  3.  0.  8. 25.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 6.  6.  0. 11.  6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 255 

action type: take_action - action -1
Learning step: 0
desired expected reward: -62.7103385925293






Player: 1 
cards in hand: [ 6.  6.  0. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [29.  8. 25.  8. 10.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29. 25. 15. 15.  3.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  0. 11.  6.] 
cards in discard: [] 
cards in deck: 34 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [29.  8. 25.  8. 10.] 
adversary cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29. 25. 15. 15.  3.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [29.  8. 25.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 25.  8. 10.] 
expected returns: [[-165.64833]
 [-176.66634]
 [-181.35927]
 [-171.81499]
 [-181.35927]
 [-184.78717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 25.  8. 10.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29. 25. 15. 15.  3.  0.  8. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 10.  0. 16.  6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.] 
adversary owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -62.7103385925293





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-185.32982]
 [-165.64833]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 25.  8. 10.] 
cards in discard: [25.  3. 15. 11.  8. 11.  0.  0. 10. 15. 29. 11.  0. 10. 11.  3. 10. 15.
 15. 11.  8. 29. 10.  0. 29. 25. 15. 15.  3.  0.  8. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 1 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [ 0. 10.  0. 16.  6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.] 
adversary owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
adversary victory points: -5
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 240   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 235 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: -165.6483612060547



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0. 16.  6.] 
cards in discard: [ 6.  6.  0. 11.  6.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0 10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10
 29 16  1  0 10  0 14  0 15  0  0  0  1 10  3] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 27. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15.  8. 15. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15.  8. 15. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15.  8. 15. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.  0.] 
cards in deck: 29 
card top of deck: [] 
played cards: [16.] 
owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15.  8. 15. 15. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
adversary victory points: 3
player victory points: -4 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [15.  8. 15. 15. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 15. 15. 29.] 
expected returns: [[18.058464]
 [17.058098]
 [19.604656]
 [17.058098]
 [17.058098]
 [27.381992]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 15. 15. 29.] 
cards in discard: [] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
adversary owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 205 

action type: buy - action -1.0
Learning step: 0
desired expected reward: -165.6483612060547



action possibilites: [-1.  8. 15. 15.] 
expected returns: [[10.382929]
 [12.059078]
 [ 9.415993]
 [ 9.415993]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 15. 15.] 
cards in discard: [15. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 15 25 15  8  8 11 15 15 15 15 15 15] -> size -> 40 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
adversary owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 225 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 18.52178955078125



action possibilites: [-1] 
expected returns: [[14.205591]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [15. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
adversary owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 10.798173904418945





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ 5.787621]
 [14.249315]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [15. 25.] 
cards in deck: 34 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [0. 0. 0. 8. 6.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
adversary owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
adversary victory points: -4
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 210   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: 245 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.205591201782227






Player: 1 
cards in hand: [0. 0. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 6.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [10  0  8  0  8  0  6  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29
 16  1  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15. 11. 29.  8.] 
adversary cards in discard: [15. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29 16  1
  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15. 11. 29.  8.] 
adversary cards in discard: [15. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.] 
cards in deck: 24 
card top of deck: [] 
played cards: [8.] 
owned cards: [10  8  0  8  0  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29 16  1
  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [15. 15. 11. 29.  8.] 
adversary cards in discard: [15. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
adversary victory points: 3
player victory points: -3 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [15. 15. 11. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 15. 11. 29.  8.] 
expected returns: [[-15.80582  ]
 [-16.890036 ]
 [-16.890036 ]
 [ -6.8797107]
 [ -5.14968  ]
 [-14.053265 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 15. 11. 29.  8.] 
cards in discard: [15. 25. 29.  8.] 
cards in deck: 29 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  0  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29 16  1
  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: 175 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.249313354492188



action possibilites: [-1. 15. 11. 11.] 
expected returns: [[-15.162474]
 [-16.173412]
 [ -6.730427]
 [ -6.730427]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 11.] 
cards in discard: [15. 25. 29.  8. 15.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15] -> size -> 38 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  1.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  0  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29 16  1
  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[ -5   0   0 180   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 195 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: -15.262979507446289



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 5 
Chapel: 7 
Witch: 4 
Poacher: 5 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [15. 11.] 
cards in discard: [15. 25. 29.  8. 15.  8. 15.] 
cards in deck: 28 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  3  3  3 11 29 10 29 29 25 25 11 11 10 29 25 29 10 11  8
 10  8 10  8 25  8  8 11 15 15 15 15 15 15 15] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 26. 30. 26. 30.  8.  0.  9.  3.  0.  6.  4.  9. 10.  1. 10.  0.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  6.  0. 11.  6.  3.  0. 16. 10.  0.  6.  8.  0.  0.] 
adversary owned cards: [10  8  0  8  0  0  6  6  6  0  0  6  6  8 11  1  0  0  0  0 10 29 16  1
  0 10  0 14  0 15  0  0  0  1 10  3  3  0] -> size -> 38 
adversary victory points: -3
player victory points: 3 

Reward from previous game state: 
[     -5 3000000       0     180       0       0      40       0       0
       0       0     -40       0       0      64       0] 
sum of rewards: 3000239 

action type: gain_card_n - action 8
Learning step: 120010.09375
desired expected reward: 119996.5859375



