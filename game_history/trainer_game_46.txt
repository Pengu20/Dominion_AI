 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[308.42044]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -615 

action type: buy - action -1.0
Learning step: -46.2838020324707
desired expected reward: 264.3922119140625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[286.24567]
 [295.20312]
 [293.05597]
 [271.568  ]
 [289.49637]
 [303.78183]
 [295.4454 ]
 [299.7354 ]
 [282.60434]
 [293.51898]
 [293.18158]
 [310.47144]]
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.09214973449707
desired expected reward: 302.6194763183594



buy possibilites: [-1] 
expected returns: [[277.83304]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 16.0
Learning step: -6.723573207855225
desired expected reward: 282.7727355957031






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [16.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[307.7751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.037003993988037
desired expected reward: 270.7960205078125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[292.7011 ]
 [301.13284]
 [299.06216]
 [279.4479 ]
 [309.26816]
 [301.35822]
 [299.4867 ]
 [315.70392]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.806233406066895
desired expected reward: 300.2892150878906



buy possibilites: [-1] 
expected returns: [[299.48972]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [16.  0.  3.  0.  0.  0.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [0. 0. 0. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -9.496537208557129
desired expected reward: 283.2045593261719






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [0. 0. 0. 0. 3. 8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[277.84872]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.829367637634277
desired expected reward: 290.66033935546875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[263.2371 ]
 [270.34167]
 [267.74524]
 [251.5262 ]
 [265.60834]
 [276.2434 ]
 [270.81357]
 [273.3739 ]
 [259.87134]
 [268.33783]
 [267.73196]
 [279.86115]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8. 10.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.947705268859863
desired expected reward: 269.6131286621094



buy possibilites: [-1] 
expected returns: [[305.49402]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 0.] 
cards in discard: [6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
action values: 0 
buys: 0 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -21.352697372436523
desired expected reward: 230.1735382080078






Player: 1 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 8] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3.  3.  0.  0. 16.] 
adversary cards in discard: [6. 0. 0. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[362.0462 ]
 [339.52914]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 16.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -8.076022148132324
desired expected reward: 297.4179992675781





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[334.86267]
 [342.06638]
 [320.25284]
 [344.29782]
 [360.7044 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 16.] 
cards in discard: [6. 0. 0. 0. 3. 0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -10.984055519104004
desired expected reward: 348.9880676269531



buy possibilites: [-1] 
expected returns: [[341.49155]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 16.] 
cards in discard: [6. 0. 0. 0. 3. 0. 8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  8] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 3.] 
adversary cards in discard: [29.  0.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -5 

action type: buy - action 8.0
Learning step: -9.781332015991211
desired expected reward: 334.5164794921875






Player: 1 
cards in hand: [0. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 30. 30.  8.  9.  9. 10.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 3.] 
cards in discard: [29.  0.  3.  0.  0.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [16.  0.  8.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  8] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [16.  0.  8.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
expected returns: [[306.0233 ]
 [289.29434]
 [294.6593 ]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  8] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 30. 30.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -11.037650108337402
desired expected reward: 330.4538879394531



action possibilites: [-1] 
expected returns: [[342.20273]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  4  0] 
sum of rewards: 22 

action type: gain_card_n - action 2
Learning step: -7.179799556732178
desired expected reward: 312.40740966796875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[310.84604]
 [320.88882]
 [318.7947 ]
 [295.57632]
 [330.93372]
 [320.9983 ]
 [319.16675]
 [339.0174 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 18 

action type: take_action - action -1
Learning step: -9.016220092773438
desired expected reward: 333.1865234375



buy possibilites: [-1] 
expected returns: [[311.82635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [ 3. 11.] 
cards in deck: 9 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 36 

action type: buy - action 11.0
Learning step: -7.519618988037109
desired expected reward: 319.1946105957031






Player: 1 
cards in hand: [ 3. 29.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  8 29 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 0.] 
adversary cards in discard: [ 3. 11. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [3. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[292.75433]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -9.09278678894043
desired expected reward: 302.73358154296875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[263.93295]
 [272.78183]
 [270.9168 ]
 [250.39345]
 [281.4491 ]
 [272.88498]
 [271.23816]
 [288.47803]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 16.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.650487899780273
desired expected reward: 284.6175842285156



buy possibilites: [-1] 
expected returns: [[331.61356]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 0.] 
cards in discard: [ 3. 11. 16.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 3 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[ -5.   0.   3.   0.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -32.0 

action type: buy - action 0.0
Learning step: -7.3353447914123535
desired expected reward: 256.5976257324219






Player: 1 
cards in hand: [ 0.  0.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 11.] 
cards in discard: [29.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [29.  8.  3.  0. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[272.6169]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -10.482416152954102
desired expected reward: 321.1311340332031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[255.56544]
 [262.36365]
 [259.5645 ]
 [244.55801]
 [268.1431 ]
 [262.8586 ]
 [260.1628 ]
 [271.4779 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  8. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.00817584991455
desired expected reward: 267.4701232910156



buy possibilites: [-1] 
expected returns: [[285.07715]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 0.] 
cards in discard: [8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3. 29.  3.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.  0.  3.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  2.  0.] 
sum of rewards: 0.0 

action type: buy - action 8.0
Learning step: -6.728692054748535
desired expected reward: 256.1298522949219






Player: 1 
cards in hand: [ 0.  3. 29.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [8. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 29.  3.  3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [ 0.  3.  3. 16.  0.] 
adversary cards in discard: [8. 0. 0. 3. 6. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0  8] -> size -> 17 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[332.61456]
 [312.78232]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  0.] 
cards in discard: [8. 0. 0. 3. 6. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 16  0  6  3 11  0  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.115261077880859
desired expected reward: 277.9618835449219



action possibilites: [-1] 
expected returns: [[342.8648]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 23 

action type: gain_card_n - action 10
Learning step: -4.779217720031738
desired expected reward: 268.09429931640625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[320.50375]
 [326.8656 ]
 [307.53937]
 [328.99457]
 [342.2059 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  9.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 7 

action type: take_action - action -1
Learning step: -9.47179126739502
desired expected reward: 333.39300537109375



buy possibilites: [-1] 
expected returns: [[302.51978]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [ 0.  3. 29.  3.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -304.0 

action type: buy - action 6.0
Learning step: -23.770273208618164
desired expected reward: 283.7690734863281






Player: 1 
cards in hand: [11. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  0.] 
cards in discard: [ 0.  3. 29.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 0.  3. 29.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 0.  3. 29.  3.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29] -> size -> 12 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 30. 30. 29. 30.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 0.  3. 29.  3.  3.  4.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [11.  0.  0.  0.  0.] 
adversary cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
adversary victory points: 1
player victory points: 6 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [11.  0.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[228.51683]
 [222.01811]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: buy - action -1
Learning step: -12.726847648620605
desired expected reward: 289.7929382324219





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[209.3045 ]
 [218.60312]
 [216.72823]
 [194.8964 ]
 [212.7093 ]
 [228.28955]
 [218.76308]
 [223.63855]
 [205.99629]
 [217.14487]
 [216.9055 ]
 [237.22498]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [27. 30. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -54 

action type: take_action - action -1.0
Learning step: -9.31192398071289
desired expected reward: 220.5299530029297



buy possibilites: [-1] 
expected returns: [[217.18425]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [ 8.  0.  0.  3.  6.  0. 15.  6. 16.  0.  3.  0.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3.  0. 29.  4.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
adversary victory points: 6
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -50.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -49.5 

action type: buy - action 1.0
Learning step: -8.248537063598633
desired expected reward: 210.35458374023438






Player: 1 
cards in hand: [ 3.  0. 29.  4.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  4.  8.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 4. 8. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  8 29 11  0 29  4] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 3. 11.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [ 3. 11.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
expected returns: [[273.06235]
 [265.35037]
 [256.40054]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8.  8.  9.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1
Learning step: -5.599130153656006
desired expected reward: 211.58511352539062



action possibilites: [-1] 
expected returns: [[292.88565]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 3.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 22 

action type: gain_card_n - action 4
Learning step: -4.209014892578125
desired expected reward: 233.7698211669922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[274.45422]
 [262.4128 ]
 [291.1109 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 3.] 
cards in discard: [16.] 
cards in deck: 14 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3.  0. 11.] 
adversary cards in discard: [29.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 6 

action type: take_action - action -1
Learning step: -8.130926132202148
desired expected reward: 284.7547302246094






Player: 1 
cards in hand: [ 0. 29.  3.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0. 11.] 
cards in discard: [29.  8.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  0. 11.  0.] 
cards in discard: [29.  8.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29] -> size -> 10 
action values: 1 
buys: 0 
player value: 1 
card supply: [27. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  8.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8. 10. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0.] 
cards in discard: [29.  8.  3.  0. 14.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [0. 6. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
adversary victory points: 1
player victory points: 2 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [0. 6. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[294.39206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: buy - action -1.0
Learning step: -8.655268669128418
desired expected reward: 282.4556579589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[279.5382 ]
 [285.6041 ]
 [282.99634]
 [269.5418 ]
 [281.5409 ]
 [289.9251 ]
 [286.06815]
 [287.59247]
 [276.26663]
 [283.51553]
 [282.67615]
 [291.5797 ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16] -> size -> 20 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8.  9. 10. 10. 10.  9.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1.0
Learning step: -8.996217727661133
desired expected reward: 284.3494873046875



buy possibilites: [-1] 
expected returns: [[282.4028]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3. 15.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8.  9. 10. 10. 10.  8.] 
adversary cards in hand: [ 0. 29.  3. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14] -> size -> 12 
adversary victory points: 2
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -10   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: 18 

action type: buy - action 15.0
Learning step: -6.8797454833984375
desired expected reward: 275.79644775390625






Player: 1 
cards in hand: [ 0. 29.  3. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3. 11.  0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  8.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
adversary victory points: 1
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  3.  0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
adversary victory points: 1
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.] 
cards in discard: [29.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29] -> size -> 13 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 29. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
adversary victory points: 1
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  3.  0.] 
cards in discard: [29.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 0.] 
adversary cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [1. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[222.82407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -10.333147048950195
desired expected reward: 272.06964111328125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[205.03165]
 [211.41249]
 [202.53156]
 [209.88089]
 [198.00386]
 [195.1612 ]
 [207.33751]
 [217.5534 ]
 [211.58026]
 [222.25273]
 [214.6091 ]
 [202.56042]
 [205.57771]
 [210.20404]
 [198.22838]
 [209.90979]
 [222.31384]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10. 10.  8.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -7.588199138641357
desired expected reward: 214.05596923828125



buy possibilites: [-1] 
expected returns: [[169.95595]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 0.] 
cards in discard: [16. 11.  3.  0.  8.  3. 15.  0.  6.  0.  0.  0. 22.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10.  9.  8.] 
adversary cards in hand: [14.  3.  8.  0. 29.] 
adversary cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -11.5 

action type: buy - action 22.0
Learning step: -6.662410259246826
desired expected reward: 191.5659637451172






Player: 1 
cards in hand: [14.  3.  8.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0. 29.] 
cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10.  9.  8.] 
adversary cards in hand: [ 3. 15. 16.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1. 14.  8.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.  0.  0.] 
cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10.  9.  8.] 
adversary cards in hand: [ 3. 15. 16.  6.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
adversary victory points: 1
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10.  9.  8.] 
adversary cards in hand: [15. 16.  3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29.  3. 11.  0. 29.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  7.  9. 10. 10.  9.  8.] 
adversary cards in hand: [15. 16.  3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 0. 0.] 
cards in discard: [29.  3. 11.  0. 29.  3.  0. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  6.  9. 10. 10.  9.  8.] 
adversary cards in hand: [15. 16.  3.] 
adversary cards in discard: [3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [15. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[332.66473]
 [317.4233 ]
 [314.23453]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  3.] 
cards in discard: [3. 6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3 16  0  6  3 11  0  8 15  6  1 16 15 22] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  6.  9. 10. 10.  9.  8.] 
adversary cards in hand: [14.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5    0    1  -20    0    0    0 -120    0    0    0    0    0 -600
   98    0] 
sum of rewards: -646 

action type: discard_down_to_3_cards - action 7
Learning step: -35.8584098815918
desired expected reward: 179.80105590820312



action possibilites: [-1] 
expected returns: [[362.30423]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.] 
cards in discard: [ 3.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [14.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: 1 

action type: gain_card_n - action 8
Learning step: -0.004787445068359375
desired expected reward: 164.1278533935547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[336.22592]
 [321.6982 ]
 [359.7733 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 3.  6. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  8.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [14.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1
Learning step: -11.227694511413574
desired expected reward: 351.0765380859375



buy possibilites: [-1] 
expected returns: [[259.00748]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.] 
cards in discard: [ 3.  6. 14.  6.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [14.  8. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[  -5    0   -1  -40    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -326 

action type: buy - action 6.0
Learning step: -25.56141471862793
desired expected reward: 276.2202453613281






Player: 1 
cards in hand: [14.  8. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 14.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29] -> size -> 15 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  7. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  3.  0.  0.] 
cards in discard: [8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 15.  0.  0.  3.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[209.86023]
 [193.3468 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  0.  0.  3.] 
cards in discard: [ 3.  6. 14.  6. 16. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -10.810599327087402
desired expected reward: 248.19688415527344



action possibilites: [-1] 
expected returns: [[151.6007]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  6. 14.  6. 16. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action 15.0
Learning step: -7.338037967681885
desired expected reward: 181.6430206298828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[137.3321 ]
 [142.83109]
 [141.84941]
 [131.32677]
 [129.07516]
 [139.38596]
 [148.86902]
 [142.8725 ]
 [153.11113]
 [145.93048]
 [135.43715]
 [138.34186]
 [142.0491 ]
 [131.86084]
 [141.9184 ]
 [154.15001]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  6. 14.  6. 16. 15.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6. 10.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -5.703996181488037
desired expected reward: 145.89669799804688



buy possibilites: [-1] 
expected returns: [[146.22919]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25.] 
cards in deck: 12 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [29.  3.  0.  0. 29.] 
adversary cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 24 

action type: buy - action 25.0
Learning step: -3.1653993129730225
desired expected reward: 149.94570922851562






Player: 1 
cards in hand: [29.  3.  0.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0. 29.] 
cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11. 22.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 29. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 29. 11.] 
cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11. 22.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
adversary victory points: -1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 11.] 
cards in discard: [ 8. 29. 14.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10. 10.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11. 22.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
adversary victory points: -1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 29. 11.] 
cards in discard: [ 8. 29. 14.  8.  3.  0.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10.  9.  9.  8.] 
adversary cards in hand: [ 0. 16.  0. 11. 22.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
adversary victory points: -1
player victory points: 3 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  0. 11. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11. 22.] 
expected returns: [[176.74506]
 [158.68796]
 [170.13411]
 [149.48276]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 11. 22.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  8. 10.  9.  9.  8.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: buy - action -1
Learning step: -6.075736045837402
desired expected reward: 140.15345764160156



action possibilites: [-1] 
expected returns: [[176.56702]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  0. 22.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -10 

action type: gain_card_n - action 8
Learning step: -4.337430000305176
desired expected reward: 151.86631774902344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[156.54582]
 [161.5663 ]
 [146.9356 ]
 [162.5735 ]
 [175.08118]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  0. 22.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
adversary victory points: 3
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -26 

action type: take_action - action -1
Learning step: -6.5128021240234375
desired expected reward: 170.05421447753906






Player: 1 
cards in hand: [11. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  3.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  0.  3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10] -> size -> 17 
action values: 2 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 28. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  9.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 3.] 
cards in discard: [ 3. 10.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29. 29. 10. 11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 8. 0. 1.] 
adversary cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [0. 0. 8. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[115.47737 ]
 [107.456184]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  3. 14.  0. 29.] 
adversary cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -9.045121192932129
desired expected reward: 166.03604125976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[104.494865]
 [109.22779 ]
 [107.98933 ]
 [ 99.50895 ]
 [ 97.6132  ]
 [106.21159 ]
 [113.60665 ]
 [109.34298 ]
 [117.49189 ]
 [111.46277 ]
 [102.54764 ]
 [104.739494]
 [108.20921 ]
 [ 99.49723 ]
 [107.93061 ]
 [117.23223 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14] -> size -> 24 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  6.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  3. 14.  0. 29.] 
adversary cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -6.15681791305542
desired expected reward: 109.32056427001953



buy possibilites: [-1] 
expected returns: [[109.42411]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 0. 1.] 
cards in discard: [ 3.  6. 14.  6. 16. 15. 25. 15.  0.  0.  3. 14. 11.  0. 16.  0. 22.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  3. 14.  0. 29.] 
adversary cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -50.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -54.0 

action type: buy - action 8.0
Learning step: -5.705106258392334
desired expected reward: 103.63787078857422






Player: 1 
cards in hand: [ 8.  3. 14.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  0. 29.] 
cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.  8. 14. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  0. 29.] 
cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 14.  0.  0.] 
cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
action values: 1 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  0.  0.] 
cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 4 
card supply: [26. 29. 30. 27. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
adversary victory points: -1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  3. 14.  0.  0.] 
cards in discard: [ 3. 10. 29. 29. 10. 11.  3.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  6. 14.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 14.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[224.70749]
 [206.0682 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 14.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -4.019951820373535
desired expected reward: 105.40415954589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[208.95256]
 [213.62354]
 [199.3773 ]
 [215.21143]
 [224.86   ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  7.  8.  8.  5.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1.0
Learning step: -9.529491424560547
desired expected reward: 210.7006072998047



buy possibilites: [-1] 
expected returns: [[198.31705]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6. 14.  6.  0.] 
cards in discard: [8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  8.  8.  4.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [11.  3.  0.  8.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3] -> size -> 20 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   8   0] 
sum of rewards: -58 

action type: buy - action 8.0
Learning step: -9.198439598083496
desired expected reward: 206.01300048828125






Player: 1 
cards in hand: [11.  3.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  0.  8.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  8.  8.  4.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 22.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  4.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 22.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [16.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  4.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 22.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 0.] 
cards in discard: [16.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  0.  0. 22.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
adversary victory points: -1
player victory points: 5 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [ 3.  3.  0.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[141.76361]
 [125.59535]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 22.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  8.  0.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action -1
Learning step: -10.255636215209961
desired expected reward: 188.06141662597656



action possibilites: [-1] 
expected returns: [[139.31393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  0.  0. 25. 15.  6.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 15. 16. 11.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  8.  0.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: LIBRARY: skip_action_card - action 0
Learning step: -1.2263755798339844
desired expected reward: 99.99240112304688





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[126.39035]
 [130.34781]
 [118.44661]
 [131.9322 ]
 [141.03178]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25. 15.  6.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 15. 16. 11.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8] -> size -> 26 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  7.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  8.  0.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
adversary victory points: 5
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -60   0   0  80   0   0   0   0   0   0   0   0   0] 
sum of rewards: 14 

action type: take_action - action -1
Learning step: -3.346369981765747
desired expected reward: 135.96755981445312



buy possibilites: [-1] 
expected returns: [[100.02246]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  0.  0. 25. 15.  6.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.  6.] 
cards in deck: 9 
card top of deck: [] 
played cards: [22. 15. 16. 11.] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0.  8.  0.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
adversary owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -70.    0.    0.   80.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -297.0 

action type: buy - action 6.0
Learning step: -18.521825790405273
desired expected reward: 99.92481231689453






Player: 1 
cards in hand: [ 3. 29.  0.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  8.  0.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  8 29 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8. 14.  8.  0.] 
adversary cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [ 0.  8. 14.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.  8.] 
expected returns: [[50.839977]
 [44.52989 ]
 [40.044506]
 [44.52989 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 14.  8.  0.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3 16  0  6  3 11  0  8 15  6  1 16 15 22 14  6 25 14
  8  8  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14.  3. 10. 29.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -7.3375725746154785
desired expected reward: 92.68489074707031



action possibilites: [-1] 
expected returns: [[26.387314]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14.  3. 10. 29.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: trash_cards_n_from_hand - action 7
Learning step: -3.747995138168335
desired expected reward: 36.08619689941406





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[19.749022]
 [16.458256]
 [27.681538]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.] 
cards in discard: [ 8.  0.  6. 14.  6.  0.  6. 22. 15. 16. 11.  3.  3.  0.  0. 25. 15.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 14.  3. 10. 29.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -3.188711643218994
desired expected reward: 23.1986026763916






Player: 1 
cards in hand: [ 3. 14.  3. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 10. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 14.  3. 10. 29.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 14.  3. 10. 29.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 1 
buys: 1 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16.  1.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
adversary victory points: -2
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  1.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[209.57498]
 [198.7956 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0. 29. 10.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.  3. 14.  3. 10. 29.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -0.229487806558609
desired expected reward: 27.452056884765625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[197.0754 ]
 [201.9781 ]
 [200.61374]
 [191.53008]
 [189.10355]
 [198.89595]
 [206.36818]
 [202.1326 ]
 [209.98259]
 [204.19258]
 [194.71382]
 [196.82521]
 [200.91705]
 [191.27425]
 [200.44806]
 [209.54309]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [25. 29. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0. 29. 10.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.  3. 14.  3. 10. 29.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -9.120352745056152
desired expected reward: 196.21058654785156



buy possibilites: [-1] 
expected returns: [[175.72678]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  1.  0.  0.] 
cards in discard: [1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 29.  0. 29. 10.] 
adversary cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.  3. 14.  3. 10. 29.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -60.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -62.5 

action type: buy - action 1.0
Learning step: -9.27005386352539
desired expected reward: 192.70806884765625






Player: 1 
cards in hand: [ 3. 29.  0. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 29. 10.] 
cards in discard: [16.  8. 11.  3.  0.  8.  0.  0.  8.  0.  3. 14.  3. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 22. 14.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29. 10.  3.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 22. 14.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 2 
buys: 0 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 22. 14.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  3.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 22. 14.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  3.  8.] 
cards in discard: [8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 11.  0. 22. 14.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  0. 22. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22. 14.] 
expected returns: [[109.71498 ]
 [106.57628 ]
 [ 93.794556]
 [ 96.48111 ]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 22. 14.] 
cards in discard: [ 1.  0. 16.  1.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10. 16.  0.  0. 14.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0  8] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1
Learning step: -9.893912315368652
desired expected reward: 165.83287048339844



action possibilites: [-1] 
expected returns: [[130.75452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0. 14.  6.  6.  3.] 
cards in discard: [ 1.  0. 16.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22. 14. 15.] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10. 16.  0.  0. 14.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0  8] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: LIBRARY: skip_action_card - action 0
Learning step: -3.902780532836914
desired expected reward: 125.99236297607422





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[115.92361]
 [110.30244]
 [131.06886]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0. 14.  6.  6.  3.] 
cards in discard: [ 1.  0. 16.  1.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [22. 14. 15.] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [10. 16.  0.  0. 14.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0  8] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  60   0   0   0   0   0   0   0   0   0] 
sum of rewards: -7 

action type: take_action - action -1
Learning step: -4.205224514007568
desired expected reward: 126.5492935180664






Player: 1 
cards in hand: [10. 16.  0.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16. 14.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.  0. 14.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8 10  3 10  3 16  8  0  8] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  6. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  6. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 14.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 8.  6. 25.  0.  0.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [ 8.  6. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[102.092735]
 [ 96.71514 ]
 [102.12939 ]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6. 25.  0.  0.] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3 16  0  6  3 11  0 15  6  1 16 15 22 14  6 25 14  8  8
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: buy - action -1.0
Learning step: -7.645989894866943
desired expected reward: 123.4228744506836



action possibilites: [-1] 
expected returns: [[70.63308]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 10
Learning step: -5.0025787353515625
desired expected reward: 90.8338851928711





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[63.379517]
 [59.308533]
 [71.095604]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -3.8767616748809814
desired expected reward: 66.75631713867188



buy possibilites: [-1] 
expected returns: [[92.06556]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  3.  8.  8.  0.] 
adversary cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
adversary owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20 -30   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: buy - action 0.0
Learning step: -4.397501468658447
desired expected reward: 58.98202133178711






Player: 1 
cards in hand: [29.  3.  8.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  8.  8.  0.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  8 11  0 29  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  8.  0. 16.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  8.  0. 16.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 29. 10.  3.  0. 29.  3.  8.  0. 16.  0.  0. 14.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  8.  0. 16.] 
adversary cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  8.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 16.] 
expected returns: [[88.672035]
 [79.65716 ]
 [81.03657 ]
 [78.0357  ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  8.  0. 16.] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1
Learning step: -5.560054779052734
desired expected reward: 86.50550842285156





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[75.728485]
 [68.422966]
 [88.137566]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  8.  0. 16.] 
cards in discard: [ 1.  0. 16.  1.  0.  0. 22. 14. 15.  6. 11.  0. 14.  6.  6.  3.  0.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [29.  8.  0.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 18 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: take_action - action -1.0
Learning step: -5.488938808441162
desired expected reward: 83.18309020996094



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [29.  8.  0.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  3. 11.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  7.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  0. 16.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8.  0.  3.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  0. 16.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8.  0.  3.] 
cards in discard: [16.] 
cards in deck: 13 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [14.  0. 16.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
adversary victory points: -1
player victory points: 4 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [14.  0. 16.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
expected returns: [[96.96969]
 [83.08753]
 [86.178  ]
 [88.83932]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0. 16.  6.  8.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3 16  0  3 11  0 15  6  1 16 15 22 14  6 14  8  8  6  1  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14.  8. 10.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -56 

action type: buy - action -1.0
Learning step: -5.302577495574951
desired expected reward: 82.83500671386719



action possibilites: [-1] 
expected returns: [[143.35674]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14.  8. 10.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: trash_cards_n_from_hand - action 8
Learning step: -2.6233391761779785
desired expected reward: 78.35397338867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[127.85157 ]
 [119.084404]
 [143.0297  ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  6.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14.  8. 10.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
adversary victory points: 4
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -36 

action type: take_action - action -1
Learning step: -6.040055274963379
desired expected reward: 137.31668090820312



buy possibilites: [-1] 
expected returns: [[107.78607]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  6.] 
cards in discard: [6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 14.  8. 10.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2  -60    0    0   20    0    0    0    0    0    0 -300
    0    0] 
sum of rewards: -347 

action type: buy - action 6.0
Learning step: -20.666057586669922
desired expected reward: 98.41835021972656






Player: 1 
cards in hand: [ 0. 14.  8. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8. 10.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 14.  8. 10.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15.  8. 11.  3. 16.] 
adversary cards in discard: [ 6.  8. 16.  6.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [23. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15.  3. 16.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16] -> size -> 19 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15.  3. 16.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 10.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [15.  3. 16.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
adversary victory points: -2
player victory points: 4 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [15.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[34.837475]
 [26.676668]
 [25.402044]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  3. 16.] 
cards in discard: [ 6.  8. 16.  6.  8. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  3 11  0 15  6  1 16 15 22  6 14  8  8  6  1  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  7. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0. 29.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[   -5     0    -2   -60     0     0     0     0     0     0     0     0
     0 -1200    75     0] 
sum of rewards: -1192 

action type: discard_down_to_3_cards - action 9
Learning step: -60.49937057495117
desired expected reward: -30.379865646362305



action possibilites: [-1] 
expected returns: [[39.91495]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0. 29.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0  16   0] 
sum of rewards: -31 

action type: gain_card_n - action 11
Learning step: -4.133739471435547
desired expected reward: 65.50277709960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.452951]
 [22.751259]
 [41.40137 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  0. 29.  3.] 
adversary cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
adversary victory points: 4
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -3.6487510204315186
desired expected reward: 36.26620101928711






Player: 1 
cards in hand: [ 0.  8.  0. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  0. 29.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  1.  0.  6.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
adversary victory points: -2
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  1.  0.  6.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
adversary victory points: -2
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  0. 29.  3.] 
cards in discard: [16. 11. 29.  8.  0.  3.  0. 14.  0.  8. 10.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 15.  1.  0.  6.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
adversary owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [ 0. 15.  1.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[54.15256 ]
 [48.651566]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 15.  1.  0.  6.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -4.782155513763428
desired expected reward: 36.61920928955078



action possibilites: [-1] 
expected returns: [[55.429623]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 6.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 21 
action values: 0 
buys: 0 
player value: 3 
card supply: [22. 28. 30. 25. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action 15.0
Learning step: -3.9905190467834473
desired expected reward: 43.76319122314453





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[46.627316]
 [50.122696]
 [45.158882]
 [49.0326  ]
 [42.713684]
 [41.025047]
 [47.86497 ]
 [53.12321 ]
 [50.275913]
 [55.786217]
 [51.549988]
 [45.01129 ]
 [46.44104 ]
 [49.247524]
 [42.56537 ]
 [48.886967]
 [55.000862]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14] -> size -> 21 
action values: 0 
buys: 1 
player value: 6 
card supply: [22. 28. 30. 25. 29.  8.  5.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1
Learning step: -4.5338592529296875
desired expected reward: 50.8957633972168



buy possibilites: [-1] 
expected returns: [[99.85869]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 6.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 6 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  3.  0. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -80.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -368.0 

action type: buy - action 6.0
Learning step: -18.204431533813477
desired expected reward: 22.82060432434082






Player: 1 
cards in hand: [ 3.  0.  3.  0. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 16.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3] -> size -> 21 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  2.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3.  0. 16.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [22.  3.  6.  0.  0.] 
adversary cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
adversary victory points: -3
player victory points: 5 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [22.  3.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[36.76643]
 [27.28434]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  6.  0.  0.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: buy - action -1
Learning step: -8.675697326660156
desired expected reward: 91.18299102783203





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[26.990318]
 [28.920668]
 [22.574282]
 [29.855764]
 [33.800552]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  6.  0.  0.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -88 

action type: take_action - action -1.0
Learning step: -5.5875678062438965
desired expected reward: 30.981565475463867



buy possibilites: [-1] 
expected returns: [[61.842693]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.  3.  6.  0.  0.] 
cards in discard: [ 6.  8. 16.  6.  8. 11. 14. 16.  3.  6. 15.  1.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  3. 10.  0.  3.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
adversary victory points: 5
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -80.   0.   0.   0. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -118.0 

action type: buy - action 0.0
Learning step: -5.85805606842041
desired expected reward: 21.132266998291016






Player: 1 
cards in hand: [ 0.  3. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 25. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 10.  0.  3.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 11.  0. 14.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  0. 14.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[94.49903]
 [88.30597]
 [74.03479]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3] -> size -> 23 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -6.199664115905762
desired expected reward: 55.643028259277344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[75.59675 ]
 [81.25297 ]
 [80.46946 ]
 [67.084175]
 [77.77732 ]
 [88.02774 ]
 [81.16613 ]
 [84.83148 ]
 [73.7757  ]
 [80.56842 ]
 [80.55736 ]
 [94.499344]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0. 14.  1.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 24. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29.  0.  3. 16.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3] -> size -> 23 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: take_action - action -1.0
Learning step: -7.516312599182129
desired expected reward: 81.08558654785156



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 29.  0.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  3. 16.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 24. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  1.  6. 14.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1. 11. 16. 14.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  3. 16. 14.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 24. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  1.  6. 14.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 16. 14.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 28. 30. 23. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  1.  6. 14.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3. 16. 14.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [21. 28. 30. 23. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3. 15.  1.  6. 14.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [ 3. 15.  1.  6. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[103.952255]
 [ 91.83058 ]
 [ 85.531715]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  6. 14.] 
cards in discard: [ 0. 11.  0. 14.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  8.  8.  8. 29.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -8.08509349822998
desired expected reward: 86.41424560546875



action possibilites: [-1] 
expected returns: [[45.376343]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 28. 30. 23. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action 14.0
Learning step: -7.086733341217041
desired expected reward: 67.06729125976562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.494965]
 [36.779987]
 [35.828342]
 [26.28623 ]
 [33.993534]
 [41.488472]
 [36.808113]
 [39.212303]
 [30.879894]
 [35.98958 ]
 [35.801937]
 [45.643192]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 28. 30. 23. 29.  8.  4.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -5.858042240142822
desired expected reward: 39.5182991027832



buy possibilites: [-1] 
expected returns: [[20.366041]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 15.  1.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
action values: 0 
buys: 0 
player value: 4 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [0. 8. 8.] 
adversary cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -110.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -399.0 

action type: buy - action 6.0
Learning step: -20.806076049804688
desired expected reward: 5.480155944824219






Player: 1 
cards in hand: [0. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  8  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 16.  0.  6.  6.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 16.  0.  6.  6.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  3.  0.  3.  0. 16.  3.  0.  3. 10.  0.  3.  3. 29. 11.  0.  3. 16.
 14.  8. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 16.  0.  6.  6.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 6. 16.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[34.325706]
 [29.99834 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  6.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -6.248950481414795
desired expected reward: 14.117090225219727





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[27.161293]
 [24.309483]
 [31.604805]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  6.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [21. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: take_action - action -1.0
Learning step: -7.0311198234558105
desired expected reward: 27.070842742919922



buy possibilites: [-1] 
expected returns: [[-9.872842]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 16.  0.  6.  6.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0.  0.  8.  0. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -110.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -149.0 

action type: buy - action 0.0
Learning step: -9.030203819274902
desired expected reward: 18.131092071533203






Player: 1 
cards in hand: [ 0.  0.  8.  0. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 22.  8.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  1.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 22.  8.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  8.  0. 14.] 
cards in discard: [8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  6. 22.  8.] 
adversary cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6. 22.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
expected returns: [[30.743126]
 [24.669056]
 [29.470291]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6. 22.  8.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -4.819169044494629
desired expected reward: -14.692010879516602



action possibilites: [-1] 
expected returns: [[44.353516]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 16.  8.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -59 

action type: LIBRARY: skip_action_card - action 0
Learning step: -3.629627227783203
desired expected reward: 29.922000885009766





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[39.04375 ]
 [40.376083]
 [34.767723]
 [44.039482]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 16.  8.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 23. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   60    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -59 

action type: take_action - action -1
Learning step: -4.276604175567627
desired expected reward: 40.07691192626953



buy possibilites: [-1] 
expected returns: [[48.5238]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 0.] 
cards in discard: [ 0. 11.  0. 14.  1.  6. 14.  3. 15.  1.  6.  0.  6. 16.  0.  6.  6.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [22. 16.  8.] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [16.  0.  8.  0.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   60    0    0    0    0    0    0    0
    8    0] 
sum of rewards: -40 

action type: buy - action 3.0
Learning step: -2.927018642425537
desired expected reward: 37.44906234741211






Player: 1 
cards in hand: [16.  0.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [ 8.  0.  0.  8.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 22.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  8.  0.  3.] 
cards in discard: [ 8.  0.  0.  8.  0. 14.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 22.  6.  6.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [ 6. 22.  6.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.] 
expected returns: [[43.335007]
 [31.158657]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 22.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1
Learning step: -7.084888458251953
desired expected reward: 41.43891143798828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[34.186394]
 [28.593035]
 [42.447544]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 22.  6.  6.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [11. 29. 29.  3.  0.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: take_action - action -1.0
Learning step: -6.550727844238281
desired expected reward: 32.2822380065918



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [11. 29. 29.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29.  3.  0.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 14. 15.  0.  1.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 


action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  8.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 14. 15.  0.  1.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  8.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 14. 15.  0.  1.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  3.  0.  8.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [19. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6. 14. 15.  0.  1.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.] 
adversary owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
adversary victory points: -3
player victory points: 7 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 6. 14. 15.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[25.255547]
 [17.323719]
 [19.310194]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14. 15.  0.  1.] 
cards in discard: [ 6. 22.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6
  0  3] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -108 

action type: buy - action -1.0
Learning step: -7.067450046539307
desired expected reward: 35.38009262084961



action possibilites: [-1] 
expected returns: [[19.360008]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 14.  1.] 
cards in discard: [ 6. 22.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action 15.0
Learning step: -4.8240556716918945
desired expected reward: 14.095437049865723





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 9.908269 ]
 [12.849058 ]
 [12.37204  ]
 [ 7.5198727]
 [ 6.9136   ]
 [11.020916 ]
 [15.967732 ]
 [18.065296 ]
 [14.468867 ]
 [ 8.878083 ]
 [10.513535 ]
 [12.448771 ]
 [ 7.689433 ]
 [12.373656 ]
 [18.774723 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  1.] 
cards in discard: [ 6. 22.  6.  6.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3] -> size -> 25 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 22. 29.  8.  3.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
adversary victory points: 7
player victory points: -3 

Reward from previous game state: 
[  -5    0   -3 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -88 

action type: take_action - action -1
Learning step: -5.09677267074585
desired expected reward: 14.263235092163086



buy possibilites: [-1] 
expected returns: [[18.349575]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 14.  1.] 
cards in discard: [ 6. 22.  6.  6.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6] -> size -> 26 
action values: 0 
buys: 0 
player value: 5 
card supply: [19. 28. 30. 22. 29.  8.  2.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  3.  3. 10.  3.] 
adversary cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5.    0.   -4. -110.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -399.0 

action type: buy - action 6.0
Learning step: -19.882814407348633
desired expected reward: -12.969217300415039






Player: 1 
cards in hand: [ 3.  3.  3. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 22. 29.  8.  2.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  0. 11.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6] -> size -> 26 
adversary victory points: -4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [19. 28. 30. 22. 29.  8.  2.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  0. 11.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6] -> size -> 26 
adversary victory points: -4
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3.  3. 10.  3.] 
cards in discard: [ 8.  0.  0.  8.  0. 14. 16.  0.  8.  0.  3. 11.  0. 29. 29.  3.  0.  8.
  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  2.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  8.  6.  0. 11.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6] -> size -> 26 
adversary victory points: -4
player victory points: 7 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [ 6.  8.  6.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
expected returns: [[ 1.2446713 ]
 [-1.1798413 ]
 [-0.02637267]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  8.  6.  0. 11.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  2.  6.  8.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -119 

action type: buy - action -1
Learning step: -6.866902828216553
desired expected reward: 11.482671737670898



action possibilites: [-1] 
expected returns: [[22.071411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 6. 0.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  2.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    9    0] 
sum of rewards: -90 

action type: gain_card_n - action 5
Learning step: -3.8994758129119873
desired expected reward: -5.97782039642334





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[14.055398]
 [11.068125]
 [20.812218]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 22. 29.  8.  2.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: -4 

Reward from previous game state: 
[  -5    0   -4 -110    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -99 

action type: take_action - action -1
Learning step: -5.707770824432373
desired expected reward: 16.36363983154297



buy possibilites: [-1] 
expected returns: [[4.1904426]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 6. 0.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0.  8.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
adversary victory points: 7
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -120.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -410.0 

action type: buy - action 6.0
Learning step: -20.95911979675293
desired expected reward: -9.89099407196045






Player: 1 
cards in hand: [ 3.  0.  8.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  3. 16.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3 11  0  0 14 29  3 29  3 10  3 16  8  0  8  0 16  0  3  8  3  3  8
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [8.] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 0. 16.  3.  3. 14.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 0. 16.  3.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[1.8386865]
 [1.3974099]
 [2.2926712]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 16.  3.  3. 14.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.667951583862305
desired expected reward: -1.4775090217590332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[1.4545815]
 [2.783287 ]
 [2.332015 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 16.  3.  3. 14.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [14.  3. 29.  0.  3.] 
adversary cards in discard: [8.] 
adversary owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.542521953582764
desired expected reward: -3.703841209411621



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [14.  3. 29.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 29.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 29.  0.  3.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [3. 8. 0. 1. 0.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.  0.
 16.  3.  3. 14.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.  0.
 16.  3.  3. 14.  8.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  0.  3.] 
cards in discard: [8.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [3. 0. 0.] 
adversary cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.  0.
 16.  3.  3. 14.  8.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[50.43013]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.  0.
 16.  3.  3. 14.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.] 
adversary owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[   -5     0    -5  -100     0     0     0     0     0     0     0     0
     0 -2400   100     0] 
sum of rewards: -2410 

action type: discard_down_to_3_cards - action 2
Learning step: -121.93275451660156
desired expected reward: -70.58406829833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[47.83634 ]
 [49.519638]
 [43.79644 ]
 [53.16578 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [ 6. 22.  6.  6.  0.  6. 15.  6. 14.  1. 11.  6. 11.  6.  8.  6.  0.  0.
 16.  3.  3. 14.  8.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [0. 0. 0. 8. 3.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.] 
adversary owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -6.927398204803467
desired expected reward: 43.50273132324219



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 8. 3.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [11  0  0 14 29 29  3 10  3  8  0  8  0 16  0  3  8  3  3  8  0  0] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  0.  6. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  0.  6. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  0.  6. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 6.  0.  6. 15. 16.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 15. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
expected returns: [[51.50526 ]
 [48.59954 ]
 [48.307144]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 15. 16.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 15 22  6 14  8  8  6  1  0  6 14  6  0  6  0
  3  6 11  6] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  8.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1.0
Learning step: -7.098669528961182
desired expected reward: 46.067108154296875



action possibilites: [-1] 
expected returns: [[15.465139]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
   16    0] 
sum of rewards: -74 

action type: gain_card_n - action 14
Learning step: -5.336543560028076
desired expected reward: 37.45143508911133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[12.447338]
 [10.020415]
 [15.466465]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.98809289932251
desired expected reward: 10.477046966552734



buy possibilites: [-1] 
expected returns: [[-6.1559277]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [15.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  0. 29.  8.  0.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   20.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -120.0 

action type: buy - action 0.0
Learning step: -6.760875225067139
desired expected reward: 5.686460018157959






Player: 1 
cards in hand: [ 3.  0. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14. 14.  0.  3.  1.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14. 14.  0.  3.  1.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 29.  8.  0.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14. 14.  0.  3.  1.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [14. 14.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 14.] 
expected returns: [[-20.977278]
 [-18.063944]
 [-18.063944]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 14.  0.  3.  1.] 
cards in discard: [15.  0. 16.  6.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8. 11.  0. 10.  3.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.617618083953857
desired expected reward: -11.77354621887207



action possibilites: [-1] 
expected returns: [[-7.0157824]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  3.  1.] 
cards in discard: [15.  0. 16.  6.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action 14.0
Learning step: -3.7606594562530518
desired expected reward: -21.704574584960938





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.3638315]
 [-5.993147 ]
 [-5.788273 ]
 [-4.4190993]
 [-4.1373606]
 [-5.7636967]
 [-5.1594605]
 [-4.8678346]
 [-5.5973244]
 [-5.04307  ]
 [-5.4889216]
 [-5.743257 ]
 [-4.587234 ]
 [-5.615855 ]
 [-3.740838 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  1.] 
cards in discard: [15.  0. 16.  6.  0.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 5 
card supply: [15. 28. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -90 

action type: take_action - action -1
Learning step: -4.264845371246338
desired expected reward: -11.280628204345703



buy possibilites: [-1] 
expected returns: [[5.7456074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  0.  3.  1.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 8. 11. 10.] 
adversary cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
adversary owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.     0.    -5.  -100.     0.     0.    20.     0.     0.     0.
    0.     0.     0.     0.     4.5    0. ] 
sum of rewards: -85.5 

action type: buy - action 1.0
Learning step: -3.8460662364959717
desired expected reward: -9.839211463928223






Player: 1 
cards in hand: [ 8. 11. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [11 14 29 29  3 10  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  0.  6. 16. 22.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  0.  6. 16. 22.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  0.  6. 16. 22.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
adversary victory points: -5
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 14.  3. 29.  0.  3.  0.  8.  3.  0.  3.  0. 29.  8.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6.  0.  6. 16. 22.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
adversary victory points: -5
player victory points: 5 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  6. 16. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 22.] 
expected returns: [[ 2.302645  ]
 [-0.56960106]
 [-1.6912857 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  6. 16. 22.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -5.786433696746826
desired expected reward: -0.04082632064819336





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 0.34094167]
 [-1.3585745 ]
 [ 3.2907093 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16. 22.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: take_action - action -1.0
Learning step: -5.597493648529053
desired expected reward: -3.294849157333374



buy possibilites: [-1] 
expected returns: [[11.322891]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  6. 16. 22.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 3.  8.  3.  3. 16.] 
adversary cards in discard: [] 
adversary owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0  0] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.    0.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -140.0 

action type: buy - action 0.0
Learning step: -6.762281894683838
desired expected reward: -6.421338081359863






Player: 1 
cards in hand: [ 3.  8.  3.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  3.  3. 16.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 29  3  3  8  8  0 16  0  3  8  3  3  8  0  0  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  1.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  1.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  1.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [11.  0.  1.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
adversary victory points: -5
player victory points: 4 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11.  0.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[4.070612 ]
 [4.0320272]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  6.  6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -5.474985599517822
desired expected reward: 5.84790563583374





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
expected returns: [[5.508465 ]
 [5.4088507]
 [5.4390984]
 [5.532654 ]
 [5.4705334]
 [5.517144 ]
 [5.808079 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  6.  6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  7.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: take_action - action -1.0
Learning step: -5.079121112823486
desired expected reward: -1.0085062980651855



buy possibilites: [-1] 
expected returns: [[-4.1341968]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  6.  6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [8. 3. 0. 8. 0.] 
adversary cards in discard: [0. 8. 3. 3.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -82 

action type: buy - action 11.0
Learning step: -4.466546535491943
desired expected reward: 1.0039935111999512






Player: 1 
cards in hand: [8. 3. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0 11] -> size -> 32 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [0. 8. 3. 3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0 11] -> size -> 32 
adversary victory points: -5
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 0. 8. 0.] 
cards in discard: [0. 8. 3. 3. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 6. 0. 8. 6.] 
adversary cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
adversary owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0 11] -> size -> 32 
adversary victory points: -5
player victory points: 4 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [3. 6. 0. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[7.330288 ]
 [5.8091965]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 8. 6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  0  3 11  0  6  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3
  6 11  6 15  0  1  0 11] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [29. 14.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -4.645293712615967
desired expected reward: -8.77949047088623



action possibilites: [-1] 
expected returns: [[30.204952]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [29. 14.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: trash_cards_n_from_hand - action 3
Learning step: -3.062424421310425
desired expected reward: 2.778294801712036





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[21.348156]
 [17.516285]
 [29.47633 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6.] 
cards in discard: [15.  0. 16.  6.  0.  6.  1. 14. 14.  0.  3.  1.  0.  6.  0.  6. 16. 22.
 11. 11.  0.  1.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [29. 14.  0.  0.  8.] 
adversary cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0.] 
adversary owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -4.446131706237793
desired expected reward: 25.758819580078125






Player: 1 
cards in hand: [29. 14.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 14.  8.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 14.  0.  0.  8.] 
cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1. 14.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  0.  8. 29.] 
cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [14 29 29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [0. 8. 3. 3. 0. 8. 3. 0. 8. 0. 0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [16.  0. 11.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [16.  0. 11.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.  8.] 
expected returns: [[2.208494 ]
 [3.4880192]
 [3.0291302]
 [3.6098735]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0. 11.  3.  8.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  0  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11
  6 15  0  1  0 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1.0
Learning step: -5.477756023406982
desired expected reward: 16.37331199645996



action possibilites: [-1] 
expected returns: [[-10.034722]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: trash_cards_n_from_hand - action 0
Learning step: -3.8248627185821533
desired expected reward: -0.843235969543457





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-9.689116]
 [-7.99566 ]
 [-9.982399]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 11.  3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [3. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -69 

action type: take_action - action -1
Learning step: -3.1554818153381348
desired expected reward: -13.190204620361328






Player: 1 
cards in hand: [3. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 11.  3.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 22. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 11.  3.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
adversary victory points: -4
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 6. 15.  0.  1.  0.] 
adversary cards in discard: [ 8. 16. 11.  3.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-5.1979446]
 [-4.0486283]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  0.  1.  0.] 
cards in discard: [ 8. 16. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1.0
Learning step: -4.55394172668457
desired expected reward: -14.536340713500977





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-1.5227289]
 [-1.7690406]
 [-1.9596299]
 [-1.3209263]
 [-1.6933978]
 [-1.6380358]
 [-1.6771762]
 [-1.5348469]
 [-1.8358076]
 [-1.8635342]
 [-1.791991 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  1.  0.] 
cards in discard: [ 8. 16. 11.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 27. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: take_action - action -1.0
Learning step: -4.730206489562988
desired expected reward: -9.885553359985352



buy possibilites: [-1] 
expected returns: [[-5.0960197]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15.  0.  1.  0.] 
cards in discard: [ 8. 16. 11.  3.  1.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [ 0. 29.  0.  0.  0.] 
adversary cards in discard: [3. 3. 0. 0. 0. 3.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5.    0.   -4.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -94.5 

action type: buy - action 1.0
Learning step: -4.751208782196045
desired expected reward: -6.520244598388672






Player: 1 
cards in hand: [ 0. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  0.  0.] 
cards in discard: [3. 3. 0. 0. 0. 3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14.  6.  6.  6. 16.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14.  6.  6.  6. 16.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [3. 3. 0. 0. 0. 3. 3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  9.  7.] 
adversary cards in hand: [14.  6.  6.  6. 16.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [14.  6.  6.  6. 16.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
adversary victory points: -4
player victory points: 5 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [14.  6.  6.  6. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
expected returns: [[-4.822206]
 [-3.435317]
 [-4.083246]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  6. 16.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 0. 3. 8. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -99 

action type: buy - action -1
Learning step: -4.787597179412842
desired expected reward: -9.883617401123047



action possibilites: [-1] 
expected returns: [[-6.769189]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 16.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action 14.0
Learning step: -3.9305408000946045
desired expected reward: -7.3658576011657715





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6. -1.] 
expected returns: [[-5.9578285]
 [-6.1757784]
 [-4.8009205]
 [-6.3317184]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 16.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 26. 30. 21. 29.  8.  1.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -79 

action type: take_action - action -1
Learning step: -3.7421765327453613
desired expected reward: -10.51136589050293



buy possibilites: [-1] 
expected returns: [[8.278272]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  6. 16.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.  8.  8.] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   20.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -390.0 

action type: buy - action 6.0
Learning step: -19.073692321777344
desired expected reward: -23.874614715576172






Player: 1 
cards in hand: [0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6. 11.  3.  0. 22.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
adversary victory points: -5
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [ 3.  3.  0.  0.  0.  3.  3. 22. 29.  0.  0.  0.  0.  8.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6. 11.  3.  0. 22.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
adversary victory points: -5
player victory points: 5 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  3.  0. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 22.] 
expected returns: [[-6.190505]
 [-7.048641]
 [-5.565466]]
Chosen action: 22 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0. 22.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -110 

action type: buy - action -1
Learning step: -6.054784297943115
desired expected reward: 2.223487377166748



action possibilites: [-1] 
expected returns: [[-6.7100096]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  3.  0.  8.  6. 11.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -70 

action type: LIBRARY: skip_action_card - action 1
Learning step: -3.329538345336914
desired expected reward: -9.621020317077637





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-5.7415953]
 [-6.664113 ]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  8.  6. 11.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [11. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5    0   -5 -100    0    0   40    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -70 

action type: take_action - action -1
Learning step: -3.3039562702178955
desired expected reward: -10.013965606689453



buy possibilites: [-1] 
expected returns: [[6.0955973]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  3.  0.  8.  6. 11.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [22. 14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [22.  3.  0.  0.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
adversary victory points: 5
player victory points: -5 

Reward from previous game state: 
[  -5.    0.   -5. -100.    0.    0.   40.  -30.    0.    0.    0.    0.
    0.    0.    0.    0.] 
sum of rewards: -100.0 

action type: buy - action 0.0
Learning step: -4.575769424438477
desired expected reward: -10.317364692687988






Player: 1 
cards in hand: [22.  3.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.  3.  0.  0.  8.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [29  3  8  8  0  0  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [3. 0. 6. 1. 1.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
adversary victory points: -5
player victory points: 5 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [22.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [3. 0. 6. 1. 1.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
adversary victory points: -5
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [22.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [3. 0. 6. 1. 1.] 
adversary cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
adversary victory points: -5
player victory points: 4 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 1. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-1.70245]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  3.  8. 29.  0.] 
adversary cards in discard: [ 8. 22.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: buy - action -1
Learning step: -5.343085289001465
desired expected reward: 0.7525119781494141





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-5.1716766]
 [-6.082966 ]
 [-5.59974  ]
 [-4.1438394]
 [-5.4891148]
 [-6.1588264]
 [-5.7369986]
 [-6.1365223]
 [-4.5285716]
 [-4.7656403]
 [-5.626399 ]
 [-3.9037352]
 [-5.3856416]
 [-4.3032455]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 26. 30. 21. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  3.  8. 29.  0.] 
adversary cards in discard: [ 8. 22.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -5 

Reward from previous game state: 
[ -5   0  -5 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -100 

action type: take_action - action -1.0
Learning step: -5.031945705413818
desired expected reward: -6.734395980834961



buy possibilites: [-1] 
expected returns: [[6.5968103]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 1. 1.] 
cards in discard: [ 8. 16. 11.  3.  1.  6. 15.  0.  1.  0.  6. 14.  6.  6.  6. 16.  0. 22.
 14.  6. 11.  3.  0.  8.  6. 11.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  3.  8. 29.  0.] 
adversary cards in discard: [ 8. 22.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5.   0.  -4. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -87.0 

action type: buy - action 3.0
Learning step: -3.9215848445892334
desired expected reward: -9.521327018737793






Player: 1 
cards in hand: [ 0.  3.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  8. 29.  0.] 
cards in discard: [ 8. 22.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  1. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
adversary victory points: -4
player victory points: 4 


action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 8.] 
cards in discard: [ 8. 22.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 1 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  1. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
adversary victory points: -4
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 8.] 
cards in discard: [ 8. 22.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [16.  1. 11.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
adversary victory points: -4
player victory points: 4 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [16.  1. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 11.] 
expected returns: [[-7.526868 ]
 [-7.2573624]
 [-7.9670677]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: buy - action -1
Learning step: -4.9406208992004395
desired expected reward: 1.6561894416809082





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
expected returns: [[-6.7848263]
 [-7.6896505]
 [-7.113083 ]
 [-7.1371574]
 [-7.7004194]
 [-7.5631   ]
 [-6.0018787]
 [-7.154828 ]
 [-6.887335 ]
 [-7.1484957]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 11.  0.  0.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [10. 26. 30. 20. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -4 

Reward from previous game state: 
[ -5   0  -4 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -89 

action type: take_action - action -1.0
Learning step: -4.255246639251709
desired expected reward: -11.348249435424805



buy possibilites: [-1] 
expected returns: [[-12.0306635]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1. 11.  0.  0.] 
cards in discard: [3.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 3. 0. 3. 3.] 
adversary cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
adversary owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
adversary victory points: 4
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -70.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -76.0 

action type: buy - action 3.0
Learning step: -3.7150356769561768
desired expected reward: -10.828120231628418






Player: 1 
cards in hand: [8. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 0. 3. 3.] 
cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  3  8  3  3  8  0  0  0  0  0  0  0  3 22] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8.  1.  6. 22.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
adversary victory points: -3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8.  1.  6. 22.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [ 8. 22.  0.  3. 29.  8.  0.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8.  1.  6. 22.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [ 0.  8.  1.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 22.] 
expected returns: [[14.283168]
 [12.517339]
 [10.00418 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8.  1.  6. 22.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -1.545640230178833
desired expected reward: -13.576303482055664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[10.496462]
 [11.656104]
 [11.334963]
 [12.710225]
 [11.391796]
 [13.459704]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  6. 22.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 26. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.7946949005126953
desired expected reward: 10.43543815612793



buy possibilites: [-1] 
expected returns: [[0.7665055]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8.  1.  6. 22.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0  18   0] 
sum of rewards: -30 

action type: buy - action 1.0
Learning step: -2.065558910369873
desired expected reward: 9.590543746948242






Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  0  0  0  3 22] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6. 11.  1.  6.  6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1] -> size -> 35 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6. 11.  1.  6.  6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1] -> size -> 35 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6. 11.  1.  6.  6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1] -> size -> 35 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 6. 11.  1.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-6.6811953]
 [-7.1083603]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  1.  6.  6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  6.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 29.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.5934081077575684
desired expected reward: -1.8269026279449463



action possibilites: [-1] 
expected returns: [[-8.059041]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 6. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 29.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0  -1   0   0  16   0] 
sum of rewards: -13 

action type: gain_card_n - action 3
Learning step: -0.5181547999382019
desired expected reward: -6.781626224517822





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-7.027734 ]
 [-7.2746544]
 [-7.521372 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 6. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16.] 
cards in deck: 18 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 8.  0.  0.  8. 29.] 
adversary cards in discard: [8. 0. 0. 0.] 
adversary owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.1606686115264893
desired expected reward: -9.219709396362305






Player: 1 
cards in hand: [ 8.  0.  0.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  0.  8. 29.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  0  0  3 22] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  0.  3. 16. 14.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  0.  3. 16. 14.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.] 
cards in discard: [8. 0. 0. 0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [8.] 
owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
action values: 0 
buys: 1 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 6.  0.  3. 16. 14.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [ 6.  0.  3. 16. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 14.] 
expected returns: [[-6.893423 ]
 [-6.282895 ]
 [-5.3184166]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 16. 14.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [ 0.  8. 22.  3.  8.] 
adversary cards in discard: [] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -2.162444591522217
desired expected reward: -9.683816909790039



action possibilites: [-1] 
expected returns: [[43.08489]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  0.  3. 16.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [22.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action 14.0
Learning step: -0.15867887437343597
desired expected reward: -5.596902847290039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[46.27458 ]
 [46.41848 ]
 [46.38861 ]
 [46.765293]
 [46.48512 ]
 [47.135197]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  8.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [22.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -2.5061123371124268
desired expected reward: 40.57877731323242



buy possibilites: [-1] 
expected returns: [[-6.991543]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  0.  3. 16.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 3. 8.] 
adversary cards in discard: [22.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0  -2   0   0  18   0] 
sum of rewards: -12 

action type: buy - action 10.0
Learning step: -3.081566572189331
desired expected reward: 43.403568267822266






Player: 1 
cards in hand: [0. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [22.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 37 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [22.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  3 22] -> size -> 10 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 37 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [22.  8.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [8. 6. 0. 0. 6.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 37 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [8. 6. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-7.425475 ]
 [-7.3424597]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 6. 0. 0. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  0  6 14  6  0  6  0  3  6 11  6
 15  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  0.] 
adversary cards in discard: [22.  8.  0.  0.  3.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.216552495956421
desired expected reward: -9.20809555053711



action possibilites: [-1] 
expected returns: [[1.7302806]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  0.] 
adversary cards in discard: [22.  8.  0.  0.  3.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: trash_cards_n_from_hand - action 1
Learning step: -0.996675968170166
desired expected reward: -8.284530639648438





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[2.4091632]
 [2.7645962]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10] -> size -> 36 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 9. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  0.] 
adversary cards in discard: [22.  8.  0.  0.  3.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.4282678365707397
desired expected reward: 0.3020128011703491



buy possibilites: [-1] 
expected returns: [[-7.2075043]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 6.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 8.  0.  8. 29.  0.] 
adversary cards in discard: [22.  8.  0.  0.  3.  8.] 
adversary owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.  20. -30.   0.   0.   0.  -2.   0.   0.
   0.   0.] 
sum of rewards: -60.0 

action type: buy - action 0.0
Learning step: -3.2826268672943115
desired expected reward: -0.8734726905822754






Player: 1 
cards in hand: [ 8.  0.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 29.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  8. 29.  0.] 
cards in discard: [22.  8.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [29  8  8  8  8  0  0  0  3 22  0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 6. 15.  3.  3.  3.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0.] 
cards in discard: [22.  8.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 6. 15.  3.  3.  3.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0.] 
cards in discard: [22.  8.  0.  0.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 6. 15.  3.  3.  3.] 
adversary cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 6. 15.  3.  3.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[-8.746005]
 [-9.45194 ]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15.  3.  3.  3.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.244269371032715
desired expected reward: -9.451773643493652



action possibilites: [-1] 
expected returns: [[-6.5395317]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action 15.0
Learning step: -1.0745426416397095
desired expected reward: -10.526480674743652





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.152439 ]
 [-6.7109585]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 8. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.2176716327667236
desired expected reward: -7.757203102111816



buy possibilites: [-1] 
expected returns: [[-6.223074]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 3. 3.] 
cards in discard: [ 3. 16.  1. 11.  0.  0.  1.  0.  8.  1.  6. 22. 16. 11.  6.  1.  6.  6.
 10. 14.  6.  0.  3. 16.  0.  8.  6.  0.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20 -30   0   0   0  -3   0   0   0   0] 
sum of rewards: -61 

action type: buy - action 0.0
Learning step: -2.882397413253784
desired expected reward: -9.03483772277832






Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  6.  1. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  8  0  0  3 22  0] -> size -> 9 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 25. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  6.  1. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  8  0  0  3 22  0  1] -> size -> 10 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 3.  6.  1. 11. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 3.  6.  1. 11. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 14.] 
expected returns: [[-7.3725758]
 [-7.6262236]
 [-5.438224 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6.  1. 11. 14.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 22.  8.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0  1] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.2418038845062256
desired expected reward: -8.46487808227539





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.2526913]
 [-6.687729 ]
 [-7.3725758]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6.  1. 11. 14.] 
cards in discard: [] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [ 1. 22.  8.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  8  8  0  0  3 22  0  1] -> size -> 10 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.183598041534424
desired expected reward: -9.556173324584961



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 1. 22.  8.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 22.  8.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1. 22.  8.  8.  8.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  8  8  0  0  3 22  0  1] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 3 0 1] -> size -> 7 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 3 0 1] -> size -> 7 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 7. 24. 30. 19. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0 3 0 1 3] -> size -> 8 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [10.  0.  6.  0.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
adversary victory points: -3
player victory points: 2 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [10.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[1.334373 ]
 [0.5651653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3.  6.  1. 11. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [8 8 0 0 3 0 1 3] -> size -> 8 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: buy - action -1.0
Learning step: -2.53406023979187
desired expected reward: -9.906635284423828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-0.8060031 ]
 [-0.8037559 ]
 [-0.63484573]
 [-0.42149997]
 [-0.5930928 ]
 [ 0.16503477]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3.  6.  1. 11. 14.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  7.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [8 8 0 0 3 0 1 3] -> size -> 8 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -58 

action type: take_action - action -1.0
Learning step: -2.924330234527588
desired expected reward: -2.6666157245635986



buy possibilites: [-1] 
expected returns: [[-9.410342]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  6.  0.  0.] 
cards in discard: [ 3.  6.  1. 11. 14. 10.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [3. 8. 1.] 
adversary owned cards: [8 8 0 0 3 0 1 3] -> size -> 8 
adversary victory points: 2
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -50   0   0   0   0   0   0   0  -4   0   0  18   0] 
sum of rewards: -44 

action type: buy - action 10.0
Learning step: -2.221930980682373
desired expected reward: -6.0179667472839355






Player: 1 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 3 0 1 3] -> size -> 8 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [11. 16.  0. 15.  8.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 39 
adversary victory points: -3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 1 3] -> size -> 5 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [11. 16.  0. 15.  8.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 39 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [3. 8. 1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 1 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [11. 16.  0. 15.  8.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 39 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [11. 16.  0. 15.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 16. 15.  8.] 
expected returns: [[-7.7817984]
 [-7.974594 ]
 [-6.8451157]
 [-6.6879883]
 [-7.6076765]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  0. 15.  8.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  0  6  0  3  6 11  6 15
  0  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [3. 0. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 1 3] -> size -> 5 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.0953590869903564
desired expected reward: -11.505701065063477



action possibilites: [-1] 
expected returns: [[-8.384773]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 16.  8.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 38 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [3. 0. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 1 3] -> size -> 5 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action 15.0
Learning step: -1.2542580366134644
desired expected reward: -7.942246437072754





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-7.6424494]
 [-8.585548 ]
 [-7.9622   ]
 [-8.799859 ]
 [-7.9873657]
 [-8.383804 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  6.  8.  7.] 
adversary cards in hand: [3. 0. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 1 3] -> size -> 5 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.1657297611236572
desired expected reward: -9.55050277709961



buy possibilites: [-1] 
expected returns: [[-7.7817984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 16.  8.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10 10] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  5.  8.  7.] 
adversary cards in hand: [3. 0. 8. 1. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 1 3] -> size -> 5 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0  -4   0   0  18   0] 
sum of rewards: -14 

action type: buy - action 10.0
Learning step: -0.475722074508667
desired expected reward: -8.463088989257812






Player: 1 
cards in hand: [3. 0. 8. 1. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 1. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 1 3] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  5.  8.  7.] 
adversary cards in hand: [ 0.  1.  6.  3. 16.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10 10] -> size -> 39 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 1 3] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  5.  8.  7.] 
adversary cards in hand: [ 0.  1.  6.  3. 16.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10 10] -> size -> 39 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 1. 8.] 
cards in discard: [10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  1  3 10] -> size -> 6 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 0.  1.  6.  3. 16.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.] 
adversary owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10 10] -> size -> 39 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  6.  3. 16.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-7.7817984]
 [-6.8451157]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  6.  3. 16.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11  1 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0
  1  0 11  1  6  0  3  3  1 16 10  0  0 10 10] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 24. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 8.  0.  1. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  1  3 10] -> size -> 6 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1
Learning step: -2.175353765487671
desired expected reward: -9.957152366638184



action possibilites: [-1] 
expected returns: [[-7.746125]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 8.  0.  1. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  1  3 10] -> size -> 6 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0  -4   0   0   9   0] 
sum of rewards: -23 

action type: gain_card_n - action 1
Learning step: -0.9695577621459961
desired expected reward: -8.064157485961914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.4054766]
 [-7.767913 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1.] 
cards in deck: 18 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 8.  0.  1. 10.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 8  8  0  1  3 10] -> size -> 6 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -28 

action type: take_action - action -1
Learning step: -1.1719856262207031
desired expected reward: -8.918110847473145






Player: 1 
cards in hand: [ 8.  0.  1. 10.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0.  1. 10.  8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8  8  0  1  3 10] -> size -> 6 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [14.  8.  6.  1.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [14.  8.  6.  1.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 3] -> size -> 3 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [14.  8.  6.  1.  0.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
adversary victory points: -3
player victory points: 1 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [14.  8.  6.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.  8.] 
expected returns: [[-7.7817984]
 [-5.5584393]
 [-7.6076765]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  8.  6.  1.  0.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: buy - action -1.0
Learning step: -2.168381929397583
desired expected reward: -9.936294555664062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-6.4054766]
 [-7.5551167]
 [-6.9365816]
 [-7.974594 ]
 [-6.9770813]
 [-7.7817984]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  6.  1.  0.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 7. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -48 

action type: take_action - action -1.0
Learning step: -2.174323081970215
desired expected reward: -9.956121444702148



buy possibilites: [-1] 
expected returns: [[-7.7817984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  8.  6.  1.  0.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [ 6. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [8. 8. 3.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 3] -> size -> 3 
adversary victory points: 1
player victory points: -3 

Reward from previous game state: 
[ -5.   0.  -3. -40.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -83.0 

action type: buy - action 0.0
Learning step: -4.00481653213501
desired expected reward: -10.410293579101562






Player: 1 
cards in hand: [8. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 3] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 1.  6.  6. 11.  3.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
adversary victory points: -3
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 6. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 1.  6.  6. 11.  3.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
adversary victory points: -3
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8] -> size -> 2 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 6. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 1.  6.  6. 11.  3.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
adversary victory points: -3
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [ 1.  6.  6. 11.  3.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
adversary victory points: -3
player victory points: 0 





         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 1.  6.  6. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[-7.7817984]
 [-7.974594 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6.  6. 11.  3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  4.  8.  7.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1
Learning step: -1.688146948814392
desired expected reward: -9.469944953918457



action possibilites: [-1] 
expected returns: [[-8.265354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 6. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0  -6   0   0   9   0] 
sum of rewards: -15 

action type: gain_card_n - action 7
Learning step: -0.648917019367218
desired expected reward: -6.172385215759277





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-6.589177]
 [-7.229165]
 [-8.265355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 6. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10.] 
cards in deck: 8 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0] -> size -> 3 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -18 

action type: take_action - action -1
Learning step: -0.6521801352500916
desired expected reward: -8.917533874511719






Player: 1 
cards in hand: [8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  6.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
adversary victory points: -3
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0] -> size -> 3 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 5. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  6.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
adversary victory points: -3
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 4. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [ 0.  3.  3. 16.  6.] 
adversary cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.] 
adversary owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
adversary victory points: -3
player victory points: 0 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  3. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
expected returns: [[-7.89917  ]
 [-7.3846264]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 16.  6.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22  6 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1
  0 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 18. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -38 

action type: buy - action -1.0
Learning step: -1.6586151123046875
desired expected reward: -9.923969268798828



action possibilites: [-1] 
expected returns: [[-8.265354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0  -6   0   0   4   0] 
sum of rewards: 2 

action type: gain_card_n - action 1
Learning step: -0.5647141337394714
desired expected reward: 9.010159492492676





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.589177]
 [-8.265355]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3.] 
cards in discard: [ 3.  6.  1. 11. 14. 10. 10.  0.  6.  0.  0. 10. 15. 11. 16.  8.  1. 16.
  0.  6.  3.  0. 14.  8.  6.  1.  0. 10. 11.  1.  6.  6.  3.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 4. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 8. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: 0.44634953141212463
desired expected reward: -7.819004535675049






Player: 1 
cards in hand: [0. 8. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 4. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [14.  1.  1.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 4. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [14.  1.  1.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8. 8. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [14.  1.  1.  6. 22.] 
adversary cards in discard: [] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [14.  1.  1.  6. 22.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 22.] 
expected returns: [[-12.030048]
 [ -9.767692]
 [ -8.891796]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  1.  1.  6. 22.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 0. 0. 0. 8.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -0.6154180765151978
desired expected reward: -8.880772590637207



action possibilites: [-1] 
expected returns: [[-12.062471]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  1.  6. 22.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action 14.0
Learning step: 0.4144044518470764
desired expected reward: -9.301795959472656





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-10.838587 ]
 [-12.088358 ]
 [-10.193701 ]
 [-11.332495 ]
 [ -9.212013 ]
 [-11.256221 ]
 [-12.512646 ]
 [-13.5986595]
 [-12.095617 ]
 [ -9.8826   ]
 [-10.095215 ]
 [-11.384782 ]
 [ -8.802918 ]
 [-11.005067 ]
 [-12.039124 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  1.  6. 22.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 6 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [0. 0. 8.] 
adversary cards in discard: [8. 0.] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: 4 

action type: take_action - action -1
Learning step: 0.554149329662323
desired expected reward: -11.508321762084961






Player: 1 
cards in hand: [0. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8.] 
cards in discard: [8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [6. 8. 1. 0. 8.] 
adversary cards in discard: [14.  1.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [6. 8. 1. 0. 8.] 
adversary cards in discard: [14.  1.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [8. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [8.] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [6. 8. 1. 0. 8.] 
adversary cards in discard: [14.  1.  1.  6. 22.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
adversary victory points: -1
player victory points: 0 





         -------------------- Turn: 61 -------------------- 
Player: 0 
cards in hand: [6. 8. 1. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
expected returns: [[-12.71502 ]
 [-12.359342]
 [-12.359342]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 1. 0. 8.] 
cards in discard: [14.  1.  1.  6. 22.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  8  6  1  6 14  6  6  0  3  6 11  6 15  0  1  0
 11  1  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -16 

action type: buy - action -1.0
Learning step: -0.45352980494499207
desired expected reward: -12.49265193939209



action possibilites: [-1] 
expected returns: [[-9.004878]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0.] 
cards in discard: [14.  1.  1.  6. 22.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 39 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 5
Learning step: 1.033309817314148
desired expected reward: -8.685078620910645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-7.552747 ]
 [-8.415519 ]
 [-7.9852457]
 [-8.688795 ]
 [-7.993717 ]
 [-8.383026 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [14.  1.  1.  6. 22.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  3.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 1.016566276550293
desired expected reward: -7.988311767578125



buy possibilites: [-1] 
expected returns: [[-9.742491]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0.] 
cards in discard: [14.  1.  1.  6. 22. 10.] 
cards in deck: 31 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0] -> size -> 4 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0 -5  0  0 18  0] 
sum of rewards: 28 

action type: buy - action 10.0
Learning step: 1.5804798603057861
desired expected reward: -6.413237571716309






Player: 1 
cards in hand: [8. 8. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10.  3. 11.  6.  3.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0] -> size -> 4 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 3. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10.  3. 11.  6.  3.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 0. 0.] 
cards in discard: [0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 2. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10.  3. 11.  6.  3.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
adversary victory points: 0
player victory points: 0 





         -------------------- Turn: 62 -------------------- 
Player: 0 
cards in hand: [10.  3. 11.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[ -9.538593]
 [-10.629875]
 [-10.741898]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 11.  6.  3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: -0.009347820654511452
desired expected reward: -9.751838684082031



action possibilites: [-1. 11.] 
expected returns: [[-4.839052]
 [-5.717582]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 11.  6.  3.  3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10] -> size -> 40 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 17. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 0 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 10.0
Learning step: 1.1993924379348755
desired expected reward: -10.072233200073242



action possibilites: [-1.] 
expected returns: [[-8.642493]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 40  0  0  0  0 -6  0  0  4  0] 
sum of rewards: 44 

action type: gain_card_n - action 2
Learning step: 2.2845847606658936
desired expected reward: -3.2962305545806885





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.7324324]
 [-8.642493 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [10. 11.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 1 
buys: 1 
player value: 0 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 46 

action type: take_action - action -1.0
Learning step: 2.5593793392181396
desired expected reward: -6.083113670349121






Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [15. 11.  0.  3. 10.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [15. 11.  0.  3. 10.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
adversary victory points: 1
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 63 -------------------- 
Player: 0 
cards in hand: [15. 11.  0.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 10.] 
expected returns: [[-8.642493 ]
 [-7.1898775]
 [-8.701454 ]
 [-7.4947853]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  0.  3. 10.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: buy - action -1.0
Learning step: 0.5521541833877563
desired expected reward: -8.090338706970215





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.7324324]
 [-8.642493 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  0.  3. 10.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 1 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 0. 0. 8. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0] -> size -> 5 
adversary victory points: 0
player victory points: 1 

Reward from previous game state: 
[-5  0  1 10  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: 6 

action type: take_action - action -1.0
Learning step: 0.5593792796134949
desired expected reward: -8.083113670349121



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [8. 0. 0. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10. 16.  3.  6.  6.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
adversary victory points: 1
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0] -> size -> 5 
action values: 0 
buys: 1 
player value: 3 
card supply: [ 2. 23. 30. 16. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10. 16.  3.  6.  6.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
adversary victory points: 1
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 8. 0.] 
cards in discard: [3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [8 8 0 0 0 3] -> size -> 6 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 2. 23. 30. 15. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [10. 16.  3.  6.  6.] 
adversary cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.] 
adversary owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
adversary victory points: 1
player victory points: 1 





         -------------------- Turn: 64 -------------------- 
Player: 0 
cards in hand: [10. 16.  3.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 16.] 
expected returns: [[-8.642493 ]
 [-7.4947853]
 [-7.2605457]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  3.  6.  6.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 15. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -4 

action type: buy - action -1.0
Learning step: 0.056766510009765625
desired expected reward: -8.585726737976074



action possibilites: [-1. 16. 16.] 
expected returns: [[-8.642493 ]
 [-7.2605457]
 [-7.2605457]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  6. 16.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 3 16  3 11 16 22 14  8  1  6 14  6  6  0  3  6 11  6 15  0  1  0 11  1
  6  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3] -> size -> 41 
action values: 2 
buys: 0 
player value: 0 
card supply: [ 2. 23. 30. 15. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 1 

Reward from previous game state: 
[-5  0  1  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 16 

action type: take_action - action 10.0
Learning step: 1.00111985206604
desired expected reward: -6.493666648864746



action possibilites: [-1. 16.] 
expected returns: [[-6.1934834]
 [-5.9602413]]
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 16.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 16.] 
owned cards: [ 3 16  3 11 16 22 14  8  1 14  6  6  0  3  6 11  6 15  0  1  0 11  1  6
  0  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3  0] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 15. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[ -5   0   2  10   0   0  40 -30   0   0   0  -6   0   0   0   0] 
sum of rewards: 11 

action type: gain_card_n - action 0
Learning step: 0.7444104552268982
desired expected reward: -5.877842903137207



action possibilites: [-1] 
expected returns: [[-7.991929]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 16. 16.] 
owned cards: [ 3 16  3 11 16 22 14  8  1 14  6  0  3  6 11  6 15  0  1  0 11  1  6  0
  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3  0  3] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 1. 23. 30. 14. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 60  0  0  0  0 -6  0  0  4  0] 
sum of rewards: 87 

action type: gain_card_n - action 1
Learning step: 4.780301570892334
desired expected reward: -7.422093868255615





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-7.4351997]
 [-7.9320126]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.  0.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 16. 16.] 
owned cards: [ 3 16  3 11 16 22 14  8  1 14  6  0  3  6 11  6 15  0  1  0 11  1  6  0
  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3  0  3] -> size -> 41 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 1. 23. 30. 14. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[-5  0  4 30  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 89 

action type: take_action - action -1
Learning step: 4.6767730712890625
desired expected reward: -3.3151559829711914



Player 0 won the game! 



Player 0 bought cards:
Copper: 12 
Silver: 5 
Gold: 0 
Estate: 3 
Duchy: 0 
Province: 0 
Curse: 10 

Remodel: 1 
Workshop: 2 
Chapel: 4 
Witch: 1 
Poacher: 0 
Militia: 0 
Market: 0 
Village: 4 
Library: 1 
Moneylender: 1 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [3.] 
cards in discard: [14.  1.  1.  6. 22. 10.  8.  1.  0.  3. 10. 11.  3.  6.  3.  3. 15. 11.
  0.  3. 10.  0.  3.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [10. 16. 16.] 
owned cards: [ 3 16  3 11 16 22 14  8  1 14  6  0  3  6 11  6 15  0  1  0 11  1  6  0
  3  3  1 16 10  0  0 10 10  1  0 10  3 10  3  0  3  0] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 0. 23. 30. 14. 29.  8.  0.  5.  6.  0.  9.  6.  6. 10.  2.  8.  7.] 
adversary cards in hand: [8. 8. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [8 8 0 0 0 3] -> size -> 6 
adversary victory points: 1
player victory points: 4 

Reward from previous game state: 
[ -5 500   4  30   0   0  60 -30   0   0   0  -7   0   0   0   0] 
sum of rewards: 552 

action type: buy - action 0.0
Learning step: 27.971759796142578
desired expected reward: 20.53656578063965



