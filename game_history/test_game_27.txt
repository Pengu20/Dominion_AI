 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[21.038118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[  -5 -500    0    0    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -505 

action type: buy - action -1.0
Learning step: -15.410021781921387
desired expected reward: -6.742580413818359





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[18.988728]
 [21.03604 ]
 [19.868612]
 [16.216093]
 [19.49233 ]
 [22.885546]
 [21.99361 ]
 [22.95227 ]
 [19.217209]
 [20.822418]
 [21.264519]
 [21.41941 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 21.474950790405273



buy possibilites: [-1] 
expected returns: [[24.375431]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [3. 0. 3. 0. 3. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 27 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 22.952266693115234






         -------------------- Turn: 2 -------------------- 
Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 29. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [3. 0. 3. 0. 3. 0. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 0 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [29.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[25.181902]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 24.375431060791016





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.456299]
 [25.503609]
 [24.336184]
 [20.683666]
 [27.344357]
 [26.457415]
 [25.28999 ]
 [25.886982]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29] -> size -> 11 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10. 10. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 25.438650131225586



buy possibilites: [-1] 
expected returns: [[26.93]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [29.  0.  0.  0.  0.  3. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 0. 3. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 13 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 27.344358444213867






         -------------------- Turn: 3 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9. 10. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[27.231619]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.93000030517578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[25.044891]
 [25.936829]
 [22.234312]
 [28.087101]
 [27.50886 ]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11] -> size -> 12 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  9. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.536649703979492



buy possibilites: [-1] 
expected returns: [[26.921885]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 3.] 
adversary cards in discard: [8. 3. 0. 3. 0. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0] 
sum of rewards: 3 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 28.087100982666016






         -------------------- Turn: 4 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 3. 0. 3. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 28. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 3.] 
cards in discard: [8. 3. 0. 3. 0. 3. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [11. 29.  0.  0.  0.] 
adversary cards in discard: [8. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [11. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[25.941954]
 [27.41213 ]
 [27.478853]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  0.  0.  0.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.921884536743164



action possibilites: [-1. 11.] 
expected returns: [[31.066484]
 [32.53666 ]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0.  0.  0.] 
cards in discard: [8. 3. 3. 0. 0. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8] -> size -> 13 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10. 10. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 27.588594436645508



action possibilites: [-1] 
expected returns: [[28.78012]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 32.985374450683594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[27.072363]
 [29.147694]
 [27.964298]
 [25.445177]
 [24.26178 ]
 [27.582874]
 [31.006508]
 [30.11457 ]
 [32.700413]
 [31.07323 ]
 [27.30399 ]
 [26.847624]
 [28.931175]
 [24.772291]
 [29.37932 ]
 [29.53633 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10] -> size -> 14 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8. 10.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.780120849609375



buy possibilites: [-1] 
expected returns: [[32.512524]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0.] 
cards in discard: [ 8.  3.  3.  0.  0.  3. 10. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 32.70041275024414






         -------------------- Turn: 5 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 3 3 8 3] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 27. 30.  8. 10. 10.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [16.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 3. 29.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 3. 29.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[29.445068]
 [30.98197 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.51252365112305



action possibilites: [-1.] 
expected returns: [[34.54568]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
action values: 1 
buys: 0 
player value: 1 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 31.188377380371094





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[32.50653 ]
 [34.58186 ]
 [33.398464]
 [29.695951]
 [33.01704 ]
 [36.44067 ]
 [35.54874 ]
 [36.507397]
 [32.738163]
 [34.36534 ]
 [34.813488]
 [34.970497]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  9. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 34.54568099975586



buy possibilites: [-1] 
expected returns: [[33.841656]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [29.] 
cards in deck: 9 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [16.  8.  0.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 36.50739669799805






         -------------------- Turn: 6 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  8.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  8.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16] -> size -> 15 
action values: 0 
buys: 1 
player value: 2 
card supply: [30. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 0.] 
cards in discard: [16.  8.  0.  0.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0] -> size -> 16 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 10. 25.  0.  0.] 
adversary cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
adversary victory points: 3
player victory points: 6 





Player: 0 
cards in hand: [ 0. 10. 25.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[29.628262]
 [29.047956]
 [32.662685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.  0.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8. 10.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0] -> size -> 16 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 33.84165573120117



action possibilites: [-1] 
expected returns: [[36.8563]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  0. 11.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.7034912109375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[34.727654]
 [36.745964]
 [35.5951  ]
 [31.994236]
 [35.224102]
 [38.553734]
 [37.686283]
 [38.618496]
 [34.952866]
 [36.535416]
 [36.971172]
 [37.12388 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 11.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29] -> size -> 16 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  8. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.856300354003906



buy possibilites: [-1] 
expected returns: [[32.9872]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  0. 11.  0.] 
cards in discard: [29. 29.  3.  0.  0.  0.  3. 29.] 
cards in deck: 2 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 0. 3. 3. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6] -> size -> 17 
adversary victory points: 6
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 32  0] 
sum of rewards: 47 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 38.61849594116211






         -------------------- Turn: 7 -------------------- 
Player: 1 
cards in hand: [3. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 1 
card supply: [29. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 3. 3.] 
cards in discard: [6. 0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [25.  3.  0.  8.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [25.  3.  0.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8.] 
expected returns: [[30.470743]
 [33.568977]
 [31.025234]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  0.  8.  3.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  9.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.98720169067383



action possibilites: [-1] 
expected returns: [[31.014101]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.6939811706543





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.061338]
 [29.953272]
 [26.250757]
 [32.103546]
 [31.525303]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  3. 29.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29] -> size -> 17 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  8.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.014101028442383



buy possibilites: [-1] 
expected returns: [[30.967148]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8.  3. 29.  0.] 
cards in discard: [8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 3. 3. 0. 8.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.103546142578125






         -------------------- Turn: 8 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 8.] 
cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [6. 0. 3. 0. 3. 3. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0. 11. 29.  0.  0.] 
adversary cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 11. 29.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[34.7325  ]
 [36.16235 ]
 [36.227116]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 29.  0.  0.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 30.967147827148438



action possibilites: [-1. 11. 29.] 
expected returns: [[33.362026]
 [34.791874]
 [34.85664 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 29.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 36.32423400878906



action possibilites: [-1. 11. 10.] 
expected returns: [[38.61418 ]
 [40.044033]
 [38.025715]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  0. 10.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8] -> size -> 18 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  9. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.85663986206055



action possibilites: [-1] 
expected returns: [[44.20029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  9  0] 
sum of rewards: 64 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 41.18896484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[42.22804 ]
 [44.246353]
 [43.095486]
 [40.64549 ]
 [39.49462 ]
 [42.724487]
 [46.05412 ]
 [45.18667 ]
 [47.701435]
 [46.11888 ]
 [42.453255]
 [42.009384]
 [44.035805]
 [39.99107 ]
 [44.47156 ]
 [44.624264]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0. 10.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  9.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 44.20029067993164



buy possibilites: [-1] 
expected returns: [[42.94884]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 10.] 
cards in discard: [ 8. 25.  3.  0.  8.  3. 29.  0. 10. 25.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 29. 11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 0.  0.  0. 16.  0.] 
adversary cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0 50  0] 
sum of rewards: 105 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 47.70143508911133






         -------------------- Turn: 9 -------------------- 
Player: 1 
cards in hand: [ 0.  0.  0. 16.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  0.] 
cards in discard: [6. 0. 3. 0. 3. 3. 3. 6. 8. 3. 3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29. 29.  3.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
adversary victory points: 3
player victory points: 4 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 29.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29.] 
expected returns: [[32.682037]
 [34.218937]
 [34.218937]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  3.  0.  0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.9488410949707



action possibilites: [-1. 29.] 
expected returns: [[36.514805]
 [38.05171 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 14 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 1 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.30475997924805



action possibilites: [-1.] 
expected returns: [[39.552692]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
action values: 1 
buys: 0 
player value: 2 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 38.05170440673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[37.623737]
 [39.613834]
 [38.478992]
 [36.06348 ]
 [34.928646]
 [38.113167]
 [41.396175]
 [40.54092 ]
 [43.020443]
 [41.46019 ]
 [37.84583 ]
 [37.40817 ]
 [39.406082]
 [35.41807 ]
 [39.83592 ]
 [39.98643 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25] -> size -> 20 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  8.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 39.55269241333008



buy possibilites: [-1] 
expected returns: [[42.314487]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0. 3.] 
cards in discard: [25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [ 6. 16.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 50  0] 
sum of rewards: 85 

action type: buy - action 25.0
Learning step: 0
desired expected reward: 43.020442962646484






         -------------------- Turn: 10 -------------------- 
Player: 1 
cards in hand: [ 6. 16.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 16.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  6  0  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 30. 30. 27. 30.  8.  8.  9.  9.  7.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0] -> size -> 17 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  7.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  7.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [0. 8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8] -> size -> 18 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [29.  0. 25.  0.  8.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [29.  0. 25.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.  8.] 
expected returns: [[40.234753]
 [41.729374]
 [43.31192 ]
 [40.797157]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 25.  0.  8.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  8.  9.  9.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8] -> size -> 18 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 42.31448745727539



action possibilites: [-1] 
expected returns: [[37.150593]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  8.  0.  3.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  9.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 43.36305618286133





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[35.278862]
 [37.21993 ]
 [36.113113]
 [32.65005 ]
 [38.9585  ]
 [38.124245]
 [37.017437]
 [37.583344]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8.  0.  3.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25] -> size -> 21 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  9.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.15059280395508



buy possibilites: [-1] 
expected returns: [[35.118305]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  0.  0.  8.  0.  3.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [3. 8. 3. 0. 3.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.958499908447266






         -------------------- Turn: 11 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 1 
card supply: [27. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 3. 0. 3.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [10.  0. 10.  8. 11.] 
adversary cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11] -> size -> 22 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [10.  0. 10.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 11.] 
expected returns: [[37.448994]
 [36.868645]
 [36.868645]
 [38.00348 ]
 [38.858738]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8. 11.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  8. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.11830520629883



action possibilites: [-1] 
expected returns: [[30.473774]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 39.65862274169922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[28.274797]
 [25.694818]
 [30.536469]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 10.  8.] 
cards in discard: [25. 29. 29.  3.  0.  0.  0.  3. 11. 25. 29.  0.  0.  8.  0.  3. 10.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 0.] 
adversary cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.473773956298828






         -------------------- Turn: 12 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0] -> size -> 20 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  6.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 0.] 
cards in discard: [ 0.  8. 16.  0.  0.  0.  6.  0.  3.  8.  3.  0.  3.  8.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29.  0.  3. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
adversary victory points: 3
player victory points: 4 





Player: 0 
cards in hand: [ 0. 29.  0.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[31.87628 ]
 [33.364338]
 [34.991524]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  7.  9.  8.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8] -> size -> 21 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.536466598510742



action possibilites: [-1] 
expected returns: [[36.324104]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  8.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.06542205810547





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[34.58415 ]
 [36.65948 ]
 [35.476086]
 [31.773565]
 [38.51829 ]
 [37.626354]
 [36.442963]
 [37.04811 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  8.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.32410430908203



buy possibilites: [-1] 
expected returns: [[35.31929]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0.  3.  0.  8.] 
cards in discard: [11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 3. 0. 0. 3.] 
adversary cards in discard: [6.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
adversary victory points: 4
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.51829147338867






         -------------------- Turn: 13 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 0. 3.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 10.  3.  3. 10.] 
adversary cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 0. 10.  3.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[37.271534]
 [36.691517]
 [36.691517]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  3. 10.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 35.31929016113281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[35.012936]
 [32.318867]
 [37.374695]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  3. 10.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 6. 0. 6. 8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 37.3057975769043



 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 14 -------------------- 
Player: 1 
cards in hand: [3. 6. 0. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 0. 6. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  3  3  8  3 16  0  0  6  0  8  6  0  8  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3.] 
cards in discard: [6. 3. 3. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3.] 
cards in discard: [6. 3. 3. 0. 0. 3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0. 29. 25.  0. 29.] 
adversary cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
adversary victory points: 3
player victory points: 5 





Player: 0 
cards in hand: [ 0. 29. 25.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.] 
expected returns: [[32.525055]
 [33.986305]
 [35.56885 ]
 [33.986305]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 25.  0. 29.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  6.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 8. 3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6] -> size -> 19 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 37.374698638916016



action possibilites: [-1] 
expected returns: [[25.15365]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29.  0. 29. 11.  0.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.58712387084961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[23.300625]
 [25.07737 ]
 [24.055508]
 [21.084782]
 [26.703531]
 [25.921448]
 [24.890335]
 [25.414413]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 29. 11.  0.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  7.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.153650283813477



buy possibilites: [-1] 
expected returns: [[26.49613]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 29.  0. 29. 11.  0.] 
cards in discard: [11. 25.  0. 29.  0.  3.  0.  8.  0. 10.  3.  3. 10. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  6.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3.  0. 16.  3.  8.] 
adversary cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6] -> size -> 20 
adversary victory points: 5
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 26.70353126525879






         -------------------- Turn: 15 -------------------- 
Player: 1 
cards in hand: [ 3.  0. 16.  3.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.  8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  6.  5.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11. 10. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11. 10. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 8.] 
cards in discard: [6. 3. 3. 0. 0. 3. 8. 3. 6. 8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [25. 11. 10. 25.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [25. 11. 10. 25.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11. 10. 25.  8.] 
expected returns: [[31.120317]
 [33.970844]
 [32.444786]
 [30.575039]
 [33.970844]
 [31.641243]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11. 10. 25.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  5.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 26.496129989624023



action possibilites: [-1] 
expected returns: [[31.515295]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 34.07917404174805





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[29.501682]
 [26.883753]
 [31.796637]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  8.  3. 10.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 0.] 
adversary cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6] -> size -> 21 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.515295028686523






         -------------------- Turn: 16 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6] -> size -> 19 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 27. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [26. 30. 30. 27. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0.] 
cards in discard: [ 6.  3.  3.  0.  0.  3.  8.  3.  6.  8. 16.  0.  3.  8.  6.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 8. 3. 0. 0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
adversary victory points: 3
player victory points: 3 





Player: 0 
cards in hand: [0. 8. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[33.227287]
 [33.789692]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 3. 0. 0.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11
 11] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.7966365814209



action possibilites: [-1] 
expected returns: [[24.281557]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 8
Learning step: 0
desired expected reward: 33.721126556396484





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.328524]
 [19.99407 ]
 [24.479107]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.] 
cards in deck: 13 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [0. 3. 6. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.281557083129883






         -------------------- Turn: 17 -------------------- 
Player: 1 
cards in hand: [0. 3. 6. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11. 25. 29. 29.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 30. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11. 25. 29. 29.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 0. 0.] 
cards in discard: [1.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [10. 11. 25. 29. 29.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 3 





Player: 0 
cards in hand: [10. 11. 25. 29. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 25. 29. 29.] 
expected returns: [[29.70302 ]
 [29.125828]
 [31.105791]
 [32.72195 ]
 [31.169336]
 [31.169336]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 25. 29. 29.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  4.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [1. 0. 3. 6. 0. 0.] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1] -> size -> 21 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.47910499572754



action possibilites: [-1] 
expected returns: [[24.148668]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 29. 29.  0. 11.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [1. 0. 3. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.8049201965332





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[22.33772 ]
 [20.096659]
 [24.498392]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11. 29. 29.  0. 11.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 3. 16.  0.  0.  8.] 
adversary cards in discard: [1. 0. 3. 6. 0. 0. 6.] 
adversary owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6] -> size -> 22 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.14866828918457






         -------------------- Turn: 18 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0.  0.  8.] 
cards in discard: [1. 0. 3. 6. 0. 0. 6.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8.] 
cards in discard: [1. 0. 3. 6. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [1. 0. 3. 6. 0. 0. 6. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8.] 
cards in discard: [1. 0. 3. 6. 0. 0. 6. 0. 0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [ 0.  0. 11. 29.  0.] 
adversary cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [ 0.  0. 11. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.] 
expected returns: [[27.94931 ]
 [29.276628]
 [29.336987]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11. 29.  0.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
adversary owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.49839210510254



action possibilites: [-1. 11.] 
expected returns: [[34.31877]
 [35.68819]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  0.  3.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11] -> size -> 21 
action values: 1 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  7. 10. 10.] 
adversary cards in hand: [3. 8. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
adversary owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.33698844909668



action possibilites: [-1] 
expected returns: [[37.57034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
adversary owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 36.483978271484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[35.341145]
 [37.416477]
 [36.233074]
 [32.57488 ]
 [35.85165 ]
 [39.275284]
 [38.38335 ]
 [39.34201 ]
 [35.57277 ]
 [37.19996 ]
 [37.6481  ]
 [37.80511 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  7. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
adversary owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 37.57033920288086



buy possibilites: [-1] 
expected returns: [[44.382015]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3.] 
cards in discard: [25. 11. 10. 25.  8.  3. 10.  8. 25. 10. 11. 29. 29.  0. 11. 10. 29.] 
cards in deck: 0 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 8. 3. 6. 3.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
adversary owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 32  0] 
sum of rewards: 67 

action type: buy - action 29.0
Learning step: 0
desired expected reward: 39.342010498046875






         -------------------- Turn: 19 -------------------- 
Player: 1 
cards in hand: [3. 8. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 3. 6. 3.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  3  8  3 16  0  0  0  8  0  8  6  6  8  6  3  1  6  0  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 25. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0] -> size -> 21 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 25. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0] -> size -> 21 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [11. 25. 29. 29. 25.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [11. 25. 29. 29. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29. 29. 25.] 
expected returns: [[22.589869]
 [23.75574 ]
 [25.098883]
 [23.808527]
 [23.808527]
 [25.098883]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29. 29. 25.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  3.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0] -> size -> 21 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 44.382015228271484



action possibilites: [-1] 
expected returns: [[26.829344]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29. 29. 25. 29.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.  6.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.208059310913086





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[25.141277]
 [22.762674]
 [27.278244]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29. 29. 25. 29.  8.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 0 
buys: 1 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [3. 0. 8. 6. 8.] 
adversary cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.  6.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6] -> size -> 22 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.829343795776367






         -------------------- Turn: 20 -------------------- 
Player: 1 
cards in hand: [3. 0. 8. 6. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 8. 6. 8.] 
cards in discard: [ 1.  0.  3.  6.  0.  0.  6.  0.  0. 16.  3.  0.  8.  8.  3.  3.  6.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [ 3.  0. 10. 29.  3.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3.  0. 10. 29.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.] 
expected returns: [[28.014402]
 [27.505465]
 [29.306944]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10. 29.  3.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.27824592590332



action possibilites: [-1. 10. 11.] 
expected returns: [[33.041977]
 [32.48187 ]
 [34.403126]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3. 11.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  6. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 29.367918014526367



action possibilites: [-1] 
expected returns: [[31.50487]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  9  0] 
sum of rewards: 44 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 35.50201416015625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[29.467382]
 [30.267187]
 [26.980505]
 [32.215652]
 [31.688576]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  4.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.50486946105957



buy possibilites: [-1] 
expected returns: [[32.08226]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 10.  3.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  8  0] 
sum of rewards: 43 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 32.21565246582031






         -------------------- Turn: 21 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  6  8  6  3  1  6  0  0  6  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0] -> size -> 22 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  6.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [10. 10. 25.  0. 10.] 
adversary cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
adversary victory points: 2
player victory points: 2 





Player: 0 
cards in hand: [10. 10. 25.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 25. 10.] 
expected returns: [[30.280268]
 [29.782068]
 [29.782068]
 [33.029137]
 [29.782068]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 25.  0. 10.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  2.  9.  5.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11] -> size -> 23 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 32.08226013183594



action possibilites: [-1] 
expected returns: [[25.993626]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  0. 10.  0. 11.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.029136657714844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[24.095163]
 [24.835783]
 [21.82129 ]
 [26.644646]
 [26.155344]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0. 11.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8] -> size -> 25 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 29. 30. 26. 30.  8.  1.  9.  5.  3.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.99362564086914



buy possibilites: [-1] 
expected returns: [[27.911516]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10.  0. 10.  0. 11.] 
cards in discard: [25. 11. 29. 29. 25. 29.  8. 10.  8. 29. 11.  3.  0. 10.  3.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [3. 3. 0. 6. 1.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6] -> size -> 24 
adversary victory points: 2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 26.6446475982666






         -------------------- Turn: 22 -------------------- 
Player: 1 
cards in hand: [3. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [11.  8.  0.  0.  0.  6.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 29. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 6. 1.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [ 0. 11.  8. 11.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8] -> size -> 26 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 0. 11.  8. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 11.] 
expected returns: [[22.923826]
 [24.186495]
 [23.414751]
 [24.186495]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  8. 11.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  5. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 27.911516189575195



action possibilites: [-1] 
expected returns: [[22.82112]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  8. 11.  0.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  9  0] 
sum of rewards: 24 

action type: gain_card_n - action 9
Learning step: 0
desired expected reward: 25.28501319885254





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[21.129402]
 [21.86392 ]
 [18.814901]
 [23.634624]
 [23.158314]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0.] 
cards in discard: [10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  2.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.82111930847168



buy possibilites: [-1] 
expected returns: [[25.157322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  8. 11.  0.] 
cards in discard: [10.  8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 0. 6. 8. 3.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
adversary owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  8  0] 
sum of rewards: 23 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 23.63462257385254






         -------------------- Turn: 23 -------------------- 
Player: 1 
cards in hand: [0. 0. 6. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 8. 3.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  3  3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6
  1] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1] -> size -> 23 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11. 10.  0. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 0. 11. 10.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 10. 29.] 
expected returns: [[33.1013  ]
 [34.425766]
 [32.556026]
 [34.485855]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 29.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.15732192993164



action possibilites: [-1. 11. 10. 25.] 
expected returns: [[37.84026 ]
 [39.258194]
 [37.276608]
 [40.905506]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0. 25.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  1.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1] -> size -> 23 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 29.0
Learning step: 0
desired expected reward: 34.487300872802734



action possibilites: [-1] 
expected returns: [[36.47084]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11. 10.  0.  8. 25.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 28. 30. 26. 30.  8.  0.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 40.905513763427734





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[34.380512]
 [36.39822 ]
 [35.247356]
 [38.205986]
 [37.338535]
 [36.18767 ]
 [36.77613 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  8. 25.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 28. 30. 26. 30.  8.  0.  9.  5.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 36.47084045410156



buy possibilites: [-1] 
expected returns: [[34.86917]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11. 10.  0.  8. 25.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3.  3. 16.  0.  0.] 
adversary cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6] -> size -> 24 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 18  0] 
sum of rewards: 53 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 38.20598220825195






         -------------------- Turn: 24 -------------------- 
Player: 1 
cards in hand: [ 3.  3. 16.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [23. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  3. 16.  0.  0.] 
cards in discard: [11.  8.  0.  0.  0.  6.  1.  3.  3.  0.  6.  1.  8.  0.  6.  6.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10.  3. 29. 10. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [10.  3. 29. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29. 10. 29.] 
expected returns: [[27.291328]
 [26.79762 ]
 [28.567167]
 [26.79762 ]
 [28.567167]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 29. 10. 29.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 34.869171142578125



action possibilites: [-1. 10. 10. 29.] 
expected returns: [[24.664312]
 [24.134   ]
 [24.134   ]
 [26.017847]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 10. 29.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.] 
cards in deck: 7 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 26.973262786865234



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[35.79154 ]
 [35.246037]
 [35.246037]
 [36.312786]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 10 25 29 29  8 10 25 25 11 10 11 11 10 29 10
  8  8 10  8 11] -> size -> 29 
action values: 1 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.322866439819336



action possibilites: [-1] 
expected returns: [[33.22463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 35.28959655761719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[31.396349]
 [32.13243 ]
 [33.918514]
 [33.438175]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  1.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 33.22462844848633



buy possibilites: [-1] 
expected returns: [[28.978037]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.
  8.] 
cards in deck: 6 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [16.  3.  6.  8.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  8  0] 
sum of rewards: 63 

action type: buy - action 8.0
Learning step: 0
desired expected reward: 33.91851043701172






         -------------------- Turn: 25 -------------------- 
Player: 1 
cards in hand: [16.  3.  6.  8.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.  8.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  6.  8.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25. 10. 11. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.
  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  8.  8.] 
cards in discard: [] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0] -> size -> 25 
action values: 1 
buys: 1 
player value: 0 
card supply: [22. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25. 10. 11. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.
  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  6.  8.  8.] 
cards in discard: [0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [10. 25. 10. 11. 29.] 
adversary cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.
  8. 29. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [10. 25. 10. 11. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 10. 11. 29.] 
expected returns: [[30.278793]
 [29.764727]
 [32.97396 ]
 [29.764727]
 [31.527658]
 [31.584251]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 25. 10. 11. 29.] 
cards in discard: [10.  8. 11.  0.  8. 11.  0. 11. 29. 25.  0. 11. 10.  0.  8. 25.  8.  3.
  8. 29. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 28.978036880493164



action possibilites: [-1] 
expected returns: [[21.632452]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10. 11. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 32.97395706176758





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[19.795084]
 [21.803694]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 10. 11. 29. 11.  3.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [6. 0. 3. 3. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 21.6324520111084






         -------------------- Turn: 26 -------------------- 
Player: 1 
cards in hand: [6. 0. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  4.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 0. 3. 3. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  3.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0.  0.  0.  8. 10.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 0.  0.  0.  8. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10.] 
expected returns: [[24.540417]
 [25.025652]
 [24.044645]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  8. 10.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 10 11 11 10 29 10  8  8
 10  8 11  8] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  3.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 21.803693771362305



action possibilites: [-1] 
expected returns: [[28.584253]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  3.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 24.03583335876465





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[26.976831]
 [28.793766]
 [27.751312]
 [30.432667]
 [28.602783]
 [29.136372]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  3.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 28.584253311157227



buy possibilites: [-1] 
expected returns: [[25.519773]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 0. 11.  6.  0.  8.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 18  0] 
sum of rewards: 33 

action type: buy - action 11.0
Learning step: 0
desired expected reward: 30.432666778564453






         -------------------- Turn: 27 -------------------- 
Player: 1 
cards in hand: [ 0. 11.  6.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  0.  8.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  0  0  8  0  8  8  6  3  1  6  0  0  6  0 11  6  1  6
  0  0 11] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11] -> size -> 24 
action values: 0 
buys: 1 
player value: 0 
card supply: [21. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [ 3. 29.  0. 10. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 3. 29.  0. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10. 11.] 
expected returns: [[21.695463]
 [23.065275]
 [21.156042]
 [23.005896]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  0. 10. 11.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1
Learning step: 0
desired expected reward: 25.519773483276367



action possibilites: [-1. 10. 25.] 
expected returns: [[32.70103 ]
 [32.145897]
 [35.603516]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 25.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 24.060705184936523



action possibilites: [-1] 
expected returns: [[26.087717]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  8.  8.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 35.603515625





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[24.039064]
 [24.810194]
 [26.17628 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  8.  8.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [0. 3. 0. 6. 1.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.087717056274414






         -------------------- Turn: 28 -------------------- 
Player: 1 
cards in hand: [0. 3. 0. 6. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29. 25. 29.  8. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 4 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10. 10.] 
adversary cards in hand: [29. 25. 29.  8. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 6. 1.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [29. 25. 29.  8. 11.] 
adversary cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [29. 25. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25. 29.  8. 11.] 
expected returns: [[24.471682]
 [25.69875 ]
 [26.998156]
 [25.69875 ]
 [24.933372]
 [25.64559 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25. 29.  8. 11.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.176280975341797



action possibilites: [-1] 
expected returns: [[25.453085]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 29.  8. 11.  8.  8.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.998157501220703





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.580393]
 [25.43855 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29. 29.  8. 11.  8.  8.] 
cards in discard: [25. 10. 10. 11. 29. 11.  3. 11.  8.  0.  0.  0.  3. 11. 29. 25.  0. 10.
  8.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [8. 0. 0. 0. 6.] 
adversary cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 25.45308494567871






         -------------------- Turn: 29 -------------------- 
Player: 1 
cards in hand: [8. 0. 0. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 0. 6.] 
cards in discard: [ 0. 16.  3.  6.  8.  8. 11.  6.  0.  3.  3.  1.  0.  8.  6. 15.  0.  3.
  0.  6.  1.  0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 8.  3. 29.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [ 8.  3. 29.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29.  8. 11.] 
expected returns: [[23.50861 ]
 [23.991913]
 [24.792736]
 [23.991913]
 [24.737177]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  3. 29.  8. 11.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 25.43855094909668



action possibilites: [-1.  8. 11. 10.] 
expected returns: [[23.79744 ]
 [24.289476]
 [25.053389]
 [23.282484]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10.] 
cards in discard: [3. 8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  9.] 
adversary cards in hand: [ 0.  3. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.203454971313477



action possibilites: [-1] 
expected returns: [[27.162333]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 10.] 
cards in discard: [ 3.  8. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 24.290157318115234





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.096615]
 [27.257986]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 10.] 
cards in discard: [ 3.  8. 15.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [ 0.  3. 15.  6.  8.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.16233253479004






         -------------------- Turn: 30 -------------------- 
Player: 1 
cards in hand: [ 0.  3. 15.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 15.  6.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  0  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11
  0 15  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 25.  0.  0. 11.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 25.  0.  0. 11.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  4. 10.  8.] 
adversary cards in hand: [11. 25.  0.  0. 11.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 8.] 
cards in discard: [10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 25.  0.  0. 11.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [11. 25.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 11.] 
expected returns: [[22.93835]
 [24.2442 ]
 [25.75202]
 [24.2442 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25.  0.  0. 11.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [10. 15.  3.  6.  8.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.257986068725586



action possibilites: [-1] 
expected returns: [[23.36629]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  0. 11. 11.  8.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [10. 15.  3.  6.  8.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.75202178955078





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.593395]
 [22.339441]
 [23.65426 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  0. 11. 11.  8.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10.] 
cards in deck: 15 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [0. 0. 8. 1. 0.] 
adversary cards in discard: [10. 15.  3.  6.  8.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.366289138793945






         -------------------- Turn: 31 -------------------- 
Player: 1 
cards in hand: [0. 0. 8. 1. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [10. 15.  3.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 29.  8. 11. 25.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [10. 15.  3.  6.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10] -> size -> 27 
action values: 0 
buys: 1 
player value: 5 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6. 10. 10.  3. 10.  8.] 
adversary cards in hand: [11. 29.  8. 11. 25.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 1. 0.] 
cards in discard: [10. 15.  3.  6.  8. 14.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [11. 29.  8. 11. 25.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [11. 29.  8. 11. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 11. 25.] 
expected returns: [[20.232645]
 [21.369656]
 [21.423532]
 [20.676373]
 [21.369656]
 [22.762238]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 11. 25.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.654260635375977



action possibilites: [-1] 
expected returns: [[18.643225]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 11.  0.  8.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.762237548828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[16.935873]
 [18.733706]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  8. 11.  0.  8.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [1. 6. 0. 0. 3.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 18.643224716186523






         -------------------- Turn: 32 -------------------- 
Player: 1 
cards in hand: [1. 6. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 25. 29.  8.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [19. 28. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 25. 29.  8.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 6. 0. 0. 3.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14  1] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [10.  0. 25. 29.  8.] 
adversary cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 





Player: 0 
cards in hand: [10.  0. 25. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25. 29.  8.] 
expected returns: [[23.595123]
 [23.163641]
 [25.867449]
 [24.690777]
 [24.007378]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25. 29.  8.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 16.  6.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14  1] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 18.733707427978516



action possibilites: [-1] 
expected returns: [[22.59607]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 29.  8. 10. 29.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 16.  6.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14  1] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.867446899414062





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[20.89661 ]
 [22.647043]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0. 29.  8. 10. 29.] 
cards in discard: [ 3.  8. 15. 29. 11.  8. 10. 25. 11.  0.  0. 11. 11.  8. 25. 11. 29.  8.
 11.  0.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  0. 16.  6.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14  1] -> size -> 29 
adversary victory points: -1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.5960693359375






         -------------------- Turn: 33 -------------------- 
Player: 1 
cards in hand: [ 8.  6.  0. 16.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  0. 16.  6.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  6  3  1  6  0  0  6  0  6  1  6  0  0 11  0
 15  0 10 14  1] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 25. 25.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: -1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 6.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 25. 25.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 6.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8. 25. 25.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8. 25. 25.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 25.] 
expected returns: [[20.777693]
 [21.278246]
 [23.566893]
 [23.566893]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 25.  0.  3.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 22.647043228149414



action possibilites: [-1] 
expected returns: [[22.828787]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 23.563081741333008





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[21.004972]
 [21.77258 ]
 [23.155977]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 25.  0.  3. 10.  0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 6.  3.  0.  8. 11.] 
adversary cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.828786849975586






         -------------------- Turn: 34 -------------------- 
Player: 1 
cards in hand: [ 6.  3.  0.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3.  0.  8. 11.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  9.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  8. 11. 11. 11.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  8. 11. 11. 11.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 8.] 
cards in discard: [10. 15.  3.  6.  8. 14.  0.  0.  8.  1.  0.  1.  1.  6.  0.  0.  3.  0.
 16.  8.  0.  6. 16.] 
cards in deck: 2 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [ 8.  8. 11. 11. 11.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8.  8. 11. 11. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8. 11. 11. 11.] 
expected returns: [[25.41723 ]
 [25.898167]
 [25.898167]
 [26.647955]
 [26.647955]
 [26.647955]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 11. 11.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  8.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.155975341796875



action possibilites: [-1] 
expected returns: [[20.29282]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 11. 11.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 25.898164749145508





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.424467]
 [20.36503 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  8. 11. 11.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [0. 1. 6. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.29281997680664






         -------------------- Turn: 35 -------------------- 
Player: 1 
cards in hand: [0. 1. 6. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [29.  0. 29. 11.  3.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [18. 27. 30. 26. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [29.  0. 29. 11.  3.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 6. 0. 3.] 
cards in discard: [3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [29.  0. 29. 11.  3.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [29.  0. 29. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 29. 11.] 
expected returns: [[28.90975 ]
 [30.209291]
 [30.209291]
 [30.152359]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0. 29. 11.  3.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  0.  8.  6.] 
adversary cards in discard: [3. 0. 1. 6. 0. 3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.365028381347656



action possibilites: [-1. 29. 10.] 
expected returns: [[30.158587]
 [31.590067]
 [29.59493 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  3. 10.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.] 
cards in deck: 11 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  0.  8.  6.] 
adversary cards in discard: [3. 0. 1. 6. 0. 3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 31.176755905151367



action possibilites: [-1.  8.] 
expected returns: [[27.784456]
 [28.272367]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  0.  8.  6.] 
adversary cards in discard: [3. 0. 1. 6. 0. 3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 29.79671287536621



action possibilites: [-1] 
expected returns: [[29.052238]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  0.  8.  6.] 
adversary cards in discard: [3. 0. 1. 6. 0. 3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 28.272367477416992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[26.886515]
 [27.655935]
 [29.011967]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10.] 
cards in deck: 10 
card top of deck: [] 
played cards: [29. 29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 2 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [16. 15.  0.  8.  6.] 
adversary cards in discard: [3. 0. 1. 6. 0. 3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 60  0  0  0  0  0  0  0  0  0] 
sum of rewards: 55 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.05223846435547






         -------------------- Turn: 36 -------------------- 
Player: 1 
cards in hand: [16. 15.  0.  8.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 15.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16. 15.  0.  8.  6.] 
cards in discard: [3. 0. 1. 6. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8. 11. 10. 25. 15.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10. 29.
 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16. 15.  0.  8.  6.] 
cards in discard: [3. 0. 1. 6. 0. 3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 8. 11. 10. 25. 15.] 
adversary cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10. 29.
 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [ 8. 11. 10. 25. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 10. 25. 15.] 
expected returns: [[27.86224 ]
 [28.308594]
 [28.997013]
 [27.395493]
 [30.329765]
 [27.74109 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 25. 15.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10. 29.
 29.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.0119686126709



action possibilites: [-1] 
expected returns: [[29.027441]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 10. 15. 29. 11.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10. 29.
 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.32976722717285





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.000347]
 [29.041243]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 10. 15. 29. 11.] 
cards in discard: [25.  8. 25.  0.  3. 10.  0. 15. 11.  8.  8. 11. 11.  0. 11.  3. 10. 29.
 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [8. 1. 0. 0. 0.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.027441024780273






         -------------------- Turn: 37 -------------------- 
Player: 1 
cards in hand: [8. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3] -> size -> 31 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 0. 0. 0.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 5 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [10. 10.  8. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [10. 10.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.  8. 29.] 
expected returns: [[21.378809]
 [20.8725  ]
 [20.8725  ]
 [21.869394]
 [22.68256 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8. 29.  0.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 16.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.041242599487305



action possibilites: [-1. 10. 10.  8.] 
expected returns: [[24.426563]
 [23.90965 ]
 [23.90965 ]
 [24.920736]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  8.] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 10 29 10  8  8 10
  8 11  8 11 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 16.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.053319931030273



action possibilites: [-1] 
expected returns: [[14.668526]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 16.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 23.991905212402344





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[13.040677]
 [14.962835]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [0. 0.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 16.  0. 10.  3.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 14.668525695800781






         -------------------- Turn: 38 -------------------- 
Player: 1 
cards in hand: [ 3. 16.  0. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 16.  0. 10.  3.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 10 14  1  0 16  3  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  7.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  8. 25. 11.] 
adversary cards in discard: [ 0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  8. 25. 11.] 
adversary cards in discard: [ 0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.] 
cards in deck: 10 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3. 10.  8. 25. 11.] 
adversary cards in discard: [ 0.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 





Player: 0 
cards in hand: [ 3. 10.  8. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.  8. 25. 11.] 
expected returns: [[27.905016]
 [27.40491 ]
 [28.391464]
 [30.585659]
 [29.14834 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 25. 11.] 
cards in discard: [ 0.  0. 29.  8.] 
cards in deck: 19 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  6.  8.  0.  1.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 14.962835311889648



action possibilites: [-1] 
expected returns: [[27.608244]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 10.  8. 11. 11.  8.] 
cards in discard: [ 0.  0. 29.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  6.  8.  0.  1.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 30.585660934448242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.486567]
 [27.720808]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 10.  8. 11. 11.  8.] 
cards in discard: [ 0.  0. 29.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11.  6.  8.  0.  1.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.608243942260742






         -------------------- Turn: 39 -------------------- 
Player: 1 
cards in hand: [11.  6.  8.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6.  8.  0.  1.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [15. 11.  3. 25. 11.] 
adversary cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  6.  8.  0.  1.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [15. 11.  3. 25. 11.] 
adversary cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [15. 11.  3. 25. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 11. 25. 11.] 
expected returns: [[16.658386]
 [16.54278 ]
 [17.741108]
 [18.998093]
 [17.741108]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 25. 11.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3. 11.  6.  8.  0.  1.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.720808029174805



action possibilites: [-1] 
expected returns: [[30.107862]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11.  3. 11.  0.  8.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3. 11.  6.  8.  0.  1.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 18.99809455871582





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.949345]
 [30.166208]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11.  3. 11.  0.  8.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8.] 
cards in deck: 10 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 3.  0.  8. 14.  6.] 
adversary cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3. 11.  6.  8.  0.  1.] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 30.10786247253418






         -------------------- Turn: 40 -------------------- 
Player: 1 
cards in hand: [ 3.  0.  8. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 14.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  8. 14.  6.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3. 11.  6.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11. 11. 15.  0. 29.] 
adversary cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  8. 14.  6.] 
cards in discard: [ 3.  0.  1.  6.  0.  3. 16. 15.  0.  8.  6.  0.  8.  1.  0.  0.  0. 25.
 16.  3.  0.  3. 11.  6.  8.  0.  1.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11. 11. 15.  0. 29.] 
adversary cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 11. 15.  0. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 11. 15. 29.] 
expected returns: [[25.285341]
 [26.534687]
 [26.534687]
 [25.153341]
 [26.591644]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 15.  0. 29.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 30.166208267211914



action possibilites: [-1. 11. 11. 25.] 
expected returns: [[30.592981]
 [31.915243]
 [31.915243]
 [33.43857 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11. 25.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.
 15.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 24.960126876831055



action possibilites: [-1] 
expected returns: [[24.96298]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 11.  8. 29.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.
 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 33.43856430053711





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[23.070162]
 [24.924307]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 11.  8. 29.] 
cards in discard: [ 0.  0. 29.  8. 25.  3. 10.  8. 11. 11.  8. 25. 15. 11.  3. 11.  0.  8.
 15.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [ 6.  1.  0. 16.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
adversary victory points: 1
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.962980270385742






         -------------------- Turn: 41 -------------------- 
Player: 1 
cards in hand: [ 6.  1.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  1.  0. 16.  3.] 
cards in discard: [] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15
  0 14  1  0 16  3  0 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  7.] 
adversary cards in hand: [11. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 1 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [15.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0.] 
cards in discard: [15.  0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11. 25. 29.  8. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11. 25. 29.  8. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 29.  8. 29.] 
expected returns: [[20.412113]
 [21.577986]
 [22.921127]
 [21.63077 ]
 [20.870697]
 [21.63077 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 29.  8. 29.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [25.  0.  0.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.924306869506836



action possibilites: [-1] 
expected returns: [[20.542545]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [25.  0.  0.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.921127319335938





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.796438]
 [20.806559]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 29.  8. 29.  8.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [25.  0.  0.  6.  6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.542545318603516






         -------------------- Turn: 42 -------------------- 
Player: 1 
cards in hand: [25.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  0.  6.  6.] 
cards in discard: [15.  0. 16.  6.  1.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 25. 29.  8.  3.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 0. 0.] 
cards in discard: [15.  0. 16.  6.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 25. 29.  8.  3.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 0. 0.] 
cards in discard: [15.  0. 16.  6.  1.  0.] 
cards in deck: 20 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 3. 25. 29.  8.  3.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 3. 25. 29.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8.] 
expected returns: [[20.114191]
 [22.338669]
 [21.168976]
 [20.509457]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 25. 29.  8.  3.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 1.  8.  0.  0. 11.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.806556701660156



action possibilites: [-1] 
expected returns: [[26.422373]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 29.  8.  3.  8.  0.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 1.  8.  0.  0. 11.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 22.338668823242188





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.438194]
 [26.581463]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 29.  8.  3.  8.  0.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0.] 
cards in deck: 14 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [ 1.  8.  0.  0. 11.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
adversary owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.422372817993164






         -------------------- Turn: 43 -------------------- 
Player: 1 
cards in hand: [ 1.  8.  0.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8.  0.  0. 11.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  0  8  8  3  1  6  0  0  6  0  6  1  6  0  0 11  0 15  0
 14  1  0 16  3  0 25 15  0] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11.  0.  8. 29. 10.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11.  0.  8. 29. 10.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [11.  0.  8. 29. 10.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [11.  0.  8. 29. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8. 29. 10.] 
expected returns: [[21.216454]
 [22.323256]
 [21.649557]
 [22.373575]
 [20.763239]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8. 29. 10.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.581464767456055



action possibilites: [-1. 11. 10. 11.] 
expected returns: [[26.063599]
 [27.333471]
 [25.543325]
 [27.333471]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 11.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15] -> size -> 28 
action values: 1 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  6.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 23.218111038208008



action possibilites: [-1] 
expected returns: [[20.233274]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 26.56309700012207





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[18.33602 ]
 [20.266579]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15.] 
cards in deck: 8 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [15.  8.  8.  0.  3.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 20.233274459838867






         -------------------- Turn: 44 -------------------- 
Player: 1 
cards in hand: [15.  8.  8.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8.  0.  3.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  0  6  0  6  1  6  0  0 11  0 15  0 14  1
  0 16  3  0 25 15  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0. 11. 15. 25.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 8. 3.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0. 11. 15. 25.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0] -> size -> 30 
action values: 0 
buys: 1 
player value: 3 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  2.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0. 11. 15. 25.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 8. 3.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11.] 
cards in deck: 10 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0 11] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 8.  0. 11. 15. 25.] 
adversary cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [ 8.  0. 11. 15. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11. 15. 25.] 
expected returns: [[26.069668]
 [26.470203]
 [27.088312]
 [25.962101]
 [28.262177]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 15. 25.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [14.  3. 16.  1.  8.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 20.26658058166504



action possibilites: [-1] 
expected returns: [[27.237547]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11. 15. 11. 11.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [14.  3. 16.  1.  8.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 28.262174606323242





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.405977]
 [27.282492]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8.  0. 11. 15. 11. 11.] 
cards in discard: [25. 11. 29.  8. 29.  8.  0. 25.  3. 29.  8.  3.  8.  0.  0.  8. 15. 29.
 11. 10. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [14.  3. 16.  1.  8.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0 11] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.237546920776367






         -------------------- Turn: 45 -------------------- 
Player: 1 
cards in hand: [14.  3. 16.  1.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.  8.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3. 16.  1.  8.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  1  6  0  0 11  0 15  0 14  1  0
 16  3  0 25 15  0 11] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [25. 29.  8. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  8.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [25. 29.  8. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  8.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [16.] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [25. 29.  8. 15. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 





Player: 0 
cards in hand: [25. 29.  8. 15. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.  8. 15. 15.] 
expected returns: [[17.843359]
 [20.473597]
 [19.110079]
 [18.317339]
 [17.714651]
 [17.714651]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 29.  8. 15. 15.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0. 16. 14.  3.  8.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.282489776611328



action possibilites: [-1] 
expected returns: [[26.04759]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  8. 15. 15. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0. 16. 14.  3.  8.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 20.473596572875977





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[24.04939 ]
 [26.146515]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  8. 15. 15. 11.  8.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [0. 3. 3. 0. 6.] 
adversary cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0. 16. 14.  3.  8.] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 26.047590255737305






         -------------------- Turn: 46 -------------------- 
Player: 1 
cards in hand: [0. 3. 3. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0. 16. 14.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [29. 11.  3. 11.  3.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 6.] 
cards in discard: [15.  0. 16.  6.  1.  0. 25.  0.  0.  6.  6.  0.  0.  8.  0. 11. 11. 15.
  8.  8.  3.  0. 16. 14.  3.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [29. 11.  3. 11.  3.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
adversary victory points: 2
player victory points: 0 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [29. 11.  3. 11.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11. 11.] 
expected returns: [[21.517038]
 [22.757135]
 [22.703375]
 [22.703375]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 11.  3. 11.  3.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 26.146516799926758



action possibilites: [-1. 11.  8.] 
expected returns: [[24.266851]
 [25.491417]
 [24.748535]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  3.  8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15] -> size -> 29 
action values: 1 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  5.] 
adversary cards in hand: [ 0.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 21.203577041625977



action possibilites: [-1] 
expected returns: [[23.436129]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 24.88131332397461





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.682125]
 [23.521944]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0.  3.  3.  8. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
adversary victory points: 0
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 23.436128616333008






         -------------------- Turn: 47 -------------------- 
Player: 1 
cards in hand: [ 0.  3.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 3  8  3 16  8  8  8  3  6  0  6  0  6  6  0  0 11  0 15  0 14  1  0 16
  3  0 25 15  0 11  0] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [25. 11.  8.  0. 11.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: 0 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [25. 11.  8.  0. 11.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [25. 11.  8.  0. 11.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [25. 11.  8.  0. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 11.  8. 11.] 
expected returns: [[27.064426]
 [29.854595]
 [28.359287]
 [27.573763]
 [28.359287]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25. 11.  8.  0. 11.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.521944046020508



action possibilites: [-1] 
expected returns: [[22.946745]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  8.  0. 11. 25. 15.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 29.854597091674805





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[21.127756]
 [23.069815]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  8.  0. 11. 25. 15.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8.] 
cards in deck: 9 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [ 0. 25.  6.  3.  0.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 22.946744918823242






         -------------------- Turn: 48 -------------------- 
Player: 1 
cards in hand: [ 0. 25.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 25.  6.  3.  0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 29.  8. 29.  0.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6.  3.  0.] 
cards in discard: [8.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [15. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 29.  8. 29.  0.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 25.  6.  3.  0.] 
cards in discard: [8. 0.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [11. 29.  8. 29.  0.] 
adversary cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [11. 29.  8. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 29.  8. 29.] 
expected returns: [[25.260027]
 [26.351385]
 [26.400824]
 [25.689259]
 [26.400824]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 29.  8. 29.  0.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [14. 16.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 23.069814682006836



action possibilites: [-1. 11.  8.] 
expected returns: [[25.043589]
 [26.252588]
 [25.519133]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15. 29.  8.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  4.] 
adversary cards in hand: [14. 16.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 8
Learning step: 0
desired expected reward: 25.689258575439453



action possibilites: [-1] 
expected returns: [[24.496393]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15. 29.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [14. 16.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0 16  0] 
sum of rewards: 51 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 25.519134521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[22.650671]
 [23.340122]
 [24.555285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [25. 29.  8. 15. 15. 11.  8. 11.  3. 15. 29. 11.  3.  8. 25. 11.  8.  0.
 11. 25. 15. 29.  8. 15.] 
cards in deck: 3 
card top of deck: [] 
played cards: [29. 11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [14. 16.  0.  6.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.49639320373535






         -------------------- Turn: 49 -------------------- 
Player: 1 
cards in hand: [14. 16.  0.  6.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 16.] 
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14. 16.  0.  6.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [29. 11. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 0 
player value: 2 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [29. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0] -> size -> 28 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  9. 10.  3. 10.  3.] 
adversary cards in hand: [29. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  0.  6.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [29. 10.  0.] 
adversary cards in discard: [11.  0.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [29. 10.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
expected returns: [[24.30559 ]
 [25.54977 ]
 [23.815752]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 10.  0.] 
cards in discard: [11.  0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5   0   0   0   0   0   0   0   0   0   0   0   0   0 224   0] 
sum of rewards: 219 

action type: discard_down_to_3_cards - action 1
Learning step: 0
desired expected reward: 8.630435943603516



action possibilites: [-1.  8.] 
expected returns: [[29.1296  ]
 [29.630783]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [11.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 23.991004943847656



action possibilites: [-1] 
expected returns: [[24.621912]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [11.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action 8.0
Learning step: 0
desired expected reward: 29.630781173706055





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[22.736479]
 [24.862055]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [11.  0. 10.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [3. 0. 6. 8. 6.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 24.621912002563477






         -------------------- Turn: 50 -------------------- 
Player: 1 
cards in hand: [3. 0. 6. 8. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 8. 6.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 25. 11. 15. 11.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 6.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14] -> size -> 29 
action values: 0 
buys: 1 
player value: 1 
card supply: [14. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 25. 11. 15. 11.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 8. 6.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14  0] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 25. 11. 15. 11.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 8. 25. 11. 15. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 11. 15. 11.] 
expected returns: [[23.852669]
 [24.334843]
 [26.506628]
 [25.083994]
 [23.722742]
 [25.083994]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25. 11. 15. 11.] 
cards in discard: [11.  0. 10.  0. 29.  8.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15. 16.  0.  1.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14  0] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 24.8620548248291



action possibilites: [-1] 
expected returns: [[29.774893]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 11. 15. 11. 11.  3.] 
cards in discard: [11.  0. 10.  0. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15. 16.  0.  1.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14  0] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 26.50662612915039





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[27.746147]
 [29.85927 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 11. 15. 11. 11.  3.] 
cards in discard: [11.  0. 10.  0. 29.  8.] 
cards in deck: 18 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15. 16.  0.  1.  0.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14  0] -> size -> 30 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 29.774892807006836






         -------------------- Turn: 51 -------------------- 
Player: 1 
cards in hand: [15. 16.  0.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 16.] 
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 16.  0.  1.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  0  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15
  0 11  0  0 14  0] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 29.  3.  0. 25.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  1.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 29.  3.  0. 25.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  1.  0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 6 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [ 8. 29.  3.  0. 25.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [ 8. 29.  3.  0. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 29. 25.] 
expected returns: [[22.79387 ]
 [23.261377]
 [24.036291]
 [25.35192 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0. 25.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 29.85927391052246



action possibilites: [-1] 
expected returns: [[27.453081]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 29.  3.  0. 25. 29.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action 25.0
Learning step: 0
desired expected reward: 25.351919174194336





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[25.430624]
 [27.563147]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 8. 29.  3.  0. 25. 29.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8. 11.  0.  8.] 
adversary cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
adversary owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 27.453081130981445






         -------------------- Turn: 52 -------------------- 
Player: 1 
cards in hand: [15.  8. 11.  0.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 11.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 11.  0.  8.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 8 16  8  8  8  3  6  6  6  6  0  0  0 15  0 14  1  0 16  3  0 25 15  0
 11  0  0 14  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8.  8. 29.  8.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8.  8. 29.  8.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0] -> size -> 26 
action values: 0 
buys: 1 
player value: 1 
card supply: [13. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8.  8. 29.  8.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 8.  0.  0. 25.  6.  3.  0. 14. 14. 16.  0.  6.  0.  0.  3.  0.  6.  8.
  6. 15. 16.  1.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [8.] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [15.  8.  8. 29.  8.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [15.  8.  8. 29.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.  8. 29.  8.] 
expected returns: [[26.178112]
 [26.063951]
 [26.598158]
 [26.598158]
 [27.304487]
 [26.598158]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8.  8. 29.  8.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 27.563146591186523



action possibilites: [-1.  8.  8. 15.] 
expected returns: [[23.293228]
 [23.691832]
 [23.691832]
 [23.187998]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8. 15.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 25.895753860473633



action possibilites: [-1] 
expected returns: [[31.42146]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: trash_cards_n_from_hand - action 1
Learning step: 0
desired expected reward: 23.032419204711914





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[29.36902 ]
 [31.519619]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15.] 
cards in deck: 5 
card top of deck: [] 
played cards: [29.  8.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [6. 8. 0. 6. 0.] 
adversary cards in discard: [] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.421459197998047






         -------------------- Turn: 53 -------------------- 
Player: 1 
cards in hand: [6. 8. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [11. 15. 11. 15.  0.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 6. 0.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [11. 15. 11. 15.  0.] 
adversary cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15. 29.  8.  8.] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
adversary victory points: 2
player victory points: -2 


 --------- NOTHING HAPPENED --------- 



Player: 0 
cards in hand: [11. 15. 11. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 11. 15.] 
expected returns: [[32.08187 ]
 [33.34014 ]
 [31.948189]
 [33.34014 ]
 [31.948189]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 15. 11. 15.  0.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15. 29.  8.  8.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  3.] 
adversary cards in hand: [16.  3.  0.  0.  6.] 
adversary cards in discard: [6. 8. 0. 6. 0.] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.519620895385742



action possibilites: [-1] 
expected returns: [[31.008198]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15. 11. 15.  0.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15. 29.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [16.  3.  0.  0.  6.] 
adversary cards in discard: [6. 8. 0. 6. 0.] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0 16  0] 
sum of rewards: 31 

action type: gain_card_n - action 8
Learning step: 0
desired expected reward: 32.57388687133789





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[28.918612]
 [31.06651 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15. 11. 15.  0.] 
cards in discard: [11.  0. 10.  0. 29.  8. 25.  8. 11. 15. 11. 11.  3. 25.  8. 29.  3.  0.
 25. 29.  8. 15. 29.  8.  8. 15.] 
cards in deck: 0 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [16.  3.  0.  0.  6.] 
adversary cards in discard: [6. 8. 0. 6. 0.] 
adversary owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: take_action - action -1
Learning step: 0
desired expected reward: 31.008197784423828






         -------------------- Turn: 54 -------------------- 
Player: 1 
cards in hand: [16.  3.  0.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  6.] 
cards in discard: [6. 8. 0. 6. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [16  8  8  8  3  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0
 14  0  0] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [15.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [6. 8. 0. 6. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [15.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [6. 8. 0. 6. 0. 0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [11. 27. 30. 25. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [15.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [6. 8. 0. 6. 0. 0. 3.] 
cards in deck: 17 
card top of deck: [] 
played cards: [16.] 
owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [15.  8. 29.  3. 29.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
adversary victory points: 2
player victory points: -2 





Player: 0 
cards in hand: [15.  8. 29.  3. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8. 29. 29.] 
expected returns: [[21.845934]
 [21.724312]
 [22.293861]
 [23.036297]
 [23.036297]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 29.  3. 29.] 
cards in discard: [] 
cards in deck: 26 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [ 0.  0. 16. 14. 25.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -5 

action type: buy - action -1.0
Learning step: 0
desired expected reward: 31.066511154174805



action possibilites: [-1. 15.  8. 29.] 
expected returns: [[27.48128 ]
 [27.35417 ]
 [27.957449]
 [28.74719 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  8. 29.] 
cards in discard: [ 3. 11.] 
cards in deck: 25 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 1 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [ 0.  0. 16. 14. 25.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 20  0  0  0  0  0  0  0  0  0] 
sum of rewards: 15 

action type: discard_n_cards - action 9
Learning step: 0
desired expected reward: 23.915693283081055



action possibilites: [-1.] 
expected returns: [[27.174212]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0.] 
cards in discard: [ 3. 11. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 1 
buys: 0 
player value: 2 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [ 0.  0. 16. 14. 25.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: discard_n_cards - action 1
Learning step: 0
desired expected reward: 27.166696548461914





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[25.080748]
 [26.910053]
 [25.866957]
 [28.548496]
 [26.719194]
 [27.25253 ]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0.] 
cards in discard: [ 3. 11. 15.  8.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15] -> size -> 31 
action values: 0 
buys: 1 
player value: 3 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  1.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [ 0.  0. 16. 14. 25.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[-5  0  0  0  0  0 40  0  0  0  0  0  0  0  0  0] 
sum of rewards: 35 

action type: take_action - action -1.0
Learning step: 0
desired expected reward: 27.174211502075195



Player 0 won the game! 



Player 0 bought cards:
Copper: 0 
Silver: 0 
Gold: 0 
Estate: 0 
Duchy: 0 
Province: 0 
Curse: 0 

Remodel: 0 
Workshop: 7 
Chapel: 6 
Witch: 3 
Poacher: 4 
Militia: 0 
Market: 0 
Village: 0 
Library: 0 
Moneylender: 0 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [0.] 
cards in discard: [ 3. 11. 15.  8. 11.] 
cards in deck: 24 
card top of deck: [] 
played cards: [29. 29.] 
owned cards: [ 0  0  0  0  3  3 29 11  8 25 29 29  8 25 25 11 11 11 29  8  8 10  8 11
  8 11 15 15 15 15 15 11] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 27. 30. 24. 30.  8.  0.  8.  0.  0.  6.  6.  8. 10.  3. 10.  2.] 
adversary cards in hand: [ 0.  0. 16. 14. 25.] 
adversary cards in discard: [ 6.  8.  0.  6.  0.  0.  3. 16.  0.  0.  6.] 
adversary owned cards: [16  8  8  8  6  6  6  6  0  0  0  0 14  1  0 16  3  0 25 15  0  0  0 14
  0  0  0  3] -> size -> 28 
adversary victory points: -2
player victory points: 2 

Reward from previous game state: 
[ -5 500   0   0   0   0  40   0   0   0   0   0   0   0   9   0] 
sum of rewards: 544 

action type: buy - action 11.0
Learning step: 15.463543891906738
desired expected reward: 44.01203918457031



