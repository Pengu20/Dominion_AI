 --------- CARDS IN THIS GAME --------- 
Game cards: [['Copper' '0' '0']
 ['Silver' '1' '3']
 ['Gold' '2' '6']
 ['Estate' '3' '2']
 ['Duchy' '4' '5']
 ['Province' '5' '8']
 ['Curse' '6' '0']
 ['Remodel' '16' '4']
 ['Workshop' '11' '3']
 ['Chapel' '8' '2']
 ['Witch' '25' '5']
 ['Poacher' '29' '4']
 ['Militia' '14' '4']
 ['Market' '23' '5']
 ['Village' '10' '3']
 ['Library' '22' '5']
 ['Moneylender' '15' '4']]






         -------------------- Turn: 1 -------------------- 
Player: 0 
cards in hand: [0. 0. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[288.80334]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[  -5 -500   -2  -60    0    0   20    0    0    0    0    0    0    0
    4    0] 
sum of rewards: -543 

action type: buy - action 8.0
Learning step: -26.802993774414062
desired expected reward: -33.74311447143555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[259.79047]
 [276.93802]
 [269.82654]
 [224.3909 ]
 [286.00638]
 [271.8211 ]
 [267.01434]
 [289.8998 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 3 
card supply: [30. 30. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.439969062805176
desired expected reward: 281.8568115234375



buy possibilites: [-1] 
expected returns: [[285.19473]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 3. 3.] 
cards in discard: [1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 0. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 18  0] 
sum of rewards: 16 

action type: buy - action 1.0
Learning step: -6.630019664764404
desired expected reward: 270.3080139160156






Player: 1 
cards in hand: [0. 0. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 1 
buys: 0 
player value: 0 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3] -> size -> 10 
action values: 0 
buys: 1 
player value: 5 
card supply: [30. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 0.] 
cards in discard: [0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 0 
player value: 5 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 3. 0. 0. 0.] 
adversary cards in discard: [1. 0. 0. 0. 3. 3.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 2 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[320.9894]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.146311283111572
desired expected reward: 278.0484313964844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[296.2463 ]
 [315.58463]
 [307.2273 ]
 [261.90198]
 [304.3466 ]
 [325.72153]
 [309.41058]
 [310.3646 ]
 [278.3868 ]
 [303.37833]
 [295.02988]
 [329.88492]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [1. 0. 0. 0. 3. 3.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 1] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -9.136658668518066
desired expected reward: 311.4600524902344



buy possibilites: [-1] 
expected returns: [[302.27335]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 0. 0.] 
cards in discard: [ 1.  0.  0.  0.  3.  3. 10.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [0. 0. 0. 0. 0. 0.] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5.   0.   3.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
  4.5  0. ] 
sum of rewards: 2.5 

action type: buy - action 10.0
Learning step: -8.242765426635742
desired expected reward: 295.1355285644531






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [0. 0. 0. 0. 0. 0.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 3 -------------------- 
Player: 0 
cards in hand: [3. 3. 1. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[284.32407]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -8.765424728393555
desired expected reward: 293.5079345703125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[256.8948 ]
 [271.28314]
 [263.13968]
 [223.17883]
 [263.23163]
 [278.1438 ]
 [268.15436]
 [268.63016]
 [239.49025]
 [261.2391 ]
 [254.737  ]
 [279.55545]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10. 10.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -8.442825317382812
desired expected reward: 278.145751953125



buy possibilites: [-1] 
expected returns: [[266.97763]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1. 0. 0.] 
cards in discard: [15.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [0. 0. 3. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0 32  0] 
sum of rewards: 30 

action type: buy - action 15.0
Learning step: -5.229852199554443
desired expected reward: 249.50711059570312






Player: 1 
cards in hand: [0. 0. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [15.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [0 0 0 0 0 0 0 3 3 3 0] -> size -> 11 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  9. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [15.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 0. 0.] 
cards in discard: [10.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 10.  0.  3.] 
adversary cards in discard: [15.  3.  3.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
adversary victory points: 3
player victory points: 3 





         -------------------- Turn: 4 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 10.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[271.26147]
 [253.29034]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [15.  3.  3.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: buy - action -1
Learning step: -7.608772277832031
desired expected reward: 259.3688659667969





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[248.41954]
 [262.86215]
 [255.45566]
 [219.30507]
 [270.06418]
 [259.37918]
 [253.58435]
 [272.00845]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [15.  3.  3.  1.  0.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8. 10. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 3 

Reward from previous game state: 
[-5  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0] 
sum of rewards: -2 

action type: take_action - action -1.0
Learning step: -7.5621843338012695
desired expected reward: 258.6724548339844



buy possibilites: [-1] 
expected returns: [[260.39963]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 10.  0.  3.] 
cards in discard: [15.  3.  3.  1.  0.  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [10.  0.  0.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[  -5.    0.    2.  -10.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -313.0 

action type: buy - action 6.0
Learning step: -20.756261825561523
desired expected reward: 198.548828125






Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [10.  0.  0.  3.  0.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 5 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[279.68225]
 [255.80582]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1
Learning step: -7.590188503265381
desired expected reward: 252.80943298339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[247.6059 ]
 [262.77353]
 [255.8146 ]
 [216.53328]
 [254.34882]
 [268.57037]
 [257.97607]
 [258.3216 ]
 [230.7429 ]
 [252.13513]
 [245.61258]
 [269.87265]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 15.  0.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.809910774230957
desired expected reward: 269.99896240234375



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [0. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10] -> size -> 12 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 30. 30.  8.  9. 10. 10. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 3.] 
cards in discard: [11.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [0. 3. 3. 3. 1.] 
adversary cards in discard: [ 0.  0. 15.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
adversary victory points: 2
player victory points: 3 





         -------------------- Turn: 6 -------------------- 
Player: 0 
cards in hand: [0. 3. 3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[281.71603]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 0.  0. 15.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: buy - action -1.0
Learning step: -7.806294918060303
desired expected reward: 262.06634521484375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[249.2341 ]
 [267.02353]
 [259.3874 ]
 [214.55507]
 [275.30185]
 [261.49396]
 [255.83844]
 [278.13498]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 0.  0. 15.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  9. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -10   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -13 

action type: take_action - action -1.0
Learning step: -8.803964614868164
desired expected reward: 272.8554992675781



buy possibilites: [-1] 
expected returns: [[242.44882]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 3. 1.] 
cards in discard: [ 0.  0. 15.  0.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  3.  0.  0.] 
adversary cards in discard: [11.  0.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[  -5.    0.    1.  -20.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -324.0 

action type: buy - action 6.0
Learning step: -21.071592330932617
desired expected reward: 193.48345947265625






Player: 1 
cards in hand: [ 0. 10.  3.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  0.  0.  0.  0.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11] -> size -> 13 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 30. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  3.  0.  0.] 
cards in discard: [11.  0.  0.  0.  0.  3.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 1.  6. 10.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 7 -------------------- 
Player: 0 
cards in hand: [ 1.  6. 10.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[221.38849]
 [204.42609]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  6. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -8.996696472167969
desired expected reward: 233.45211791992188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[194.10513]
 [209.02654]
 [201.99817]
 [162.05212]
 [200.6298 ]
 [215.09454]
 [204.49614]
 [204.81609]
 [176.78755]
 [198.91933]
 [192.37701]
 [216.31248]]
Chosen buy action: 14.0 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  0.] 
cards in discard: [] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6] -> size -> 15 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10. 10. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: take_action - action -1.0
Learning step: -8.176633834838867
desired expected reward: 212.83868408203125



buy possibilites: [-1] 
expected returns: [[184.50229]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  6. 10.  0.  0.] 
cards in discard: [14.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  0.  3.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0  32   0] 
sum of rewards: -2 

action type: buy - action 14.0
Learning step: -4.788076877593994
desired expected reward: 171.99949645996094






Player: 1 
cards in hand: [ 0. 10.  0.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3] -> size -> 14 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 29. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  0.  3.  0.] 
cards in discard: [1.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 0.  0. 15.  0.  6.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 16 
adversary victory points: 1
player victory points: 4 





         -------------------- Turn: 8 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 15.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[167.68823]
 [146.52487]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 15.  0.  6.] 
cards in discard: [14.  1.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -34 

action type: buy - action -1
Learning step: -7.390541076660156
desired expected reward: 177.11175537109375



action possibilites: [-1] 
expected returns: [[204.20973]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  1.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 15 
action values: 0 
buys: 0 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action 15.0
Learning step: -3.279127597808838
desired expected reward: 140.1977996826172





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[183.013  ]
 [197.01283]
 [190.3951 ]
 [164.94077]
 [154.93633]
 [188.97267]
 [203.09428]
 [192.71416]
 [215.19926]
 [192.98312]
 [167.94984]
 [176.87166]
 [187.65761]
 [162.08269]
 [181.64154]
 [204.02509]]
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  1.  6. 10.  0.  0.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14] -> size -> 15 
action values: 0 
buys: 1 
player value: 5 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9. 10.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -14 

action type: take_action - action -1
Learning step: -6.549380779266357
desired expected reward: 197.6603546142578



buy possibilites: [-1] 
expected returns: [[194.65157]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6.] 
cards in discard: [14.  1.  6. 10.  0.  0. 23.] 
cards in deck: 5 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 11.  0.  0.] 
adversary cards in discard: [ 1.  0. 10.  0.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
adversary victory points: 4
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -30   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 36 

action type: buy - action 23.0
Learning step: -2.6639244556427
desired expected reward: 174.207763671875






Player: 1 
cards in hand: [ 3.  0. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 11.  0.  0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1] -> size -> 15 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  8. 10.  9. 10. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
adversary victory points: 1
player victory points: 4 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6] -> size -> 16 
action values: 0 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9. 10. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
adversary victory points: 1
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6] -> size -> 16 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9. 10. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
adversary victory points: 1
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0. 0.] 
cards in discard: [ 1.  0. 10.  0.  3.  0.  6.  8.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 0 
buys: 0 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 3.] 
adversary cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
adversary victory points: 1
player victory points: 3 





         -------------------- Turn: 9 -------------------- 
Player: 0 
cards in hand: [0. 3. 0. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[148.92206]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: buy - action -1
Learning step: -7.617906093597412
desired expected reward: 187.03366088867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[130.42464]
 [138.10632]
 [101.17211]
 [140.4443 ]
 [149.10828]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23] -> size -> 16 
action values: 0 
buys: 1 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  7. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -20   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -24 

action type: take_action - action -1.0
Learning step: -5.487795352935791
desired expected reward: 141.83096313476562



buy possibilites: [-1] 
expected returns: [[149.68944]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 3.] 
cards in discard: [14.  1.  6. 10.  0.  0. 23. 15.  0.  0.  6.  6.] 
cards in deck: 0 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 3. 0. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[  -5.    0.    0.  -30.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -335.0 

action type: buy - action 6.0
Learning step: -18.440595626831055
desired expected reward: 82.73152160644531






Player: 1 
cards in hand: [0. 3. 0. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 0. 3. 0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [10.  1.  0. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 10 -------------------- 
Player: 0 
cards in hand: [10.  1.  0. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 15.] 
expected returns: [[163.48753]
 [150.70276]
 [145.82399]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  1.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1
Learning step: -5.720048427581787
desired expected reward: 143.96939086914062





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[143.56296 ]
 [156.1325  ]
 [149.3579  ]
 [119.473694]
 [149.10535 ]
 [160.95091 ]
 [152.90399 ]
 [153.12851 ]
 [130.09424 ]
 [147.3703  ]
 [141.73373 ]
 [161.49852 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  1.  0. 15.  0.] 
cards in discard: [] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 4 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0. 10.  6.  0.  0.] 
adversary cards in discard: [0. 3. 0. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1.0
Learning step: -6.514329433441162
desired expected reward: 156.8307342529297



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  0.  0.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 23.] 
adversary cards in discard: [10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 2 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 23.] 
adversary cards in discard: [10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0. 3.] 
cards in discard: [0. 3. 0. 3. 0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 0 
buys: 1 
player value: 3 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  6.  3. 23.] 
adversary cards in discard: [10.  1.  0. 15.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 





         -------------------- Turn: 11 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  6.  3. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[206.81172]
 [183.69077]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  6.  3. 23.] 
cards in discard: [10.  1.  0. 15.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 11.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: buy - action -1.0
Learning step: -5.368916034698486
desired expected reward: 156.12960815429688



action possibilites: [-1.] 
expected returns: [[211.15135]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [10.  1.  0. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 1 
buys: 1 
player value: 1 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 11.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action 23.0
Learning step: -5.154377460479736
desired expected reward: 177.95127868652344





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[190.01765]
 [197.58545]
 [156.99095]
 [201.66533]
 [213.32863]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 3. 6.] 
cards in discard: [10.  1.  0. 15.  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 0 
buys: 2 
player value: 2 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 1.  8. 11.  0.  0.] 
adversary cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
adversary victory points: 3
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -15 

action type: take_action - action -1.0
Learning step: -6.85109281539917
desired expected reward: 204.30026245117188






Player: 1 
cards in hand: [ 1.  8. 11.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  8. 11.  0.  0.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [29. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0] -> size -> 18 
action values: 0 
buys: 1 
player value: 4 
card supply: [28. 28. 30. 29. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 3 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0. 0.] 
cards in discard: [ 0.  3.  0.  3.  0. 10.  0.  6.  0.  0.  3.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 0.  6.  0. 14.  0.] 
adversary cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
adversary victory points: 0
player victory points: 4 





         -------------------- Turn: 12 -------------------- 
Player: 0 
cards in hand: [ 0.  6.  0. 14.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[125.19169 ]
 [ 93.199875]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  0. 14.  0.] 
cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0. 10.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: buy - action -1.0
Learning step: -10.406329154968262
desired expected reward: 202.9222869873047



action possibilites: [-1] 
expected returns: [[163.49411]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action 14.0
Learning step: -1.8116130828857422
desired expected reward: 82.99299621582031





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[148.14015]
 [159.73235]
 [155.46034]
 [134.81018]
 [127.32095]
 [153.14162]
 [165.21536]
 [155.50189]
 [174.37836]
 [155.74715]
 [137.20752]
 [144.13985]
 [152.3865 ]
 [133.00214]
 [147.45691]
 [166.71255]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6] -> size -> 17 
action values: 0 
buys: 1 
player value: 5 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9. 10. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -25 

action type: take_action - action -1
Learning step: -5.881825923919678
desired expected reward: 157.61228942871094



buy possibilites: [-1] 
expected returns: [[146.4576]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [10.  1.  0. 15.  0. 23.  3.  0.  6.  3.  6. 25.] 
cards in deck: 1 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 3.] 
adversary cards in discard: [10.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
adversary victory points: 4
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -40   0   0  20   0   0   0   0   0   0   0  50   0] 
sum of rewards: 25 

action type: buy - action 25.0
Learning step: -4.173622131347656
desired expected reward: 170.20474243164062






Player: 1 
cards in hand: [0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [23. 14.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
adversary victory points: 0
player victory points: 4 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3] -> size -> 19 
action values: 0 
buys: 1 
player value: 2 
card supply: [28. 28. 30. 28. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [23. 14.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
adversary victory points: 0
player victory points: 4 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3.] 
cards in discard: [10.  3.  3.] 
cards in deck: 14 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
action values: 0 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [23. 14.  6.  0.  3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
adversary victory points: 0
player victory points: 5 





         -------------------- Turn: 13 -------------------- 
Player: 0 
cards in hand: [23. 14.  6.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 14.] 
expected returns: [[169.54785]
 [147.45958]
 [140.73195]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 14.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
action values: 1 
buys: 0 
player value: 0 
card supply: [28. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 1. 0. 0. 3.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: buy - action -1
Learning step: -6.539157867431641
desired expected reward: 139.91844177246094



action possibilites: [-1] 
expected returns: [[152.50624]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
action values: 0 
buys: 0 
player value: 2 
card supply: [28. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action 14.0
Learning step: -5.346244812011719
desired expected reward: 135.20645141601562





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[138.82281]
 [151.77142]
 [144.81915]
 [114.29826]
 [156.91443]
 [148.35834]
 [142.72244]
 [157.55531]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.  3.] 
cards in discard: [] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25] -> size -> 18 
action values: 0 
buys: 1 
player value: 3 
card supply: [28. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -35 

action type: take_action - action -1
Learning step: -6.041195869445801
desired expected reward: 146.4650421142578



buy possibilites: [-1] 
expected returns: [[223.8651]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  6.  0.  3.] 
cards in discard: [0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
action values: 0 
buys: 0 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [0. 0. 0.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
adversary victory points: 5
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -50.   0.   0.  20. -30.   0.   0.   0.   0.   0.   0.
   0.   0.] 
sum of rewards: -65.0 

action type: buy - action 0.0
Learning step: -5.154175281524658
desired expected reward: 133.6686248779297






Player: 1 
cards in hand: [0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
adversary victory points: 0
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3] -> size -> 20 
action values: 0 
buys: 1 
player value: 3 
card supply: [27. 28. 30. 27. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
adversary victory points: 0
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [6. 1. 0. 0. 0.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 14 -------------------- 
Player: 0 
cards in hand: [6. 1. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[145.7354]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0. 14. 23.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -11.193679809570312
desired expected reward: 212.67141723632812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[131.15988 ]
 [143.84413 ]
 [139.28053 ]
 [114.58036 ]
 [105.94968 ]
 [136.76826 ]
 [149.80344 ]
 [139.37048 ]
 [157.74374 ]
 [139.71143 ]
 [118.00627 ]
 [126.89407 ]
 [136.1278  ]
 [112.751045]
 [130.63374 ]
 [151.64676 ]]
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0. 14. 23.  6.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0] -> size -> 19 
action values: 0 
buys: 1 
player value: 5 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9. 10.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -7.312629699707031
desired expected reward: 137.1129150390625



buy possibilites: [-1] 
expected returns: [[110.46345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 1. 0. 0. 0.] 
cards in discard: [ 0. 14. 23.  6.  0.  3. 29.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
action values: 0 
buys: 0 
player value: 1 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 8.  0. 11.  0.  6.] 
adversary cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3] -> size -> 21 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.   0.   0. -60.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   8.   0.] 
sum of rewards: -57.0 

action type: buy - action 29.0
Learning step: -7.3501434326171875
desired expected reward: 132.3612823486328






Player: 1 
cards in hand: [ 8.  0. 11.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  0. 11.  0.  6.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  8. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25. 10.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10] -> size -> 22 
action values: 0 
buys: 0 
player value: 0 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25. 10.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0. 10.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10] -> size -> 22 
action values: 0 
buys: 1 
player value: 2 
card supply: [27. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25. 10.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 0. 0. 6.] 
cards in discard: [10.  3.  3.  0.  0.  3.  1.  3.  3.  0.  0.  0. 10.  0.] 
cards in deck: 4 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 0 
buys: 0 
player value: 2 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  0.  3. 25. 10.] 
adversary cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 15 -------------------- 
Player: 0 
cards in hand: [ 3.  0.  3. 25. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 10.] 
expected returns: [[142.95572]
 [152.75526]
 [130.60463]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3. 25. 10.] 
cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -5.535504341125488
desired expected reward: 104.92794036865234





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[126.74562 ]
 [103.820465]
 [142.55042 ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25. 10.] 
cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29] -> size -> 20 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  6. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -7.4244561195373535
desired expected reward: 134.38101196289062



buy possibilites: [-1] 
expected returns: [[98.370895]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  3. 25. 10.] 
cards in discard: [ 0. 14. 23.  6.  0.  3. 29.  6.  1.  0.  0.  0.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6] -> size -> 21 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  5. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[  -5.    0.   -1.  -70.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -376.0 

action type: buy - action 6.0
Learning step: -21.777677536010742
desired expected reward: 82.04278564453125






Player: 1 
cards in hand: [0. 0. 3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [14.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  5. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [14.  3.  6.  0. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6] -> size -> 21 
adversary victory points: -1
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 16 -------------------- 
Player: 0 
cards in hand: [14.  3.  6.  0. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14. 15.] 
expected returns: [[155.67122]
 [132.30174]
 [141.11559]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  3.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6] -> size -> 21 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  5. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: buy - action -1
Learning step: -5.521954536437988
desired expected reward: 92.84893798828125





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[138.16383]
 [119.79597]
 [151.80637]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0. 15.] 
cards in discard: [] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6] -> size -> 21 
action values: 0 
buys: 1 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  5. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -76 

action type: take_action - action -1.0
Learning step: -8.182769775390625
desired expected reward: 142.90386962890625



buy possibilites: [-1] 
expected returns: [[72.64592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  3.  6.  0. 15.] 
cards in discard: [6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 3.  1. 10. 10.  3.] 
adversary cards in discard: [0. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -80.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -387.0 

action type: buy - action 6.0
Learning step: -23.496862411499023
desired expected reward: 96.29910278320312






Player: 1 
cards in hand: [ 3.  1. 10. 10.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10. 10.  3.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  1.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 2 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  1.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [0. 0. 3. 3. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0] -> size -> 23 
action values: 0 
buys: 1 
player value: 3 
card supply: [26. 28. 30. 26. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  1.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1. 10.  3.  0.] 
cards in discard: [0. 0. 3. 3. 0. 3.] 
cards in deck: 12 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3] -> size -> 24 
action values: 0 
buys: 0 
player value: 1 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [ 0.  0.  0. 23.  1.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 17 -------------------- 
Player: 0 
cards in hand: [ 0.  0.  0. 23.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[77.17786 ]
 [59.425083]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 23.  1.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3] -> size -> 24 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -6.9360198974609375
desired expected reward: 65.70989990234375





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[61.794964]
 [71.48983 ]
 [67.7822  ]
 [49.882404]
 [45.028538]
 [65.80663 ]
 [75.6853  ]
 [67.757614]
 [82.898445]
 [67.80324 ]
 [52.284428]
 [58.716206]
 [64.99537 ]
 [48.92691 ]
 [60.962307]
 [76.6431  ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 23.  1.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6] -> size -> 22 
action values: 0 
buys: 1 
player value: 5 
card supply: [26. 28. 30. 25. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3] -> size -> 24 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: take_action - action -1.0
Learning step: -7.0431084632873535
desired expected reward: 67.94986724853516



buy possibilites: [-1] 
expected returns: [[107.065544]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 23.  1.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [26. 28. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [11.  0.  6.  0.  0.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3] -> size -> 24 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5.   0.  -1. -80.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -84.0 

action type: buy - action 3.0
Learning step: -5.180135250091553
desired expected reward: 62.6020622253418






Player: 1 
cards in hand: [11.  0.  6.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  6.  0.  0.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [26. 28. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0] -> size -> 25 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 28. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 28. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 0. 0.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [10.  0. 25.  0.  6.] 
adversary cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 18 -------------------- 
Player: 0 
cards in hand: [10.  0. 25.  0.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 25.] 
expected returns: [[50.58978 ]
 [41.68522 ]
 [58.310238]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0. 25.  0.  6.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  4. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1] -> size -> 26 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -8.471458435058594
desired expected reward: 98.59408569335938



action possibilites: [-1] 
expected returns: [[75.68089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  0.  0.  6.  6.  3.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 25.0
Learning step: -4.512691974639893
desired expected reward: 53.79754638671875





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[49.904537]
 [60.02625 ]
 [23.813526]
 [60.181496]
 [75.282295]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  0.  0.  6.  6.  3.] 
cards in discard: [ 6. 14.  3.  6.  0. 15.  3.  0.  0.  0. 23.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 24. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [0. 0. 3. 3. 8.] 
adversary cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6] -> size -> 27 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action -1
Learning step: -5.7340874671936035
desired expected reward: 69.94680786132812






Player: 1 
cards in hand: [0. 0. 3. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 24. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [25.  3.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6] -> size -> 27 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 24. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [25.  3.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 8.] 
cards in discard: [ 0.  0.  3.  3.  0.  3. 10.  3.  1. 10.  3.  0.  0.  1. 11.  0.  6.  0.
  0.  6.  3.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [25.  3.  6. 29.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 19 -------------------- 
Player: 0 
cards in hand: [25.  3.  6. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[ 97.92535 ]
 [104.13595 ]
 [ 94.154594]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  6. 29.  0.] 
cards in discard: [] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -5.855127811431885
desired expected reward: 69.42716217041016



action possibilites: [-1. 25. 14.] 
expected returns: [[62.13648 ]
 [69.734314]
 [45.33711 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  6.  0. 14.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 1 
buys: 0 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 0. 3. 3. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -66 

action type: take_action - action 29.0
Learning step: -6.504207134246826
desired expected reward: 85.5391845703125



action possibilites: [-1] 
expected returns: [[11.9009075]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 0 
buys: 0 
player value: 3 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action 14.0
Learning step: -4.299086093902588
desired expected reward: 41.03803634643555





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[ -3.5879467 ]
 [  4.497179  ]
 [  2.9729729 ]
 [-15.764051  ]
 [ -0.35212564]
 [  8.818136  ]
 [  0.7719765 ]
 [  0.73572016]
 [-11.074833  ]
 [ -0.05189419]
 [ -3.3455732 ]
 [  9.027452  ]]
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  6.  0.] 
cards in discard: [] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3] -> size -> 23 
action values: 0 
buys: 1 
player value: 4 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  9.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -46 

action type: take_action - action -1
Learning step: -2.846550464630127
desired expected reward: 9.054357528686523



buy possibilites: [-1] 
expected returns: [[51.957592]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  3.  6.  0.] 
cards in discard: [15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [29. 14.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0.] 
adversary cards in discard: [3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0  40   0   0   0   0   0   0   0  32   0] 
sum of rewards: -14 

action type: buy - action 15.0
Learning step: 0.6363255381584167
desired expected reward: -2.7092690467834473






Player: 1 
cards in hand: [3. 3. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0.] 
cards in discard: [3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0.] 
cards in discard: [3. 0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 1 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 6. 6. 0.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 7 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 20 -------------------- 
Player: 0 
cards in hand: [3. 0. 6. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[19.735926]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1
Learning step: -6.453821659088135
desired expected reward: 45.50376892089844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 9.890968]
 [14.026493]
 [ 3.643804]
 [13.010157]
 [18.674154]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 6. 6. 0.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 3.  0.  0. 11.  0.] 
adversary cards in discard: [3. 0. 3. 3. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.976097106933594
desired expected reward: 14.759828567504883



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 3.  0.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [3. 0. 3. 3. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3] -> size -> 28 
action values: 0 
buys: 1 
player value: 3 
card supply: [25. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0.  0. 11.  0.] 
cards in discard: [3. 0. 3. 3. 0. 0.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  0.  0.  6.  6.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
adversary victory points: -1
player victory points: 7 





         -------------------- Turn: 21 -------------------- 
Player: 0 
cards in hand: [15.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[15.2125  ]
 [ 7.327045]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  0.  0.  6.  6.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: buy - action -1.0
Learning step: -4.9546661376953125
desired expected reward: 13.719503402709961





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
expected returns: [[ 7.550551  ]
 [11.753515  ]
 [-0.07635403]
 [10.255653  ]
 [15.64632   ]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  6.  6.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15] -> size -> 24 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8.  3. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -1 

Reward from previous game state: 
[ -5   0  -1 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -86 

action type: take_action - action -1.0
Learning step: -4.814769268035889
desired expected reward: 10.397726058959961



buy possibilites: [-1] 
expected returns: [[0.3186345]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [15.  0.  0.  6.  6.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 0. 3. 1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -90.    0.    0.    0.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -397.0 

action type: buy - action 6.0
Learning step: -19.75679588317871
desired expected reward: -19.83315086364746






Player: 1 
cards in hand: [3. 3. 0. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10.  3. 23.  1.  0.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  9.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10.  3. 23.  1.  0.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 0. 3. 1.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10.  3. 23.  1.  0.] 
adversary cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 22 -------------------- 
Player: 0 
cards in hand: [10.  3. 23.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23.] 
expected returns: [[63.385757]
 [49.23878 ]
 [41.581112]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3. 23.  1.  0.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -3.6319656372070312
desired expected reward: -3.313331127166748



action possibilites: [-1. 23.] 
expected returns: [[101.7805 ]
 [ 83.98286]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action 10.0
Learning step: -4.164609432220459
desired expected reward: 45.07417297363281





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[85.38643 ]
 [95.66193 ]
 [90.21465 ]
 [67.68466 ]
 [99.31523 ]
 [92.31817 ]
 [87.7412  ]
 [97.881165]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6] -> size -> 25 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 27. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -6.861454963684082
desired expected reward: 94.9190444946289



buy possibilites: [-1] 
expected returns: [[72.09344]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3. 23.  1.  0.  3.] 
cards in discard: [15. 29. 14. 25.  3.  6.  0.  3.  0.  6.  6.  0.  6. 15.  0.  0.  6.  6.
  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [10. 10.  3.  0.  1.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -59 

action type: buy - action 1.0
Learning step: -6.110995292663574
desired expected reward: 89.55095672607422






Player: 1 
cards in hand: [10. 10.  3.  0.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  0.  1.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  0.  1.  6.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
cards in deck: 7 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 7 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
action values: 3 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 29.0 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8] -> size -> 30 
action values: 0 
buys: 1 
player value: 4 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  9.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 6. 0.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.] 
cards in deck: 6 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [15.  1.  0.  0.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
adversary victory points: -2
player victory points: 7 





         -------------------- Turn: 23 -------------------- 
Player: 0 
cards in hand: [15.  1.  0.  0.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[43.961452]
 [33.894234]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  0.  0.  0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15
  6  1] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -97 

action type: buy - action -1
Learning step: -7.561566352844238
desired expected reward: 64.53186798095703



action possibilites: [-1] 
expected returns: [[12.995693]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1] -> size -> 25 
action values: 0 
buys: 0 
player value: 3 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action 15.0
Learning step: -5.2177276611328125
desired expected reward: 27.984886169433594





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 4.550111  ]
 [ 9.022368  ]
 [ 1.5731919 ]
 [ 4.93108   ]
 [ 0.9545572 ]
 [-2.5503302 ]
 [ 6.0131865 ]
 [11.108813  ]
 [ 8.262332  ]
 [19.73056   ]
 [ 7.928727  ]
 [ 0.50105405]
 [ 1.2269304 ]
 [ 4.6579447 ]
 [-0.34529972]
 [ 3.03425   ]
 [ 9.003095  ]]
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1] -> size -> 25 
action values: 0 
buys: 1 
player value: 7 
card supply: [24. 26. 30. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1
Learning step: -4.287773132324219
desired expected reward: 8.70792007446289



buy possibilites: [-1] 
expected returns: [[14.652948]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0.] 
cards in discard: [2.] 
cards in deck: 21 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 0 
buys: 0 
player value: 1 
card supply: [24. 26. 29. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 0. 8. 3. 6.] 
adversary cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
adversary victory points: 7
player victory points: -2 

Reward from previous game state: 
[  -5.    0.   -2.  -90.    0.    0.   20.    0.    0. 1700.    0.    0.
    0.    0.   18.    0.] 
sum of rewards: 1641.0 

action type: buy - action 2.0
Learning step: 82.30103302001953
desired expected reward: 83.8742446899414






Player: 1 
cards in hand: [0. 0. 8. 3. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  6.  3. 14.] 
adversary cards in discard: [ 2. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29] -> size -> 31 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 23. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  6.  3. 14.] 
adversary cards in discard: [ 2. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 8. 3. 6.] 
cards in discard: [ 3.  0.  3.  3.  0.  0.  3.  0.  0. 11.  0.  8.  3.  3.  0.  3.  1. 29.
 10. 10.  3.  0.  1.  6.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3.  6.  3. 14.] 
adversary cards in discard: [ 2. 15.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 24 -------------------- 
Player: 0 
cards in hand: [ 0.  3.  6.  3. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[14.626377 ]
 [ 5.5271816]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  6.  3. 14.] 
cards in discard: [ 2. 15.  1.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 1. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1
Learning step: -5.826526165008545
desired expected reward: 8.826421737670898



action possibilites: [-1] 
expected returns: [[63.88276]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 2. 15.  1.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 0 
buys: 0 
player value: 2 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 1.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action 14.0
Learning step: -3.188997507095337
desired expected reward: 2.3381898403167725





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[47.81555 ]
 [59.342064]
 [54.513718]
 [27.630814]
 [63.275017]
 [55.22067 ]
 [51.205715]
 [63.33883 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3.] 
cards in discard: [ 2. 15.  1.  0.  0.] 
cards in deck: 16 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 3. 1.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1
Learning step: -6.288166046142578
desired expected reward: 57.5945930480957






Player: 1 
cards in hand: [3. 3. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 1.] 
cards in discard: [0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  6.  3.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [0. 0.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3] -> size -> 32 
action values: 0 
buys: 1 
player value: 2 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  8.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  6.  3.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 1.] 
cards in discard: [0. 0. 8.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [ 0.  3. 10.  6.  3.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
adversary victory points: -2
player victory points: 8 





         -------------------- Turn: 25 -------------------- 
Player: 0 
cards in hand: [ 0.  3. 10.  6.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[41.293564]
 [33.12114 ]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3. 10.  6.  3.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -107 

action type: buy - action -1.0
Learning step: -7.65337610244751
desired expected reward: 55.68544387817383



action possibilites: [-1.] 
expected returns: [[65.060165]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 6. 3. 1.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 2 
buys: 0 
player value: 0 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    2] 
sum of rewards: -85 

action type: take_action - action 10.0
Learning step: -4.442203044891357
desired expected reward: 28.67892837524414





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[50.647633]
 [60.66489 ]
 [56.26791 ]
 [30.985966]
 [64.44139 ]
 [57.055336]
 [53.3759  ]
 [65.12807 ]]
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 1.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2] -> size -> 26 
action values: 0 
buys: 1 
player value: 3 
card supply: [24. 26. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -6.302947521209717
desired expected reward: 58.75721740722656



buy possibilites: [-1] 
expected returns: [[44.215824]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 6. 3. 1.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1.] 
cards in deck: 10 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [3. 0. 3. 8. 8.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
adversary victory points: 8
player victory points: -2 

Reward from previous game state: 
[  -5    0   -2 -100    0    0   20    0    0    0    0    0    0    0
   18    0] 
sum of rewards: -69 

action type: buy - action 1.0
Learning step: -5.4883880615234375
desired expected reward: 55.17649459838867






Player: 1 
cards in hand: [3. 0. 3. 8. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 8. 8.] 
cards in discard: [0. 0. 8. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  3  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3
  0  1  6  3  0  8 29  3  8] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  6.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
adversary victory points: -2
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [24. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  6.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8. 3. 3. 1.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8] -> size -> 31 
action values: 0 
buys: 1 
player value: 1 
card supply: [24. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  6.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 8.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
action values: 0 
buys: 0 
player value: 1 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [29.  0.  0.  6.  6.] 
adversary cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 26 -------------------- 
Player: 0 
cards in hand: [29.  0.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
expected returns: [[44.940697]
 [37.577084]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  0.  0.  6.  6.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
cards in deck: 5 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.608679294586182
desired expected reward: 38.60714340209961



action possibilites: [-1.] 
expected returns: [[95.62335]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
action values: 1 
buys: 0 
player value: 1 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 29.0
Learning step: -2.787036657333374
desired expected reward: 28.98419952392578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[85.90276 ]
 [95.725426]
 [88.842316]
 [67.08384 ]
 [97.17247 ]
 [93.07026 ]
 [87.06716 ]
 [95.155075]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1] -> size -> 27 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  9.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1.0
Learning step: -6.07983922958374
desired expected reward: 89.54351043701172



buy possibilites: [-1] 
expected returns: [[36.870617]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 2. 15.  1.  0.  0. 14.  0.  3.  6.  3.  1. 10.  0.  3.  6.  3.  1. 11.] 
cards in deck: 4 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11] -> size -> 28 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [0. 3. 3. 0. 0.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -49 

action type: buy - action 11.0
Learning step: -6.479035377502441
desired expected reward: 90.69344329833984






Player: 1 
cards in hand: [0. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  6. 15. 25. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11] -> size -> 28 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 1.0 : ['Silver' '1' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0] -> size -> 32 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 25. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  6. 15. 25. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11] -> size -> 28 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 3. 3. 0. 0.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [11.  6. 15. 25. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11] -> size -> 28 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 27 -------------------- 
Player: 0 
cards in hand: [11.  6. 15. 25. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 15. 25. 23.] 
expected returns: [[-21.250023]
 [-19.667963]
 [-23.56706 ]
 [-17.928919]
 [-22.903254]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  6. 15. 25. 23.] 
cards in discard: [] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11] -> size -> 28 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  7. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -6.647207736968994
desired expected reward: 30.22340965270996



action possibilites: [-1] 
expected returns: [[14.476089]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 15. 25. 23.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   9   0] 
sum of rewards: -58 

action type: gain_card_n - action 9
Learning step: -1.6197586059570312
desired expected reward: -20.710344314575195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[ 8.686597  ]
 [ 0.21343732]
 [14.554967  ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 15. 25. 23.] 
cards in discard: [10.] 
cards in deck: 23 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [29.  1.  0.  0.  3.] 
adversary cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1. 0. 3. 3. 0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -3.8543689250946045
desired expected reward: 10.621719360351562






Player: 1 
cards in hand: [29.  1.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1. 0. 3. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
Chosen buy action: 16.0 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [0. 0. 8. 3. 3. 1. 0. 8. 0. 8. 1. 0. 3. 3. 0. 0.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1] -> size -> 33 
action values: 0 
buys: 1 
player value: 4 
card supply: [23. 24. 29. 22. 30.  8.  2. 10.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [29.  1.  0.  0.  3.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 28 -------------------- 
Player: 0 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[26.517117]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10. 11.  6. 15. 25. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  6.] 
adversary cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.481113910675049
desired expected reward: 10.073862075805664





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
expected returns: [[19.217459]
 [24.729168]
 [22.836012]
 [ 9.398773]
 [27.388885]
 [22.544159]
 [21.141762]
 [28.019678]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [10. 11.  6. 15. 25. 23.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 3 
card supply: [23. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  3.  3. 11.  6.] 
adversary cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16] -> size -> 34 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -5.143416881561279
desired expected reward: 21.373699188232422



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0.  3.  3. 11.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  3.  3. 11.  6.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [23. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  6.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16] -> size -> 34 
action values: 0 
buys: 1 
player value: 1 
card supply: [23. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  3.  3. 11.  6.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.] 
cards in deck: 7 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0] -> size -> 35 
action values: 0 
buys: 0 
player value: 1 
card supply: [22. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 1. 0. 6. 0.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 29 -------------------- 
Player: 0 
cards in hand: [3. 1. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[18.129036]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  6.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.  0.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -5.343080520629883
desired expected reward: 22.676597595214844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[14.404099]
 [18.675636]
 [17.362669]
 [ 6.450987]
 [16.212969]
 [21.078667]
 [17.028084]
 [17.051907]
 [10.243081]
 [16.30156 ]
 [14.430198]
 [21.913628]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 0. 6. 0.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [22. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0. 10.  6.  3.  0.] 
adversary cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.  0.  3.  3. 11.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0] -> size -> 35 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: take_action - action -1.0
Learning step: -4.859377384185791
desired expected reward: 13.269659042358398



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 10.  6.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  6.  3.  0.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.  0.  3.  3. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [22. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  3.  0.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.  0.  3.  3. 11.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0] -> size -> 35 
action values: 0 
buys: 1 
player value: 2 
card supply: [22. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10.  6.  3.  0.] 
cards in discard: [ 0.  0.  8.  3.  3.  1.  0.  8.  0.  8.  1.  0.  3.  3.  0.  0. 16. 29.
  1.  0.  0.  3.  0.  0.  3.  3. 11.  6.  0.] 
cards in deck: 2 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
action values: 0 
buys: 0 
player value: 2 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  1.  0. 15.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 30 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  0. 15.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[38.96636 ]
 [31.209064]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  0. 15.  6.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6
  1  2  1 11 10] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.6311492919921875
desired expected reward: 17.282480239868164



action possibilites: [-1] 
expected returns: [[48.63293]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10] -> size -> 28 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 15.0
Learning step: -3.8162124156951904
desired expected reward: 27.39285659790039





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[36.008446]
 [44.468742]
 [41.879673]
 [27.318779]
 [24.665277]
 [39.581173]
 [48.316437]
 [40.851185]
 [53.685524]
 [40.765   ]
 [28.76086 ]
 [33.4907  ]
 [39.049294]
 [26.9801  ]
 [35.404037]
 [49.323826]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10] -> size -> 28 
action values: 0 
buys: 1 
player value: 5 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  7.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action -1
Learning step: -4.822752475738525
desired expected reward: 43.810176849365234



buy possibilites: [-1] 
expected returns: [[43.35581]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
action values: 0 
buys: 0 
player value: 3 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0.  0. 10.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.   0.  -2. -80.   0.   0.  20.   0.   0.   0.   0.   0.   0.   0.
   2.   0.] 
sum of rewards: -65.0 

action type: buy - action 8.0
Learning step: -4.317054271697998
desired expected reward: 36.53413772583008






Player: 1 
cards in hand: [ 0.  0.  0.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0.  0. 10.] 
cards in discard: [] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [10. 14.  6. 29.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
adversary victory points: -2
player victory points: 6 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [10. 14.  6. 29.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 2.0 : ['Gold' '2' '6']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0] -> size -> 36 
action values: 0 
buys: 1 
player value: 6 
card supply: [21. 24. 29. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [10. 14.  6. 29.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 0. 1.] 
cards in discard: [2.] 
cards in deck: 30 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [10. 14.  6. 29.  6.] 
adversary cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 31 -------------------- 
Player: 0 
cards in hand: [10. 14.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 14. 29.] 
expected returns: [[51.686623]
 [41.692905]
 [22.908401]
 [45.695583]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 14.  6. 29.  6.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.5343337059021
desired expected reward: 37.821475982666016



action possibilites: [-1. 14. 29.] 
expected returns: [[13.942293 ]
 [ 3.0400321]
 [10.996972 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6. 29.  6.  2.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
cards in deck: 2 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
action values: 2 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: -64 

action type: take_action - action 10.0
Learning step: -4.468816757202148
desired expected reward: 25.700843811035156



action possibilites: [-1. 14.] 
expected returns: [[45.989727]
 [24.648844]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [14.  6.  6.  2.  3.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
action values: 2 
buys: 0 
player value: 1 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 29.0
Learning step: -2.036226987838745
desired expected reward: 8.960750579833984





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 16. 11.  8. 29. 14. 10. 15. -1.] 
expected returns: [[27.373335]
 [38.530827]
 [34.50026 ]
 [15.452425]
 [32.09329 ]
 [42.70562 ]
 [34.160755]
 [33.658268]
 [18.593996]
 [30.692331]
 [25.451458]
 [41.338596]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  2.  3.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8] -> size -> 29 
action values: 0 
buys: 1 
player value: 4 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  8.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -3.8729500770568848
desired expected reward: 42.116764068603516



buy possibilites: [-1] 
expected returns: [[28.71293]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [14.  6.  6.  2.  3.] 
cards in discard: [10. 11.  6. 15. 25. 23.  6.  3.  0.  0.  0.  3.  1.  0.  6.  0.  8. 15.
  3.  1.  6. 11.] 
cards in deck: 1 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 3. 8. 3. 3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5.    0.   -2.  -80.    0.    0.   40.    0.    0.    0.    0.    0.
   0.    0.    4.5   0. ] 
sum of rewards: -42.5 

action type: buy - action 11.0
Learning step: -3.6142404079437256
desired expected reward: 39.09138870239258






Player: 1 
cards in hand: [3. 3. 8. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [29. 25.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2] -> size -> 37 
action values: 1 
buys: 1 
player value: 0 
card supply: [21. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [29. 25.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 3. 8. 3. 3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [29. 25.  0.  6.  1.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 32 -------------------- 
Player: 0 
cards in hand: [29. 25.  0.  6.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 25.] 
expected returns: [[-7.135586 ]
 [-7.0238495]
 [-6.987408 ]]
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [29. 25.  0.  6.  1.] 
cards in discard: [] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1. 10.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0] -> size -> 38 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1
Learning step: -5.943850517272949
desired expected reward: 22.769081115722656



action possibilites: [-1. 25.] 
expected returns: [[-4.6712723]
 [-4.660433 ]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  0.  6.  1.  0.] 
cards in discard: [] 
cards in deck: 24 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 22. 30.  8.  2.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1. 10.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0] -> size -> 38 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -66 

action type: take_action - action 29.0
Learning step: -3.0537540912628174
desired expected reward: -10.07760238647461



action possibilites: [-1] 
expected returns: [[41.535263]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6.  1.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1. 10.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 25.0
Learning step: -1.1824346780776978
desired expected reward: -5.842872619628906





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[32.80794 ]
 [37.878273]
 [37.24665 ]
 [25.838701]
 [23.20072 ]
 [35.91566 ]
 [39.000603]
 [37.007957]
 [40.25381 ]
 [36.91215 ]
 [26.744812]
 [30.072771]
 [35.1484  ]
 [25.074533]
 [31.664232]
 [39.67366 ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1.  0.  3. 15.] 
cards in discard: [] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11] -> size -> 30 
action values: 0 
buys: 1 
player value: 5 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  9.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1. 10.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1
Learning step: -3.6309421062469482
desired expected reward: 37.904319763183594



buy possibilites: [-1] 
expected returns: [[37.322147]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  6.  1.  0.  3. 15.] 
cards in discard: [25.] 
cards in deck: 22 
card top of deck: [] 
played cards: [29. 25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  0. 29.  1. 10.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0  50   0] 
sum of rewards: 3 

action type: buy - action 25.0
Learning step: -1.022942066192627
desired expected reward: 39.230865478515625






Player: 1 
cards in hand: [ 3.  0. 29.  1. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 10.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 29.  1. 10.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 23.  1.  6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1. 10.  8.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  1. 10.  8.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
cards in deck: 19 
card top of deck: [] 
played cards: [29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
action values: 1 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 23.  1.  6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
adversary victory points: -2
player victory points: 5 


action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 1. 8. 1.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
action values: 2 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 23.  1.  6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8. 1.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6] -> size -> 39 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  7.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 23.  1.  6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 1. 8. 1.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11.] 
cards in deck: 18 
card top of deck: [] 
played cards: [29. 10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  6. 23.  1.  6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 33 -------------------- 
Player: 0 
cards in hand: [ 0.  6. 23.  1.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
expected returns: [[-6.037636 ]
 [-3.6986513]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  6. 23.  1.  6.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1
Learning step: -5.818084716796875
desired expected reward: 31.50406265258789



action possibilites: [-1.] 
expected returns: [[6.8953285]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
action values: 1 
buys: 1 
player value: 1 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -56 

action type: take_action - action 23.0
Learning step: -2.4599218368530273
desired expected reward: -6.158585548400879





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4.  6. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ 2.0116003 ]
 [ 6.366624  ]
 [ 5.9328756 ]
 [-0.911458  ]
 [-1.3346671 ]
 [ 3.7653987 ]
 [ 9.028567  ]
 [ 3.9422696 ]
 [ 9.977867  ]
 [ 3.9212286 ]
 [-0.21459961]
 [ 1.7205851 ]
 [ 4.0255537 ]
 [-0.654243  ]
 [ 2.302975  ]
 [10.258093  ]]
Chosen buy action: 25.0 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25] -> size -> 31 
action values: 0 
buys: 2 
player value: 5 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  8.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -57 

action type: take_action - action -1.0
Learning step: -3.0682058334350586
desired expected reward: 3.827122688293457



buy possibilites: [ 0.  6. -1.] 
expected returns: [[39.74263 ]
 [27.785505]
 [48.050285]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 6. 1. 6. 0.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25.] 
cards in deck: 16 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 6. 11.  0.  0.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0  20   0   0   0   0   0   0   0  25   0] 
sum of rewards: -32 

action type: buy - action 25.0
Learning step: -1.1705230474472046
desired expected reward: 8.807343482971191






Player: 1 
cards in hand: [ 6. 11.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  6.  8. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11] -> size -> 40 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  6.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6. 11.  0.  0.  3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 6. 3. 6. 6.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 5 





         -------------------- Turn: 34 -------------------- 
Player: 0 
cards in hand: [3. 6. 3. 6. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[-2.5640466]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8] -> size -> 41 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: buy - action -1.0
Learning step: -6.310204982757568
desired expected reward: 41.74007797241211





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[-2.1346722]
 [-8.845645 ]
 [-2.2476313]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 6. 3. 6. 6.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 1 
buys: 1 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [6. 3. 0. 0. 0.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8] -> size -> 41 
adversary victory points: 5
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -77 

action type: take_action - action -1.0
Learning step: -3.8063113689422607
desired expected reward: -6.370357990264893



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [6. 3. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 10. 10.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 5 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  6. 11.  8. 10. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8] -> size -> 41 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 28. 22. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 10. 10.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 5 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 3. 0. 0. 0.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 21. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 3.  8.  0. 10. 10.] 
adversary cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
adversary victory points: -2
player victory points: 6 





         -------------------- Turn: 35 -------------------- 
Player: 0 
cards in hand: [ 3.  8.  0. 10. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 10. 10.] 
expected returns: [[4.3084955]
 [1.4014976]
 [3.3185985]
 [3.3185985]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10. 10.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -87 

action type: buy - action -1.0
Learning step: -4.16027307510376
desired expected reward: -6.407892227172852



action possibilites: [-1.  8. 10. 11.] 
expected returns: [[18.77199 ]
 [10.736845]
 [10.492228]
 [18.033155]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 10. 11.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
cards in deck: 5 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -67 

action type: take_action - action 10.0
Learning step: -3.027496099472046
desired expected reward: -2.397831678390503



action possibilites: [-1.  8. 11. 11.] 
expected returns: [[49.274822]
 [47.141735]
 [48.413734]
 [48.413734]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8.  0. 11. 11.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 3 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action 10.0
Learning step: -1.781386375427246
desired expected reward: 8.710832595825195





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  6. -1.] 
expected returns: [[46.702606]
 [48.08112 ]
 [47.423756]]
Chosen buy action: 6.0 : ['Curse' '6' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 11. 11.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25] -> size -> 32 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 24. 28. 21. 30.  8.  1.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -2 

Reward from previous game state: 
[ -5   0  -2 -80   0   0  40   0   0   0   0   0   0   0   0   0] 
sum of rewards: -47 

action type: take_action - action -1.0
Learning step: -3.7428009510040283
desired expected reward: 45.53202819824219



buy possibilites: [-1] 
expected returns: [[22.952984]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  8.  0. 11. 11.] 
cards in discard: [25. 29. 25.  0.  6.  1.  0.  3. 15. 25. 23.  0.  6.  1.  6.  0.  3.  6.
  3.  6.  6.  6.] 
cards in deck: 4 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  0.  0. 16.  3.] 
adversary cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[  -5.    0.   -3.  -90.    0.    0.   40.    0.    0.    0.    0.    0.
    0. -300.    0.    0.] 
sum of rewards: -358.0 

action type: buy - action 6.0
Learning step: -19.787612915039062
desired expected reward: 28.29351043701172






Player: 1 
cards in hand: [ 0.  0.  0. 16.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  1.  2. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0.  0. 16.  3.] 
cards in discard: [ 2. 10.  0.  0.  0.  0.  1.  0.  3.  3.  8.  3.  3.  6. 11. 29. 10.  3.
  0.  1.  8.  1.  8.  6. 11.  0.  0.  3.  3.  6.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [ 0.  1.  2. 15. 14.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
adversary victory points: -3
player victory points: 6 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 36 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  2. 15. 14.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 14.] 
expected returns: [[42.114086]
 [32.90144 ]
 [28.34691 ]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  2. 15. 14.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [0. 1. 8. 0. 0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -98 

action type: buy - action -1
Learning step: -5.222943305969238
desired expected reward: 17.73004150390625



action possibilites: [-1] 
expected returns: [[30.422218]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  2. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
action values: 0 
buys: 0 
player value: 2 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action 14.0
Learning step: -4.632846355438232
desired expected reward: 23.714065551757812





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4.  5. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[20.006922 ]
 [27.595673 ]
 [13.637545 ]
 [23.905598 ]
 [ 7.9676113]
 [15.075058 ]
 [24.144228 ]
 [29.609104 ]
 [25.819914 ]
 [35.236034 ]
 [25.507343 ]
 [ 8.518422 ]
 [13.910919 ]
 [22.187513 ]
 [ 5.4185057]
 [17.434252 ]
 [29.38335  ]]
Chosen buy action: 4.0 : ['Duchy' '4' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  2. 15.] 
cards in discard: [] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6] -> size -> 33 
action values: 0 
buys: 1 
player value: 8 
card supply: [20. 24. 28. 21. 30.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: -3 

Reward from previous game state: 
[ -5   0  -3 -90   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -78 

action type: take_action - action -1
Learning step: -4.867621421813965
desired expected reward: 25.554595947265625



buy possibilites: [-1] 
expected returns: [[13.326565]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  2. 15.] 
cards in discard: [4.] 
cards in deck: 28 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 3 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [1. 8. 0.] 
adversary cards in discard: [0. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5.    0.    0.  -60.    0.    0.   20.    0.    0.    0.    0.    0.
   0.    0.   12.5   0. ] 
sum of rewards: -32.5 

action type: buy - action 4.0
Learning step: -1.7235326766967773
desired expected reward: 6.244075775146484






Player: 1 
cards in hand: [1. 8. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 8. 0.] 
cards in discard: [0. 0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [23.  3. 25. 29.  1.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0.] 
cards in discard: [0. 0.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3] -> size -> 42 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  5.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [23.  3. 25. 29.  1.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 8. 0.] 
cards in discard: [0. 0. 8.] 
cards in deck: 37 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [23.  3. 25. 29.  1.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 37 -------------------- 
Player: 0 
cards in hand: [23.  3. 25. 29.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 25. 29.] 
expected returns: [[-5.587368 ]
 [-5.6295295]
 [-4.4408484]
 [-5.8361835]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 25. 29.  1.] 
cards in discard: [ 4. 14.  0.  1.  2. 15.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 2. 0. 1. 6.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -4.0312066078186035
desired expected reward: 9.295358657836914



action possibilites: [-1] 
expected returns: [[12.253324]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 29.  1.  0.  6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 2. 0. 1. 6.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   1] 
sum of rewards: -44 

action type: take_action - action 25.0
Learning step: -1.702257752418518
desired expected reward: -6.143108367919922





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ 1.1233883]
 [ 8.546377 ]
 [ 5.714571 ]
 [13.60936  ]
 [ 5.160164 ]
 [ 2.9936547]
 [15.224436 ]]
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3. 29.  1.  0.  6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4] -> size -> 34 
action values: 0 
buys: 1 
player value: 3 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  6. 10.  8.] 
adversary cards in hand: [3. 2. 0. 1. 6.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.6443047523498535
desired expected reward: 9.609018325805664



buy possibilites: [-1] 
expected returns: [[5.3945284]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [23.  3. 29.  1.  0.  6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10.] 
cards in deck: 21 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10] -> size -> 35 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [3. 2. 0. 1. 6.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0  18   0] 
sum of rewards: -27 

action type: buy - action 10.0
Learning step: -1.3783055543899536
desired expected reward: 1.6153429746627808






Player: 1 
cards in hand: [3. 2. 0. 1. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 2. 0. 1. 6.] 
cards in discard: [0. 0. 8. 1. 8. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  1.  6.  6. 11.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10] -> size -> 35 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 1. 6.] 
cards in discard: [0. 0. 8. 1. 8. 0.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8] -> size -> 43 
action values: 0 
buys: 1 
player value: 6 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  4.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  1.  6.  6. 11.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10] -> size -> 35 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 2. 0. 1. 6.] 
cards in discard: [0. 0. 8. 1. 8. 0. 8.] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
action values: 0 
buys: 0 
player value: 4 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  1.  6.  6. 11.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10] -> size -> 35 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 38 -------------------- 
Player: 0 
cards in hand: [ 3.  1.  6.  6. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
expected returns: [[18.577316]
 [20.320942]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6.  6. 11.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10] -> size -> 35 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 24. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1
Learning step: -3.076488494873047
desired expected reward: 2.318039894104004



action possibilites: [-1] 
expected returns: [[16.285814]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 1. 6. 6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
action values: 0 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0  -1   0   0   9   0] 
sum of rewards: -37 

action type: gain_card_n - action 1
Learning step: -2.4990310668945312
desired expected reward: 17.810209274291992





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[13.219219 ]
 [14.081329 ]
 [14.5706005]
 [16.013597 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 1. 6. 6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1.] 
cards in deck: 16 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [20. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 3.  0. 16.  3. 10.] 
adversary cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -45 

action type: take_action - action -1
Learning step: -2.7287240028381348
desired expected reward: 13.557090759277344






Player: 1 
cards in hand: [ 3.  0. 16.  3. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3. 10.] 
cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
adversary victory points: 0
player victory points: 6 


action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0. 16.  3.  3.] 
cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
action values: 2 
buys: 0 
player value: 0 
card supply: [20. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.  3.] 
cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8] -> size -> 44 
action values: 0 
buys: 1 
player value: 1 
card supply: [20. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  0. 16.  3.  3.] 
cards in discard: [0. 0. 8. 1. 8. 0. 8. 3. 2. 0. 1. 6. 0.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 6. 3.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
adversary victory points: 0
player victory points: 6 





         -------------------- Turn: 39 -------------------- 
Player: 0 
cards in hand: [0. 0. 3. 6. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
expected returns: [[47.431118]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: buy - action -1.0
Learning step: -2.8852176666259766
desired expected reward: 11.163139343261719





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
expected returns: [[40.51806 ]
 [43.71771 ]
 [42.85942 ]
 [47.093426]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1] -> size -> 36 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  3.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -65 

action type: take_action - action -1.0
Learning step: -4.618834018707275
desired expected reward: 42.81228256225586



buy possibilites: [-1] 
expected returns: [[36.714893]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 6. 3.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 3. 3. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
adversary victory points: 6
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -60   0   0   0   0   0   0   0  -2   0   0   8   0] 
sum of rewards: -59 

action type: buy - action 8.0
Learning step: -4.266885280609131
desired expected reward: 38.592525482177734






Player: 1 
cards in hand: [0. 0. 3. 3. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10. 25.  6.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 6 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 28. 21. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10. 25.  6.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 6 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 3. 3. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [11. 25. 10. 25.  6.] 
adversary cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 40 -------------------- 
Player: 0 
cards in hand: [11. 25. 10. 25.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25. 10. 25.] 
expected returns: [[15.625477]
 [19.913342]
 [25.938404]
 [11.483091]
 [25.938404]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 25. 10. 25.  6.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1
Learning step: -5.100911617279053
desired expected reward: 31.613981246948242



action possibilites: [-1] 
expected returns: [[-6.771639]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11. 10. 25.  6. 10.  8.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 25.0
Learning step: -4.199283123016357
desired expected reward: 21.7391357421875





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-6.074151]
 [-6.345941]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11. 10. 25.  6. 10.  8.] 
cards in discard: [ 4. 14.  0.  1.  2. 15. 10. 25. 23.  3. 29.  1.  0.  6.  1. 11.  3.  1.
  6.  6.  8.  0.  0.  3.  6.  3.] 
cards in deck: 4 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
action values: 0 
buys: 1 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [0. 0. 6. 0. 6.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -2.5502662658691406
desired expected reward: -9.321905136108398






Player: 1 
cards in hand: [0. 0. 6. 0. 6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3] -> size -> 46 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  6.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 0. 6.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.] 
cards in deck: 16 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 6.  6.  6. 15.  0.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
adversary victory points: 0
player victory points: 7 





         -------------------- Turn: 41 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  6. 15.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.] 
expected returns: [[ 1.0926843]
 [-1.6704261]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  6. 15.  0.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1
  2  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -75 

action type: buy - action -1.0
Learning step: -3.430276870727539
desired expected reward: -9.776214599609375



action possibilites: [-1] 
expected returns: [[-14.458029]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 36 
action values: 0 
buys: 0 
player value: 3 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action 15.0
Learning step: -2.9917843341827393
desired expected reward: -4.6622090339660645





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-15.846462 ]
 [-14.661432 ]
 [-14.3498955]
 [-13.932491 ]
 [-15.482023 ]
 [-15.153873 ]
 [-14.363928 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8] -> size -> 36 
action values: 0 
buys: 1 
player value: 3 
card supply: [19. 23. 28. 20. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
adversary victory points: 7
player victory points: 0 

Reward from previous game state: 
[ -5   0   0 -70   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -55 

action type: take_action - action -1
Learning step: -2.3549294471740723
desired expected reward: -16.812957763671875



buy possibilites: [-1] 
expected returns: [[-5.1849303]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 6. 6.] 
cards in discard: [3.] 
cards in deck: 32 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
action values: 0 
buys: 0 
player value: 1 
card supply: [19. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [ 0. 10. 29.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5.   0.   1. -60.   0.   0.  20.   0.   0.   0.   0.  -2.   0.   0.
   2.   0.] 
sum of rewards: -44.0 

action type: buy - action 3.0
Learning step: -1.5991663932800293
desired expected reward: -15.949056625366211






Player: 1 
cards in hand: [ 0. 10. 29.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 29.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29.  8.  0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [19. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [10. 10.  3.  1.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
adversary victory points: 1
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3.  8. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  8.  0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11] -> size -> 47 
action values: 0 
buys: 1 
player value: 2 
card supply: [19. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [10. 10.  3.  1.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
adversary victory points: 1
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 10. 29.  8.  0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.] 
cards in deck: 11 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 2 
card supply: [18. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [10. 10.  3.  1.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
adversary victory points: 1
player victory points: 7 





         -------------------- Turn: 42 -------------------- 
Player: 0 
cards in hand: [10. 10.  3.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10.] 
expected returns: [[-3.1459458]
 [-2.7754283]
 [-2.7754283]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 10.  3.  1.  0.] 
cards in discard: [ 3. 15.  6.  6.  6.] 
cards in deck: 27 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -64 

action type: buy - action -1
Learning step: -3.0051815509796143
desired expected reward: -8.190112113952637



action possibilites: [-1. 10.] 
expected returns: [[8.046507 ]
 [5.2070174]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  3.  1.  0.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
action values: 2 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action 10.0
Learning step: -1.9029541015625
desired expected reward: -4.678378582000732





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[6.422919 ]
 [8.056623 ]
 [7.3846574]
 [8.813272 ]
 [7.4169173]
 [6.9522243]
 [9.374628 ]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3] -> size -> 37 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 23. 28. 19. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 1 

Reward from previous game state: 
[ -5   0   1 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -44 

action type: take_action - action -1.0
Learning step: -2.417062520980835
desired expected reward: 5.629453659057617



buy possibilites: [-1] 
expected returns: [[-5.4501915]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  3.  1.  0.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.  3.] 
cards in deck: 26 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [1. 0. 0. 0. 3.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.  -3.   0.   0.
   2.   0.] 
sum of rewards: -34.0 

action type: buy - action 3.0
Learning step: -2.1918623447418213
desired expected reward: 5.192797660827637






Player: 1 
cards in hand: [1. 0. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [10. 23.  4. 14.  6.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 23.0 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 5 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  9.  5. 10.  8.] 
adversary cards in hand: [10. 23.  4. 14.  6.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 0. 0. 3.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.] 
cards in deck: 6 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [10. 23.  4. 14.  6.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 43 -------------------- 
Player: 0 
cards in hand: [10. 23.  4. 14.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 23. 14.] 
expected returns: [[ -3.5137086]
 [ -5.690286 ]
 [ -6.569455 ]
 [-10.912155 ]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 23.  4. 14.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
cards in deck: 21 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23] -> size -> 49 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -2.5071961879730225
desired expected reward: -7.957387924194336



action possibilites: [-1. 10. 14. 11.] 
expected returns: [[25.368282]
 [19.86779 ]
 [15.434198]
 [23.769753]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  4. 14.  6. 11.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 1 
buys: 1 
player value: 1 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23] -> size -> 49 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action 23.0
Learning step: -0.7754300832748413
desired expected reward: -7.344889163970947





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[17.058306]
 [24.389444]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  4. 14.  6. 11.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6.] 
cards in deck: 20 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 1 
buys: 2 
player value: 1 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 3.  8. 11.  8.  0.] 
adversary cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23] -> size -> 49 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1.0
Learning step: -2.4284451007843018
desired expected reward: 22.939836502075195






Player: 1 
cards in hand: [ 3.  8. 11.  8.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 11.  8.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  8. 11.  8.  0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.] 
cards in deck: 1 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 23. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  3. 25.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 8. 8. 0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  3. 25.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 8. 8. 0.] 
cards in discard: [ 0.  0.  8.  1.  8.  0.  8.  3.  2.  0.  1.  6.  0. 10.  3.  0. 16.  3.
  3.  3.  0.  0.  3.  3.  3. 11.  0.  0.  6.  0.  6.  0.  0. 10. 29.  8.
  0. 23.  1.  0.  0.  0.  3.  1.] 
cards in deck: 1 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 1 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0. 11.  6.  3. 25.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 44 -------------------- 
Player: 0 
cards in hand: [ 0. 11.  6.  3. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11. 25.] 
expected returns: [[24.661924]
 [24.58777 ]
 [27.270685]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3. 25.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1.0
Learning step: -3.2841737270355225
desired expected reward: 21.105270385742188



action possibilites: [-1] 
expected returns: [[-10.986631]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  6.  3.  1.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -31 

action type: take_action - action 25.0
Learning step: -3.160733461380005
desired expected reward: 24.109947204589844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[-26.629408]
 [-19.320469]
 [-19.301245]
 [-15.999935]
 [-24.103489]
 [-22.931965]
 [-15.479946]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  3.  1.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3] -> size -> 38 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  2.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -1.530096173286438
desired expected reward: -12.516727447509766



buy possibilites: [-1] 
expected returns: [[-17.999401]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  6.  3.  1.  6.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8.] 
cards in deck: 13 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
action values: 0 
buys: 0 
player value: 1 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  3.  3. 11.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.  -4.   0.   0.
   2.   0.] 
sum of rewards: -35.0 

action type: buy - action 8.0
Learning step: -0.94981449842453
desired expected reward: -25.053255081176758






Player: 1 
cards in hand: [ 0.  1.  3.  3. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 29.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1] -> size -> 50 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  5. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 29.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  3.  3. 11.] 
cards in discard: [10.] 
cards in deck: 45 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
action values: 0 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [ 0.  1.  8. 25. 29.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 45 -------------------- 
Player: 0 
cards in hand: [ 0.  1.  8. 25. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25. 29.] 
expected returns: [[-9.888139]
 [-9.06176 ]
 [-9.941227]
 [-9.005257]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  8. 25. 29.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
action values: 1 
buys: 0 
player value: 0 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -1.9601681232452393
desired expected reward: -19.959569931030273





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
expected returns: [[ -8.601747]
 [ -9.342228]
 [ -8.848103]
 [ -9.65484 ]
 [ -9.507267]
 [ -8.75139 ]
 [-10.272816]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25. 29.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8] -> size -> 39 
action values: 0 
buys: 1 
player value: 3 
card supply: [18. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: take_action - action -1.0
Learning step: -2.360053300857544
desired expected reward: -12.248190879821777



buy possibilites: [-1] 
expected returns: [[-14.052322]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  1.  8. 25. 29.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [6. 8. 0. 0. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.   0. -30.   0.   0.   0.  -5.   0.   0.
   0.   0.] 
sum of rewards: -88.0 

action type: buy - action 0.0
Learning step: -4.28609037399292
desired expected reward: -12.887836456298828






Player: 1 
cards in hand: [6. 8. 0. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [ 8. 25.  1.  3.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11.  8. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10] -> size -> 51 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  5.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [ 8. 25.  1.  3.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [6. 8. 0. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.] 
cards in deck: 40 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [ 8. 25.  1.  3.  0.] 
adversary cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
adversary victory points: 2
player victory points: 7 





         -------------------- Turn: 46 -------------------- 
Player: 0 
cards in hand: [ 8. 25.  1.  3.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-13.670368]
 [-13.98312 ]
 [-14.966209]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8. 25.  1.  3.  0.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -53 

action type: buy - action -1
Learning step: -2.2635674476623535
desired expected reward: -16.315889358520508



action possibilites: [-1] 
expected returns: [[-14.726751]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 1. 3. 0. 3. 2.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   3] 
sum of rewards: -30 

action type: take_action - action 25.0
Learning step: -1.0830410718917847
desired expected reward: -16.049257278442383





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11.  8. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.487757 ]
 [-17.074219 ]
 [-14.76647  ]
 [-15.550364 ]
 [-16.823318 ]
 [-17.177174 ]
 [-15.630177 ]
 [-17.77571  ]
 [-17.451687 ]
 [-17.656158 ]
 [-15.035999 ]
 [-14.502579 ]
 [-16.018112 ]
 [-15.363478 ]
 [-15.304132 ]
 [-14.7267475]]
Chosen buy action: 8.0 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 0. 3. 2.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0] -> size -> 40 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  1.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -33 

action type: take_action - action -1
Learning step: -1.2653355598449707
desired expected reward: -15.992086410522461



buy possibilites: [-1] 
expected returns: [[5.347467]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 1. 3. 0. 3. 2.] 
cards in discard: [ 3. 15.  6.  6.  6.  3. 10. 10.  3.  1.  0.  6. 23. 10.  4. 14.  6. 11.
  8. 25.  0. 11.  6.  3.  1.  6.  0.  0.  1.  8. 25. 29.  8.] 
cards in deck: 1 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8] -> size -> 41 
action values: 0 
buys: 0 
player value: 4 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 0. 0. 6. 0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
adversary victory points: 7
player victory points: 2 

Reward from previous game state: 
[ -5.   0.   2. -50.   0.   0.  20.   0.   0.   0.   0.  -6.   0.   0.
   2.   0.] 
sum of rewards: -37.0 

action type: buy - action 8.0
Learning step: -0.8408964276313782
desired expected reward: -18.616607666015625






Player: 1 
cards in hand: [0. 0. 0. 6. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11] -> size -> 52 
action values: 0 
buys: 1 
player value: 4 
card supply: [17. 22. 28. 18. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 7 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 6. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.] 
cards in deck: 35 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
action values: 0 
buys: 0 
player value: 2 
card supply: [17. 22. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [10. 11. 11.  8. 15.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8] -> size -> 41 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 47 -------------------- 
Player: 0 
cards in hand: [10. 11. 11.  8. 15.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11. 11.  8. 15.] 
expected returns: [[20.922737]
 [19.063972]
 [21.296888]
 [21.296888]
 [20.211548]
 [18.003767]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11. 11.  8. 15.] 
cards in discard: [] 
cards in deck: 36 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8] -> size -> 41 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 22. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 2. 1. 8. 3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1
Learning step: -2.956867218017578
desired expected reward: 2.3905997276306152



action possibilites: [-1] 
expected returns: [[-9.661052]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 11.  8. 15.] 
cards in discard: [1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 2. 1. 8. 3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0  -7   0   0   9   0] 
sum of rewards: -41 

action type: gain_card_n - action 1
Learning step: -3.307605028152466
desired expected reward: 17.49701690673828





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[ -9.904773]
 [-10.834753]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10. 11.  8. 15.] 
cards in discard: [1.] 
cards in deck: 36 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 0 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [0. 2. 1. 8. 3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -1.8972629308700562
desired expected reward: -11.558314323425293






Player: 1 
cards in hand: [0. 2. 1. 8. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 2. 1. 8. 3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [25.  3.  6. 29.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
adversary victory points: 2
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  2.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 8. 3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 6 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  4. 10.  8.] 
adversary cards in hand: [25.  3.  6. 29.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
adversary victory points: 2
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 2. 1. 8. 3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.] 
cards in deck: 30 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
action values: 0 
buys: 0 
player value: 3 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [25.  3.  6. 29.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
adversary victory points: 2
player victory points: 8 





         -------------------- Turn: 48 -------------------- 
Player: 0 
cards in hand: [25.  3.  6. 29.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25. 29.] 
expected returns: [[11.783011]
 [15.811931]
 [ 7.672266]]
Chosen action: 25 : ['Witch' '25' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  3.  6. 29.  6.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.] 
cards in deck: 31 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  1.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -63 

action type: buy - action -1.0
Learning step: -2.145312547683716
desired expected reward: -16.424869537353516



action possibilites: [-1] 
expected returns: [[10.576889]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  6. 29.  6.  1. 14.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  1.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   2] 
sum of rewards: -41 

action type: take_action - action 25.0
Learning step: -2.60261607170105
desired expected reward: 13.209308624267578





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[10.072238]
 [10.563206]
 [10.797629]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  6.  1. 14.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1] -> size -> 42 
action values: 0 
buys: 1 
player value: 2 
card supply: [17. 21. 28. 17. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  1.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
adversary victory points: 8
player victory points: 2 

Reward from previous game state: 
[ -5   0   2 -60   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -43 

action type: take_action - action -1
Learning step: -2.4410293102264404
desired expected reward: 8.135859489440918



buy possibilites: [-1] 
expected returns: [[-11.602663]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  6. 29.  6.  1. 14.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3.] 
cards in deck: 29 
card top of deck: [] 
played cards: [25.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [10.  6.  0.  1.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0  -8   0   0   8   0] 
sum of rewards: -32 

action type: buy - action 3.0
Learning step: -2.3892204761505127
desired expected reward: 8.173989295959473






Player: 1 
cards in hand: [10.  6.  0.  1.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.  6.  0.  1.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [17. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  1.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10] -> size -> 54 
action values: 0 
buys: 1 
player value: 3 
card supply: [17. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.  6.  0.  1.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0.] 
cards in deck: 25 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 3 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10.  0.  6.  6.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 49 -------------------- 
Player: 0 
cards in hand: [ 0. 10.  0.  6.  6.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-3.473561 ]
 [-2.5430136]]
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10.  0.  6.  6.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
cards in deck: 24 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  8.  3.  8. 11.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -2.084547519683838
desired expected reward: -13.687210083007812



action possibilites: [-1.] 
expected returns: [[-18.718742]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 2 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  8.  3.  8. 11.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action 10.0
Learning step: -1.894020676612854
desired expected reward: -4.437044143676758





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-32.77641 ]
 [-23.179731]
 [-17.292671]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 6. 6. 6.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14.] 
cards in deck: 23 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  8.  3.  8. 11.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1.0
Learning step: -1.1674059629440308
desired expected reward: -19.88614845275879






Player: 1 
cards in hand: [ 8.  8.  3.  8. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.  8.  8. 11.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  8.  3.  8. 11.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10 11  3  1  6  8  0  3  3  3 10  0  3  0  1
  6  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0
 23  1 10 11  3 10  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [15.  1.  2.  8.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [8. 3. 8.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [15.  1.  2.  8.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [8. 3. 8.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.] 
cards in deck: 20 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [15.  1.  2.  8.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 50 -------------------- 
Player: 0 
cards in hand: [15.  1.  2.  8.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15.  8.] 
expected returns: [[-14.106385]
 [-13.542632]
 [-14.621127]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [15.  1.  2.  8.  3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -2.0488576889038086
desired expected reward: -19.34149169921875



action possibilites: [-1] 
expected returns: [[-12.474537]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 2. 8. 3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 0 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action 15.0
Learning step: -1.2035454511642456
desired expected reward: -14.746177673339844





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-16.152195]
 [-18.66345 ]
 [-15.594344]
 [-13.539015]
 [-17.620893]
 [-17.437128]
 [-20.737688]
 [-18.474506]
 [-11.482009]
 [-11.899696]
 [-15.320332]
 [-11.326526]
 [-13.414585]
 [-15.69607 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 2. 8. 3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 5 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [16.  3.  0.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -32 

action type: take_action - action -1
Learning step: -1.2984704971313477
desired expected reward: -13.7730073928833






Player: 1 
cards in hand: [16.  3.  0.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 16.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [16.  3.  0.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  3. 10.  1.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0] -> size -> 54 
action values: 0 
buys: 1 
player value: 2 
card supply: [16. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  3. 10.  1.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [16.  3.  0.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0.] 
cards in deck: 15 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
action values: 0 
buys: 0 
player value: 2 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  3. 10.  1.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 51 -------------------- 
Player: 0 
cards in hand: [ 6.  3. 10.  1.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10.] 
expected returns: [[-11.557678]
 [-11.586772]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  3. 10.  1.  0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [23. 10.  3. 29.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1.0
Learning step: -2.075477361679077
desired expected reward: -17.771549224853516





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-11.397507]
 [-11.193314]
 [-11.86772 ]
 [-10.858754]
 [-11.586772]
 [-11.557678]]
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  1.  0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  4.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [23. 10.  3. 29.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: take_action - action -1.0
Learning step: -2.2752845287323
desired expected reward: -13.832958221435547



buy possibilites: [-1] 
expected returns: [[-16.145182]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  3. 10.  1.  0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  3.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [23. 10.  3. 29.  0.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0  -9   0   0  18   0] 
sum of rewards: -43 

action type: buy - action 11.0
Learning step: -1.9703291654586792
desired expected reward: -12.82907772064209






Player: 1 
cards in hand: [23. 10.  3. 29.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23. 10.  3. 29.  0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3.] 
cards in deck: 10 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  3.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 25.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1. 23. 29.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [23.  3. 29.  0.  0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3.] 
cards in deck: 9 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
action values: 2 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  3.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 25.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
adversary victory points: 3
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
action values: 2 
buys: 0 
player value: 1 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  3.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 25.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
adversary victory points: 3
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0] -> size -> 55 
action values: 0 
buys: 1 
player value: 3 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  3.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 25.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
adversary victory points: 3
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 0.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [10. 29.] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 8.  6.  3. 25.  0.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
adversary victory points: 3
player victory points: 8 





         -------------------- Turn: 52 -------------------- 
Player: 0 
cards in hand: [ 8.  6.  3. 25.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 25.] 
expected returns: [[-11.602664]
 [-10.864509]
 [-13.898363]]
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 8.  6.  3. 25.  0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6  6 14 23  6 25  0 29  6  6  3 15  6  1  2
  1 11 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
adversary victory points: 8
player victory points: 3 

Reward from previous game state: 
[ -5   0   3 -50   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -52 

action type: buy - action -1
Learning step: -2.057359457015991
desired expected reward: -18.20254135131836



action possibilites: [-1] 
expected returns: [[-17.93311]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 42 
action values: 0 
buys: 0 
player value: 0 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: trash_cards_n_from_hand - action 7
Learning step: -1.1129413843154907
desired expected reward: -7.6835551261901855





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-18.97042 ]
 [-17.933111]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11] -> size -> 42 
action values: 0 
buys: 1 
player value: 1 
card supply: [15. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1
Learning step: -0.565158486366272
desired expected reward: -18.498268127441406



buy possibilites: [-1] 
expected returns: [[-14.807371]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.] 
cards in deck: 8 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
action values: 0 
buys: 0 
player value: 1 
card supply: [14. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [11.  0.  1.  0.  3.] 
adversary cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.  20. -30.   0.   0.   0.  -8.   0.   0.
   0.   0.] 
sum of rewards: -59.0 

action type: buy - action 0.0
Learning step: -2.3346447944641113
desired expected reward: -21.305065155029297






Player: 1 
cards in hand: [11.  0.  1.  0.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [14. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0.  4.  1. 25.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11] -> size -> 56 
action values: 0 
buys: 1 
player value: 4 
card supply: [14. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0.  4.  1. 25.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [11.  0.  1.  0.  3.] 
cards in discard: [10.  0.  1.  3.  3. 11. 11.  6.  8.  0.  0.  0.  3.  0.  0.  0.  6.  0.
 10.  0.  2.  1.  8.  3.  0. 10.  6.  0.  1.  3.  8.  8.  3.  8.  0. 16.
  3.  0.  0.  3. 23.  8. 11. 10. 29.  3.  0.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11  0] -> size -> 57 
action values: 0 
buys: 0 
player value: 4 
card supply: [13. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0.  4.  1. 25.  3.] 
adversary cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 53 -------------------- 
Player: 0 
cards in hand: [ 0.  4.  1. 25.  3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.] 
expected returns: [[-12.031252]
 [-14.374882]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  4.  1. 25.  3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
action values: 1 
buys: 0 
player value: 0 
card supply: [13. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11  0] -> size -> 57 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -1.5991297960281372
desired expected reward: -16.40650177001953





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[ -9.46139 ]
 [-11.322258]
 [ -9.517216]
 [-11.913898]
 [ -9.723046]
 [-12.031252]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  1. 25.  3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0] -> size -> 43 
action values: 0 
buys: 1 
player value: 3 
card supply: [13. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11  0] -> size -> 57 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -1.680567741394043
desired expected reward: -13.711821556091309



buy possibilites: [-1] 
expected returns: [[-4.4995275]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  4.  1. 25.  3.] 
cards in discard: [ 1. 11. 10. 11.  8. 15.  3. 25.  3.  6. 29.  6.  1. 14. 10.  0.  0.  6.
  6.  6. 15.  1.  2.  8.  3. 11.  6.  3. 10.  1.  0.  0.  8.  3.  0.  0.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
action values: 0 
buys: 0 
player value: 3 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [0. 8. 0. 0. 3.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11  0] -> size -> 57 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.   0. -30.   0.   0.   0.  -9.   0.   0.
   0.   0.] 
sum of rewards: -80.0 

action type: buy - action 0.0
Learning step: -3.6281700134277344
desired expected reward: -13.089560508728027






Player: 1 
cards in hand: [0. 8. 0. 0. 3.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
Chosen action: 8 : ['Chapel' '8' '2']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 8. 0. 0. 3.] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0  0  0  3  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6
  3  0  8 29  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23
  1 10 11  3 10  0  0 11  0] -> size -> 57 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  3.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 0 
buys: 0 
player value: 0 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  3.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 7 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [] 
cards in discard: [] 
cards in deck: 52 
card top of deck: [] 
played cards: [8.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 0 
buys: 1 
player value: 0 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 6.  6.  3.  8. 23.] 
adversary cards in discard: [] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
adversary victory points: 4
player victory points: 7 





         -------------------- Turn: 54 -------------------- 
Player: 0 
cards in hand: [ 6.  6.  3.  8. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8. 23.] 
expected returns: [[-9.62174 ]
 [-9.912828]
 [-9.106155]]
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  8. 23.] 
cards in discard: [] 
cards in deck: 39 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
action values: 1 
buys: 0 
player value: 0 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 10. 29.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -31 

action type: buy - action -1
Learning step: -1.5369815826416016
desired expected reward: -6.036509037017822



action possibilites: [-1.  8. 11.] 
expected returns: [[-8.775314]
 [-9.063207]
 [-9.211653]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  6.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
action values: 1 
buys: 1 
player value: 1 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 10. 29.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action 23.0
Learning step: -0.2960089147090912
desired expected reward: -9.4021635055542





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-8.734287 ]
 [-8.8896885]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3.  8. 11.] 
cards in discard: [] 
cards in deck: 38 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0] -> size -> 44 
action values: 1 
buys: 2 
player value: 1 
card supply: [12. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 10. 29.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -11 

action type: take_action - action -1.0
Learning step: -0.3090019226074219
desired expected reward: -9.084318161010742



buy possibilites: [ 0. -1.] 
expected returns: [[-18.999365]
 [-18.51559 ]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  6.  3.  8. 11.] 
cards in discard: [0.] 
cards in deck: 38 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
action values: 1 
buys: 1 
player value: 1 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [ 0. 10. 10. 10. 29.] 
adversary cards in discard: [8.] 
adversary owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
adversary victory points: 7
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -30   0   0  20 -30   0   0   0 -10   0   0   0   0] 
sum of rewards: -51 

action type: buy - action 0.0
Learning step: -2.533766269683838
desired expected reward: -11.26805305480957






Player: 1 
cards in hand: [ 0. 10. 10. 10. 29.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 10. 10. 29.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 10. 29.] 
cards in discard: [8.] 
cards in deck: 47 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10. 10. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 10. 29. 10.] 
cards in discard: [8.] 
cards in deck: 46 
card top of deck: [] 
played cards: [10.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 2 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10. 29. 10.] 
Chosen action: 10 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 10. 29. 10.  3.] 
cards in discard: [8.] 
cards in deck: 45 
card top of deck: [] 
played cards: [10. 10.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 3 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 29. 10. 16.] 
Chosen action: 29 : ['Poacher' '29' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 29. 10.  3. 16.] 
cards in discard: [8.] 
cards in deck: 44 
card top of deck: [] 
played cards: [10. 10. 10.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 4 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10. 16.] 
Chosen action: 16 : ['Remodel' '16' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10. 16.  0.] 
cards in discard: [8. 0. 3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [10. 10. 10. 29.] 
owned cards: [ 0  0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29
  3  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3
 10  0  0 11  0] -> size -> 53 
action values: 4 
buys: 0 
player value: 1 
card supply: [11. 21. 28. 16. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 7 


action possibilites: [-1. 10.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [10.] 
cards in discard: [8. 0. 3. 3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [10. 10. 10. 29. 16.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
action values: 3 
buys: 0 
player value: 1 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [10.] 
cards in discard: [8. 0. 3. 3.] 
cards in deck: 43 
card top of deck: [] 
played cards: [10. 10. 10. 29. 16.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
action values: 3 
buys: 1 
player value: 1 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 0. 1. 3. 8.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 55 -------------------- 
Player: 0 
cards in hand: [1. 0. 1. 3. 8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.  8.] 
expected returns: [[-11.875454]
 [-11.76907 ]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1.0
Learning step: -1.389877200126648
desired expected reward: -19.90547752380371





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[ -9.976715 ]
 [-10.723459 ]
 [ -9.638076 ]
 [ -8.270737 ]
 [-10.444981 ]
 [-10.934362 ]
 [-15.110477 ]
 [-10.949102 ]
 [ -7.7546062]
 [ -8.519806 ]
 [-10.041297 ]
 [ -7.3237953]
 [ -9.284862 ]
 [-11.4145355]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0] -> size -> 45 
action values: 0 
buys: 1 
player value: 5 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3. 10.  8.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -1.664380431175232
desired expected reward: -13.539834022521973



buy possibilites: [-1] 
expected returns: [[-9.39078]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 0. 1. 3. 8.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22] -> size -> 46 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  8.] 
adversary cards in hand: [1. 3. 3. 0. 0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0 -11   0   0  50   0] 
sum of rewards: -2 

action type: buy - action 22.0
Learning step: 0.05489721521735191
desired expected reward: -7.268898010253906






Player: 1 
cards in hand: [1. 3. 3. 0. 0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  8.] 
adversary cards in hand: [ 6.  2.  3. 29. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22] -> size -> 46 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 15.0 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3] -> size -> 53 
action values: 0 
buys: 1 
player value: 4 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  8.] 
adversary cards in hand: [ 6.  2.  3. 29. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22] -> size -> 46 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [1. 3. 3. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.] 
cards in deck: 38 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15] -> size -> 54 
action values: 0 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 6.  2.  3. 29. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22] -> size -> 46 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 56 -------------------- 
Player: 0 
cards in hand: [ 6.  2.  3. 29. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 29. 11.] 
expected returns: [[-16.074905]
 [-15.291052]
 [-15.877733]]
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  2.  3. 29. 11.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22] -> size -> 46 
action values: 1 
buys: 0 
player value: 0 
card supply: [11. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15] -> size -> 54 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -1.9318370819091797
desired expected reward: -11.322617530822754



action possibilites: [-1] 
expected returns: [[-14.295162]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 6.  2.  3. 29.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15] -> size -> 54 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20 -30   0   0   0 -12   0   0   0   0] 
sum of rewards: -63 

action type: gain_card_n - action 0
Learning step: -2.828573703765869
desired expected reward: -15.689922332763672





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
expected returns: [[-17.504454]
 [-18.2161  ]
 [-17.185522]
 [-17.670923]
 [-17.034742]
 [-16.902502]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 6.  2.  3. 29.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 3 
card supply: [10. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  1.  0. 11.  0.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15] -> size -> 54 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1
Learning step: -0.7238330841064453
desired expected reward: -15.01899528503418






Player: 1 
cards in hand: [ 0.  1.  0. 11.  0.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: 11 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  1.  0. 11.  0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.] 
cards in deck: 33 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15] -> size -> 54 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 21. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [25.  8. 15.  0. 10.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
adversary victory points: 4
player victory points: 8 


action possibilites: [-1] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1] -> size -> 55 
action values: 0 
buys: 0 
player value: 0 
card supply: [10. 20. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [25.  8. 15.  0. 10.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
Chosen buy action: 11.0 : ['Workshop' '11' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1] -> size -> 55 
action values: 0 
buys: 1 
player value: 5 
card supply: [10. 20. 28. 15. 29.  8.  0.  9.  2.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [25.  8. 15.  0. 10.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
adversary victory points: 4
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 1. 0. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.] 
cards in deck: 33 
card top of deck: [] 
played cards: [11.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 0 
buys: 0 
player value: 2 
card supply: [10. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [25.  8. 15.  0. 10.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
adversary victory points: 4
player victory points: 8 





         -------------------- Turn: 57 -------------------- 
Player: 0 
cards in hand: [25.  8. 15.  0. 10.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 25.  8. 15. 10.] 
expected returns: [[-7.412169]
 [-8.305105]
 [-9.234932]
 [-8.890586]
 [-8.719394]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [25.  8. 15.  0. 10.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
action values: 1 
buys: 0 
player value: 0 
card supply: [10. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1.0
Learning step: -1.3277523517608643
desired expected reward: -19.46113395690918





----------- BUY PHASE ----------- 
buy possibilites: [ 0. -1.] 
expected returns: [[-9.236698 ]
 [-7.3510475]]
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8. 15.  0. 10.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0] -> size -> 47 
action values: 0 
buys: 1 
player value: 1 
card supply: [10. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: take_action - action -1.0
Learning step: -1.8599122762680054
desired expected reward: -9.27208137512207



buy possibilites: [-1] 
expected returns: [[-20.097883]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [25.  8. 15.  0. 10.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 0.  0. 11.  6.  8.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5.   0.   4. -40.   0.   0.   0. -30.   0.   0.   0. -13.   0.   0.
   0.   0.] 
sum of rewards: -84.0 

action type: buy - action 0.0
Learning step: -4.190367221832275
desired expected reward: -13.427066802978516






Player: 1 
cards in hand: [ 0.  0. 11.  6.  8.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.  8.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 11.  6.  8.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  1. 15.  6. 25.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
adversary victory points: 4
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0.  0. 11.  6.  8.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.] 
cards in deck: 28 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  1. 15.  6. 25.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
adversary victory points: 4
player victory points: 8 


 --------- NOTHING HAPPENED --------- 



         -------------------- Turn: 58 -------------------- 
Player: 0 
cards in hand: [ 3.  1. 15.  6. 25.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 15. 25.] 
expected returns: [[-19.040504]
 [-19.379625]
 [-21.831049]]
Chosen action: 15 : ['Moneylender' '15' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1. 15.  6. 25.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 23.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -41 

action type: buy - action -1
Learning step: -1.490249752998352
desired expected reward: -21.588132858276367



action possibilites: [-1] 
expected returns: [[-14.728775]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  1.  6. 25.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 23.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action 15.0
Learning step: -0.41241636872291565
desired expected reward: -19.792037963867188





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-14.287327]
 [-14.433403]
 [-14.728779]]
Chosen buy action: 3.0 : ['Estate' '3' '2']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6. 25.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0] -> size -> 48 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 9. 20. 28. 15. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 23.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 4 

Reward from previous game state: 
[ -5   0   4 -40   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -21 

action type: take_action - action -1
Learning step: -0.6381673216819763
desired expected reward: -15.366942405700684



buy possibilites: [-1] 
expected returns: [[-9.352589]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 3.  1.  6. 25.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3.] 
cards in deck: 18 
card top of deck: [] 
played cards: [15.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 9. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 3.  0.  3.  6. 23.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0 -14   0   0   8   0] 
sum of rewards: -16 

action type: buy - action 3.0
Learning step: -0.2887626588344574
desired expected reward: -14.722173690795898






Player: 1 
cards in hand: [ 3.  0.  3.  6. 23.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 23.] 
Chosen action: 23 : ['Market' '23' '5']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 3.  0.  3.  6. 23.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
cards in deck: 23 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 9. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 10. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 


action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 1 
buys: 1 
player value: 1 
card supply: [ 9. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 10. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 11. 10. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11] -> size -> 56 
action values: 0 
buys: 2 
player value: 3 
card supply: [ 9. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  3.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 10. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 


buy possibilites: [ 0. -1.] 
Chosen buy action: 0.0 : ['Copper' '0' '0']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10] -> size -> 57 
action values: 0 
buys: 1 
player value: 0 
card supply: [ 9. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 10. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [3. 0. 3. 6. 0.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0.] 
cards in deck: 22 
card top of deck: [] 
played cards: [23.] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0] -> size -> 58 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 1.  3.  6. 10. 11.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 





         -------------------- Turn: 59 -------------------- 
Player: 0 
cards in hand: [ 1.  3.  6. 10. 11.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 10. 11.] 
expected returns: [[-11.884541]
 [-12.99505 ]
 [-12.091713]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 1.  3.  6. 10. 11.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0] -> size -> 58 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1
Learning step: -1.306817650794983
desired expected reward: -10.659406661987305





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  3. -1.] 
expected returns: [[-13.874653]
 [-12.17717 ]
 [-11.884541]]
Chosen buy action: -1.0 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 1.  3.  6. 10. 11.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.] 
cards in deck: 13 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 2 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 0. 11.  0.  3.  1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0] -> size -> 58 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: take_action - action -1.0
Learning step: -1.1853796243667603
desired expected reward: -13.069920539855957



 --------- NOTHING HAPPENED --------- 



Player: 1 
cards in hand: [ 0. 11.  0.  3.  1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 11.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0. 11.  0.  3.  1.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0] -> size -> 58 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  4.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  1.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0] -> size -> 58 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  2.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  4.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 


buy possibilites: [-1] 
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [ 0. 11.  0.  3.  1.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.] 
cards in deck: 17 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
action values: 0 
buys: 0 
player value: 1 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  9.  7.] 
adversary cards in hand: [ 0.  0. 14.  0.  4.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
adversary victory points: 5
player victory points: 8 





         -------------------- Turn: 60 -------------------- 
Player: 0 
cards in hand: [ 0.  0. 14.  0.  4.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1. 14.] 
expected returns: [[-13.429699]
 [-12.836304]]
Chosen action: 14 : ['Militia' '14' '4']


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [ 0.  0. 14.  0.  4.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  9.  7.] 
adversary cards in hand: [0. 0. 0. 8. 1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0   0   0   0   0   0   0   0   0   0   0] 
sum of rewards: -30 

action type: buy - action -1.0
Learning step: -1.1993486881256104
desired expected reward: -13.08388900756836



action possibilites: [-1] 
expected returns: [[-14.167418]]
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 0. 4.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 0 
player value: 2 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  9.  7.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action 14.0
Learning step: -0.17695169150829315
desired expected reward: -13.01325511932373





----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3.  4. 16. 11. 25. 29. 14. 23. 10. 22. 15. -1.] 
expected returns: [[-15.77327  ]
 [-15.9669285]
 [-14.066168 ]
 [-14.809917 ]
 [-15.994411 ]
 [-14.982174 ]
 [-17.192326 ]
 [-16.745382 ]
 [-14.113932 ]
 [-13.745098 ]
 [-14.881866 ]
 [-13.641615 ]
 [-14.515224 ]
 [-14.167419 ]]
Chosen buy action: 22.0 : ['Library' '22' '5']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3] -> size -> 49 
action values: 0 
buys: 1 
player value: 5 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  9.  7.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0   0   0   0   0   0] 
sum of rewards: -10 

action type: take_action - action -1
Learning step: -0.12103557586669922
desired expected reward: -14.288453102111816



buy possibilites: [-1] 
expected returns: [[-15.140646]]
Chosen buy action: -1 : None


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 0. 4.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.
 22.] 
cards in deck: 8 
card top of deck: [] 
played cards: [14.] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  8.  7.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[ -5   0   5 -30   0   0  20   0   0   0   0 -15   0   0  50   0] 
sum of rewards: 25 

action type: buy - action 22.0
Learning step: 1.5914161205291748
desired expected reward: -12.05019474029541






Player: 1 
cards in hand: [0. 0. 1.] 
----------- ACTION PHASE ----------- 
action possibilites: [-1.] 
Chosen action: -1 : None


 --- GAME STATE ---
Action that is taken: take_action 
cards in hand: [0. 0. 1.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
action values: 1 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  8.  7.] 
adversary cards in hand: [ 8.  1. 10.  3.  6.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.
 22. 14.  0.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3 22] -> size -> 50 
adversary victory points: 5
player victory points: 8 




----------- BUY PHASE ----------- 
buy possibilites: [ 0.  1.  3. 16. 11. 29. 14. 10. 15. -1.] 
Chosen buy action: 10.0 : ['Village' '10' '3']


 --- GAME STATE ---
Action that is taken: buy 
cards in hand: [0. 0. 1.] 
cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8.] 
cards in deck: 12 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10] -> size -> 59 
action values: 0 
buys: 1 
player value: 4 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  1.  8.  7.] 
adversary cards in hand: [ 8.  1. 10.  3.  6.] 
adversary cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.
 22. 14.  0.  0.  0.  4.] 
adversary owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3 22] -> size -> 50 
adversary victory points: 5
player victory points: 8 


Player 1 won the game! 



Player 0 bought cards:
Copper: 6 
Silver: 3 
Gold: 1 
Estate: 5 
Duchy: 1 
Province: 0 
Curse: 7 

Remodel: 0 
Workshop: 3 
Chapel: 4 
Witch: 3 
Poacher: 1 
Militia: 1 
Market: 1 
Village: 2 
Library: 2 
Moneylender: 2 


 --- GAME STATE ---
Action that is taken: None 
cards in hand: [ 8.  1. 10.  3.  6.] 
cards in discard: [ 0. 23.  6.  6.  3.  8. 11. 22.  1.  0.  1.  3.  8.  0. 11.  6.  2.  3.
 29.  0. 25.  8. 15.  0. 10.  3. 15.  3.  1.  6. 25.  1.  3.  6. 10. 11.
 22. 14.  0.  0.  0.  4.] 
cards in deck: 3 
card top of deck: [] 
played cards: [] 
owned cards: [ 0  0  0  3  3  3  1 10 15  6 14 23  6  0 29  6  6  3 15  6  1  2  1 11
 10  8 11 25 25  6  4 10  1  8  3  3  8  0  8  1  3 11  0  0  0 22  0  0
  3 22] -> size -> 50 
action values: 0 
buys: 0 
player value: 0 
card supply: [ 8. 20. 28. 14. 29.  8.  0.  9.  1.  0.  7.  8.  9.  8.  0.  8.  7.] 
adversary cards in hand: [0. 0. 1.] 
adversary cards in discard: [ 8.  0.  3.  3. 10. 10. 10. 29. 16. 10. 15.  1.  3.  3.  0.  0.  1. 11.
 11.  0.  1.  0.  0.  0.  0. 11.  6.  8. 10.  0. 23.  3.  0.  3.  6.  0.
 10.  0. 11.  0.  3.  1.  0.  8. 10.] 
adversary owned cards: [ 0  0  0  0 10  3  1  6  8  0  3  3  3 10  0  3  0  1  6  3  0  8 29  3
  8  0  1 16  0  0  2  0  6 11  8  3  8  8  0  3 11  0 23  1 10 11  3 10
  0  0 11  0  3 15  1 11 10  0 10 10] -> size -> 60 
adversary victory points: 8
player victory points: 5 

Reward from previous game state: 
[  -5 -500    5  -30    0    0    0    0    0    0    0    0    0    0
    0    0] 
sum of rewards: -530 

action type: buy - action -1
Learning step: -25.742969512939453
desired expected reward: -40.88361358642578



